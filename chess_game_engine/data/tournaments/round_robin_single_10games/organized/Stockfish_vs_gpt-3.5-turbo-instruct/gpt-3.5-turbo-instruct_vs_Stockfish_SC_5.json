{
  "result": "Stockfish wins by disqualification (gpt-3.5-turbo-instruct failed to produce a legal move)",
  "white_player": "gpt-3.5-turbo-instruct",
  "black_player": "Stockfish",
  "white_score": 0.0,
  "black_score": 1.0,
  "total_moves": 90,
  "moves": [
    "d2d4",
    "f7f5",
    "g1f3",
    "g8f6",
    "c1g5",
    "g7g6",
    "g5f6",
    "e7f6",
    "e2e3",
    "c7c6",
    "c2c4",
    "f8b4",
    "b1c3",
    "b8a6",
    "d1b3",
    "b4c3",
    "b3c3",
    "d8e7",
    "c4c5",
    "a8b8",
    "f1a6",
    "b7a6",
    "e1g1",
    "d7d5",
    "c5d6",
    "e7d6",
    "a1c1",
    "c8d7",
    "f3d2",
    "d6d5",
    "e3e4",
    "f5e4",
    "d2e4",
    "e8g8",
    "e4c5",
    "f8f7",
    "c5a6",
    "b8b6",
    "a6c7",
    "d5d6",
    "c3a5",
    "d6c7",
    "d4d5",
    "c7b7",
    "d5c6",
    "d7c6",
    "f1d1",
    "c6b5",
    "d1d8",
    "g8g7",
    "a5c3",
    "b6c6",
    "c3e1",
    "g6g5",
    "c1c6",
    "b5c6",
    "e1c3",
    "b7e7",
    "d8d1",
    "e7e6",
    "d1e1",
    "e6d5",
    "c3g3",
    "a7a5",
    "h2h4",
    "f7d7",
    "h4g5",
    "f6g5",
    "e1e5",
    "d5d1",
    "e5e1",
    "d1e1",
    "g1h2",
    "e1e7",
    "g3c3",
    "g7f7",
    "c3c6",
    "e7d6",
    "c6d6",
    "d7d6",
    "h2g3",
    "f7g6",
    "f2f4",
    "g6f5",
    "f4g5",
    "d6d3",
    "g3h4",
    "d3d2",
    "g2g4",
    "f5f4"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2d4",
      "move_san": "d4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f7f5",
      "move_san": "f5",
      "fen_after": "rnbqkbnr/ppppp1pp/8/5p2/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/ppppp1pp/8/5p2/3P4/5N2/PPP1PPPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g8f6",
      "move_san": "Nf6",
      "fen_after": "rnbqkb1r/ppppp1pp/5n2/5p2/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1g5",
      "move_san": "Bg5",
      "fen_after": "rnbqkb1r/ppppp1pp/5n2/5pB1/3P4/5N2/PPP1PPPP/RN1QKB1R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g7g6",
      "move_san": "g6",
      "fen_after": "rnbqkb1r/ppppp2p/5np1/5pB1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g5f6",
      "move_san": "Bxf6",
      "fen_after": "rnbqkb1r/ppppp2p/5Bp1/5p2/3P4/5N2/PPP1PPPP/RN1QKB1R b KQkq - 0 4"
    },
    {
      "move_number": 8,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7f6",
      "move_san": "exf6",
      "fen_after": "rnbqkb1r/pppp3p/5pp1/5p2/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 5"
    },
    {
      "move_number": 9,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e3",
      "move_san": "e3",
      "fen_after": "rnbqkb1r/pppp3p/5pp1/5p2/3P4/4PN2/PPP2PPP/RN1QKB1R b KQkq - 0 5"
    },
    {
      "move_number": 10,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "c7c6",
      "move_san": "c6",
      "fen_after": "rnbqkb1r/pp1p3p/2p2pp1/5p2/3P4/4PN2/PPP2PPP/RN1QKB1R w KQkq - 0 6"
    },
    {
      "move_number": 11,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c2c4",
      "move_san": "c4",
      "fen_after": "rnbqkb1r/pp1p3p/2p2pp1/5p2/2PP4/4PN2/PP3PPP/RN1QKB1R b KQkq - 0 6"
    },
    {
      "move_number": 12,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f8b4",
      "move_san": "Bb4+",
      "fen_after": "rnbqk2r/pp1p3p/2p2pp1/5p2/1bPP4/4PN2/PP3PPP/RN1QKB1R w KQkq - 1 7"
    },
    {
      "move_number": 13,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b1c3",
      "move_san": "Nc3",
      "fen_after": "rnbqk2r/pp1p3p/2p2pp1/5p2/1bPP4/2N1PN2/PP3PPP/R2QKB1R b KQkq - 2 7"
    },
    {
      "move_number": 14,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b8a6",
      "move_san": "Na6",
      "fen_after": "r1bqk2r/pp1p3p/n1p2pp1/5p2/1bPP4/2N1PN2/PP3PPP/R2QKB1R w KQkq - 3 8"
    },
    {
      "move_number": 15,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1b3",
      "move_san": "Qb3",
      "fen_after": "r1bqk2r/pp1p3p/n1p2pp1/5p2/1bPP4/1QN1PN2/PP3PPP/R3KB1R b KQkq - 4 8"
    },
    {
      "move_number": 16,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b4c3",
      "move_san": "Bxc3+",
      "fen_after": "r1bqk2r/pp1p3p/n1p2pp1/5p2/2PP4/1Qb1PN2/PP3PPP/R3KB1R w KQkq - 0 9"
    },
    {
      "move_number": 17,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b3c3",
      "move_san": "Qxc3",
      "fen_after": "r1bqk2r/pp1p3p/n1p2pp1/5p2/2PP4/2Q1PN2/PP3PPP/R3KB1R b KQkq - 0 9"
    },
    {
      "move_number": 18,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d8e7",
      "move_san": "Qe7",
      "fen_after": "r1b1k2r/pp1pq2p/n1p2pp1/5p2/2PP4/2Q1PN2/PP3PPP/R3KB1R w KQkq - 1 10"
    },
    {
      "move_number": 19,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c4c5",
      "move_san": "c5",
      "fen_after": "r1b1k2r/pp1pq2p/n1p2pp1/2P2p2/3P4/2Q1PN2/PP3PPP/R3KB1R b KQkq - 0 10"
    },
    {
      "move_number": 20,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "a8b8",
      "move_san": "Rb8",
      "fen_after": "1rb1k2r/pp1pq2p/n1p2pp1/2P2p2/3P4/2Q1PN2/PP3PPP/R3KB1R w KQk - 1 11"
    },
    {
      "move_number": 21,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1a6",
      "move_san": "Bxa6",
      "fen_after": "1rb1k2r/pp1pq2p/B1p2pp1/2P2p2/3P4/2Q1PN2/PP3PPP/R3K2R b KQk - 0 11"
    },
    {
      "move_number": 22,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b7a6",
      "move_san": "bxa6",
      "fen_after": "1rb1k2r/p2pq2p/p1p2pp1/2P2p2/3P4/2Q1PN2/PP3PPP/R3K2R w KQk - 0 12"
    },
    {
      "move_number": 23,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1g1",
      "move_san": "O-O",
      "fen_after": "1rb1k2r/p2pq2p/p1p2pp1/2P2p2/3P4/2Q1PN2/PP3PPP/R4RK1 b k - 1 12"
    },
    {
      "move_number": 24,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d7d5",
      "move_san": "d5",
      "fen_after": "1rb1k2r/p3q2p/p1p2pp1/2Pp1p2/3P4/2Q1PN2/PP3PPP/R4RK1 w k d6 0 13"
    },
    {
      "move_number": 25,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c5d6",
      "move_san": "cxd6",
      "fen_after": "1rb1k2r/p3q2p/p1pP1pp1/5p2/3P4/2Q1PN2/PP3PPP/R4RK1 b k - 0 13"
    },
    {
      "move_number": 26,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7d6",
      "move_san": "Qxd6",
      "fen_after": "1rb1k2r/p6p/p1pq1pp1/5p2/3P4/2Q1PN2/PP3PPP/R4RK1 w k - 0 14"
    },
    {
      "move_number": 27,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a1c1",
      "move_san": "Rac1",
      "fen_after": "1rb1k2r/p6p/p1pq1pp1/5p2/3P4/2Q1PN2/PP3PPP/2R2RK1 b k - 1 14"
    },
    {
      "move_number": 28,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "c8d7",
      "move_san": "Bd7",
      "fen_after": "1r2k2r/p2b3p/p1pq1pp1/5p2/3P4/2Q1PN2/PP3PPP/2R2RK1 w k - 2 15"
    },
    {
      "move_number": 29,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3d2",
      "move_san": "Nd2",
      "fen_after": "1r2k2r/p2b3p/p1pq1pp1/5p2/3P4/2Q1P3/PP1N1PPP/2R2RK1 b k - 3 15"
    },
    {
      "move_number": 30,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d6d5",
      "move_san": "Qd5",
      "fen_after": "1r2k2r/p2b3p/p1p2pp1/3q1p2/3P4/2Q1P3/PP1N1PPP/2R2RK1 w k - 4 16"
    },
    {
      "move_number": 31,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e3e4",
      "move_san": "e4",
      "fen_after": "1r2k2r/p2b3p/p1p2pp1/3q1p2/3PP3/2Q5/PP1N1PPP/2R2RK1 b k - 0 16"
    },
    {
      "move_number": 32,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f5e4",
      "move_san": "fxe4",
      "fen_after": "1r2k2r/p2b3p/p1p2pp1/3q4/3Pp3/2Q5/PP1N1PPP/2R2RK1 w k - 0 17"
    },
    {
      "move_number": 33,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2e4",
      "move_san": "Nxe4",
      "fen_after": "1r2k2r/p2b3p/p1p2pp1/3q4/3PN3/2Q5/PP3PPP/2R2RK1 b k - 0 17"
    },
    {
      "move_number": 34,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e8g8",
      "move_san": "O-O",
      "fen_after": "1r3rk1/p2b3p/p1p2pp1/3q4/3PN3/2Q5/PP3PPP/2R2RK1 w - - 1 18"
    },
    {
      "move_number": 35,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e4c5",
      "move_san": "Nc5",
      "fen_after": "1r3rk1/p2b3p/p1p2pp1/2Nq4/3P4/2Q5/PP3PPP/2R2RK1 b - - 2 18"
    },
    {
      "move_number": 36,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f8f7",
      "move_san": "Rf7",
      "fen_after": "1r4k1/p2b1r1p/p1p2pp1/2Nq4/3P4/2Q5/PP3PPP/2R2RK1 w - - 3 19"
    },
    {
      "move_number": 37,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c5a6",
      "move_san": "Nxa6",
      "fen_after": "1r4k1/p2b1r1p/N1p2pp1/3q4/3P4/2Q5/PP3PPP/2R2RK1 b - - 0 19"
    },
    {
      "move_number": 38,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b8b6",
      "move_san": "Rb6",
      "fen_after": "6k1/p2b1r1p/Nrp2pp1/3q4/3P4/2Q5/PP3PPP/2R2RK1 w - - 1 20"
    },
    {
      "move_number": 39,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a6c7",
      "move_san": "Nc7",
      "fen_after": "6k1/p1Nb1r1p/1rp2pp1/3q4/3P4/2Q5/PP3PPP/2R2RK1 b - - 2 20"
    },
    {
      "move_number": 40,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d5d6",
      "move_san": "Qd6",
      "fen_after": "6k1/p1Nb1r1p/1rpq1pp1/8/3P4/2Q5/PP3PPP/2R2RK1 w - - 3 21"
    },
    {
      "move_number": 41,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c3a5",
      "move_san": "Qa5",
      "fen_after": "6k1/p1Nb1r1p/1rpq1pp1/Q7/3P4/8/PP3PPP/2R2RK1 b - - 4 21"
    },
    {
      "move_number": 42,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d6c7",
      "move_san": "Qxc7",
      "fen_after": "6k1/p1qb1r1p/1rp2pp1/Q7/3P4/8/PP3PPP/2R2RK1 w - - 0 22"
    },
    {
      "move_number": 43,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d4d5",
      "move_san": "d5",
      "fen_after": "6k1/p1qb1r1p/1rp2pp1/Q2P4/8/8/PP3PPP/2R2RK1 b - - 0 22"
    },
    {
      "move_number": 44,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "c7b7",
      "move_san": "Qb7",
      "fen_after": "6k1/pq1b1r1p/1rp2pp1/Q2P4/8/8/PP3PPP/2R2RK1 w - - 1 23"
    },
    {
      "move_number": 45,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d5c6",
      "move_san": "dxc6",
      "fen_after": "6k1/pq1b1r1p/1rP2pp1/Q7/8/8/PP3PPP/2R2RK1 b - - 0 23"
    },
    {
      "move_number": 46,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d7c6",
      "move_san": "Bxc6",
      "fen_after": "6k1/pq3r1p/1rb2pp1/Q7/8/8/PP3PPP/2R2RK1 w - - 0 24"
    },
    {
      "move_number": 47,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1d1",
      "move_san": "Rfd1",
      "fen_after": "6k1/pq3r1p/1rb2pp1/Q7/8/8/PP3PPP/2RR2K1 b - - 1 24"
    },
    {
      "move_number": 48,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "c6b5",
      "move_san": "Bb5",
      "fen_after": "6k1/pq3r1p/1r3pp1/Qb6/8/8/PP3PPP/2RR2K1 w - - 2 25"
    },
    {
      "move_number": 49,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1d8",
      "move_san": "Rd8+",
      "fen_after": "3R2k1/pq3r1p/1r3pp1/Qb6/8/8/PP3PPP/2R3K1 b - - 3 25"
    },
    {
      "move_number": 50,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g8g7",
      "move_san": "Kg7",
      "fen_after": "3R4/pq3rkp/1r3pp1/Qb6/8/8/PP3PPP/2R3K1 w - - 4 26"
    },
    {
      "move_number": 51,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a5c3",
      "move_san": "Qc3",
      "fen_after": "3R4/pq3rkp/1r3pp1/1b6/8/2Q5/PP3PPP/2R3K1 b - - 5 26"
    },
    {
      "move_number": 52,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b6c6",
      "move_san": "Rc6",
      "fen_after": "3R4/pq3rkp/2r2pp1/1b6/8/2Q5/PP3PPP/2R3K1 w - - 6 27"
    },
    {
      "move_number": 53,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c3e1",
      "move_san": "Qe1",
      "fen_after": "3R4/pq3rkp/2r2pp1/1b6/8/8/PP3PPP/2R1Q1K1 b - - 7 27"
    },
    {
      "move_number": 54,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g6g5",
      "move_san": "g5",
      "fen_after": "3R4/pq3rkp/2r2p2/1b4p1/8/8/PP3PPP/2R1Q1K1 w - - 0 28"
    },
    {
      "move_number": 55,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1c6",
      "move_san": "Rxc6",
      "fen_after": "3R4/pq3rkp/2R2p2/1b4p1/8/8/PP3PPP/4Q1K1 b - - 0 28"
    },
    {
      "move_number": 56,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b5c6",
      "move_san": "Bxc6",
      "fen_after": "3R4/pq3rkp/2b2p2/6p1/8/8/PP3PPP/4Q1K1 w - - 0 29"
    },
    {
      "move_number": 57,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1c3",
      "move_san": "Qc3",
      "fen_after": "3R4/pq3rkp/2b2p2/6p1/8/2Q5/PP3PPP/6K1 b - - 1 29"
    },
    {
      "move_number": 58,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b7e7",
      "move_san": "Qe7",
      "fen_after": "3R4/p3qrkp/2b2p2/6p1/8/2Q5/PP3PPP/6K1 w - - 2 30"
    },
    {
      "move_number": 59,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d8d1",
      "move_san": "Rd1",
      "fen_after": "8/p3qrkp/2b2p2/6p1/8/2Q5/PP3PPP/3R2K1 b - - 3 30"
    },
    {
      "move_number": 60,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7e6",
      "move_san": "Qe6",
      "fen_after": "8/p4rkp/2b1qp2/6p1/8/2Q5/PP3PPP/3R2K1 w - - 4 31"
    },
    {
      "move_number": 61,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1e1",
      "move_san": "Re1",
      "fen_after": "8/p4rkp/2b1qp2/6p1/8/2Q5/PP3PPP/4R1K1 b - - 5 31"
    },
    {
      "move_number": 62,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e6d5",
      "move_san": "Qd5",
      "fen_after": "8/p4rkp/2b2p2/3q2p1/8/2Q5/PP3PPP/4R1K1 w - - 6 32"
    },
    {
      "move_number": 63,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c3g3",
      "move_san": "Qg3",
      "fen_after": "8/p4rkp/2b2p2/3q2p1/8/6Q1/PP3PPP/4R1K1 b - - 7 32"
    },
    {
      "move_number": 64,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "a7a5",
      "move_san": "a5",
      "fen_after": "8/5rkp/2b2p2/p2q2p1/8/6Q1/PP3PPP/4R1K1 w - - 0 33"
    },
    {
      "move_number": 65,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h2h4",
      "move_san": "h4",
      "fen_after": "8/5rkp/2b2p2/p2q2p1/7P/6Q1/PP3PP1/4R1K1 b - - 0 33"
    },
    {
      "move_number": 66,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f7d7",
      "move_san": "Rd7",
      "fen_after": "8/3r2kp/2b2p2/p2q2p1/7P/6Q1/PP3PP1/4R1K1 w - - 1 34"
    },
    {
      "move_number": 67,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h4g5",
      "move_san": "hxg5",
      "fen_after": "8/3r2kp/2b2p2/p2q2P1/8/6Q1/PP3PP1/4R1K1 b - - 0 34"
    },
    {
      "move_number": 68,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f6g5",
      "move_san": "fxg5",
      "fen_after": "8/3r2kp/2b5/p2q2p1/8/6Q1/PP3PP1/4R1K1 w - - 0 35"
    },
    {
      "move_number": 69,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1e5",
      "move_san": "Re5",
      "fen_after": "8/3r2kp/2b5/p2qR1p1/8/6Q1/PP3PP1/6K1 b - - 1 35"
    },
    {
      "move_number": 70,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d5d1",
      "move_san": "Qd1+",
      "fen_after": "8/3r2kp/2b5/p3R1p1/8/6Q1/PP3PP1/3q2K1 w - - 2 36"
    },
    {
      "move_number": 71,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e5e1",
      "move_san": "Re1",
      "fen_after": "8/3r2kp/2b5/p5p1/8/6Q1/PP3PP1/3qR1K1 b - - 3 36"
    },
    {
      "move_number": 72,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d1e1",
      "move_san": "Qxe1+",
      "fen_after": "8/3r2kp/2b5/p5p1/8/6Q1/PP3PP1/4q1K1 w - - 0 37"
    },
    {
      "move_number": 73,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1h2",
      "move_san": "Kh2",
      "fen_after": "8/3r2kp/2b5/p5p1/8/6Q1/PP3PPK/4q3 b - - 1 37"
    },
    {
      "move_number": 74,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e1e7",
      "move_san": "Qe7",
      "fen_after": "8/3rq1kp/2b5/p5p1/8/6Q1/PP3PPK/8 w - - 2 38"
    },
    {
      "move_number": 75,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g3c3",
      "move_san": "Qc3+",
      "fen_after": "8/3rq1kp/2b5/p5p1/8/2Q5/PP3PPK/8 b - - 3 38"
    },
    {
      "move_number": 76,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g7f7",
      "move_san": "Kf7",
      "fen_after": "8/3rqk1p/2b5/p5p1/8/2Q5/PP3PPK/8 w - - 4 39"
    },
    {
      "move_number": 77,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c3c6",
      "move_san": "Qxc6",
      "fen_after": "8/3rqk1p/2Q5/p5p1/8/8/PP3PPK/8 b - - 0 39"
    },
    {
      "move_number": 78,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7d6",
      "move_san": "Qd6+",
      "fen_after": "8/3r1k1p/2Qq4/p5p1/8/8/PP3PPK/8 w - - 1 40"
    },
    {
      "move_number": 79,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c6d6",
      "move_san": "Qxd6",
      "fen_after": "8/3r1k1p/3Q4/p5p1/8/8/PP3PPK/8 b - - 0 40"
    },
    {
      "move_number": 80,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d7d6",
      "move_san": "Rxd6",
      "fen_after": "8/5k1p/3r4/p5p1/8/8/PP3PPK/8 w - - 0 41"
    },
    {
      "move_number": 81,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h2g3",
      "move_san": "Kg3",
      "fen_after": "8/5k1p/3r4/p5p1/8/6K1/PP3PP1/8 b - - 1 41"
    },
    {
      "move_number": 82,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f7g6",
      "move_san": "Kg6",
      "fen_after": "8/7p/3r2k1/p5p1/8/6K1/PP3PP1/8 w - - 2 42"
    },
    {
      "move_number": 83,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f2f4",
      "move_san": "f4",
      "fen_after": "8/7p/3r2k1/p5p1/5P2/6K1/PP4P1/8 b - - 0 42"
    },
    {
      "move_number": 84,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g6f5",
      "move_san": "Kf5",
      "fen_after": "8/7p/3r4/p4kp1/5P2/6K1/PP4P1/8 w - - 1 43"
    },
    {
      "move_number": 85,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f4g5",
      "move_san": "fxg5",
      "fen_after": "8/7p/3r4/p4kP1/8/6K1/PP4P1/8 b - - 0 43"
    },
    {
      "move_number": 86,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d6d3",
      "move_san": "Rd3+",
      "fen_after": "8/7p/8/p4kP1/8/3r2K1/PP4P1/8 w - - 1 44"
    },
    {
      "move_number": 87,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g3h4",
      "move_san": "Kh4",
      "fen_after": "8/7p/8/p4kP1/7K/3r4/PP4P1/8 b - - 2 44"
    },
    {
      "move_number": 88,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d3d2",
      "move_san": "Rd2",
      "fen_after": "8/7p/8/p4kP1/7K/8/PP1r2P1/8 w - - 3 45"
    },
    {
      "move_number": 89,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g2g4",
      "move_san": "g4+",
      "fen_after": "8/7p/8/p4kP1/6PK/8/PP1r4/8 b - - 0 45"
    },
    {
      "move_number": 90,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f5f4",
      "move_san": "Kf4",
      "fen_after": "8/7p/8/p5P1/5kPK/8/PP1r4/8 w - - 1 46"
    }
  ],
  "final_fen": "8/7p/8/p5P1/5kPK/8/PP1r4/8 w - - 1 46",
  "white_tokens": {
    "prompt_tokens": 172942,
    "completion_tokens": 251231,
    "total_tokens": 424173
  },
  "black_tokens": {
    "prompt_tokens": 0,
    "completion_tokens": 0,
    "total_tokens": 0
  },
  "white_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 633,
          "total_tokens": 743,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1913,
        "total_tokens": 2242
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 633,
          "total_tokens": 743,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 411,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1691,
        "total_tokens": 2038
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 411,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1920,
        "total_tokens": 2294
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 316,
          "total_tokens": 449,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1596,
        "total_tokens": 1994
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 316,
          "total_tokens": 449,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 441,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 505,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 172,
          "total_tokens": 312,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 1118,
        "total_tokens": 1540
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 441,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 505,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 172,
          "total_tokens": 312,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 449,
        "total_completion_tokens": 1920,
        "total_tokens": 2369
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 381,
          "total_tokens": 538,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 363,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 640,
          "total_tokens": 796,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 470,
        "total_completion_tokens": 1384,
        "total_tokens": 1854
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 381,
          "total_tokens": 538,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 363,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 640,
          "total_tokens": 796,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 164,
          "completion_tokens": 640,
          "total_tokens": 804,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 164,
          "completion_tokens": 342,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 163,
          "completion_tokens": 427,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 491,
        "total_completion_tokens": 1409,
        "total_tokens": 1900
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 164,
          "completion_tokens": 640,
          "total_tokens": 804,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 164,
          "completion_tokens": 342,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 163,
          "completion_tokens": 427,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 515,
        "total_completion_tokens": 1920,
        "total_tokens": 2435
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1920,
        "total_tokens": 2456
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 285,
          "total_tokens": 473,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 217,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 200,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 563,
        "total_completion_tokens": 702,
        "total_tokens": 1265
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 285,
          "total_tokens": 473,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 217,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 200,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 640,
          "total_tokens": 837,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 512,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 393,
          "total_tokens": 589,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 590,
        "total_completion_tokens": 1545,
        "total_tokens": 2135
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 640,
          "total_tokens": 837,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 512,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 393,
          "total_tokens": 589,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 124,
          "total_tokens": 330,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 365,
          "total_tokens": 570,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 617,
        "total_completion_tokens": 1129,
        "total_tokens": 1746
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 124,
          "total_tokens": 330,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 365,
          "total_tokens": 570,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 365,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 162,
          "total_tokens": 375,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 641,
        "total_completion_tokens": 1167,
        "total_tokens": 1808
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 365,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 162,
          "total_tokens": 375,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 283,
          "total_tokens": 505,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 308,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 665,
        "total_completion_tokens": 1231,
        "total_tokens": 1896
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 283,
          "total_tokens": 505,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 308,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 209,
          "total_tokens": 440,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 514,
          "total_tokens": 744,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 692,
        "total_completion_tokens": 1363,
        "total_tokens": 2055
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 209,
          "total_tokens": 440,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 514,
          "total_tokens": 744,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 722,
        "total_completion_tokens": 1920,
        "total_tokens": 2642
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 35,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 149,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 329,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 640,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 752,
        "total_completion_tokens": 1118,
        "total_tokens": 1870
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 149,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 329,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 640,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 37,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 260,
          "completion_tokens": 353,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 782,
        "total_completion_tokens": 1633,
        "total_tokens": 2415
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 260,
          "completion_tokens": 353,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 39,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 271,
          "completion_tokens": 194,
          "total_tokens": 465,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 271,
          "completion_tokens": 640,
          "total_tokens": 911,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 270,
          "completion_tokens": 252,
          "total_tokens": 522,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 812,
        "total_completion_tokens": 1086,
        "total_tokens": 1898
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 271,
          "completion_tokens": 194,
          "total_tokens": 465,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 271,
          "completion_tokens": 640,
          "total_tokens": 911,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 270,
          "completion_tokens": 252,
          "total_tokens": 522,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 41,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 279,
          "completion_tokens": 452,
          "total_tokens": 731,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 279,
          "completion_tokens": 44,
          "total_tokens": 323,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 278,
          "completion_tokens": 8,
          "total_tokens": 286,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 836,
        "total_completion_tokens": 504,
        "total_tokens": 1340
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 279,
          "completion_tokens": 452,
          "total_tokens": 731,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 279,
          "completion_tokens": 44,
          "total_tokens": 323,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 278,
          "completion_tokens": 8,
          "total_tokens": 286,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 43,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 287,
          "completion_tokens": 640,
          "total_tokens": 927,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 287,
          "completion_tokens": 108,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 286,
          "completion_tokens": 500,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 860,
        "total_completion_tokens": 1248,
        "total_tokens": 2108
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 287,
          "completion_tokens": 640,
          "total_tokens": 927,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 287,
          "completion_tokens": 108,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 286,
          "completion_tokens": 500,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 45,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 296,
          "completion_tokens": 304,
          "total_tokens": 600,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 296,
          "completion_tokens": 640,
          "total_tokens": 936,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 295,
          "completion_tokens": 640,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 887,
        "total_completion_tokens": 1584,
        "total_tokens": 2471
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 296,
          "completion_tokens": 304,
          "total_tokens": 600,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 296,
          "completion_tokens": 640,
          "total_tokens": 936,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 295,
          "completion_tokens": 640,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 47,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 306,
          "completion_tokens": 629,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 306,
          "completion_tokens": 166,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 305,
          "completion_tokens": 640,
          "total_tokens": 945,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 917,
        "total_completion_tokens": 1435,
        "total_tokens": 2352
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 306,
          "completion_tokens": 629,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 306,
          "completion_tokens": 166,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 305,
          "completion_tokens": 640,
          "total_tokens": 945,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 49,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 314,
          "completion_tokens": 640,
          "total_tokens": 954,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 314,
          "completion_tokens": 23,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 313,
          "completion_tokens": 640,
          "total_tokens": 953,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 941,
        "total_completion_tokens": 1303,
        "total_tokens": 2244
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 314,
          "completion_tokens": 640,
          "total_tokens": 954,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 314,
          "completion_tokens": 23,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 313,
          "completion_tokens": 640,
          "total_tokens": 953,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 51,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 322,
          "completion_tokens": 386,
          "total_tokens": 708,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 322,
          "completion_tokens": 221,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 321,
          "completion_tokens": 640,
          "total_tokens": 961,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 965,
        "total_completion_tokens": 1247,
        "total_tokens": 2212
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 322,
          "completion_tokens": 386,
          "total_tokens": 708,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 322,
          "completion_tokens": 221,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 321,
          "completion_tokens": 640,
          "total_tokens": 961,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 53,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 330,
          "completion_tokens": 640,
          "total_tokens": 970,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 330,
          "completion_tokens": 23,
          "total_tokens": 353,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 329,
          "completion_tokens": 618,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 989,
        "total_completion_tokens": 1281,
        "total_tokens": 2270
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 330,
          "completion_tokens": 640,
          "total_tokens": 970,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 330,
          "completion_tokens": 23,
          "total_tokens": 353,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 329,
          "completion_tokens": 618,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 55,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 640,
          "total_tokens": 977,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 169,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 640,
          "total_tokens": 976,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1010,
        "total_completion_tokens": 1449,
        "total_tokens": 2459
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 640,
          "total_tokens": 977,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 169,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 640,
          "total_tokens": 976,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 57,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 345,
          "completion_tokens": 236,
          "total_tokens": 581,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 345,
          "completion_tokens": 358,
          "total_tokens": 703,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 344,
          "completion_tokens": 249,
          "total_tokens": 593,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1034,
        "total_completion_tokens": 843,
        "total_tokens": 1877
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 345,
          "completion_tokens": 236,
          "total_tokens": 581,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 345,
          "completion_tokens": 358,
          "total_tokens": 703,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 344,
          "completion_tokens": 249,
          "total_tokens": 593,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 59,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 351,
          "completion_tokens": 6,
          "total_tokens": 357,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1055,
        "total_completion_tokens": 1286,
        "total_tokens": 2341
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 351,
          "completion_tokens": 6,
          "total_tokens": 357,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 61,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 361,
          "completion_tokens": 8,
          "total_tokens": 369,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 361,
          "completion_tokens": 199,
          "total_tokens": 560,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 360,
          "completion_tokens": 8,
          "total_tokens": 368,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1082,
        "total_completion_tokens": 215,
        "total_tokens": 1297
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 361,
          "completion_tokens": 8,
          "total_tokens": 369,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 361,
          "completion_tokens": 199,
          "total_tokens": 560,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 360,
          "completion_tokens": 8,
          "total_tokens": 368,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 63,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 368,
          "completion_tokens": 387,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1106,
        "total_completion_tokens": 1667,
        "total_tokens": 2773
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 368,
          "completion_tokens": 387,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 65,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 378,
          "completion_tokens": 640,
          "total_tokens": 1018,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 378,
          "completion_tokens": 432,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 377,
          "completion_tokens": 640,
          "total_tokens": 1017,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1133,
        "total_completion_tokens": 1712,
        "total_tokens": 2845
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 378,
          "completion_tokens": 640,
          "total_tokens": 1018,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 378,
          "completion_tokens": 432,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 377,
          "completion_tokens": 640,
          "total_tokens": 1017,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 67,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 387,
          "completion_tokens": 338,
          "total_tokens": 725,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 387,
          "completion_tokens": 361,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 386,
          "completion_tokens": 170,
          "total_tokens": 556,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1160,
        "total_completion_tokens": 869,
        "total_tokens": 2029
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 387,
          "completion_tokens": 338,
          "total_tokens": 725,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 387,
          "completion_tokens": 361,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 386,
          "completion_tokens": 170,
          "total_tokens": 556,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 69,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 395,
          "completion_tokens": 229,
          "total_tokens": 624,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 395,
          "completion_tokens": 640,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 394,
          "completion_tokens": 640,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1184,
        "total_completion_tokens": 1509,
        "total_tokens": 2693
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 395,
          "completion_tokens": 229,
          "total_tokens": 624,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 395,
          "completion_tokens": 640,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 394,
          "completion_tokens": 640,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 71,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 402,
          "completion_tokens": 8,
          "total_tokens": 410,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1208,
        "total_completion_tokens": 1288,
        "total_tokens": 2496
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 402,
          "completion_tokens": 8,
          "total_tokens": 410,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 73,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 409,
          "completion_tokens": 8,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1229,
        "total_completion_tokens": 1288,
        "total_tokens": 2517
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 409,
          "completion_tokens": 8,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 75,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 418,
          "completion_tokens": 640,
          "total_tokens": 1058,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 418,
          "completion_tokens": 124,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 417,
          "completion_tokens": 640,
          "total_tokens": 1057,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1253,
        "total_completion_tokens": 1404,
        "total_tokens": 2657
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 418,
          "completion_tokens": 640,
          "total_tokens": 1058,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 418,
          "completion_tokens": 124,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 417,
          "completion_tokens": 640,
          "total_tokens": 1057,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 77,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 426,
          "completion_tokens": 640,
          "total_tokens": 1066,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1280,
        "total_completion_tokens": 1920,
        "total_tokens": 3200
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 426,
          "completion_tokens": 640,
          "total_tokens": 1066,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 79,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 434,
          "completion_tokens": 640,
          "total_tokens": 1074,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1304,
        "total_completion_tokens": 1920,
        "total_tokens": 3224
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 434,
          "completion_tokens": 640,
          "total_tokens": 1074,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 81,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 444,
          "completion_tokens": 640,
          "total_tokens": 1084,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 444,
          "completion_tokens": 8,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 443,
          "completion_tokens": 612,
          "total_tokens": 1055,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1331,
        "total_completion_tokens": 1260,
        "total_tokens": 2591
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 444,
          "completion_tokens": 640,
          "total_tokens": 1084,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 444,
          "completion_tokens": 8,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 443,
          "completion_tokens": 612,
          "total_tokens": 1055,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 83,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 451,
          "completion_tokens": 518,
          "total_tokens": 969,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 451,
          "completion_tokens": 564,
          "total_tokens": 1015,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 450,
          "completion_tokens": 606,
          "total_tokens": 1056,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1352,
        "total_completion_tokens": 1688,
        "total_tokens": 3040
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 451,
          "completion_tokens": 518,
          "total_tokens": 969,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 451,
          "completion_tokens": 564,
          "total_tokens": 1015,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 450,
          "completion_tokens": 606,
          "total_tokens": 1056,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 85,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 459,
          "completion_tokens": 640,
          "total_tokens": 1099,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 459,
          "completion_tokens": 8,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 458,
          "completion_tokens": 640,
          "total_tokens": 1098,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1376,
        "total_completion_tokens": 1288,
        "total_tokens": 2664
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 459,
          "completion_tokens": 640,
          "total_tokens": 1099,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 459,
          "completion_tokens": 8,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 458,
          "completion_tokens": 640,
          "total_tokens": 1098,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 87,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 467,
          "completion_tokens": 423,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 467,
          "completion_tokens": 640,
          "total_tokens": 1107,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 466,
          "completion_tokens": 640,
          "total_tokens": 1106,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1400,
        "total_completion_tokens": 1703,
        "total_tokens": 3103
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 467,
          "completion_tokens": 423,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 467,
          "completion_tokens": 640,
          "total_tokens": 1107,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 466,
          "completion_tokens": 640,
          "total_tokens": 1106,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 89,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 475,
          "completion_tokens": 7,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 475,
          "completion_tokens": 640,
          "total_tokens": 1115,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 474,
          "completion_tokens": 640,
          "total_tokens": 1114,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1424,
        "total_completion_tokens": 1287,
        "total_tokens": 2711
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 475,
          "completion_tokens": 7,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 475,
          "completion_tokens": 640,
          "total_tokens": 1115,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 474,
          "completion_tokens": 640,
          "total_tokens": 1114,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 91,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 222,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1451,
        "total_completion_tokens": 1502,
        "total_tokens": 2953
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 222,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 93,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 491,
          "completion_tokens": 640,
          "total_tokens": 1131,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 491,
          "completion_tokens": 8,
          "total_tokens": 499,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 490,
          "completion_tokens": 164,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1472,
        "total_completion_tokens": 812,
        "total_tokens": 2284
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 491,
          "completion_tokens": 640,
          "total_tokens": 1131,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 491,
          "completion_tokens": 8,
          "total_tokens": 499,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 490,
          "completion_tokens": 164,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 95,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 498,
          "completion_tokens": 640,
          "total_tokens": 1138,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 498,
          "completion_tokens": 201,
          "total_tokens": 699,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 497,
          "completion_tokens": 640,
          "total_tokens": 1137,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1493,
        "total_completion_tokens": 1481,
        "total_tokens": 2974
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 498,
          "completion_tokens": 640,
          "total_tokens": 1138,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 498,
          "completion_tokens": 201,
          "total_tokens": 699,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 497,
          "completion_tokens": 640,
          "total_tokens": 1137,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 97,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 507,
          "completion_tokens": 535,
          "total_tokens": 1042,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 507,
          "completion_tokens": 528,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 506,
          "completion_tokens": 528,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1520,
        "total_completion_tokens": 1591,
        "total_tokens": 3111
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 507,
          "completion_tokens": 535,
          "total_tokens": 1042,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 507,
          "completion_tokens": 528,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 506,
          "completion_tokens": 528,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 99,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 515,
          "completion_tokens": 528,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 515,
          "completion_tokens": 549,
          "total_tokens": 1064,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 514,
          "completion_tokens": 640,
          "total_tokens": 1154,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1544,
        "total_completion_tokens": 1717,
        "total_tokens": 3261
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 515,
          "completion_tokens": 528,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 515,
          "completion_tokens": 549,
          "total_tokens": 1064,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 514,
          "completion_tokens": 640,
          "total_tokens": 1154,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 101,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 524,
          "completion_tokens": 205,
          "total_tokens": 729,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 524,
          "completion_tokens": 597,
          "total_tokens": 1121,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 523,
          "completion_tokens": 640,
          "total_tokens": 1163,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1571,
        "total_completion_tokens": 1442,
        "total_tokens": 3013
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 524,
          "completion_tokens": 205,
          "total_tokens": 729,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 524,
          "completion_tokens": 597,
          "total_tokens": 1121,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 523,
          "completion_tokens": 640,
          "total_tokens": 1163,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 103,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 532,
          "completion_tokens": 25,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 532,
          "completion_tokens": 361,
          "total_tokens": 893,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 531,
          "completion_tokens": 22,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1595,
        "total_completion_tokens": 408,
        "total_tokens": 2003
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 532,
          "completion_tokens": 25,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 532,
          "completion_tokens": 361,
          "total_tokens": 893,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 531,
          "completion_tokens": 22,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 105,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 539,
          "completion_tokens": 640,
          "total_tokens": 1179,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 539,
          "completion_tokens": 281,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 538,
          "completion_tokens": 283,
          "total_tokens": 821,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1616,
        "total_completion_tokens": 1204,
        "total_tokens": 2820
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 539,
          "completion_tokens": 640,
          "total_tokens": 1179,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 539,
          "completion_tokens": 281,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 538,
          "completion_tokens": 283,
          "total_tokens": 821,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 107,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 547,
          "completion_tokens": 139,
          "total_tokens": 686,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 547,
          "completion_tokens": 332,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 546,
          "completion_tokens": 354,
          "total_tokens": 900,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1640,
        "total_completion_tokens": 825,
        "total_tokens": 2465
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 547,
          "completion_tokens": 139,
          "total_tokens": 686,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 547,
          "completion_tokens": 332,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 546,
          "completion_tokens": 354,
          "total_tokens": 900,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 109,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 554,
          "completion_tokens": 640,
          "total_tokens": 1194,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1664,
        "total_completion_tokens": 1920,
        "total_tokens": 3584
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 554,
          "completion_tokens": 640,
          "total_tokens": 1194,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 115,
          "completion_tokens": 407,
          "total_tokens": 522,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 115,
          "completion_tokens": 278,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 114,
          "completion_tokens": 366,
          "total_tokens": 480,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 344,
        "total_completion_tokens": 1051,
        "total_tokens": 1395
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 115,
          "completion_tokens": 407,
          "total_tokens": 522,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 115,
          "completion_tokens": 278,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 114,
          "completion_tokens": 366,
          "total_tokens": 480,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 368,
        "total_completion_tokens": 1920,
        "total_tokens": 2288
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 130,
          "completion_tokens": 518,
          "total_tokens": 648,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 129,
          "completion_tokens": 586,
          "total_tokens": 715,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 389,
        "total_completion_tokens": 1744,
        "total_tokens": 2133
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 130,
          "completion_tokens": 518,
          "total_tokens": 648,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 129,
          "completion_tokens": 586,
          "total_tokens": 715,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 137,
          "completion_tokens": 640,
          "total_tokens": 777,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 137,
          "completion_tokens": 500,
          "total_tokens": 637,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 136,
          "completion_tokens": 566,
          "total_tokens": 702,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 410,
        "total_completion_tokens": 1706,
        "total_tokens": 2116
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 137,
          "completion_tokens": 640,
          "total_tokens": 777,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 137,
          "completion_tokens": 500,
          "total_tokens": 637,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 136,
          "completion_tokens": 566,
          "total_tokens": 702,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 549,
          "total_tokens": 694,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 144,
          "completion_tokens": 243,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 434,
        "total_completion_tokens": 1432,
        "total_tokens": 1866
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 549,
          "total_tokens": 694,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 144,
          "completion_tokens": 243,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 152,
          "completion_tokens": 640,
          "total_tokens": 792,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 152,
          "completion_tokens": 312,
          "total_tokens": 464,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 151,
          "completion_tokens": 640,
          "total_tokens": 791,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 455,
        "total_completion_tokens": 1592,
        "total_tokens": 2047
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 152,
          "completion_tokens": 640,
          "total_tokens": 792,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 152,
          "completion_tokens": 312,
          "total_tokens": 464,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 151,
          "completion_tokens": 640,
          "total_tokens": 791,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 159,
          "completion_tokens": 463,
          "total_tokens": 622,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 479,
        "total_completion_tokens": 1743,
        "total_tokens": 2222
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 159,
          "completion_tokens": 463,
          "total_tokens": 622,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 451,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 451,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 379,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 1281,
        "total_tokens": 1784
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 451,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 451,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 379,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 437,
          "total_tokens": 615,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 533,
        "total_completion_tokens": 1717,
        "total_tokens": 2250
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 437,
          "total_tokens": 615,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 382,
          "total_tokens": 569,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 315,
          "total_tokens": 502,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 207,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 560,
        "total_completion_tokens": 904,
        "total_tokens": 1464
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 382,
          "total_tokens": 569,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 315,
          "total_tokens": 502,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 207,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 383,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 144,
          "total_tokens": 339,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 1167,
        "total_tokens": 1754
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 383,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 144,
          "total_tokens": 339,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 126,
          "total_tokens": 331,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 241,
          "total_tokens": 446,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 559,
          "total_tokens": 763,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 614,
        "total_completion_tokens": 926,
        "total_tokens": 1540
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 126,
          "total_tokens": 331,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 241,
          "total_tokens": 446,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 559,
          "total_tokens": 763,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 215,
          "completion_tokens": 331,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 215,
          "completion_tokens": 533,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 214,
          "completion_tokens": 213,
          "total_tokens": 427,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 644,
        "total_completion_tokens": 1077,
        "total_tokens": 1721
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 215,
          "completion_tokens": 331,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 215,
          "completion_tokens": 533,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 214,
          "completion_tokens": 213,
          "total_tokens": 427,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 640,
          "total_tokens": 863,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 640,
          "total_tokens": 863,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 668,
        "total_completion_tokens": 1920,
        "total_tokens": 2588
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 640,
          "total_tokens": 863,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 640,
          "total_tokens": 863,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 233,
          "completion_tokens": 14,
          "total_tokens": 247,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 233,
          "completion_tokens": 14,
          "total_tokens": 247,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 232,
          "completion_tokens": 14,
          "total_tokens": 246,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 698,
        "total_completion_tokens": 42,
        "total_tokens": 740
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 233,
          "completion_tokens": 14,
          "total_tokens": 247,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 233,
          "completion_tokens": 14,
          "total_tokens": 247,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 232,
          "completion_tokens": 14,
          "total_tokens": 246,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1920,
        "total_tokens": 2249
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 464,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1744,
        "total_tokens": 2091
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 464,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 496,
          "total_tokens": 621,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1776,
        "total_tokens": 2150
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 496,
          "total_tokens": 621,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1920,
        "total_tokens": 2318
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 247,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 387,
          "total_tokens": 528,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 425,
        "total_completion_tokens": 1274,
        "total_tokens": 1699
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 247,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 387,
          "total_tokens": 528,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 338,
          "total_tokens": 488,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 449,
        "total_completion_tokens": 1618,
        "total_tokens": 2067
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 338,
          "total_tokens": 488,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 158,
          "completion_tokens": 407,
          "total_tokens": 565,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 158,
          "completion_tokens": 564,
          "total_tokens": 722,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 157,
          "completion_tokens": 375,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 473,
        "total_completion_tokens": 1346,
        "total_tokens": 1819
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 158,
          "completion_tokens": 407,
          "total_tokens": 565,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 158,
          "completion_tokens": 564,
          "total_tokens": 722,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 157,
          "completion_tokens": 375,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 167,
          "completion_tokens": 640,
          "total_tokens": 807,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 167,
          "completion_tokens": 640,
          "total_tokens": 807,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 166,
          "completion_tokens": 640,
          "total_tokens": 806,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 500,
        "total_completion_tokens": 1920,
        "total_tokens": 2420
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 167,
          "completion_tokens": 640,
          "total_tokens": 807,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 167,
          "completion_tokens": 640,
          "total_tokens": 807,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 166,
          "completion_tokens": 640,
          "total_tokens": 806,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 174,
          "completion_tokens": 640,
          "total_tokens": 814,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 174,
          "completion_tokens": 640,
          "total_tokens": 814,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 173,
          "completion_tokens": 640,
          "total_tokens": 813,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 521,
        "total_completion_tokens": 1920,
        "total_tokens": 2441
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 174,
          "completion_tokens": 640,
          "total_tokens": 814,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 174,
          "completion_tokens": 640,
          "total_tokens": 814,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 173,
          "completion_tokens": 640,
          "total_tokens": 813,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 640,
          "total_tokens": 821,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 211,
          "total_tokens": 392,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 557,
          "total_tokens": 737,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 542,
        "total_completion_tokens": 1408,
        "total_tokens": 1950
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 640,
          "total_tokens": 821,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 211,
          "total_tokens": 392,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 557,
          "total_tokens": 737,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 199,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 465,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 566,
        "total_completion_tokens": 1304,
        "total_tokens": 1870
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 199,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 465,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 452,
          "total_tokens": 647,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 1732,
        "total_tokens": 2319
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 452,
          "total_tokens": 647,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 375,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 450,
          "total_tokens": 655,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 553,
          "total_tokens": 757,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 614,
        "total_completion_tokens": 1378,
        "total_tokens": 1992
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 375,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 450,
          "total_tokens": 655,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 553,
          "total_tokens": 757,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 610,
          "total_tokens": 823,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 640,
          "total_tokens": 853,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 434,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 638,
        "total_completion_tokens": 1684,
        "total_tokens": 2322
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 610,
          "total_tokens": 823,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 640,
          "total_tokens": 853,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 434,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 396,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 413,
          "total_tokens": 636,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 668,
        "total_completion_tokens": 1449,
        "total_tokens": 2117
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 396,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 413,
          "total_tokens": 636,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 640,
          "total_tokens": 870,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 692,
        "total_completion_tokens": 1920,
        "total_tokens": 2612
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 640,
          "total_tokens": 870,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 354,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 374,
          "total_tokens": 615,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 722,
        "total_completion_tokens": 1368,
        "total_tokens": 2090
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 354,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 374,
          "total_tokens": 615,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 35,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 329,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 424,
          "total_tokens": 675,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 262,
          "total_tokens": 512,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 752,
        "total_completion_tokens": 1015,
        "total_tokens": 1767
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 329,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 424,
          "total_tokens": 675,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 262,
          "total_tokens": 512,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 37,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 258,
          "completion_tokens": 640,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 258,
          "completion_tokens": 640,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 257,
          "completion_tokens": 640,
          "total_tokens": 897,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 773,
        "total_completion_tokens": 1920,
        "total_tokens": 2693
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 258,
          "completion_tokens": 640,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 258,
          "completion_tokens": 640,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 257,
          "completion_tokens": 640,
          "total_tokens": 897,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 39,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 265,
          "completion_tokens": 500,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 265,
          "completion_tokens": 640,
          "total_tokens": 905,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 264,
          "completion_tokens": 615,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 794,
        "total_completion_tokens": 1755,
        "total_tokens": 2549
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 265,
          "completion_tokens": 500,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 265,
          "completion_tokens": 640,
          "total_tokens": 905,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 264,
          "completion_tokens": 615,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 41,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 272,
          "completion_tokens": 87,
          "total_tokens": 359,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 272,
          "completion_tokens": 83,
          "total_tokens": 355,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 271,
          "completion_tokens": 409,
          "total_tokens": 680,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 815,
        "total_completion_tokens": 579,
        "total_tokens": 1394
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 272,
          "completion_tokens": 87,
          "total_tokens": 359,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 272,
          "completion_tokens": 83,
          "total_tokens": 355,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 271,
          "completion_tokens": 409,
          "total_tokens": 680,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 43,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 282,
          "completion_tokens": 640,
          "total_tokens": 922,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 282,
          "completion_tokens": 640,
          "total_tokens": 922,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 281,
          "completion_tokens": 324,
          "total_tokens": 605,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 845,
        "total_completion_tokens": 1604,
        "total_tokens": 2449
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 282,
          "completion_tokens": 640,
          "total_tokens": 922,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 282,
          "completion_tokens": 640,
          "total_tokens": 922,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 281,
          "completion_tokens": 324,
          "total_tokens": 605,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 45,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 289,
          "completion_tokens": 302,
          "total_tokens": 591,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 289,
          "completion_tokens": 150,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 288,
          "completion_tokens": 640,
          "total_tokens": 928,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 866,
        "total_completion_tokens": 1092,
        "total_tokens": 1958
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 289,
          "completion_tokens": 302,
          "total_tokens": 591,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 289,
          "completion_tokens": 150,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 288,
          "completion_tokens": 640,
          "total_tokens": 928,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 47,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 298,
          "completion_tokens": 292,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 298,
          "completion_tokens": 640,
          "total_tokens": 938,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 297,
          "completion_tokens": 640,
          "total_tokens": 937,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 893,
        "total_completion_tokens": 1572,
        "total_tokens": 2465
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 298,
          "completion_tokens": 292,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 298,
          "completion_tokens": 640,
          "total_tokens": 938,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 297,
          "completion_tokens": 640,
          "total_tokens": 937,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 49,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 308,
          "completion_tokens": 296,
          "total_tokens": 604,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 308,
          "completion_tokens": 27,
          "total_tokens": 335,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 307,
          "completion_tokens": 640,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 923,
        "total_completion_tokens": 963,
        "total_tokens": 1886
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 308,
          "completion_tokens": 296,
          "total_tokens": 604,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 308,
          "completion_tokens": 27,
          "total_tokens": 335,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 307,
          "completion_tokens": 640,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 51,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 317,
          "completion_tokens": 640,
          "total_tokens": 957,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 317,
          "completion_tokens": 640,
          "total_tokens": 957,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 316,
          "completion_tokens": 269,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 950,
        "total_completion_tokens": 1549,
        "total_tokens": 2499
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 317,
          "completion_tokens": 640,
          "total_tokens": 957,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 317,
          "completion_tokens": 640,
          "total_tokens": 957,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 316,
          "completion_tokens": 269,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 53,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 325,
          "completion_tokens": 640,
          "total_tokens": 965,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 325,
          "completion_tokens": 640,
          "total_tokens": 965,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 324,
          "completion_tokens": 640,
          "total_tokens": 964,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 974,
        "total_completion_tokens": 1920,
        "total_tokens": 2894
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 325,
          "completion_tokens": 640,
          "total_tokens": 965,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 325,
          "completion_tokens": 640,
          "total_tokens": 965,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 324,
          "completion_tokens": 640,
          "total_tokens": 964,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 55,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 334,
          "completion_tokens": 330,
          "total_tokens": 664,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 334,
          "completion_tokens": 239,
          "total_tokens": 573,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 333,
          "completion_tokens": 280,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1001,
        "total_completion_tokens": 849,
        "total_tokens": 1850
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 334,
          "completion_tokens": 330,
          "total_tokens": 664,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 334,
          "completion_tokens": 239,
          "total_tokens": 573,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 333,
          "completion_tokens": 280,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 57,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 343,
          "completion_tokens": 113,
          "total_tokens": 456,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 343,
          "completion_tokens": 150,
          "total_tokens": 493,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 342,
          "completion_tokens": 121,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1028,
        "total_completion_tokens": 384,
        "total_tokens": 1412
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 343,
          "completion_tokens": 113,
          "total_tokens": 456,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 343,
          "completion_tokens": 150,
          "total_tokens": 493,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 342,
          "completion_tokens": 121,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 59,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 350,
          "completion_tokens": 341,
          "total_tokens": 691,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 350,
          "completion_tokens": 74,
          "total_tokens": 424,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 349,
          "completion_tokens": 302,
          "total_tokens": 651,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1049,
        "total_completion_tokens": 717,
        "total_tokens": 1766
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 350,
          "completion_tokens": 341,
          "total_tokens": 691,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 350,
          "completion_tokens": 74,
          "total_tokens": 424,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 349,
          "completion_tokens": 302,
          "total_tokens": 651,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 61,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 358,
          "completion_tokens": 390,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 358,
          "completion_tokens": 23,
          "total_tokens": 381,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 357,
          "completion_tokens": 417,
          "total_tokens": 774,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1073,
        "total_completion_tokens": 830,
        "total_tokens": 1903
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 358,
          "completion_tokens": 390,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 358,
          "completion_tokens": 23,
          "total_tokens": 381,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 357,
          "completion_tokens": 417,
          "total_tokens": 774,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 63,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 365,
          "completion_tokens": 273,
          "total_tokens": 638,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 365,
          "completion_tokens": 272,
          "total_tokens": 637,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 364,
          "completion_tokens": 272,
          "total_tokens": 636,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1094,
        "total_completion_tokens": 817,
        "total_tokens": 1911
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 365,
          "completion_tokens": 273,
          "total_tokens": 638,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 365,
          "completion_tokens": 272,
          "total_tokens": 637,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 364,
          "completion_tokens": 272,
          "total_tokens": 636,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 65,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 373,
          "completion_tokens": 440,
          "total_tokens": 813,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 373,
          "completion_tokens": 8,
          "total_tokens": 381,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 372,
          "completion_tokens": 640,
          "total_tokens": 1012,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1118,
        "total_completion_tokens": 1088,
        "total_tokens": 2206
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 373,
          "completion_tokens": 440,
          "total_tokens": 813,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 373,
          "completion_tokens": 8,
          "total_tokens": 381,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 372,
          "completion_tokens": 640,
          "total_tokens": 1012,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 67,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 382,
          "completion_tokens": 461,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 382,
          "completion_tokens": 35,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 381,
          "completion_tokens": 376,
          "total_tokens": 757,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1145,
        "total_completion_tokens": 872,
        "total_tokens": 2017
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 382,
          "completion_tokens": 461,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 382,
          "completion_tokens": 35,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 381,
          "completion_tokens": 376,
          "total_tokens": 757,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 69,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 389,
          "completion_tokens": 46,
          "total_tokens": 435,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 389,
          "completion_tokens": 46,
          "total_tokens": 435,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 388,
          "completion_tokens": 46,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1166,
        "total_completion_tokens": 138,
        "total_tokens": 1304
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 389,
          "completion_tokens": 46,
          "total_tokens": 435,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 389,
          "completion_tokens": 46,
          "total_tokens": 435,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 388,
          "completion_tokens": 46,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 71,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 399,
          "completion_tokens": 324,
          "total_tokens": 723,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 399,
          "completion_tokens": 77,
          "total_tokens": 476,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 398,
          "completion_tokens": 58,
          "total_tokens": 456,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1196,
        "total_completion_tokens": 459,
        "total_tokens": 1655
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 399,
          "completion_tokens": 324,
          "total_tokens": 723,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 399,
          "completion_tokens": 77,
          "total_tokens": 476,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 398,
          "completion_tokens": 58,
          "total_tokens": 456,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 73,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 408,
          "completion_tokens": 88,
          "total_tokens": 496,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 408,
          "completion_tokens": 131,
          "total_tokens": 539,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 407,
          "completion_tokens": 380,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1223,
        "total_completion_tokens": 599,
        "total_tokens": 1822
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 408,
          "completion_tokens": 88,
          "total_tokens": 496,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 408,
          "completion_tokens": 131,
          "total_tokens": 539,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 407,
          "completion_tokens": 380,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 75,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 417,
          "completion_tokens": 8,
          "total_tokens": 425,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 417,
          "completion_tokens": 24,
          "total_tokens": 441,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 416,
          "completion_tokens": 344,
          "total_tokens": 760,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1250,
        "total_completion_tokens": 376,
        "total_tokens": 1626
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 417,
          "completion_tokens": 8,
          "total_tokens": 425,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 417,
          "completion_tokens": 24,
          "total_tokens": 441,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 416,
          "completion_tokens": 344,
          "total_tokens": 760,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 77,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 425,
          "completion_tokens": 10,
          "total_tokens": 435,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 425,
          "completion_tokens": 484,
          "total_tokens": 909,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 424,
          "completion_tokens": 600,
          "total_tokens": 1024,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1274,
        "total_completion_tokens": 1094,
        "total_tokens": 2368
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 425,
          "completion_tokens": 10,
          "total_tokens": 435,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 425,
          "completion_tokens": 484,
          "total_tokens": 909,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 424,
          "completion_tokens": 600,
          "total_tokens": 1024,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 79,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 435,
          "completion_tokens": 236,
          "total_tokens": 671,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 434,
          "completion_tokens": 275,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1304,
        "total_completion_tokens": 1151,
        "total_tokens": 2455
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 435,
          "completion_tokens": 236,
          "total_tokens": 671,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 434,
          "completion_tokens": 275,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 81,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 442,
          "completion_tokens": 472,
          "total_tokens": 914,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 442,
          "completion_tokens": 640,
          "total_tokens": 1082,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 441,
          "completion_tokens": 9,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1325,
        "total_completion_tokens": 1121,
        "total_tokens": 2446
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 442,
          "completion_tokens": 472,
          "total_tokens": 914,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 442,
          "completion_tokens": 640,
          "total_tokens": 1082,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 441,
          "completion_tokens": 9,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 83,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 451,
          "completion_tokens": 413,
          "total_tokens": 864,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 451,
          "completion_tokens": 413,
          "total_tokens": 864,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 450,
          "completion_tokens": 640,
          "total_tokens": 1090,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1352,
        "total_completion_tokens": 1466,
        "total_tokens": 2818
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 451,
          "completion_tokens": 413,
          "total_tokens": 864,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 451,
          "completion_tokens": 413,
          "total_tokens": 864,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 450,
          "completion_tokens": 640,
          "total_tokens": 1090,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 85,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 460,
          "completion_tokens": 640,
          "total_tokens": 1100,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 460,
          "completion_tokens": 640,
          "total_tokens": 1100,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 459,
          "completion_tokens": 587,
          "total_tokens": 1046,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1379,
        "total_completion_tokens": 1867,
        "total_tokens": 3246
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 460,
          "completion_tokens": 640,
          "total_tokens": 1100,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 460,
          "completion_tokens": 640,
          "total_tokens": 1100,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 459,
          "completion_tokens": 587,
          "total_tokens": 1046,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 87,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 470,
          "completion_tokens": 33,
          "total_tokens": 503,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 470,
          "completion_tokens": 383,
          "total_tokens": 853,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 469,
          "completion_tokens": 429,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1409,
        "total_completion_tokens": 845,
        "total_tokens": 2254
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 470,
          "completion_tokens": 33,
          "total_tokens": 503,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 470,
          "completion_tokens": 383,
          "total_tokens": 853,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 469,
          "completion_tokens": 429,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 89,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 477,
          "completion_tokens": 640,
          "total_tokens": 1117,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 477,
          "completion_tokens": 228,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 476,
          "completion_tokens": 8,
          "total_tokens": 484,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1430,
        "total_completion_tokens": 876,
        "total_tokens": 2306
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 477,
          "completion_tokens": 640,
          "total_tokens": 1117,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 477,
          "completion_tokens": 228,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 476,
          "completion_tokens": 8,
          "total_tokens": 484,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 91,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 86,
          "total_tokens": 570,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 640,
          "total_tokens": 1123,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1451,
        "total_completion_tokens": 1366,
        "total_tokens": 2817
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 86,
          "total_tokens": 570,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 640,
          "total_tokens": 1123,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 93,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 492,
          "completion_tokens": 156,
          "total_tokens": 648,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 492,
          "completion_tokens": 127,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 491,
          "completion_tokens": 182,
          "total_tokens": 673,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1475,
        "total_completion_tokens": 465,
        "total_tokens": 1940
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 492,
          "completion_tokens": 156,
          "total_tokens": 648,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 492,
          "completion_tokens": 127,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 491,
          "completion_tokens": 182,
          "total_tokens": 673,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 95,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 500,
          "completion_tokens": 510,
          "total_tokens": 1010,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 500,
          "completion_tokens": 31,
          "total_tokens": 531,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 499,
          "completion_tokens": 509,
          "total_tokens": 1008,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1499,
        "total_completion_tokens": 1050,
        "total_tokens": 2549
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 500,
          "completion_tokens": 510,
          "total_tokens": 1010,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 500,
          "completion_tokens": 31,
          "total_tokens": 531,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 499,
          "completion_tokens": 509,
          "total_tokens": 1008,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 97,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 508,
          "completion_tokens": 510,
          "total_tokens": 1018,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 508,
          "completion_tokens": 511,
          "total_tokens": 1019,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 507,
          "completion_tokens": 557,
          "total_tokens": 1064,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1523,
        "total_completion_tokens": 1578,
        "total_tokens": 3101
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 508,
          "completion_tokens": 510,
          "total_tokens": 1018,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 508,
          "completion_tokens": 511,
          "total_tokens": 1019,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 507,
          "completion_tokens": 557,
          "total_tokens": 1064,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 99,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 515,
          "completion_tokens": 504,
          "total_tokens": 1019,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 515,
          "completion_tokens": 531,
          "total_tokens": 1046,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 514,
          "completion_tokens": 531,
          "total_tokens": 1045,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1544,
        "total_completion_tokens": 1566,
        "total_tokens": 3110
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 515,
          "completion_tokens": 504,
          "total_tokens": 1019,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 515,
          "completion_tokens": 531,
          "total_tokens": 1046,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 514,
          "completion_tokens": 531,
          "total_tokens": 1045,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 101,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 523,
          "completion_tokens": 575,
          "total_tokens": 1098,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 523,
          "completion_tokens": 589,
          "total_tokens": 1112,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 522,
          "completion_tokens": 551,
          "total_tokens": 1073,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1568,
        "total_completion_tokens": 1715,
        "total_tokens": 3283
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 523,
          "completion_tokens": 575,
          "total_tokens": 1098,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 523,
          "completion_tokens": 589,
          "total_tokens": 1112,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 522,
          "completion_tokens": 551,
          "total_tokens": 1073,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 419,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1699,
        "total_tokens": 2040
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 419,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 305,
          "total_tokens": 427,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 365,
        "total_completion_tokens": 1585,
        "total_tokens": 1950
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 305,
          "total_tokens": 427,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 130,
          "completion_tokens": 342,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 130,
          "completion_tokens": 409,
          "total_tokens": 539,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 129,
          "completion_tokens": 640,
          "total_tokens": 769,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 389,
        "total_completion_tokens": 1391,
        "total_tokens": 1780
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 130,
          "completion_tokens": 342,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 130,
          "completion_tokens": 409,
          "total_tokens": 539,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 129,
          "completion_tokens": 640,
          "total_tokens": 769,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 137,
          "completion_tokens": 640,
          "total_tokens": 777,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 137,
          "completion_tokens": 384,
          "total_tokens": 521,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 136,
          "completion_tokens": 586,
          "total_tokens": 722,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 410,
        "total_completion_tokens": 1610,
        "total_tokens": 2020
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 137,
          "completion_tokens": 640,
          "total_tokens": 777,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 137,
          "completion_tokens": 384,
          "total_tokens": 521,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 136,
          "completion_tokens": 586,
          "total_tokens": 722,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 472,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 144,
          "completion_tokens": 496,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 434,
        "total_completion_tokens": 1608,
        "total_tokens": 2042
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 472,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 144,
          "completion_tokens": 496,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 153,
          "completion_tokens": 640,
          "total_tokens": 793,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 153,
          "completion_tokens": 438,
          "total_tokens": 591,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 152,
          "completion_tokens": 640,
          "total_tokens": 792,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 458,
        "total_completion_tokens": 1718,
        "total_tokens": 2176
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 153,
          "completion_tokens": 640,
          "total_tokens": 793,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 153,
          "completion_tokens": 438,
          "total_tokens": 591,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 152,
          "completion_tokens": 640,
          "total_tokens": 792,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 284,
          "total_tokens": 444,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1564,
        "total_tokens": 2046
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 284,
          "total_tokens": 444,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 435,
          "total_tokens": 604,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 640,
          "total_tokens": 808,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 506,
        "total_completion_tokens": 1715,
        "total_tokens": 2221
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 435,
          "total_tokens": 604,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 640,
          "total_tokens": 808,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 558,
          "total_tokens": 735,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 640,
          "total_tokens": 816,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 530,
        "total_completion_tokens": 1838,
        "total_tokens": 2368
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 558,
          "total_tokens": 735,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 640,
          "total_tokens": 816,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 367,
          "total_tokens": 552,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 484,
          "total_tokens": 669,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 640,
          "total_tokens": 824,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 554,
        "total_completion_tokens": 1491,
        "total_tokens": 2045
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 367,
          "total_tokens": 552,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 484,
          "total_tokens": 669,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 640,
          "total_tokens": 824,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 192,
          "completion_tokens": 399,
          "total_tokens": 591,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 578,
        "total_completion_tokens": 1679,
        "total_tokens": 2257
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 192,
          "completion_tokens": 399,
          "total_tokens": 591,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 201,
          "completion_tokens": 640,
          "total_tokens": 841,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 201,
          "completion_tokens": 175,
          "total_tokens": 376,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 200,
          "completion_tokens": 316,
          "total_tokens": 516,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 602,
        "total_completion_tokens": 1131,
        "total_tokens": 1733
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 201,
          "completion_tokens": 640,
          "total_tokens": 841,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 201,
          "completion_tokens": 175,
          "total_tokens": 376,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 200,
          "completion_tokens": 316,
          "total_tokens": 516,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 210,
          "completion_tokens": 640,
          "total_tokens": 850,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 210,
          "completion_tokens": 640,
          "total_tokens": 850,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 209,
          "completion_tokens": 251,
          "total_tokens": 460,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 629,
        "total_completion_tokens": 1531,
        "total_tokens": 2160
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 210,
          "completion_tokens": 640,
          "total_tokens": 850,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 210,
          "completion_tokens": 640,
          "total_tokens": 850,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 209,
          "completion_tokens": 251,
          "total_tokens": 460,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 219,
          "completion_tokens": 422,
          "total_tokens": 641,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 219,
          "completion_tokens": 249,
          "total_tokens": 468,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 218,
          "completion_tokens": 21,
          "total_tokens": 239,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 656,
        "total_completion_tokens": 692,
        "total_tokens": 1348
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 219,
          "completion_tokens": 422,
          "total_tokens": 641,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 219,
          "completion_tokens": 249,
          "total_tokens": 468,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 218,
          "completion_tokens": 21,
          "total_tokens": 239,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 227,
          "completion_tokens": 640,
          "total_tokens": 867,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 227,
          "completion_tokens": 505,
          "total_tokens": 732,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 226,
          "completion_tokens": 68,
          "total_tokens": 294,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 680,
        "total_completion_tokens": 1213,
        "total_tokens": 1893
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 227,
          "completion_tokens": 640,
          "total_tokens": 867,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 227,
          "completion_tokens": 505,
          "total_tokens": 732,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 226,
          "completion_tokens": 68,
          "total_tokens": 294,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 237,
          "completion_tokens": 85,
          "total_tokens": 322,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 236,
          "completion_tokens": 640,
          "total_tokens": 876,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 710,
        "total_completion_tokens": 1365,
        "total_tokens": 2075
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 237,
          "completion_tokens": 85,
          "total_tokens": 322,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 236,
          "completion_tokens": 640,
          "total_tokens": 876,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 34,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 245,
          "completion_tokens": 327,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 245,
          "completion_tokens": 640,
          "total_tokens": 885,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 244,
          "completion_tokens": 640,
          "total_tokens": 884,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 734,
        "total_completion_tokens": 1607,
        "total_tokens": 2341
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 245,
          "completion_tokens": 327,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 245,
          "completion_tokens": 640,
          "total_tokens": 885,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 244,
          "completion_tokens": 640,
          "total_tokens": 884,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 36,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 254,
          "completion_tokens": 640,
          "total_tokens": 894,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 254,
          "completion_tokens": 640,
          "total_tokens": 894,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 253,
          "completion_tokens": 254,
          "total_tokens": 507,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 761,
        "total_completion_tokens": 1534,
        "total_tokens": 2295
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 254,
          "completion_tokens": 640,
          "total_tokens": 894,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 254,
          "completion_tokens": 640,
          "total_tokens": 894,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 253,
          "completion_tokens": 254,
          "total_tokens": 507,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 38,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 263,
          "completion_tokens": 393,
          "total_tokens": 656,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 263,
          "completion_tokens": 205,
          "total_tokens": 468,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 262,
          "completion_tokens": 640,
          "total_tokens": 902,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 788,
        "total_completion_tokens": 1238,
        "total_tokens": 2026
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 263,
          "completion_tokens": 393,
          "total_tokens": 656,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 263,
          "completion_tokens": 205,
          "total_tokens": 468,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 262,
          "completion_tokens": 640,
          "total_tokens": 902,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 40,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 273,
          "completion_tokens": 88,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 273,
          "completion_tokens": 640,
          "total_tokens": 913,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 272,
          "completion_tokens": 640,
          "total_tokens": 912,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 818,
        "total_completion_tokens": 1368,
        "total_tokens": 2186
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 273,
          "completion_tokens": 88,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 273,
          "completion_tokens": 640,
          "total_tokens": 913,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 272,
          "completion_tokens": 640,
          "total_tokens": 912,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 42,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 283,
          "completion_tokens": 640,
          "total_tokens": 923,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 283,
          "completion_tokens": 132,
          "total_tokens": 415,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 282,
          "completion_tokens": 56,
          "total_tokens": 338,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 848,
        "total_completion_tokens": 828,
        "total_tokens": 1676
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 283,
          "completion_tokens": 640,
          "total_tokens": 923,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 283,
          "completion_tokens": 132,
          "total_tokens": 415,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 282,
          "completion_tokens": 56,
          "total_tokens": 338,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 44,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 291,
          "completion_tokens": 640,
          "total_tokens": 931,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 291,
          "completion_tokens": 640,
          "total_tokens": 931,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 290,
          "completion_tokens": 640,
          "total_tokens": 930,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 872,
        "total_completion_tokens": 1920,
        "total_tokens": 2792
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 291,
          "completion_tokens": 640,
          "total_tokens": 931,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 291,
          "completion_tokens": 640,
          "total_tokens": 931,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 290,
          "completion_tokens": 640,
          "total_tokens": 930,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 46,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 300,
          "completion_tokens": 640,
          "total_tokens": 940,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 300,
          "completion_tokens": 640,
          "total_tokens": 940,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 299,
          "completion_tokens": 640,
          "total_tokens": 939,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 899,
        "total_completion_tokens": 1920,
        "total_tokens": 2819
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 300,
          "completion_tokens": 640,
          "total_tokens": 940,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 300,
          "completion_tokens": 640,
          "total_tokens": 940,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 299,
          "completion_tokens": 640,
          "total_tokens": 939,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 48,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 308,
          "completion_tokens": 181,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 308,
          "completion_tokens": 377,
          "total_tokens": 685,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 307,
          "completion_tokens": 181,
          "total_tokens": 488,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 923,
        "total_completion_tokens": 739,
        "total_tokens": 1662
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 308,
          "completion_tokens": 181,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 308,
          "completion_tokens": 377,
          "total_tokens": 685,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 307,
          "completion_tokens": 181,
          "total_tokens": 488,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 50,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 316,
          "completion_tokens": 28,
          "total_tokens": 344,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 316,
          "completion_tokens": 28,
          "total_tokens": 344,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 315,
          "completion_tokens": 28,
          "total_tokens": 343,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 947,
        "total_completion_tokens": 84,
        "total_tokens": 1031
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 316,
          "completion_tokens": 28,
          "total_tokens": 344,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 316,
          "completion_tokens": 28,
          "total_tokens": 344,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 315,
          "completion_tokens": 28,
          "total_tokens": 343,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 52,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 324,
          "completion_tokens": 138,
          "total_tokens": 462,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 324,
          "completion_tokens": 138,
          "total_tokens": 462,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 323,
          "completion_tokens": 8,
          "total_tokens": 331,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 971,
        "total_completion_tokens": 284,
        "total_tokens": 1255
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 324,
          "completion_tokens": 138,
          "total_tokens": 462,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 324,
          "completion_tokens": 138,
          "total_tokens": 462,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 323,
          "completion_tokens": 8,
          "total_tokens": 331,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 54,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 332,
          "completion_tokens": 240,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 332,
          "completion_tokens": 55,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 331,
          "completion_tokens": 240,
          "total_tokens": 571,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 995,
        "total_completion_tokens": 535,
        "total_tokens": 1530
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 332,
          "completion_tokens": 240,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 332,
          "completion_tokens": 55,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 331,
          "completion_tokens": 240,
          "total_tokens": 571,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 56,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 339,
          "completion_tokens": 307,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 339,
          "completion_tokens": 248,
          "total_tokens": 587,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 338,
          "completion_tokens": 248,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1016,
        "total_completion_tokens": 803,
        "total_tokens": 1819
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 339,
          "completion_tokens": 307,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 339,
          "completion_tokens": 248,
          "total_tokens": 587,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 338,
          "completion_tokens": 248,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 58,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 346,
          "completion_tokens": 21,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 346,
          "completion_tokens": 21,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 345,
          "completion_tokens": 640,
          "total_tokens": 985,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1037,
        "total_completion_tokens": 682,
        "total_tokens": 1719
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 346,
          "completion_tokens": 21,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 346,
          "completion_tokens": 21,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 345,
          "completion_tokens": 640,
          "total_tokens": 985,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 60,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 354,
          "completion_tokens": 263,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 354,
          "completion_tokens": 263,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 353,
          "completion_tokens": 263,
          "total_tokens": 616,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1061,
        "total_completion_tokens": 789,
        "total_tokens": 1850
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 354,
          "completion_tokens": 263,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 354,
          "completion_tokens": 263,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 353,
          "completion_tokens": 263,
          "total_tokens": 616,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 62,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 363,
          "completion_tokens": 276,
          "total_tokens": 639,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 363,
          "completion_tokens": 12,
          "total_tokens": 375,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 362,
          "completion_tokens": 640,
          "total_tokens": 1002,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1088,
        "total_completion_tokens": 928,
        "total_tokens": 2016
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 363,
          "completion_tokens": 276,
          "total_tokens": 639,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 363,
          "completion_tokens": 12,
          "total_tokens": 375,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 362,
          "completion_tokens": 640,
          "total_tokens": 1002,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 264,
          "total_tokens": 374,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 600,
          "total_tokens": 710,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1504,
        "total_tokens": 1833
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 264,
          "total_tokens": 374,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 600,
          "total_tokens": 710,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 411,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 596,
          "total_tokens": 712,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 282,
          "total_tokens": 397,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1289,
        "total_tokens": 1636
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 411,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 596,
          "total_tokens": 712,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 282,
          "total_tokens": 397,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1920,
        "total_tokens": 2294
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 255,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 414,
          "total_tokens": 547,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1309,
        "total_tokens": 1707
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 255,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 414,
          "total_tokens": 547,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 586,
          "total_tokens": 728,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 425,
        "total_completion_tokens": 1866,
        "total_tokens": 2291
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 586,
          "total_tokens": 728,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 120,
          "total_tokens": 269,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 241,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 234,
          "total_tokens": 382,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 595,
        "total_tokens": 1041
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 120,
          "total_tokens": 269,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 241,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 234,
          "total_tokens": 382,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 158,
          "completion_tokens": 640,
          "total_tokens": 798,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 158,
          "completion_tokens": 454,
          "total_tokens": 612,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 157,
          "completion_tokens": 442,
          "total_tokens": 599,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 473,
        "total_completion_tokens": 1536,
        "total_tokens": 2009
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 158,
          "completion_tokens": 640,
          "total_tokens": 798,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 158,
          "completion_tokens": 454,
          "total_tokens": 612,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 157,
          "completion_tokens": 442,
          "total_tokens": 599,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 223,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 279,
          "total_tokens": 445,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 640,
          "total_tokens": 805,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 497,
        "total_completion_tokens": 1142,
        "total_tokens": 1639
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 223,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 279,
          "total_tokens": 445,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 640,
          "total_tokens": 805,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 176,
          "completion_tokens": 195,
          "total_tokens": 371,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 176,
          "completion_tokens": 306,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 175,
          "completion_tokens": 225,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 527,
        "total_completion_tokens": 726,
        "total_tokens": 1253
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 176,
          "completion_tokens": 195,
          "total_tokens": 371,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 176,
          "completion_tokens": 306,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 175,
          "completion_tokens": 225,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 374,
          "total_tokens": 559,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 428,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 417,
          "total_tokens": 601,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 554,
        "total_completion_tokens": 1219,
        "total_tokens": 1773
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 374,
          "total_tokens": 559,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 428,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 417,
          "total_tokens": 601,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 192,
          "completion_tokens": 342,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 578,
        "total_completion_tokens": 1622,
        "total_tokens": 2200
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 193,
          "completion_tokens": 640,
          "total_tokens": 833,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 192,
          "completion_tokens": 342,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 202,
          "completion_tokens": 164,
          "total_tokens": 366,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 202,
          "completion_tokens": 187,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 201,
          "completion_tokens": 191,
          "total_tokens": 392,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 605,
        "total_completion_tokens": 542,
        "total_tokens": 1147
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 202,
          "completion_tokens": 164,
          "total_tokens": 366,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 202,
          "completion_tokens": 187,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 201,
          "completion_tokens": 191,
          "total_tokens": 392,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 209,
          "completion_tokens": 445,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 209,
          "completion_tokens": 421,
          "total_tokens": 630,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 208,
          "completion_tokens": 640,
          "total_tokens": 848,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 626,
        "total_completion_tokens": 1506,
        "total_tokens": 2132
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 209,
          "completion_tokens": 445,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 209,
          "completion_tokens": 421,
          "total_tokens": 630,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 208,
          "completion_tokens": 640,
          "total_tokens": 848,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 218,
          "completion_tokens": 569,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 218,
          "completion_tokens": 424,
          "total_tokens": 642,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 217,
          "completion_tokens": 640,
          "total_tokens": 857,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 653,
        "total_completion_tokens": 1633,
        "total_tokens": 2286
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 218,
          "completion_tokens": 569,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 218,
          "completion_tokens": 424,
          "total_tokens": 642,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 217,
          "completion_tokens": 640,
          "total_tokens": 857,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 226,
          "completion_tokens": 640,
          "total_tokens": 866,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 226,
          "completion_tokens": 289,
          "total_tokens": 515,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 225,
          "completion_tokens": 640,
          "total_tokens": 865,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 677,
        "total_completion_tokens": 1569,
        "total_tokens": 2246
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 226,
          "completion_tokens": 640,
          "total_tokens": 866,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 226,
          "completion_tokens": 289,
          "total_tokens": 515,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 225,
          "completion_tokens": 640,
          "total_tokens": 865,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 234,
          "completion_tokens": 640,
          "total_tokens": 874,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 234,
          "completion_tokens": 640,
          "total_tokens": 874,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 233,
          "completion_tokens": 158,
          "total_tokens": 391,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 701,
        "total_completion_tokens": 1438,
        "total_tokens": 2139
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 234,
          "completion_tokens": 640,
          "total_tokens": 874,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 234,
          "completion_tokens": 640,
          "total_tokens": 874,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 233,
          "completion_tokens": 158,
          "total_tokens": 391,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 242,
          "completion_tokens": 640,
          "total_tokens": 882,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 242,
          "completion_tokens": 415,
          "total_tokens": 657,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 241,
          "completion_tokens": 264,
          "total_tokens": 505,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 725,
        "total_completion_tokens": 1319,
        "total_tokens": 2044
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 242,
          "completion_tokens": 640,
          "total_tokens": 882,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 242,
          "completion_tokens": 415,
          "total_tokens": 657,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 241,
          "completion_tokens": 264,
          "total_tokens": 505,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 35,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 250,
          "completion_tokens": 483,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 250,
          "completion_tokens": 640,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 249,
          "completion_tokens": 201,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 749,
        "total_completion_tokens": 1324,
        "total_tokens": 2073
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 250,
          "completion_tokens": 483,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 250,
          "completion_tokens": 640,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 249,
          "completion_tokens": 201,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 37,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 259,
          "completion_tokens": 640,
          "total_tokens": 899,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 259,
          "completion_tokens": 314,
          "total_tokens": 573,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 258,
          "completion_tokens": 258,
          "total_tokens": 516,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 776,
        "total_completion_tokens": 1212,
        "total_tokens": 1988
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 259,
          "completion_tokens": 640,
          "total_tokens": 899,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 259,
          "completion_tokens": 314,
          "total_tokens": 573,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 258,
          "completion_tokens": 258,
          "total_tokens": 516,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 39,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 268,
          "completion_tokens": 329,
          "total_tokens": 597,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 268,
          "completion_tokens": 304,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 267,
          "completion_tokens": 162,
          "total_tokens": 429,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 803,
        "total_completion_tokens": 795,
        "total_tokens": 1598
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 268,
          "completion_tokens": 329,
          "total_tokens": 597,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 268,
          "completion_tokens": 304,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 267,
          "completion_tokens": 162,
          "total_tokens": 429,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 41,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 278,
          "completion_tokens": 640,
          "total_tokens": 918,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 278,
          "completion_tokens": 290,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 277,
          "completion_tokens": 134,
          "total_tokens": 411,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 833,
        "total_completion_tokens": 1064,
        "total_tokens": 1897
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 278,
          "completion_tokens": 640,
          "total_tokens": 918,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 278,
          "completion_tokens": 290,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 277,
          "completion_tokens": 134,
          "total_tokens": 411,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 43,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 287,
          "completion_tokens": 356,
          "total_tokens": 643,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 287,
          "completion_tokens": 640,
          "total_tokens": 927,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 286,
          "completion_tokens": 214,
          "total_tokens": 500,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 860,
        "total_completion_tokens": 1210,
        "total_tokens": 2070
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 287,
          "completion_tokens": 356,
          "total_tokens": 643,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 287,
          "completion_tokens": 640,
          "total_tokens": 927,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 286,
          "completion_tokens": 214,
          "total_tokens": 500,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 45,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 295,
          "completion_tokens": 100,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 295,
          "completion_tokens": 100,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 294,
          "completion_tokens": 111,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 884,
        "total_completion_tokens": 311,
        "total_tokens": 1195
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 295,
          "completion_tokens": 100,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 295,
          "completion_tokens": 100,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 294,
          "completion_tokens": 111,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 47,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 304,
          "completion_tokens": 230,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 304,
          "completion_tokens": 183,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 303,
          "completion_tokens": 239,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 911,
        "total_completion_tokens": 652,
        "total_tokens": 1563
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 304,
          "completion_tokens": 230,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 304,
          "completion_tokens": 183,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 303,
          "completion_tokens": 239,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 49,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 313,
          "completion_tokens": 258,
          "total_tokens": 571,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 313,
          "completion_tokens": 332,
          "total_tokens": 645,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 312,
          "completion_tokens": 337,
          "total_tokens": 649,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 938,
        "total_completion_tokens": 927,
        "total_tokens": 1865
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 313,
          "completion_tokens": 258,
          "total_tokens": 571,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 313,
          "completion_tokens": 332,
          "total_tokens": 645,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 312,
          "completion_tokens": 337,
          "total_tokens": 649,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 51,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 321,
          "completion_tokens": 247,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 321,
          "completion_tokens": 247,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 320,
          "completion_tokens": 248,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 962,
        "total_completion_tokens": 742,
        "total_tokens": 1704
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 321,
          "completion_tokens": 247,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 321,
          "completion_tokens": 247,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 320,
          "completion_tokens": 248,
          "total_tokens": 568,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 53,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 330,
          "completion_tokens": 27,
          "total_tokens": 357,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 330,
          "completion_tokens": 63,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 329,
          "completion_tokens": 23,
          "total_tokens": 352,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 989,
        "total_completion_tokens": 113,
        "total_tokens": 1102
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 330,
          "completion_tokens": 27,
          "total_tokens": 357,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 330,
          "completion_tokens": 63,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 329,
          "completion_tokens": 23,
          "total_tokens": 352,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 55,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 640,
          "total_tokens": 977,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 115,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 637,
          "total_tokens": 973,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1010,
        "total_completion_tokens": 1392,
        "total_tokens": 2402
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 640,
          "total_tokens": 977,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 115,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 637,
          "total_tokens": 973,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 57,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 346,
          "completion_tokens": 344,
          "total_tokens": 690,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 346,
          "completion_tokens": 45,
          "total_tokens": 391,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 345,
          "completion_tokens": 426,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1037,
        "total_completion_tokens": 815,
        "total_tokens": 1852
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 346,
          "completion_tokens": 344,
          "total_tokens": 690,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 346,
          "completion_tokens": 45,
          "total_tokens": 391,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 345,
          "completion_tokens": 426,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 59,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 355,
          "completion_tokens": 522,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 355,
          "completion_tokens": 640,
          "total_tokens": 995,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 354,
          "completion_tokens": 522,
          "total_tokens": 876,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1064,
        "total_completion_tokens": 1684,
        "total_tokens": 2748
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 355,
          "completion_tokens": 522,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 355,
          "completion_tokens": 640,
          "total_tokens": 995,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 354,
          "completion_tokens": 522,
          "total_tokens": 876,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 61,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 363,
          "completion_tokens": 508,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 363,
          "completion_tokens": 502,
          "total_tokens": 865,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 362,
          "completion_tokens": 466,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1088,
        "total_completion_tokens": 1476,
        "total_tokens": 2564
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 363,
          "completion_tokens": 508,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 363,
          "completion_tokens": 502,
          "total_tokens": 865,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 362,
          "completion_tokens": 466,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 63,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 371,
          "completion_tokens": 347,
          "total_tokens": 718,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 371,
          "completion_tokens": 409,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 370,
          "completion_tokens": 640,
          "total_tokens": 1010,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1112,
        "total_completion_tokens": 1396,
        "total_tokens": 2508
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 371,
          "completion_tokens": 347,
          "total_tokens": 718,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 371,
          "completion_tokens": 409,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 370,
          "completion_tokens": 640,
          "total_tokens": 1010,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 65,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 379,
          "completion_tokens": 490,
          "total_tokens": 869,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 379,
          "completion_tokens": 90,
          "total_tokens": 469,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 378,
          "completion_tokens": 98,
          "total_tokens": 476,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1136,
        "total_completion_tokens": 678,
        "total_tokens": 1814
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 379,
          "completion_tokens": 490,
          "total_tokens": 869,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 379,
          "completion_tokens": 90,
          "total_tokens": 469,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 378,
          "completion_tokens": 98,
          "total_tokens": 476,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 67,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 388,
          "completion_tokens": 380,
          "total_tokens": 768,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 388,
          "completion_tokens": 183,
          "total_tokens": 571,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 387,
          "completion_tokens": 640,
          "total_tokens": 1027,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1163,
        "total_completion_tokens": 1203,
        "total_tokens": 2366
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 388,
          "completion_tokens": 380,
          "total_tokens": 768,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 388,
          "completion_tokens": 183,
          "total_tokens": 571,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 387,
          "completion_tokens": 640,
          "total_tokens": 1027,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 69,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 397,
          "completion_tokens": 640,
          "total_tokens": 1037,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 397,
          "completion_tokens": 640,
          "total_tokens": 1037,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 396,
          "completion_tokens": 640,
          "total_tokens": 1036,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1190,
        "total_completion_tokens": 1920,
        "total_tokens": 3110
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 397,
          "completion_tokens": 640,
          "total_tokens": 1037,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 397,
          "completion_tokens": 640,
          "total_tokens": 1037,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 396,
          "completion_tokens": 640,
          "total_tokens": 1036,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 71,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 406,
          "completion_tokens": 32,
          "total_tokens": 438,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 406,
          "completion_tokens": 27,
          "total_tokens": 433,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 405,
          "completion_tokens": 32,
          "total_tokens": 437,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1217,
        "total_completion_tokens": 91,
        "total_tokens": 1308
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 406,
          "completion_tokens": 32,
          "total_tokens": 438,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 406,
          "completion_tokens": 27,
          "total_tokens": 433,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 405,
          "completion_tokens": 32,
          "total_tokens": 437,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 73,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 415,
          "completion_tokens": 498,
          "total_tokens": 913,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 415,
          "completion_tokens": 212,
          "total_tokens": 627,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 414,
          "completion_tokens": 203,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1244,
        "total_completion_tokens": 913,
        "total_tokens": 2157
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 415,
          "completion_tokens": 498,
          "total_tokens": 913,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 415,
          "completion_tokens": 212,
          "total_tokens": 627,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 414,
          "completion_tokens": 203,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 75,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 423,
          "completion_tokens": 343,
          "total_tokens": 766,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 423,
          "completion_tokens": 29,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 422,
          "completion_tokens": 343,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1268,
        "total_completion_tokens": 715,
        "total_tokens": 1983
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 423,
          "completion_tokens": 343,
          "total_tokens": 766,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 423,
          "completion_tokens": 29,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 422,
          "completion_tokens": 343,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 77,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 433,
          "completion_tokens": 401,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 433,
          "completion_tokens": 465,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 432,
          "completion_tokens": 456,
          "total_tokens": 888,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1298,
        "total_completion_tokens": 1322,
        "total_tokens": 2620
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 433,
          "completion_tokens": 401,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 433,
          "completion_tokens": 465,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 432,
          "completion_tokens": 456,
          "total_tokens": 888,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 79,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 444,
          "completion_tokens": 504,
          "total_tokens": 948,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 444,
          "completion_tokens": 135,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 443,
          "completion_tokens": 84,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1331,
        "total_completion_tokens": 723,
        "total_tokens": 2054
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 444,
          "completion_tokens": 504,
          "total_tokens": 948,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 444,
          "completion_tokens": 135,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 443,
          "completion_tokens": 84,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 81,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 453,
          "completion_tokens": 640,
          "total_tokens": 1093,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 453,
          "completion_tokens": 92,
          "total_tokens": 545,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 452,
          "completion_tokens": 640,
          "total_tokens": 1092,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1358,
        "total_completion_tokens": 1372,
        "total_tokens": 2730
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 453,
          "completion_tokens": 640,
          "total_tokens": 1093,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 453,
          "completion_tokens": 92,
          "total_tokens": 545,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 452,
          "completion_tokens": 640,
          "total_tokens": 1092,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 83,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 460,
          "completion_tokens": 481,
          "total_tokens": 941,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 460,
          "completion_tokens": 482,
          "total_tokens": 942,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 459,
          "completion_tokens": 482,
          "total_tokens": 941,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1379,
        "total_completion_tokens": 1445,
        "total_tokens": 2824
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 460,
          "completion_tokens": 481,
          "total_tokens": 941,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 460,
          "completion_tokens": 482,
          "total_tokens": 942,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 459,
          "completion_tokens": 482,
          "total_tokens": 941,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 85,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 468,
          "completion_tokens": 369,
          "total_tokens": 837,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 468,
          "completion_tokens": 109,
          "total_tokens": 577,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 467,
          "completion_tokens": 369,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1403,
        "total_completion_tokens": 847,
        "total_tokens": 2250
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 468,
          "completion_tokens": 369,
          "total_tokens": 837,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 468,
          "completion_tokens": 109,
          "total_tokens": 577,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 467,
          "completion_tokens": 369,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 87,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 477,
          "completion_tokens": 640,
          "total_tokens": 1117,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 477,
          "completion_tokens": 640,
          "total_tokens": 1117,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 476,
          "completion_tokens": 374,
          "total_tokens": 850,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1430,
        "total_completion_tokens": 1654,
        "total_tokens": 3084
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 477,
          "completion_tokens": 640,
          "total_tokens": 1117,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 477,
          "completion_tokens": 640,
          "total_tokens": 1117,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 476,
          "completion_tokens": 374,
          "total_tokens": 850,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 89,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 416,
          "total_tokens": 900,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 41,
          "total_tokens": 525,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 8,
          "total_tokens": 491,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1451,
        "total_completion_tokens": 465,
        "total_tokens": 1916
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 416,
          "total_tokens": 900,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 41,
          "total_tokens": 525,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 8,
          "total_tokens": 491,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "black_token_log": [],
  "white_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 d5\nd4 d5 Nf3 Nf6 Bf4 Bf5 e3 e6 c4 c6 Nc3 Nbd7 Qb3 Qb6 c5 Qxb3 axb3 Be7 b4 O-O b5 cxb5 Bxb5 a6 Ba4 b5 Bb3 Rfc8 O-O Bd3 Rfd1 Bc4 Bc2 b4 Na4 b3 Bd3 Bxd3 Rxd3 Ne4 Rxb3 g5 Bg3 g4 Ne5 Nxe5 Bxe5 f6 Bg3 h5 Nb6 Nxg3 hxg3 Rcb8 Rba3 Ra7 Rxa6 Rxa6 Rxa6 Kf7 Ra7 Ke8 Kf1 Bd8 Ke2 Bxb6 cxb6 Rxb6 Kd2 e5 Kc3 Rb8 b4 Rc8+ Kd3 Rc1 b5 Rb1 Ra5 Rb1+ Kc2 Rf1 b6 Rxf2+ Kc3 Rxg2 b7 Rxg3 b8=Q+ Kf7 Rb7+ Kg6 Qg8+ Kf5 Qh7+ Ke6 Qd7#\nd4 d5 Nf3 Nf6 Bf4 Bf5 e3 e6 c4 c6 Nc3 Nbd7 Qb3 Qb6 c5 Qxb3 axb3 Be7 b4 O-O b5 cxb5 Bxb5 a6 Ba4 b5 Bb3 Rfc8 O-O Bd3 Rfd1 Bc4 Bc2 b4 Na4 b3 Bd3 Bxd3 Rxd3 Ne4 Rxb3 g5 Bg3 g4 Ne5 Nxe5 Bxe5 f6 Bg3 h5 Nb6 Nxg3 hxg3 Rcb8 Rba3 Ra7 Rxa6 Rxa6 Rxa6 Kf7 Ra7 Ke8 Kf1 Bd8 Ke2 Bxb6 cxb6 Rxb6 Kd2 e5 Kc3 Rb8 b4 Rc8+ Kd3 Rc1 b5 Rb1 Ra5 Rb1+ Kc2 Rf1 b6 Rxf2+ Kc3 Rxg2 b7 Rxg3 b8=Q+ Kf7 Rb7+ Kg6 Qg8+ Kf5 Qh7+ Ke6 Qd7# e4 e5 Nf3 Nc6 Nc3 Nbd7 Qb3 Qb6 c5 Qxb3 axb3 Be7 b4 O-O b5 cxb5 Bxb5 a6 Ba4 b5 Bb3 Rfc8 O-O Bd8 Rfd1 Bc7 Bxc7 Rxc7 b6 Rb7 Ra5 Rb1+ Kc2 Rf1 b7 Rxf2+ Kc3 Rxg2 b8=Q+ Kf7 Rb7+ Kg6 Qh8",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6",
            "Bf4",
            "Bf5",
            "e3",
            "e6",
            "c4",
            "c6",
            "Nc3",
            "Nbd7",
            "Qb3",
            "Qb6",
            "c5",
            "Qxb3",
            "axb3",
            "Be7",
            "b4",
            "O-O",
            "b5",
            "cxb5",
            "Bxb5",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Rfc8",
            "O-O",
            "Bd3",
            "Rfd1",
            "Bc4",
            "Bc2",
            "b4",
            "Na4",
            "b3",
            "Bd3",
            "Bxd3",
            "Rxd3",
            "Ne4",
            "Rxb3",
            "g5",
            "Bg3",
            "g4",
            "Ne5",
            "Nxe5",
            "Bxe5",
            "f6",
            "Bg3",
            "h5",
            "Nb6",
            "Nxg3",
            "hxg3",
            "Rcb8",
            "Rba3",
            "Ra7",
            "Rxa6",
            "Rxa6",
            "Rxa6",
            "Kf7",
            "Ra7",
            "Ke8",
            "Kf1",
            "Bd8",
            "Ke2",
            "Bxb6",
            "cxb6",
            "Rxb6",
            "Kd2",
            "e5",
            "Kc3",
            "Rb8",
            "b4",
            "Rc8+",
            "Kd3",
            "Rc1",
            "b5",
            "Rb1",
            "Ra5",
            "Rb1+",
            "Kc2",
            "Rf1",
            "b6",
            "Rxf2+",
            "Kc3",
            "Rxg2",
            "b7",
            "Rxg3",
            "b8=Q+",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Qg8+",
            "Kf5",
            "Qh7+",
            "Ke6",
            "Qd7#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Nc3",
            "Nbd7",
            "Qb3",
            "Qb6",
            "c5",
            "Qxb3",
            "axb3",
            "Be7",
            "b4",
            "O-O",
            "b5",
            "cxb5",
            "Bxb5",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Rfc8",
            "O-O",
            "Bd8",
            "Rfd1",
            "Bc7",
            "Bxc7",
            "Rxc7",
            "b6",
            "Rb7",
            "Ra5",
            "Rb1+",
            "Kc2",
            "Rf1",
            "b7",
            "Rxf2+",
            "Kc3",
            "Rxg2",
            "b8=Q+",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Qh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Qxh7 Kd8 17. Qg8+ Kd7 18. Qf7+ Kd8 19. Bg5+ Qxg5 20. Qf8+ Kd7 21. Nf6+ Kc7 22. Ne8+ Kb6 23. Qxd6 Bh3 24. Qc7+ Ka6 25. Qg3 Qxg3 26. fxg3 Rxe8 27. gxh3 Rxe4 28. Rae1 Rb4 29. b3 Nd4 30. c3 Nc2 31. cxb4 Nxe1 32. Rxe1 Kb5 33. Re4 a5 34. bxa5 Kxa5 35. h4 b5 36. h5 b4 37. h6 Kb5 38. h7 Kc5 39. h8=Q Kd5 40. Qe5+ Kc6 41. Rc4+ Kb6 42. Qc5+ Ka6 43. Qxb4 Ka7 44. Rc5 Ka6 45. Ra5# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Qxh7 Kd8 Qxh6 Kd7 Nf6+ Kc7 Ne8+ Kb6 Qxd6 Bh3 Qc7+ Ka6 Qg3 Qxg3 fxg3 Rxe8 gxh3 Rxe4 Rae1 Rb4 b3 Nd4 c3 Nc2 cxb4 Nxe1 Rxe1 Kb5 Re4 a5 bxa5 Kxa5 h4 b5 h5 b4 h6 Kb5 h7 Kc5 h8=Q Kd5 Qe5+ Kc6 Rc4+ Kb6 Qc7+ Ka6 Qc6+ Ka7 Qc7+ Ka6 Rc6+ Kb5 Qb6#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 633,
            "total_tokens": 743,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Qxh7",
            "Kd8",
            "Qxh6",
            "Kd7",
            "Nf6+",
            "Kc7",
            "Ne8+",
            "Kb6",
            "Qxd6",
            "Bh3",
            "Qc7+",
            "Ka6",
            "Qg3",
            "Qxg3",
            "fxg3",
            "Rxe8",
            "gxh3",
            "Rxe4",
            "Rae1",
            "Rb4",
            "b3",
            "Nd4",
            "c3",
            "Nc2",
            "cxb4",
            "Nxe1",
            "Rxe1",
            "Kb5",
            "Re4",
            "a5",
            "bxa5",
            "Kxa5",
            "h4",
            "b5",
            "h5",
            "b4",
            "h6",
            "Kb5",
            "h7",
            "Kc5",
            "h8=Q",
            "Kd5",
            "Qe5+",
            "Kc6",
            "Rc4+",
            "Kb6",
            "Qc7+",
            "Ka6",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka6",
            "Rc6+",
            "Kb5",
            "Qb6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5\nd4 d5 Nc3 Nf6 Bg5 e6 e4 Be7 e5 Nfd7 Bxe7 Qxe7 Nf3 O-O Bd3 c5 O-O cxd4 Nxd4 Nxe5 Re1 Nxd3 Qxd3 Nc6 Nxc6 bxc6 Nxd5 cxd5 Qxd5 exd5 Rxe7 Be6 Re1 Rfc8 c3 Kf8 Rb7 Rcb8 Rxb8+ Rxb8 b3 Rc8 Rc1 d4 c4 d3 Rd1 Bf5 f3 Rd8 g4 Bg6 h4 h6 h5 Bh7 Kf2 f5 Ke3 fxg4 fxg4 Re8+ Kd4 Re4+ Kc3 Rxg4 c5 Rg5 b4 Rxh5 c6 Ke7 c7 Kd7 Kb3 Kxc7 a4 Kb6 Kc4 Rg4+ Kc3 h5 a5+ Kb5 a6 Kxa6 b5+ Kxb5 Kd2 h4 Ke3 h3 Kf3 Rg6 Kf4 h2 Kf5 h1=Q Ke5 Qe4#\nd4 d5 Nc3 Nf6 Bg5 e6 e4 Be7 e5 Nfd7 Bxe7 Qxe7 Nf3 O-O Bd3 c5 O-O cxd4 Nxd4 Nxe5 Re1 Nxd3 Qxd3 Nc6 Nxc6 bxc6 Nxd5 cxd5 Qxd5 exd5 Rxe7 Be6 Re1 Rfc8 c3 Kf8 Rb7 Rcb8 Rxb8+ Rxb8 b3 Rc8 Rc1 d4 c4 d3 Rd1 Bf5 f3 Rd8 g4 Bg6 h4 h6 h5 Bh7 Kf2 f5 Ke3 fxg4 fxg4 Re8+ Kd4 Re4+ Kc3 Rxg4 c5 Rg5 b4 Rxh5 c6 Ke7 c7 Kd7 Kb3 Kxc7 a4 Kb6 Kc4 Rg4+ Kc3 h5 a5+ Kb5 a6 Kxa6 b5+ Kxb5 Kd2 h4 Ke3 h3 Kf3 Rg6 Kf4 h2 Kf5 h1=Q Ke5 Qe4# d4 d5 Nc3 Nf6 Bg5 e6 e4 Be7 e5 Nfd7 Bxe7 Qxe7 Nf3 O-O Bd3 c5 O-O cxd4 Nxd4 Nxe5 Re1 Nxd3 Qxd3 Nc6 Nxc6 bxc6 Nxd5 cxd5 Qxd5 exd5 Rxe7 Be6 Re1 Rfc8 c3 Kf8 Rb7 Rcb8 Rxb8+ Rxb8 b3 Rc8 Rc1 d4 c4 d",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nf3",
              "Nf6",
              "Bf4",
              "Bf5",
              "e3",
              "e6",
              "c4",
              "c6",
              "Nc3",
              "Nbd7",
              "Qb3",
              "Qb6",
              "c5",
              "Qxb3",
              "axb3",
              "Be7",
              "b4",
              "O-O",
              "b5",
              "cxb5",
              "Bxb5",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Rfc8",
              "O-O",
              "Bd3",
              "Rfd1",
              "Bc4",
              "Bc2",
              "b4",
              "Na4",
              "b3",
              "Bd3",
              "Bxd3",
              "Rxd3",
              "Ne4",
              "Rxb3",
              "g5",
              "Bg3",
              "g4",
              "Ne5",
              "Nxe5",
              "Bxe5",
              "f6",
              "Bg3",
              "h5",
              "Nb6",
              "Nxg3",
              "hxg3",
              "Rcb8",
              "Rba3",
              "Ra7",
              "Rxa6",
              "Rxa6",
              "Rxa6",
              "Kf7",
              "Ra7",
              "Ke8",
              "Kf1",
              "Bd8",
              "Ke2",
              "Bxb6",
              "cxb6",
              "Rxb6",
              "Kd2",
              "e5",
              "Kc3",
              "Rb8",
              "b4",
              "Rc8+",
              "Kd3",
              "Rc1",
              "b5",
              "Rb1",
              "Ra5",
              "Rb1+",
              "Kc2",
              "Rf1",
              "b6",
              "Rxf2+",
              "Kc3",
              "Rxg2",
              "b7",
              "Rxg3",
              "b8=Q+",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Qg8+",
              "Kf5",
              "Qh7+",
              "Ke6",
              "Qd7#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Nc3",
              "Nbd7",
              "Qb3",
              "Qb6",
              "c5",
              "Qxb3",
              "axb3",
              "Be7",
              "b4",
              "O-O",
              "b5",
              "cxb5",
              "Bxb5",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Rfc8",
              "O-O",
              "Bd8",
              "Rfd1",
              "Bc7",
              "Bxc7",
              "Rxc7",
              "b6",
              "Rb7",
              "Ra5",
              "Rb1+",
              "Kc2",
              "Rf1",
              "b7",
              "Rxf2+",
              "Kc3",
              "Rxg2",
              "b8=Q+",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Qh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Qxh7",
              "Kd8",
              "Qxh6",
              "Kd7",
              "Nf6+",
              "Kc7",
              "Ne8+",
              "Kb6",
              "Qxd6",
              "Bh3",
              "Qc7+",
              "Ka6",
              "Qg3",
              "Qxg3",
              "fxg3",
              "Rxe8",
              "gxh3",
              "Rxe4",
              "Rae1",
              "Rb4",
              "b3",
              "Nd4",
              "c3",
              "Nc2",
              "cxb4",
              "Nxe1",
              "Rxe1",
              "Kb5",
              "Re4",
              "a5",
              "bxa5",
              "Kxa5",
              "h4",
              "b5",
              "h5",
              "b4",
              "h6",
              "Kb5",
              "h7",
              "Kc5",
              "h8=Q",
              "Kd5",
              "Qe5+",
              "Kc6",
              "Rc4+",
              "Kb6",
              "Qc7+",
              "Ka6",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka6",
              "Rc6+",
              "Kb5",
              "Qb6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 633,
            "total_tokens": 743,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1913,
          "total_tokens": 2242
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 633,
            "total_tokens": 743,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 O-O 7. Bd3 d6 8. c3 Nc6 9. Qc2 g6 10. O-O-O a6 11. h4 b5 12. h5 b4 13. hxg6 hxg6 14. exf5 exf5 15. g4 bxc3 16. bxc3 Ne7 17. gxf5 Bxf5 18. Rdg1 Bg7 19. Nh4 Bxd3 20. Qxd3 Rxf2 21. Nxg6 Nxg6 22. Qxg6 Qf6 23. Qh7+ Kf8 24. Rg6 Qf7 25. Rhg1 Qxa2 26. Qxg7+ Ke8 27. Re1+ Kd8 28. Qg8+ Qxg8 29. Rxg8+ Kd7 30. Rxa8 Kc6 31. Rxa6+ Kb5 32. Ra7 c5 33. dxc5 dxc5 34. Re5 Kb6 35. Rae7 Kb5 36. Rc7 Ka4 37. Rexc5 Rf4 38. Rb7 Rf1+ 39. Kc2 Rf2 40. Rc8 Rf5 41. Ra8+ Ra5 42. Rxa5+ Kxa5 43. c4 Ka6 44. Rb1 Ka5 45. c5 Ka4 46. c6 Ka3 47. c7 Ka2 48. c8=Q Ka3 49. Qa8# e4 Nc3 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "O-O",
            "Bd3",
            "d6",
            "c3",
            "Nc6",
            "Qc2",
            "g6",
            "O-O-O",
            "a6",
            "h4",
            "b5",
            "h5",
            "b4",
            "hxg6",
            "hxg6",
            "exf5",
            "exf5",
            "g4",
            "bxc3",
            "bxc3",
            "Ne7",
            "gxf5",
            "Bxf5",
            "Rdg1",
            "Bg7",
            "Nh4",
            "Bxd3",
            "Qxd3",
            "Rxf2",
            "Nxg6",
            "Nxg6",
            "Qxg6",
            "Qf6",
            "Qh7+",
            "Kf8",
            "Rg6",
            "Qf7",
            "Rhg1",
            "Qxa2",
            "Qxg7+",
            "Ke8",
            "Re1+",
            "Kd8",
            "Qg8+",
            "Qxg8",
            "Rxg8+",
            "Kd7",
            "Rxa8",
            "Kc6",
            "Rxa6+",
            "Kb5",
            "Ra7",
            "c5",
            "dxc5",
            "dxc5",
            "Re5",
            "Kb6",
            "Rae7",
            "Kb5",
            "Rc7",
            "Ka4",
            "Rexc5",
            "Rf4",
            "Rb7",
            "Rf1+",
            "Kc2",
            "Rf2",
            "Rc8",
            "Rf5",
            "Ra8+",
            "Ra5",
            "Rxa5+",
            "Kxa5",
            "c4",
            "Ka6",
            "Rb1",
            "Ka5",
            "c5",
            "Ka4",
            "c6",
            "Ka3",
            "c7",
            "Ka2",
            "c8=Q",
            "Ka3",
            "Qa8#",
            "e4",
            "Nc3",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nf6 3. c4 e6 4. Nc3 Bb4 5. Qc2 O-O 6. g3 b6 7. Bg2 Bb7 8. O-O Bxc3 9. Qxc3 d6 10. b3 Nbd7 11. Bb2 Qe7 12. Rad1 Rae8 13. Rfe1 Ne4 14. Qc2 Ndf6 15. Nd2 Nxf2 16. Kxf2 Ng4+ 17. Kg1 Ne3 18. Qd3 Nxg2 19. Rf1 f4 20. d5 Ne3 21. Rxf4 Nxd1 22. Rh4 g6 23. Ba1 exd5 24. cxd5 Qxe2 25. Qd4 Qe1+ 26. Kg2 Ne3+ 27. Kh3 Bc8+ 28. g4 Rf3+ 29. Nxf3 Qf1+ 30. Kg3 Qg2+ 31. Kf4 Rf8+ 32. Kg5 Qxf3 33. Qg7# Nf3+ 34. Kh6 Qf4+ 35. g5 Qxh4# Nf5+ 37. Qxf5 Rxf5 38. Bf6 Rxf6 39. gxf6 Qxh4# Nf3+ 41. Kh6 Qxh4# Nf3+ 43. Kh6 Qxh4# Nf3+ 45. Kh6 Qxh4# Nf3+ 47. Kh6 Qxh4# Nf3+ 49. Kh6 Qxh4# Nf3+ 51. Kh6 Qxh4# Nf3+ 53. Kh6 Qxh4# Nf3+ 55. Kh6 Qxh4# Nf3+ 57. Kh6 Qxh4# Nf3+ 59. Kh6 Qxh4# Nf3+ 61. Kh6 Qxh4# Nf3+ 63. Kh6 Qxh4# Nf3+ 65. Kh6 Qxh4# Nf3+ 67. Kh6 Qxh4# Nf3+ 69. Kh6 Qxh4# Nf3+ 71. Kh6 Qxh4# Nf3+ 73. Kh6 Qxh4# Nf3+ 75. Kh6 Qxh4# Nf3+ 77. Kh6 Qxh4# Nf3+ 79. Kh6 Qxh4# Nf3+ 81. Kh6 Qxh4# Nf3+ 83. Kh6 Qxh4# Nf3+ 85. Kh6",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nf6 3. c4 e6 4. Nc3 Bb4 5. Qc2 O-O 6. g3 b6 7. Bg2 Bb7 8. O-O Bxc3 9. Qxc3 d6 10. b3 Nbd7 11. Bb2 Qe7 12. Rad1 Rae8 13. Rfe1 Ne4 14. Qc2 Ndf6 15. Nd2 Nxd2 16. Bxb7 Nde4 17. f3 Ng5 18. h4 Nf7 19. Bc6 Rd8 20. e4 fxe4 21. Bxe4 Nxe4 22. Qxe4 Rde8 23. Kg2 Qd7 24. Qg4 Nh6 25. Qh3 Qf7 26. g4 Qf4 27. Bc1 Qf6 28. Bg5 Qg6 29. Re2 Nf7 30. Bc1 e5 31. h5 Qf6 32. d5 Ng5 33. Bxg5 Qxg5 34. Qg3 Rf4 35. Rde1 Ref8 36. Re4 Rxf3 37. Qxf3 Rxf3 38. Kxf3 Qd2 39. R1e2 Qd3+ 40. R4e3 Qd1 41. Kg2 Qd4 42. Re4 Qd3 43. R4e3 Qd4 44. Re4 Qd3 45. R4e3 Qd4 46. Re4 Qd3 47. R4e3 Qd4 48. Re4 Qd3 49. R4e3 Qd4 50. Re4 Qd3 51. R4e3 Qd4 52. Re4 Qd3 53. R4e3 Qd4 54. Re4 Qd3 55. R4e3 Qd4 56. Re4 Qd3 57. R4e3 Qd4 58. Re4 Qd3 59. R4e3 Qd4 60. Re4 Qd3 61. R4e3 Qd4 62. Re4 Qd3 63. R4e3 Qd4 64. Re4 Qd3 65. R4e3 Qd4 66. Re4 Qd3 67. R4e3 Qd4 68. Re4 Qd3 69. R4e3 Qd4 70. Re4 Qd3 71. R4e3 Qd4 72. Re4 Qd3 73. R4e3 Qd4 74. Re4 Qd3 75. R4e3",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "c4",
            "e6",
            "Nc3",
            "Bb4",
            "Qc2",
            "O-O",
            "g3",
            "b6",
            "Bg2",
            "Bb7",
            "O-O",
            "Bxc3",
            "Qxc3",
            "d6",
            "b3",
            "Nbd7",
            "Bb2",
            "Qe7",
            "Rad1",
            "Rae8",
            "Rfe1",
            "Ne4",
            "Qc2",
            "Ndf6",
            "Nd2",
            "Nxd2",
            "Bxb7",
            "Nde4",
            "f3",
            "Ng5",
            "h4",
            "Nf7",
            "Bc6",
            "Rd8",
            "e4",
            "fxe4",
            "Bxe4",
            "Nxe4",
            "Qxe4",
            "Rde8",
            "Kg2",
            "Qd7",
            "Qg4",
            "Nh6",
            "Qh3",
            "Qf7",
            "g4",
            "Qf4",
            "Bc1",
            "Qf6",
            "Bg5",
            "Qg6",
            "Re2",
            "Nf7",
            "Bc1",
            "e5",
            "h5",
            "Qf6",
            "d5",
            "Ng5",
            "Bxg5",
            "Qxg5",
            "Qg3",
            "Rf4",
            "Rde1",
            "Ref8",
            "Re4",
            "Rxf3",
            "Qxf3",
            "Rxf3",
            "Kxf3",
            "Qd2",
            "R1e2",
            "Qd3+",
            "R4e3",
            "Qd1",
            "Kg2",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "O-O",
              "Bd3",
              "d6",
              "c3",
              "Nc6",
              "Qc2",
              "g6",
              "O-O-O",
              "a6",
              "h4",
              "b5",
              "h5",
              "b4",
              "hxg6",
              "hxg6",
              "exf5",
              "exf5",
              "g4",
              "bxc3",
              "bxc3",
              "Ne7",
              "gxf5",
              "Bxf5",
              "Rdg1",
              "Bg7",
              "Nh4",
              "Bxd3",
              "Qxd3",
              "Rxf2",
              "Nxg6",
              "Nxg6",
              "Qxg6",
              "Qf6",
              "Qh7+",
              "Kf8",
              "Rg6",
              "Qf7",
              "Rhg1",
              "Qxa2",
              "Qxg7+",
              "Ke8",
              "Re1+",
              "Kd8",
              "Qg8+",
              "Qxg8",
              "Rxg8+",
              "Kd7",
              "Rxa8",
              "Kc6",
              "Rxa6+",
              "Kb5",
              "Ra7",
              "c5",
              "dxc5",
              "dxc5",
              "Re5",
              "Kb6",
              "Rae7",
              "Kb5",
              "Rc7",
              "Ka4",
              "Rexc5",
              "Rf4",
              "Rb7",
              "Rf1+",
              "Kc2",
              "Rf2",
              "Rc8",
              "Rf5",
              "Ra8+",
              "Ra5",
              "Rxa5+",
              "Kxa5",
              "c4",
              "Ka6",
              "Rb1",
              "Ka5",
              "c5",
              "Ka4",
              "c6",
              "Ka3",
              "c7",
              "Ka2",
              "c8=Q",
              "Ka3",
              "Qa8#",
              "e4",
              "Nc3",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "c4",
              "e6",
              "Nc3",
              "Bb4",
              "Qc2",
              "O-O",
              "g3",
              "b6",
              "Bg2",
              "Bb7",
              "O-O",
              "Bxc3",
              "Qxc3",
              "d6",
              "b3",
              "Nbd7",
              "Bb2",
              "Qe7",
              "Rad1",
              "Rae8",
              "Rfe1",
              "Ne4",
              "Qc2",
              "Ndf6",
              "Nd2",
              "Nxd2",
              "Bxb7",
              "Nde4",
              "f3",
              "Ng5",
              "h4",
              "Nf7",
              "Bc6",
              "Rd8",
              "e4",
              "fxe4",
              "Bxe4",
              "Nxe4",
              "Qxe4",
              "Rde8",
              "Kg2",
              "Qd7",
              "Qg4",
              "Nh6",
              "Qh3",
              "Qf7",
              "g4",
              "Qf4",
              "Bc1",
              "Qf6",
              "Bg5",
              "Qg6",
              "Re2",
              "Nf7",
              "Bc1",
              "e5",
              "h5",
              "Qf6",
              "d5",
              "Ng5",
              "Bxg5",
              "Qxg5",
              "Qg3",
              "Rf4",
              "Rde1",
              "Ref8",
              "Re4",
              "Rxf3",
              "Qxf3",
              "Rxf3",
              "Kxf3",
              "Qd2",
              "R1e2",
              "Qd3+",
              "R4e3",
              "Qd1",
              "Kg2",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1691,
          "total_tokens": 2038
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppppp1pp/8/5p2/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. O-O Ne4 8. Bxe7 Qxe7 9. Ne5 Nd7 10. Nxd7 Bxd7 11. f3 Nxd2 12. Qxd2 c5 13. c3 c4 14. Bc2 b5 15. e4 fxe4 16. fxe4 Rxf1+ 17. Rxf1 Rf8 18. Rxf8+ Qxf8 19. exd5 exd5 20. Qg5 Qd6 21. Qd8+ Kf7 22. Bxh7 Qe6 23. Qg8+ Kf6 24. Qxe6+ Bxe6 25. Bc2 a5 26. Kf2 b4 27. Kf3 g5 28. g3 Bd7 29. h4 gxh4 30. gxh4 Be8 31. Kf4 Bh5 32. Bf5 Bd1 33. Bg4 Bc2 34. Bf3 Ke6 35. h5 bxc3 36. bxc3 a4 37. a3 Bd3 38. Kg5 Be4 39. Bg4+ Kf7 40. Bf5 Bf3 41. h6 Be4 42. Bxe4 dxe4 43. Kf4 Kg6 44. Kxe4 Kxh6 45. Kd5 Kg6 46. Kxc4 Kf6 47. Kb4 Ke6 48. Kxa4 Kd5 49. Kb5 Kd6 50. c4 Kc7 51. c5 Kb7 52. d5 Kc7 53. d6+ Kb7 54. c6+ Kc8 55. Kb6 Kb8 56. d7 Ka8 57. d8=Q# 1-0 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. O-O Ne4 8. Bxe7 Qxe7 9. Ne5 Nd7 10. Nxd7 Bxd7 11. f3 Nxd2 12. Qxd2 c5 13. c3 c4 14. Bc2 b5 15. e4 fxe4 16. fxe4 Rxf1+ 17. Rxf1 Rf8 18. Rxf8+ Qxf8 19. exd5 exd5 20. Qg5 Qd6 21. Qd8+ Kf7 22. Bxh7 Q",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "O-O",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Ne5",
            "Nd7",
            "Nxd7",
            "Bxd7",
            "f3",
            "Nxd2",
            "Qxd2",
            "c5",
            "c3",
            "c4",
            "Bc2",
            "b5",
            "e4",
            "fxe4",
            "fxe4",
            "Rxf1+",
            "Rxf1",
            "Rf8",
            "Rxf8+",
            "Qxf8",
            "exd5",
            "exd5",
            "Qg5",
            "Qd6",
            "Qd8+",
            "Kf7",
            "Bxh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. Ne5 Nbd7 8. Ndf3 Ne4 9. Bxe7 Qxe7 10. O-O Nxe5 11. Nxe5 Bd7 12. c4 c6 13. c5 Be8 14. f3 Ng5 15. b4 Nf7 16. Nxf7 Bxf7 17. f4 g5 18. g3 Kh8 19. a4 Rg8 20. Kh1 Rg7 21. b5 Rag8 22. bxc6 bxc6 23. Rb1 Qe8 24. Be2 h5 25. Rb7 h4 26. gxh4 gxh4 27. Bf3 Bg6 28. Rxg7 Rxg7 29. Rg1 Qb8 30. Qe1 Qd8 31. Rg5 Kg8 32. Qxh4 Qa5 33. Qg3 Kf7 34. Bh5 Bxh5 35. Rxg7+ Ke8 36. Rg8+ Kd7 37. Qg7+ Bf7 38. Qxf7# e4 Qe8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "Ne5",
            "Nbd7",
            "Ndf3",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Nxe5",
            "Nxe5",
            "Bd7",
            "c4",
            "c6",
            "c5",
            "Be8",
            "f3",
            "Ng5",
            "b4",
            "Nf7",
            "Nxf7",
            "Bxf7",
            "f4",
            "g5",
            "g3",
            "Kh8",
            "a4",
            "Rg8",
            "Kh1",
            "Rg7",
            "b5",
            "Rag8",
            "bxc6",
            "bxc6",
            "Rb1",
            "Qe8",
            "Be2",
            "h5",
            "Rb7",
            "h4",
            "gxh4",
            "gxh4",
            "Bf3",
            "Bg6",
            "Rxg7",
            "Rxg7",
            "Rg1",
            "Qb8",
            "Qe1",
            "Qd8",
            "Rg5",
            "Kg8",
            "Qxh4",
            "Qa5",
            "Qg3",
            "Kf7",
            "Bh5",
            "Bxh5",
            "Rxg7+",
            "Ke8",
            "Rg8+",
            "Kd7",
            "Qg7+",
            "Bf7",
            "Qxf7#",
            "e4",
            "Qe8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bg5",
          "neutral_uci": "c1g5",
          "neutral_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. O-O Ne4 8. Bxe7 Qxe7 9. Ne5 Nd7 10. Nxd7 Bxd7 11. f3 Nxd2 12. Qxd2 c5 13. c3 c4 14. Bc2 b5 15. e4 fxe4 16. fxe4 Rxf1+ 17. Rxf1 Rf8 18. Rxf8+ Qxf8 19. exd5 exd5 20. Qg5 Qd6 21. Qd8+ Kf7 22. Bxh7 Qe6 23. Qg8+ Kf6 24. Qxe6+ Bxe6 25. Bc2 a5 26. Kf2 b4 27. Ke3 g5 28. g3 Bg4 29. h4 gxh4 30. gxh4 Bh5 31. Kf4 Be2 32. Bf5 Bd1 33. Bg4 Bc2 34. Bf3 Ke6 35. Kg5 bxc3 36. bxc3 a4 37. a3 Be4 38. Bg4+ Kf7 39. Bf5 Bf3 40. h5 Kg7 41. h6+ Kh8 42. Kf6 Be4 43. Ke5 Bf3 44. Be6 Kh7 45. Bxd5 Be2 46. Bc6 Kxh6 47. Bxa4 Kg7 48. Bb5 Kf8 49. Kd5 Ke7 50. Bxc4 Bf3+ 51. Kc5 Kd7 52. Bd5 Be2 53. c4 Kc7 54. a4 Bd1 55. a5 Ba4 56. a6 Kb8 57. Kb6 Bc6 58. Bxc6 Kc8 59. a7 Kd8 60. a8=Q+ Ke7 61. Qe8+ Kf6 62. Qe5+ Kg6 63. Be4+ Kf7 64. Qf5+ Ke7 65. Qg6 Kd7 66. Bf5+ Ke7 67. Qe6+ Kf8 68. Qd7 Kg8 69. Bg6 Kh8 70. Qh7# e4 d3 d2 d1=Q dxe4 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "O-O",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Ne5",
            "Nd7",
            "Nxd7",
            "Bxd7",
            "f3",
            "Nxd2",
            "Qxd2",
            "c5",
            "c3",
            "c4",
            "Bc2",
            "b5",
            "e4",
            "fxe4",
            "fxe4",
            "Rxf1+",
            "Rxf1",
            "Rf8",
            "Rxf8+",
            "Qxf8",
            "exd5",
            "exd5",
            "Qg5",
            "Qd6",
            "Qd8+",
            "Kf7",
            "Bxh7",
            "Qe6",
            "Qg8+",
            "Kf6",
            "Qxe6+",
            "Bxe6",
            "Bc2",
            "a5",
            "Kf2",
            "b4",
            "Ke3",
            "g5",
            "g3",
            "Bg4",
            "h4",
            "gxh4",
            "gxh4",
            "Bh5",
            "Kf4",
            "Be2",
            "Bf5",
            "Bd1",
            "Bg4",
            "Bc2",
            "Bf3",
            "Ke6",
            "Kg5",
            "bxc3",
            "bxc3",
            "a4",
            "a3",
            "Be4",
            "Bg4+",
            "Kf7",
            "Bf5",
            "Bf3",
            "h5",
            "Kg7",
            "h6+",
            "Kh8",
            "Kf6",
            "Be4",
            "Ke5",
            "Bf3",
            "Be6",
            "Kh7",
            "Bxd5",
            "Be2",
            "Bc6",
            "Kxh6",
            "Bxa4",
            "Kg7",
            "Bb5",
            "Kf8",
            "Kd5",
            "Ke7",
            "Bxc4",
            "Bf3+",
            "Kc5",
            "Kd7",
            "Bd5",
            "Be2",
            "c4",
            "Kc7",
            "a4",
            "Bd1",
            "a5",
            "Ba4",
            "a6",
            "Kb8",
            "Kb6",
            "Bc6",
            "Bxc6",
            "Kc8",
            "a7",
            "Kd8",
            "a8=Q+",
            "Ke7",
            "Qe8+",
            "Kf6",
            "Qe5+",
            "Kg6",
            "Be4+",
            "Kf7",
            "Qf5+",
            "Ke7",
            "Qg6",
            "Kd7",
            "Bf5+",
            "Ke7",
            "Qe6+",
            "Kf8",
            "Qd7",
            "Kg8",
            "Bg6",
            "Kh8",
            "Qh7#",
            "e4",
            "d3",
            "d2",
            "d1=Q",
            "dxe4",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": "c1g5",
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "O-O",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Ne5",
              "Nd7",
              "Nxd7",
              "Bxd7",
              "f3",
              "Nxd2",
              "Qxd2",
              "c5",
              "c3",
              "c4",
              "Bc2",
              "b5",
              "e4",
              "fxe4",
              "fxe4",
              "Rxf1+",
              "Rxf1",
              "Rf8",
              "Rxf8+",
              "Qxf8",
              "exd5",
              "exd5",
              "Qg5",
              "Qd6",
              "Qd8+",
              "Kf7",
              "Bxh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "Ne5",
              "Nbd7",
              "Ndf3",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "O-O",
              "Nxe5",
              "Nxe5",
              "Bd7",
              "c4",
              "c6",
              "c5",
              "Be8",
              "f3",
              "Ng5",
              "b4",
              "Nf7",
              "Nxf7",
              "Bxf7",
              "f4",
              "g5",
              "g3",
              "Kh8",
              "a4",
              "Rg8",
              "Kh1",
              "Rg7",
              "b5",
              "Rag8",
              "bxc6",
              "bxc6",
              "Rb1",
              "Qe8",
              "Be2",
              "h5",
              "Rb7",
              "h4",
              "gxh4",
              "gxh4",
              "Bf3",
              "Bg6",
              "Rxg7",
              "Rxg7",
              "Rg1",
              "Qb8",
              "Qe1",
              "Qd8",
              "Rg5",
              "Kg8",
              "Qxh4",
              "Qa5",
              "Qg3",
              "Kf7",
              "Bh5",
              "Bxh5",
              "Rxg7+",
              "Ke8",
              "Rg8+",
              "Kd7",
              "Qg7+",
              "Bf7",
              "Qxf7#",
              "e4",
              "Qe8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "O-O",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Ne5",
              "Nd7",
              "Nxd7",
              "Bxd7",
              "f3",
              "Nxd2",
              "Qxd2",
              "c5",
              "c3",
              "c4",
              "Bc2",
              "b5",
              "e4",
              "fxe4",
              "fxe4",
              "Rxf1+",
              "Rxf1",
              "Rf8",
              "Rxf8+",
              "Qxf8",
              "exd5",
              "exd5",
              "Qg5",
              "Qd6",
              "Qd8+",
              "Kf7",
              "Bxh7",
              "Qe6",
              "Qg8+",
              "Kf6",
              "Qxe6+",
              "Bxe6",
              "Bc2",
              "a5",
              "Kf2",
              "b4",
              "Ke3",
              "g5",
              "g3",
              "Bg4",
              "h4",
              "gxh4",
              "gxh4",
              "Bh5",
              "Kf4",
              "Be2",
              "Bf5",
              "Bd1",
              "Bg4",
              "Bc2",
              "Bf3",
              "Ke6",
              "Kg5",
              "bxc3",
              "bxc3",
              "a4",
              "a3",
              "Be4",
              "Bg4+",
              "Kf7",
              "Bf5",
              "Bf3",
              "h5",
              "Kg7",
              "h6+",
              "Kh8",
              "Kf6",
              "Be4",
              "Ke5",
              "Bf3",
              "Be6",
              "Kh7",
              "Bxd5",
              "Be2",
              "Bc6",
              "Kxh6",
              "Bxa4",
              "Kg7",
              "Bb5",
              "Kf8",
              "Kd5",
              "Ke7",
              "Bxc4",
              "Bf3+",
              "Kc5",
              "Kd7",
              "Bd5",
              "Be2",
              "c4",
              "Kc7",
              "a4",
              "Bd1",
              "a5",
              "Ba4",
              "a6",
              "Kb8",
              "Kb6",
              "Bc6",
              "Bxc6",
              "Kc8",
              "a7",
              "Kd8",
              "a8=Q+",
              "Ke7",
              "Qe8+",
              "Kf6",
              "Qe5+",
              "Kg6",
              "Be4+",
              "Kf7",
              "Qf5+",
              "Ke7",
              "Qg6",
              "Kd7",
              "Bf5+",
              "Ke7",
              "Qe6+",
              "Kf8",
              "Qd7",
              "Kg8",
              "Bg6",
              "Kh8",
              "Qh7#",
              "e4",
              "d3",
              "d2",
              "d1=Q",
              "dxe4",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1920,
          "total_tokens": 2294
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppppp1pp/5n2/5p2/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd2",
          "aggressive_uci": "b1d2",
          "aggressive_response": "4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O c5 11. c3 cxd4 12. cxd4 Nc6 13. Rc1 Bd7 14. Bb5 Rac8 15. Bxc6 Bxc6 16. Ne5 Bb5 17. Rxc8 Rxc8 18. Re1 Qf4 19. g3 Qf5 20. Qb3 Rc2 21. f4 Bc4 22. Qxb7 h6 23. Qc8+ Kh7 24. Nxc4 dxc4 25. Qxe6 Qxe6 26. Rxe6 Rxb2 27. Rc6 Rxa2 28. Rxc4 Kg6 29. Rc5 Kf6 30. g4 a5 31. Rc6+ Kf7 32. Ra6 a4 33. h4 a3 34. g5 hxg5 35. hxg5 g6 36. d5 Rd2 37. Rxa3 Rxd5 38. Kf2 Ke6 39. Kf3 Kf5 40. Re3 Rd4 41. Re5# e4+ Nxe4 Qxe4",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 316,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "c5",
            "c3",
            "cxd4",
            "cxd4",
            "Nc6",
            "Rc1",
            "Bd7",
            "Bb5",
            "Rac8",
            "Bxc6",
            "Bxc6",
            "Ne5",
            "Bb5",
            "Rxc8",
            "Rxc8",
            "Re1",
            "Qf4",
            "g3",
            "Qf5",
            "Qb3",
            "Rc2",
            "f4",
            "Bc4",
            "Qxb7",
            "h6",
            "Qc8+",
            "Kh7",
            "Nxc4",
            "dxc4",
            "Qxe6",
            "Qxe6",
            "Rxe6",
            "Rxb2",
            "Rc6",
            "Rxa2",
            "Rxc4",
            "Kg6",
            "Rc5",
            "Kf6",
            "g4",
            "a5",
            "Rc6+",
            "Kf7",
            "Ra6",
            "a4",
            "h4",
            "a3",
            "g5",
            "hxg5",
            "hxg5",
            "g6",
            "d5",
            "Rd2",
            "Rxa3",
            "Rxd5",
            "Kf2",
            "Ke6",
            "Kf3",
            "Kf5",
            "Re3",
            "Rd4",
            "Re5#",
            "e4+",
            "Nxe4",
            "Qxe4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nbd2",
          "positional_uci": "b1d2",
          "positional_response": "4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O c5 11. c3 cxd4 12. cxd4 Nc6 13. Rc1 Bd7 14. Re1 Rae8 15. Qd2 Kh8 16. Bb1 e5 17. dxe5 Nxe5 18. Nxe5 Rxe5 19. Rxe5 Qxe5 20. Re1 Qd6 21. Qd3 Bf5 22. Qxf5 Rxf5 23. Bxf5 g6 24. Bd3 Kg7 25. g3 Kf6 26. Re2 Qc5 27. Kg2 Qd4 28. Bc2 Qc4 29. Rd2 Qxa2 30. Bd1 Qa5 31. Rd3 Ke5 32. Bf3 b6 33. h4 d4 34. Ra3 Qb4 35. Rxa7 Qxb2 36. Rxh7 d3 37. Rd7 d2 38. Rd5+ Ke6 39. Rd3 b5 40. Bd1 b4 41. Kf1 Qc1 42. Ke2 Qc4 43. Kxd2 Qa2+ 44. Ke3 Qa7+ 45. Ke2 Qa2+ 46. Rd2 Qc4+ 47. Ke1 b3 48. Re2+ Kf6 49. Rb2 Qc3+ 50. Rd2 b2 51. Bc2 Qxc2 52. Rxc2 b1=Q+ 53. Kd2 Qb4+ 54. Ke2 Qe4+ 55. Kd2 Qd4+ 56. Ke2 Kf5 57. Rd2 Qc4+ 58. Ke3 Qe4# 0-1\nd4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 fxe4 Nxe4 O-O Bd3 d5 Nxf6+ Qxf6 O-O c5 c3 cxd4 cxd4 Nc6 Rc1 Bd7 Re1 Rae8 Qd2 Kh8 Bb1 e5 dxe5 Nxe5 Nxe5 Rxe5 Rxe5 Qxe5 Re1 Qd6 Qd3 Bf5 Qxf5 Rxf5 Bxf5 g6 Bd3 Kg7 g3 Kf6 Re2 Qc5 Kg2 Qd4 Rd2 Qc5 Be2 Qc1 Rd3 Qxb2 Rf3+ Ke5 Re3+ Kd6 a3 d4 Rd3 Kc5 B",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "c5",
            "c3",
            "cxd4",
            "cxd4",
            "Nc6",
            "Rc1",
            "Bd7",
            "Re1",
            "Rae8",
            "Qd2",
            "Kh8",
            "Bb1",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Rxe5",
            "Qxe5",
            "Re1",
            "Qd6",
            "Qd3",
            "Bf5",
            "Qxf5",
            "Rxf5",
            "Bxf5",
            "g6",
            "Bd3",
            "Kg7",
            "g3",
            "Kf6",
            "Re2",
            "Qc5",
            "Kg2",
            "Qd4",
            "Rd2",
            "Qc5",
            "Be2",
            "Qc1",
            "Rd3",
            "Qxb2",
            "Rf3+",
            "Ke5",
            "Re3+",
            "Kd6",
            "a3",
            "d4",
            "Rd3",
            "Kc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nbd2",
          "neutral_uci": "b1d2",
          "neutral_response": "4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qe2 Rae8 13. Rae1 Re7 14. Ne5 Nxe5 15. Qxe5 Qxe5 16. Rxe5 Rf6 17. Rfe1 Kf7 18. g3 g6 19. f4 b6 20. b4 c6 21. a4 Bc8 22. Ra1 Rc7 23. a5 b5 24. Rae1 Re7 25. Kg2 Bd7 26. h3 Kg7 27. Rf1 Ref7 28. Rf2 h6 29. h4 h5 30. Rfe2 Re7 31. Rg5 Kf7 32. Ree5 Be8 33. Kf3 Kg7 34. Ke3 Kh6 35. Kd2 Bf7 36. Be2 Be8 37. Ke3 Bf7 38. g4 hxg4 39. Bxg4 Be8 40. h5 gxh5 41. Bxh5 Bxh5 42. Rxh5+ Kg7 43. Reg5+ Rg6 44. Rxg6+ Kxg6 45. Rh8 Kf5 46. Rc8 Rh7 47. Rxc6 Rh3+ 48. Kd2 Kxf4 49. Rxe6 Rh2+ 50. Kd3 Rh3+ 51. Kc2 Rh2+ 52. Kb3 Rh5 53. Re7 a6 54. Re6 Rh1 55. Rxa6 Rb1+ 56. Kc2 Ra1 57. Rb6 Ke4 58. Rxb5 Ra2+ 59. Kb3 Ra1 60. Rb6 Kd3 61. Rc6 Rb1+ 62. Ka4 Ra1+ 63. Kb5 Ra3 64. a6 Ra1 65. Kb6 Ra3 66. a7 Ra1 67. Kb7 Ra3 68. a8=Q Rxa8 69. Kxa8 Ke4 70. b5 Kd3 71. b6 Ke4 72. b7 Kd3 73. b8=Q Ke4 74. Qe5+ Kd3 75. Qxd5 Kc2 76. Qf3 Kb3 77. c4+ Kb4 78. Rb6+ Kxc4 79. Qb3+ Kxd4 80. Rd6+ Ke5 81. Qd5+ Kf4 82.",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qe2",
            "Rae8",
            "Rae1",
            "Re7",
            "Ne5",
            "Nxe5",
            "Qxe5",
            "Qxe5",
            "Rxe5",
            "Rf6",
            "Rfe1",
            "Kf7",
            "g3",
            "g6",
            "f4",
            "b6",
            "b4",
            "c6",
            "a4",
            "Bc8",
            "Ra1",
            "Rc7",
            "a5",
            "b5",
            "Rae1",
            "Re7",
            "Kg2",
            "Bd7",
            "h3",
            "Kg7",
            "Rf1",
            "Ref7",
            "Rf2",
            "h6",
            "h4",
            "h5",
            "Rfe2",
            "Re7",
            "Rg5",
            "Kf7",
            "Ree5",
            "Be8",
            "Kf3",
            "Kg7",
            "Ke3",
            "Kh6",
            "Kd2",
            "Bf7",
            "Be2",
            "Be8",
            "Ke3",
            "Bf7",
            "g4",
            "hxg4",
            "Bxg4",
            "Be8",
            "h5",
            "gxh5",
            "Bxh5",
            "Bxh5",
            "Rxh5+",
            "Kg7",
            "Reg5+",
            "Rg6",
            "Rxg6+",
            "Kxg6",
            "Rh8",
            "Kf5",
            "Rc8",
            "Rh7",
            "Rxc6",
            "Rh3+",
            "Kd2",
            "Kxf4",
            "Rxe6",
            "Rh2+",
            "Kd3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kb3",
            "Rh5",
            "Re7",
            "a6",
            "Re6",
            "Rh1",
            "Rxa6",
            "Rb1+",
            "Kc2",
            "Ra1",
            "Rb6",
            "Ke4",
            "Rxb5",
            "Ra2+",
            "Kb3",
            "Ra1",
            "Rb6",
            "Kd3",
            "Rc6",
            "Rb1+",
            "Ka4",
            "Ra1+",
            "Kb5",
            "Ra3",
            "a6",
            "Ra1",
            "Kb6",
            "Ra3",
            "a7",
            "Ra1",
            "Kb7",
            "Ra3",
            "a8=Q",
            "Rxa8",
            "Kxa8",
            "Ke4",
            "b5",
            "Kd3",
            "b6",
            "Ke4",
            "b7",
            "Kd3",
            "b8=Q",
            "Ke4",
            "Qe5+",
            "Kd3",
            "Qxd5",
            "Kc2",
            "Qf3",
            "Kb3",
            "c4+",
            "Kb4",
            "Rb6+",
            "Kxc4",
            "Qb3+",
            "Kxd4",
            "Rd6+",
            "Ke5",
            "Qd5+",
            "Kf4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1d2",
          "positional_uci": "b1d2",
          "neutral_uci": "b1d2",
          "consensus_move": "b1d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "c5",
              "c3",
              "cxd4",
              "cxd4",
              "Nc6",
              "Rc1",
              "Bd7",
              "Bb5",
              "Rac8",
              "Bxc6",
              "Bxc6",
              "Ne5",
              "Bb5",
              "Rxc8",
              "Rxc8",
              "Re1",
              "Qf4",
              "g3",
              "Qf5",
              "Qb3",
              "Rc2",
              "f4",
              "Bc4",
              "Qxb7",
              "h6",
              "Qc8+",
              "Kh7",
              "Nxc4",
              "dxc4",
              "Qxe6",
              "Qxe6",
              "Rxe6",
              "Rxb2",
              "Rc6",
              "Rxa2",
              "Rxc4",
              "Kg6",
              "Rc5",
              "Kf6",
              "g4",
              "a5",
              "Rc6+",
              "Kf7",
              "Ra6",
              "a4",
              "h4",
              "a3",
              "g5",
              "hxg5",
              "hxg5",
              "g6",
              "d5",
              "Rd2",
              "Rxa3",
              "Rxd5",
              "Kf2",
              "Ke6",
              "Kf3",
              "Kf5",
              "Re3",
              "Rd4",
              "Re5#",
              "e4+",
              "Nxe4",
              "Qxe4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "c5",
              "c3",
              "cxd4",
              "cxd4",
              "Nc6",
              "Rc1",
              "Bd7",
              "Re1",
              "Rae8",
              "Qd2",
              "Kh8",
              "Bb1",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Rxe5",
              "Qxe5",
              "Re1",
              "Qd6",
              "Qd3",
              "Bf5",
              "Qxf5",
              "Rxf5",
              "Bxf5",
              "g6",
              "Bd3",
              "Kg7",
              "g3",
              "Kf6",
              "Re2",
              "Qc5",
              "Kg2",
              "Qd4",
              "Rd2",
              "Qc5",
              "Be2",
              "Qc1",
              "Rd3",
              "Qxb2",
              "Rf3+",
              "Ke5",
              "Re3+",
              "Kd6",
              "a3",
              "d4",
              "Rd3",
              "Kc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qe2",
              "Rae8",
              "Rae1",
              "Re7",
              "Ne5",
              "Nxe5",
              "Qxe5",
              "Qxe5",
              "Rxe5",
              "Rf6",
              "Rfe1",
              "Kf7",
              "g3",
              "g6",
              "f4",
              "b6",
              "b4",
              "c6",
              "a4",
              "Bc8",
              "Ra1",
              "Rc7",
              "a5",
              "b5",
              "Rae1",
              "Re7",
              "Kg2",
              "Bd7",
              "h3",
              "Kg7",
              "Rf1",
              "Ref7",
              "Rf2",
              "h6",
              "h4",
              "h5",
              "Rfe2",
              "Re7",
              "Rg5",
              "Kf7",
              "Ree5",
              "Be8",
              "Kf3",
              "Kg7",
              "Ke3",
              "Kh6",
              "Kd2",
              "Bf7",
              "Be2",
              "Be8",
              "Ke3",
              "Bf7",
              "g4",
              "hxg4",
              "Bxg4",
              "Be8",
              "h5",
              "gxh5",
              "Bxh5",
              "Bxh5",
              "Rxh5+",
              "Kg7",
              "Reg5+",
              "Rg6",
              "Rxg6+",
              "Kxg6",
              "Rh8",
              "Kf5",
              "Rc8",
              "Rh7",
              "Rxc6",
              "Rh3+",
              "Kd2",
              "Kxf4",
              "Rxe6",
              "Rh2+",
              "Kd3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kb3",
              "Rh5",
              "Re7",
              "a6",
              "Re6",
              "Rh1",
              "Rxa6",
              "Rb1+",
              "Kc2",
              "Ra1",
              "Rb6",
              "Ke4",
              "Rxb5",
              "Ra2+",
              "Kb3",
              "Ra1",
              "Rb6",
              "Kd3",
              "Rc6",
              "Rb1+",
              "Ka4",
              "Ra1+",
              "Kb5",
              "Ra3",
              "a6",
              "Ra1",
              "Kb6",
              "Ra3",
              "a7",
              "Ra1",
              "Kb7",
              "Ra3",
              "a8=Q",
              "Rxa8",
              "Kxa8",
              "Ke4",
              "b5",
              "Kd3",
              "b6",
              "Ke4",
              "b7",
              "Kd3",
              "b8=Q",
              "Ke4",
              "Qe5+",
              "Kd3",
              "Qxd5",
              "Kc2",
              "Qf3",
              "Kb3",
              "c4+",
              "Kb4",
              "Rb6+",
              "Kxc4",
              "Qb3+",
              "Kxd4",
              "Rd6+",
              "Ke5",
              "Qd5+",
              "Kf4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 316,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1596,
          "total_tokens": 1994
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 316,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pppp2pp/4pn2/5pB1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "g5f6",
          "aggressive_response": "5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 h6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. Bb1 Rc4 19. Qd3 Rfc8 20. f4 Bb5 21. Qh7+ Kf7 22. f5 Rc1 23. fxe6+ Ke7 24. Rf5 Rxf1+ 25. Rxf1 Qxd4+ 26. Kh1 Bxf1 27. Qg6 Rc1 28. Qf7+ Kd6 29. Qd7+ Ke5 30. Qxg7+ Kxe6 31. Qxd4 Bd3+ 32. Qg1 Rxg1+ 33. Kxg1 Bxb1 34. a3 Ke5 35. Kf2 Ke4 36. Ke2 d4 37. Kd2 d3 38. b4 Kd4 39. g4 Ba2 40. h4 Be6 41. g5 hxg5 42. hxg5 Bf5 43. a4 b6 44. a5 bxa5 45. bxa5 a6 46. Kd1 Ke3 47. Ke1 d2+ 48. Kd1 Bg4+ 49. Kc2 d1=Q+ 50. Kc3 Qd4+ 51. Kb3 Be6+ 52. Kc2 Qd3+ 53. Kb2 Qb3+ 54. Kc1 Kd3 55. g6 Qc2# e4 d5 g4",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 441,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "h6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "Bb1",
            "Rc4",
            "Qd3",
            "Rfc8",
            "f4",
            "Bb5",
            "Qh7+",
            "Kf7",
            "f5",
            "Rc1",
            "fxe6+",
            "Ke7",
            "Rf5",
            "Rxf1+",
            "Rxf1",
            "Qxd4+",
            "Kh1",
            "Bxf1",
            "Qg6",
            "Rc1",
            "Qf7+",
            "Kd6",
            "Qd7+",
            "Ke5",
            "Qxg7+",
            "Kxe6",
            "Qxd4",
            "Bd3+",
            "Qg1",
            "Rxg1+",
            "Kxg1",
            "Bxb1",
            "a3",
            "Ke5",
            "Kf2",
            "Ke4",
            "Ke2",
            "d4",
            "Kd2",
            "d3",
            "b4",
            "Kd4",
            "g4",
            "Ba2",
            "h4",
            "Be6",
            "g5",
            "hxg5",
            "hxg5",
            "Bf5",
            "a4",
            "b6",
            "a5",
            "bxa5",
            "bxa5",
            "a6",
            "Kd1",
            "Ke3",
            "Ke1",
            "d2+",
            "Kd1",
            "Bg4+",
            "Kc2",
            "d1=Q+",
            "Kc3",
            "Qd4+",
            "Kb3",
            "Be6+",
            "Kc2",
            "Qd3+",
            "Kb2",
            "Qb3+",
            "Kc1",
            "Kd3",
            "g6",
            "Qc2#",
            "e4",
            "d5",
            "g4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "g5f6",
          "positional_response": "5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O c5 11. c3 cxd4 12. cxd4 Nc6 13. Rc1 Bd7 14. Re1 Rae8 15. Qd2 Kh8 16. Bb1 Qf4 17. Qxf4 Rxf4 18. Rcd1 Ref8 19. Re3 g6 20. a3 Kg7 21. b4 a6 22. Ba2 h6 23. h3 g5 24. Rd2 R8f6 25. Bb3 Be8 26. Bd1 Bh5 27. g4 Bg6 28. Kg2 Be4 29. Kg3 Bxf3 30. Bxf3 Nxd4 31. Bd1 Nc6 32. Rc3 Rc4 33. Rxc4 dxc4 34. Rd7+ Rf7 35. Rd6 Kf6 36. Be2 Ke5 37. Rd1 b5 38. Bf3 Nd4 39. Re1+ Kd6 40. Be4 c3 41. Rd1 Ke5 42. Re1 Kd6 43. Rd1 e5 44. f3 Rc7 45. Kf2 c2 46. Rc1 Rc3 47. Ke1 Rxa3 48. Bxc2 Rc3 49. Kd2 Rxc2+ 50. Rxc2 Nxc2 51. Kxc2 Kd5 52. Kd3 e4+ 53. fxe4+ Ke5 54. Ke3 Ke6 55. Kd4 Kd6 56. e5+ Ke6 57. Ke4 Ke7 58. Kd5 Kd7 59. e6+ Ke7 60. Ke5 Ke8 61. Kd6 Kd8 62. e7+ Ke8 63. Ke6 a5 64. bxa5 b4 65. a6 b3 66. a7 b2 67. a8=Q# e4 d5 c4",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 505,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "c5",
            "c3",
            "cxd4",
            "cxd4",
            "Nc6",
            "Rc1",
            "Bd7",
            "Re1",
            "Rae8",
            "Qd2",
            "Kh8",
            "Bb1",
            "Qf4",
            "Qxf4",
            "Rxf4",
            "Rcd1",
            "Ref8",
            "Re3",
            "g6",
            "a3",
            "Kg7",
            "b4",
            "a6",
            "Ba2",
            "h6",
            "h3",
            "g5",
            "Rd2",
            "R8f6",
            "Bb3",
            "Be8",
            "Bd1",
            "Bh5",
            "g4",
            "Bg6",
            "Kg2",
            "Be4",
            "Kg3",
            "Bxf3",
            "Bxf3",
            "Nxd4",
            "Bd1",
            "Nc6",
            "Rc3",
            "Rc4",
            "Rxc4",
            "dxc4",
            "Rd7+",
            "Rf7",
            "Rd6",
            "Kf6",
            "Be2",
            "Ke5",
            "Rd1",
            "b5",
            "Bf3",
            "Nd4",
            "Re1+",
            "Kd6",
            "Be4",
            "c3",
            "Rd1",
            "Ke5",
            "Re1",
            "Kd6",
            "Rd1",
            "e5",
            "f3",
            "Rc7",
            "Kf2",
            "c2",
            "Rc1",
            "Rc3",
            "Ke1",
            "Rxa3",
            "Bxc2",
            "Rc3",
            "Kd2",
            "Rxc2+",
            "Rxc2",
            "Nxc2",
            "Kxc2",
            "Kd5",
            "Kd3",
            "e4+",
            "fxe4+",
            "Ke5",
            "Ke3",
            "Ke6",
            "Kd4",
            "Kd6",
            "e5+",
            "Ke6",
            "Ke4",
            "Ke7",
            "Kd5",
            "Kd7",
            "e6+",
            "Ke7",
            "Ke5",
            "Ke8",
            "Kd6",
            "Kd8",
            "e7+",
            "Ke8",
            "Ke6",
            "a5",
            "bxa5",
            "b4",
            "a6",
            "b3",
            "a7",
            "b2",
            "a8=Q#",
            "e4",
            "d5",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "g5f6",
          "neutral_response": "5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 h6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. Bb1 Rc4 19. Qd3 Rfc8 20. Re3 Rc1 21. Rf3 Rxf1+ 22. Kxf1 Rc1+ 23. Ke2 Qg5 24. Qh7# e4 Nf6 Qh8#",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 172,
            "total_tokens": 312,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "h6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "Bb1",
            "Rc4",
            "Qd3",
            "Rfc8",
            "Re3",
            "Rc1",
            "Rf3",
            "Rxf1+",
            "Kxf1",
            "Rc1+",
            "Ke2",
            "Qg5",
            "Qh7#",
            "e4",
            "Nf6",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5f6",
          "positional_uci": "g5f6",
          "neutral_uci": "g5f6",
          "consensus_move": "g5f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "h6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "Bb1",
              "Rc4",
              "Qd3",
              "Rfc8",
              "f4",
              "Bb5",
              "Qh7+",
              "Kf7",
              "f5",
              "Rc1",
              "fxe6+",
              "Ke7",
              "Rf5",
              "Rxf1+",
              "Rxf1",
              "Qxd4+",
              "Kh1",
              "Bxf1",
              "Qg6",
              "Rc1",
              "Qf7+",
              "Kd6",
              "Qd7+",
              "Ke5",
              "Qxg7+",
              "Kxe6",
              "Qxd4",
              "Bd3+",
              "Qg1",
              "Rxg1+",
              "Kxg1",
              "Bxb1",
              "a3",
              "Ke5",
              "Kf2",
              "Ke4",
              "Ke2",
              "d4",
              "Kd2",
              "d3",
              "b4",
              "Kd4",
              "g4",
              "Ba2",
              "h4",
              "Be6",
              "g5",
              "hxg5",
              "hxg5",
              "Bf5",
              "a4",
              "b6",
              "a5",
              "bxa5",
              "bxa5",
              "a6",
              "Kd1",
              "Ke3",
              "Ke1",
              "d2+",
              "Kd1",
              "Bg4+",
              "Kc2",
              "d1=Q+",
              "Kc3",
              "Qd4+",
              "Kb3",
              "Be6+",
              "Kc2",
              "Qd3+",
              "Kb2",
              "Qb3+",
              "Kc1",
              "Kd3",
              "g6",
              "Qc2#",
              "e4",
              "d5",
              "g4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "c5",
              "c3",
              "cxd4",
              "cxd4",
              "Nc6",
              "Rc1",
              "Bd7",
              "Re1",
              "Rae8",
              "Qd2",
              "Kh8",
              "Bb1",
              "Qf4",
              "Qxf4",
              "Rxf4",
              "Rcd1",
              "Ref8",
              "Re3",
              "g6",
              "a3",
              "Kg7",
              "b4",
              "a6",
              "Ba2",
              "h6",
              "h3",
              "g5",
              "Rd2",
              "R8f6",
              "Bb3",
              "Be8",
              "Bd1",
              "Bh5",
              "g4",
              "Bg6",
              "Kg2",
              "Be4",
              "Kg3",
              "Bxf3",
              "Bxf3",
              "Nxd4",
              "Bd1",
              "Nc6",
              "Rc3",
              "Rc4",
              "Rxc4",
              "dxc4",
              "Rd7+",
              "Rf7",
              "Rd6",
              "Kf6",
              "Be2",
              "Ke5",
              "Rd1",
              "b5",
              "Bf3",
              "Nd4",
              "Re1+",
              "Kd6",
              "Be4",
              "c3",
              "Rd1",
              "Ke5",
              "Re1",
              "Kd6",
              "Rd1",
              "e5",
              "f3",
              "Rc7",
              "Kf2",
              "c2",
              "Rc1",
              "Rc3",
              "Ke1",
              "Rxa3",
              "Bxc2",
              "Rc3",
              "Kd2",
              "Rxc2+",
              "Rxc2",
              "Nxc2",
              "Kxc2",
              "Kd5",
              "Kd3",
              "e4+",
              "fxe4+",
              "Ke5",
              "Ke3",
              "Ke6",
              "Kd4",
              "Kd6",
              "e5+",
              "Ke6",
              "Ke4",
              "Ke7",
              "Kd5",
              "Kd7",
              "e6+",
              "Ke7",
              "Ke5",
              "Ke8",
              "Kd6",
              "Kd8",
              "e7+",
              "Ke8",
              "Ke6",
              "a5",
              "bxa5",
              "b4",
              "a6",
              "b3",
              "a7",
              "b2",
              "a8=Q#",
              "e4",
              "d5",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "h6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "Bb1",
              "Rc4",
              "Qd3",
              "Rfc8",
              "Re3",
              "Rc1",
              "Rf3",
              "Rxf1+",
              "Kxf1",
              "Rc1+",
              "Ke2",
              "Qg5",
              "Qh7#",
              "e4",
              "Nf6",
              "Qh8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 441,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 505,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 172,
            "total_tokens": 312,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 1118,
          "total_tokens": 1540
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 441,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 505,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 172,
            "total_tokens": 312,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppppb1pp/4pn2/5pB1/3P4/5N2/PPPNPPPP/R2QKB1R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 e5 12. dxe5 Nxe5 13. Nxe5 Qxe5 14. Qc2 Bf5 15. Rae1 Bxd3 16. Qxd3 Qd6 17. Re3 Rae8 18. Rfe1 Rxe3 19. Rxe3 c6 20. Qe2 Qf6 21. Re7 Rf7 22. Re8+ Rf8 23. Re7 Rf7 24. Re8+ Rf8 25. Re7 Rf7 26. Re8+ Rf8 27. Re7 Rf7 28. Re8+ Rf8 29. Re7 Rf7 30. Re8+ Rf8 31. Re7 Rf7 32. Re8+ Rf8 33. Re7 Rf7 34. Re8+ Rf8 35. Re7 Rf7 36. Re8+ Rf8 37. Re7 Rf7 38. Re8+ Rf8 39. Re7 Rf7 40. Re8+ Rf8 41. Re7 Rf7 42. Re8+ Rf8 43. Re7 Rf7 44. Re8+ Rf8 45. Re7 Rf7 46. Re8+ Rf8 47. Re7 Rf7 48. Re8+ Rf8 49. Re7 Rf7 50. Re8+ Rf8 51. Re7 Rf7 52. Re8+ Rf8 53. Re7 Rf7 54. Re8+ Rf8 55. Re7 Rf7 56. Re8+ Rf8 57. Re7 Rf7 58. Re8+ Rf8 59. Re7 Rf7 60. Re8+ Rf8 61. Re7 Rf7 62. Re8+ Rf8 63. Re7 Rf7 64. Re8+ Rf8 65. Re7 Rf7 66. Re8+ Rf8 67. Re7 Rf7 68. Re8+ Rf8 69. Re7 Rf7 70. Re8+ Rf8 71. Re7 Rf7 72. Re8+ Rf8 73. Re7 Rf7 74. Re8+ Rf8 75. Re7 Rf7 76. Re8+ Rf8 77. Re7 Rf7 78. Re8+ Rf8 79. Re7 Rf7 80. Re8+ Rf8 81. Re7",
          "aggressive_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Qc2",
            "Bf5",
            "Rae1",
            "Bxd3",
            "Qxd3",
            "Qd6",
            "Re3",
            "Rae8",
            "Rfe1",
            "Rxe3",
            "Rxe3",
            "c6",
            "Qe2",
            "Qf6",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 g6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. g3 Rc6 19. f4 Rfc8 20. h4 Rc1 21. h5 Rxf1+ 22. Kxf1 Rc1+ 23. Kg2 Kg7 24. hxg6 hxg6 25. Rg5 Be8 26. Qe5 Qxe5 27. Rxe5 Kf6 28. g4 Rd1 29. g5+ Kf7 30. Re3 Rd2+ 31. Kf3 Rxb2 32. Re2 Rxe2 33. Kxe2 Ke7 34. Kd2 Kd6 35. Kc3 Kc6 36. Kb4 Kb6 37. a4 a5+ 38. Kb3 Kc7 39. Bb5 Bxb5 40. axb5 Kb6 41. Ka4 Ka7 42. Kxa5 b6+ 43. Kb4 Kb7 44. Kc3 Kc7 45. Kd3 Kd6 46. Ke3 Ke7 47. Kf3 Kf7 48. Kg4 Kg7 49. Kh4 Kh7 50. Kg4 Kg7 51. Kh4 Kh7 52. Kg4 Kg7 53. Kh4 Kh7 54. Kg4 Kg7 55. Kh4 Kh7 56. Kg4 Kg7 57. Kh4 Kh7 58. Kg4 Kg7 59. Kh4 Kh7 60. Kg4 Kg7 61. Kh4 Kh7 62. Kg4 Kg7 63. Kh4 Kh7 64. Kg4 Kg7 65. Kh4 Kh7 66. Kg4 Kg7 67. Kh4 Kh7 68. Kg4 Kg7 69. Kh4 Kh7 70. Kg4 Kg7 71. Kh4 Kh7 72. Kg4 Kg7 73. Kh4 Kh7 74. Kg4 Kg7 75. Kh4 Kh7 76. Kg4 Kg7 77. Kh4 Kh7 78. Kg4 Kg7 79. Kh4 Kh7 80. Kg4 Kg7 81. Kh4 Kh7 82. Kg4 Kg7 83. Kh4 Kh7 84. Kg4 Kg7 85. Kh4 Kh7 86. Kg4 Kg7 87. Kh4 Kh7 88. Kg4 Kg7 89. Kh4 Kh7 90. Kg",
          "positional_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "g6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "g3",
            "Rc6",
            "f4",
            "Rfc8",
            "h4",
            "Rc1",
            "h5",
            "Rxf1+",
            "Kxf1",
            "Rc1+",
            "Kg2",
            "Kg7",
            "hxg6",
            "hxg6",
            "Rg5",
            "Be8",
            "Qe5",
            "Qxe5",
            "Rxe5",
            "Kf6",
            "g4",
            "Rd1",
            "g5+",
            "Kf7",
            "Re3",
            "Rd2+",
            "Kf3",
            "Rxb2",
            "Re2",
            "Rxe2",
            "Kxe2",
            "Ke7",
            "Kd2",
            "Kd6",
            "Kc3",
            "Kc6",
            "Kb4",
            "Kb6",
            "a4",
            "a5+",
            "Kb3",
            "Kc7",
            "Bb5",
            "Bxb5",
            "axb5",
            "Kb6",
            "Ka4",
            "Ka7",
            "Kxa5",
            "b6+",
            "Kb4",
            "Kb7",
            "Kc3",
            "Kc7",
            "Kd3",
            "Kd6",
            "Ke3",
            "Ke7",
            "Kf3",
            "Kf7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 h6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. Bb5 Bxb5 19. Qxb5 Rc2 20. Re2 Rxe2 21. Qxe2 Qxd4 22. Qxe6+ Kh8 23. Qe2 Qc4 24. Qxc4 dxc4 25. Rc1 b5 26. Kf1 Rd8 27. Ke2 Kg8 28. Rc3 Kf7 29. Ra3 Rd7 30. Ra5 Rb7 31. Kd2 Ke6 32. Kc3 Kd5 33. Kb4 Kc6 34. Ra6+ Kd5 35. Ra5 Kc6 36. Ra6+ Kd5 37. Ra5 Kc6 38. Ra6+ Kd5 39. Ra5 Kc6 40. Ra6+ Kd5 41. Ra5 Kc6 42. Ra6+ Kd5 43. Ra5 Kc6 44. Ra6+ Kd5 45. Ra5 Kc6 46. Ra6+ Kd5 47. Ra5 Kc6 48. Ra6+ Kd5 49. Ra5 Kc6 50. Ra6+ Kd5 51. Ra5 Kc6 52. Ra6+ Kd5 53. Ra5 Kc6 54. Ra6+ Kd5 55. Ra5 Kc6 56. Ra6+ Kd5 57. Ra5 Kc6 58. Ra6+ Kd5 59. Ra5 Kc6 60. Ra6+ Kd5 61. Ra5 Kc6 62. Ra6+ Kd5 63. Ra5 Kc6 64. Ra6+ Kd5 65. Ra5 Kc6 66. Ra6+ Kd5 67. Ra5 Kc6 68. Ra6+ Kd5 69. Ra5 Kc6 70. Ra6+ Kd5 71. Ra5 Kc6 72. Ra6+ Kd5 73. Ra5 Kc6 74. Ra6+ Kd5 75. Ra5 Kc6 76. Ra6+ Kd5 77. Ra5 Kc6 78. Ra6+ Kd5 79. Ra5 Kc6 80. Ra6+ Kd5 81. Ra5 Kc6 82. Ra6",
          "neutral_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "h6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "Bb5",
            "Bxb5",
            "Qxb5",
            "Rc2",
            "Re2",
            "Rxe2",
            "Qxe2",
            "Qxd4",
            "Qxe6+",
            "Kh8",
            "Qe2",
            "Qc4",
            "Qxc4",
            "dxc4",
            "Rc1",
            "b5",
            "Kf1",
            "Rd8",
            "Ke2",
            "Kg8",
            "Rc3",
            "Kf7",
            "Ra3",
            "Rd7",
            "Ra5",
            "Rb7",
            "Kd2",
            "Ke6",
            "Kc3",
            "Kd5",
            "Kb4",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Qc2",
              "Bf5",
              "Rae1",
              "Bxd3",
              "Qxd3",
              "Qd6",
              "Re3",
              "Rae8",
              "Rfe1",
              "Rxe3",
              "Rxe3",
              "c6",
              "Qe2",
              "Qf6",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "g6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "g3",
              "Rc6",
              "f4",
              "Rfc8",
              "h4",
              "Rc1",
              "h5",
              "Rxf1+",
              "Kxf1",
              "Rc1+",
              "Kg2",
              "Kg7",
              "hxg6",
              "hxg6",
              "Rg5",
              "Be8",
              "Qe5",
              "Qxe5",
              "Rxe5",
              "Kf6",
              "g4",
              "Rd1",
              "g5+",
              "Kf7",
              "Re3",
              "Rd2+",
              "Kf3",
              "Rxb2",
              "Re2",
              "Rxe2",
              "Kxe2",
              "Ke7",
              "Kd2",
              "Kd6",
              "Kc3",
              "Kc6",
              "Kb4",
              "Kb6",
              "a4",
              "a5+",
              "Kb3",
              "Kc7",
              "Bb5",
              "Bxb5",
              "axb5",
              "Kb6",
              "Ka4",
              "Ka7",
              "Kxa5",
              "b6+",
              "Kb4",
              "Kb7",
              "Kc3",
              "Kc7",
              "Kd3",
              "Kd6",
              "Ke3",
              "Ke7",
              "Kf3",
              "Kf7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "h6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "Bb5",
              "Bxb5",
              "Qxb5",
              "Rc2",
              "Re2",
              "Rxe2",
              "Qxe2",
              "Qxd4",
              "Qxe6+",
              "Kh8",
              "Qe2",
              "Qc4",
              "Qxc4",
              "dxc4",
              "Rc1",
              "b5",
              "Kf1",
              "Rd8",
              "Ke2",
              "Kg8",
              "Rc3",
              "Kf7",
              "Ra3",
              "Rd7",
              "Ra5",
              "Rb7",
              "Kd2",
              "Ke6",
              "Kc3",
              "Kd5",
              "Kb4",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 449,
          "total_completion_tokens": 1920,
          "total_tokens": 2369
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/pppp2pp/4pb2/5p2/3P4/5N2/PPPNPPPP/R2QKB1R w KQkq - 0 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exf5",
          "aggressive_uci": "e4f5",
          "aggressive_response": "7. exf5 exf5 8. Bc4 d5 9. Qe2+ Kf7 10. Ne5+ Kg7 11. Bb3 Re8 12. f4 c5 13. c3 Nc6 14. Ndf3 cxd4 15. cxd4 Qa5+ 16. Qd2 Qxd2+ 17. Kxd2 Be6 18. Rac1 Rac8 19. Rc5 Nxd4 20. Rxc8 Nxb3+ 21. axb3 Rxc8 22. Nd4 Bg8 23. Ra1 a6 24. Ra5 Bd8 25. Ra1 Bb6 26. Kd3 Kf6 27. Nd7+ Ke7 28. Nxb6 Rc7 29. Re1+ Kd6 30. Re8 Bf7 31. Rd8+ Kc5 32. Na4+ Kb4 33. Nc3 b5 34. Rd6 Ka5 35. Nc6+ Kb6 36. Ne5+ Kc5 37. Rxa6 Be8 38. b4+ Kxb4 39. Nxd5+ Kb3 40. Nxc7 Kxb2 41. Nxe8 b4 42. Rb6 b3 43. Nc4+ Ka2 44. Kc3 b2 45. Rxb2+ Ka1 46. Kb3 g5 47. Na3 gxf4 48. Nc2# 1-0 7. exf5 exf5 8. Bc4 d5 9. Qe2+ Kf7",
          "aggressive_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 381,
            "total_tokens": 538,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "d5",
            "Qe2+",
            "Kf7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h4",
          "positional_uci": "h2h4",
          "positional_response": "7. h4 O-O 8. h5 g5 9. exf5 exf5 10. Bd3 d5 11. c3 Nc6 12. Qc2 Bg7 13. O-O-O h6 14. Rde1 Qd6 15. Re2 Bd7 16. Rhe1 a6 17. Ne5 Nxe5 18. dxe5 Qe6 19. Nb3 b6 20. Nd4 Qe8 21. e6 Bb5 22. Nxf5 Bxd3 23. Qxd3 Qxh5 24. Nxg7 Kxg7 25. Qxd5 Rae8 26. Qd7+ Kg8 27. e7 Rf4 28. Qxc7 Qf7 29. Qxb6 Rf6 30. Qb3 Qxb3 31. axb3 Kf7 32. f3 h5 33. Re5 g4 34. fxg4 hxg4 35. R1e4 Rf2 36. Rxg4 Rxe7 37. Rxe7+ Kxe7 38. b4 Kd6 39. Kb1 Kc6 40. Ka2 Kb5 41. Kb3 Rf5 42. c4+ Kb6 43. Rg6+ Kb7 44. Ka4 Rf2 45. b3 Ra2# 0-1\n46. b5 axb5+ 47. Kxb5 Rxb2+ 48. Kc5 Rc2 49. c4 Kc7",
          "positional_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 363,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "exf5",
            "exf5",
            "Bd3",
            "d5",
            "c3",
            "Nc6",
            "Qc2",
            "Bg7",
            "O-O-O",
            "h6",
            "Rde1",
            "Qd6",
            "Re2",
            "Bd7",
            "Rhe1",
            "a6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qe6",
            "Nb3",
            "b6",
            "Nd4",
            "Qe8",
            "e6",
            "Bb5",
            "Nxf5",
            "Bxd3",
            "Qxd3",
            "Qxh5",
            "Nxg7",
            "Kxg7",
            "Qxd5",
            "Rae8",
            "Qd7+",
            "Kg8",
            "e7",
            "Rf4",
            "Qxc7",
            "Qf7",
            "Qxb6",
            "Rf6",
            "Qb3",
            "Qxb3",
            "axb3",
            "Kf7",
            "f3",
            "h5",
            "Re5",
            "g4",
            "fxg4",
            "hxg4",
            "R1e4",
            "Rf2",
            "Rxg4",
            "Rxe7",
            "Rxe7+",
            "Kxe7",
            "b4",
            "Kd6",
            "Kb1",
            "Kc6",
            "Ka2",
            "Kb5",
            "Kb3",
            "Rf5",
            "c4+",
            "Kb6",
            "Rg6+",
            "Kb7",
            "Ka4",
            "Rf2",
            "b3",
            "Ra2#",
            "b5",
            "axb5+",
            "Kxb5",
            "Rxb2+",
            "Kc5",
            "Rc2",
            "c4",
            "Kc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "h4",
          "neutral_uci": "h2h4",
          "neutral_response": "7. h4 O-O 8. h5 g5 9. exf5 exf5 10. Bd3 d5 11. c3 Nc6 12. Qc2 Bg7 13. O-O-O h6 14. Rde1 Qd6 15. Re2 Bd7 16. Rhe1 a6 17. Ne5 Nxe5 18. dxe5 Qe6 19. Nb3 b6 20. Nd4 Qe8 21. e6 Bb5 22. Nxf5 Bxd3 23. Qxd3 Qxh5 24. Nxg7 Kxg7 25. Qxd5 Rae8 26. Qd7+ Kg8 27. e7 Rf4 28. Qxc7 Qf7 29. Qxb6 Rf6 30. Qb3 Qxb3 31. axb3 Kf7 32. f3 h5 33. Re5 g4 34. fxg4 hxg4 35. R1e4 Rf2 36. Rxg4 Rxe7 37. Rxe7+ Kxe7 38. b4 Kd6 39. Kb1 Kc6 40. Ka2 Kb5 41. Kb3 Rf5 42. c4+ Kb6 43. Rg6+ Kb7 44. Ka4 Rf2 45. b3 Ra2# 0-1 46. b5 axb5+ 47. Kxb5 Rxb2+ 48. Kc5 Rc2 49. c4 Kc7 50. Rg7+ Kd8 51. Kd5 Rd2+ 52. Kc6 Rc2 53. c5 Ke8 54. Kd6 Rd2+ 55. Kc7 Rc2 56. c6 Kf8 57. Rg5 Ke7 58. Kb7 Rb2+ 59. Kc8 Rc2 60. c7 Kd6 61. Rg6+ Ke7 62. Rg4 Kd6 63. Rd4+ Ke7 64. Kb7 Rb2+ 65. Kc6 Rc2+ 66. Kb6 Rb2+ 67. Kc5 Rc2+ 68. Rc4 Rxc4+ 69. Kxc4 Kd7 70. Kd5 Kxc7 71. Ke6 Kd8 72. Kf7 Kd7 73. g4 Kd6 74. g5 Ke5 75. g6 Kf5 76. g7 Ke5 77. g8=Q Kd5 78. Qg6 Ke5 79. Qe6+ Kd4 80. Qf5 Kc4 81. Qe5 Kd3 82.",
          "neutral_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 640,
            "total_tokens": 796,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "exf5",
            "exf5",
            "Bd3",
            "d5",
            "c3",
            "Nc6",
            "Qc2",
            "Bg7",
            "O-O-O",
            "h6",
            "Rde1",
            "Qd6",
            "Re2",
            "Bd7",
            "Rhe1",
            "a6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qe6",
            "Nb3",
            "b6",
            "Nd4",
            "Qe8",
            "e6",
            "Bb5",
            "Nxf5",
            "Bxd3",
            "Qxd3",
            "Qxh5",
            "Nxg7",
            "Kxg7",
            "Qxd5",
            "Rae8",
            "Qd7+",
            "Kg8",
            "e7",
            "Rf4",
            "Qxc7",
            "Qf7",
            "Qxb6",
            "Rf6",
            "Qb3",
            "Qxb3",
            "axb3",
            "Kf7",
            "f3",
            "h5",
            "Re5",
            "g4",
            "fxg4",
            "hxg4",
            "R1e4",
            "Rf2",
            "Rxg4",
            "Rxe7",
            "Rxe7+",
            "Kxe7",
            "b4",
            "Kd6",
            "Kb1",
            "Kc6",
            "Ka2",
            "Kb5",
            "Kb3",
            "Rf5",
            "c4+",
            "Kb6",
            "Rg6+",
            "Kb7",
            "Ka4",
            "Rf2",
            "b3",
            "Ra2#",
            "b5",
            "axb5+",
            "Kxb5",
            "Rxb2+",
            "Kc5",
            "Rc2",
            "c4",
            "Kc7",
            "Rg7+",
            "Kd8",
            "Kd5",
            "Rd2+",
            "Kc6",
            "Rc2",
            "c5",
            "Ke8",
            "Kd6",
            "Rd2+",
            "Kc7",
            "Rc2",
            "c6",
            "Kf8",
            "Rg5",
            "Ke7",
            "Kb7",
            "Rb2+",
            "Kc8",
            "Rc2",
            "c7",
            "Kd6",
            "Rg6+",
            "Ke7",
            "Rg4",
            "Kd6",
            "Rd4+",
            "Ke7",
            "Kb7",
            "Rb2+",
            "Kc6",
            "Rc2+",
            "Kb6",
            "Rb2+",
            "Kc5",
            "Rc2+",
            "Rc4",
            "Rxc4+",
            "Kxc4",
            "Kd7",
            "Kd5",
            "Kxc7",
            "Ke6",
            "Kd8",
            "Kf7",
            "Kd7",
            "g4",
            "Kd6",
            "g5",
            "Ke5",
            "g6",
            "Kf5",
            "g7",
            "Ke5",
            "g8=Q",
            "Kd5",
            "Qg6",
            "Ke5",
            "Qe6+",
            "Kd4",
            "Qf5",
            "Kc4",
            "Qe5",
            "Kd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f5",
          "positional_uci": "h2h4",
          "neutral_uci": "h2h4",
          "consensus_move": "h2h4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4",
              "d5",
              "Qe2+",
              "Kf7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "exf5",
              "exf5",
              "Bd3",
              "d5",
              "c3",
              "Nc6",
              "Qc2",
              "Bg7",
              "O-O-O",
              "h6",
              "Rde1",
              "Qd6",
              "Re2",
              "Bd7",
              "Rhe1",
              "a6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Qe6",
              "Nb3",
              "b6",
              "Nd4",
              "Qe8",
              "e6",
              "Bb5",
              "Nxf5",
              "Bxd3",
              "Qxd3",
              "Qxh5",
              "Nxg7",
              "Kxg7",
              "Qxd5",
              "Rae8",
              "Qd7+",
              "Kg8",
              "e7",
              "Rf4",
              "Qxc7",
              "Qf7",
              "Qxb6",
              "Rf6",
              "Qb3",
              "Qxb3",
              "axb3",
              "Kf7",
              "f3",
              "h5",
              "Re5",
              "g4",
              "fxg4",
              "hxg4",
              "R1e4",
              "Rf2",
              "Rxg4",
              "Rxe7",
              "Rxe7+",
              "Kxe7",
              "b4",
              "Kd6",
              "Kb1",
              "Kc6",
              "Ka2",
              "Kb5",
              "Kb3",
              "Rf5",
              "c4+",
              "Kb6",
              "Rg6+",
              "Kb7",
              "Ka4",
              "Rf2",
              "b3",
              "Ra2#",
              "b5",
              "axb5+",
              "Kxb5",
              "Rxb2+",
              "Kc5",
              "Rc2",
              "c4",
              "Kc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "exf5",
              "exf5",
              "Bd3",
              "d5",
              "c3",
              "Nc6",
              "Qc2",
              "Bg7",
              "O-O-O",
              "h6",
              "Rde1",
              "Qd6",
              "Re2",
              "Bd7",
              "Rhe1",
              "a6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Qe6",
              "Nb3",
              "b6",
              "Nd4",
              "Qe8",
              "e6",
              "Bb5",
              "Nxf5",
              "Bxd3",
              "Qxd3",
              "Qxh5",
              "Nxg7",
              "Kxg7",
              "Qxd5",
              "Rae8",
              "Qd7+",
              "Kg8",
              "e7",
              "Rf4",
              "Qxc7",
              "Qf7",
              "Qxb6",
              "Rf6",
              "Qb3",
              "Qxb3",
              "axb3",
              "Kf7",
              "f3",
              "h5",
              "Re5",
              "g4",
              "fxg4",
              "hxg4",
              "R1e4",
              "Rf2",
              "Rxg4",
              "Rxe7",
              "Rxe7+",
              "Kxe7",
              "b4",
              "Kd6",
              "Kb1",
              "Kc6",
              "Ka2",
              "Kb5",
              "Kb3",
              "Rf5",
              "c4+",
              "Kb6",
              "Rg6+",
              "Kb7",
              "Ka4",
              "Rf2",
              "b3",
              "Ra2#",
              "b5",
              "axb5+",
              "Kxb5",
              "Rxb2+",
              "Kc5",
              "Rc2",
              "c4",
              "Kc7",
              "Rg7+",
              "Kd8",
              "Kd5",
              "Rd2+",
              "Kc6",
              "Rc2",
              "c5",
              "Ke8",
              "Kd6",
              "Rd2+",
              "Kc7",
              "Rc2",
              "c6",
              "Kf8",
              "Rg5",
              "Ke7",
              "Kb7",
              "Rb2+",
              "Kc8",
              "Rc2",
              "c7",
              "Kd6",
              "Rg6+",
              "Ke7",
              "Rg4",
              "Kd6",
              "Rd4+",
              "Ke7",
              "Kb7",
              "Rb2+",
              "Kc6",
              "Rc2+",
              "Kb6",
              "Rb2+",
              "Kc5",
              "Rc2+",
              "Rc4",
              "Rxc4+",
              "Kxc4",
              "Kd7",
              "Kd5",
              "Kxc7",
              "Ke6",
              "Kd8",
              "Kf7",
              "Kd7",
              "g4",
              "Kd6",
              "g5",
              "Ke5",
              "g6",
              "Kf5",
              "g7",
              "Ke5",
              "g8=Q",
              "Kd5",
              "Qg6",
              "Ke5",
              "Qe6+",
              "Kd4",
              "Qf5",
              "Kc4",
              "Qe5",
              "Kd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 157,
            "completion_tokens": 381,
            "total_tokens": 538,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 157,
            "completion_tokens": 363,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 156,
            "completion_tokens": 640,
            "total_tokens": 796,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 470,
          "total_completion_tokens": 1384,
          "total_tokens": 1854
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 157,
            "completion_tokens": 381,
            "total_tokens": 538,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 157,
            "completion_tokens": 363,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 156,
            "completion_tokens": 640,
            "total_tokens": 796,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/pppp3p/4pbp1/5p2/3PP3/5N2/PPPN1PPP/R2QKB1R w KQkq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c3",
          "aggressive_uci": "c2c3",
          "aggressive_response": "8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe7 16. h5 g5 17. h6 Rae8 18. Rh5 Bf4 19. g3 Bf7 20. gxf4 Bxh5 21. Qxh5 Rxf4 22. Nxg5 Rxf2 23. Bxh7+ Kh8 24. Bg6 Ref8 25. Nf7+ R8xf7 26. Bxf7 Qxf7 27. Qxf7 Rxf7 28. Re1 Kh7 29. Re6 Rf1+ 30. Kc2 Rf2+ 31. Kb3 Rf7 32. Kc4 Rf4+ 33. Kd5 Rf5+ 34. Ke4 Rf7 35. b4 Rd7 36. Kf5 Rf7+ 37. Rf6 Re7 38. Kg5 Re5+ 39. Rf5 Re7 40. Kf6 Re3 41. Kf7 Rxc3 42. Rf6 Re3 43. Kf8 d5 44. Rf7+ Kxh6 45. Rxc7 d4 46. Rxb7 d3 47. Rd7 Kg6 48. a4 Kf6 49. b5 Re4 50. a5 Re5 51. b6 axb6 52. axb6 Rb5 53. b7 Ke6 54. Rxd3 Rxb7 55. Re3+ Kf6 56. Rf3+ Ke6 57. Re3+ Kf6 58. Rf3+ Ke6 59. Re3+ Kf6 60. Rf3+ Ke6 61. Re3+ Kf6 62. Rf3+ Ke6 63. Re3+ Kf6 64. Rf3+ Ke6 65. Re3+ Kf6 66. Rf3+ Ke6 67. Re3+ Kf6 68. Rf3+ Ke6 69. Re3+ Kf6 70. Rf3+ Ke6 71. Re3+ Kf6 72. Rf3+ Ke6 73. Re3+ Kf6 74. Rf3+ Ke6 75. Re3+ Kf6 76. Rf3+ Ke6 77. Re3+ Kf6 78. Rf3+ Ke6 79. Re3+ Kf6 80. Rf3+ Ke6 81. Re3+ Kf6",
          "aggressive_tokens": {
            "prompt_tokens": 164,
            "completion_tokens": 640,
            "total_tokens": 804,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Bd3",
            "Nc6",
            "Qe2",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Be6",
            "Kb1",
            "Qe7",
            "h5",
            "g5",
            "h6",
            "Rae8",
            "Rh5",
            "Bf4",
            "g3",
            "Bf7",
            "gxf4",
            "Bxh5",
            "Qxh5",
            "Rxf4",
            "Nxg5",
            "Rxf2",
            "Bxh7+",
            "Kh8",
            "Bg6",
            "Ref8",
            "Nf7+",
            "R8xf7",
            "Bxf7",
            "Qxf7",
            "Qxf7",
            "Rxf7",
            "Re1",
            "Kh7",
            "Re6",
            "Rf1+",
            "Kc2",
            "Rf2+",
            "Kb3",
            "Rf7",
            "Kc4",
            "Rf4+",
            "Kd5",
            "Rf5+",
            "Ke4",
            "Rf7",
            "b4",
            "Rd7",
            "Kf5",
            "Rf7+",
            "Rf6",
            "Re7",
            "Kg5",
            "Re5+",
            "Rf5",
            "Re7",
            "Kf6",
            "Re3",
            "Kf7",
            "Rxc3",
            "Rf6",
            "Re3",
            "Kf8",
            "d5",
            "Rf7+",
            "Kxh6",
            "Rxc7",
            "d4",
            "Rxb7",
            "d3",
            "Rd7",
            "Kg6",
            "a4",
            "Kf6",
            "b5",
            "Re4",
            "a5",
            "Re5",
            "b6",
            "axb6",
            "axb6",
            "Rb5",
            "b7",
            "Ke6",
            "Rxd3",
            "Rxb7",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c3",
          "positional_uci": "c2c3",
          "positional_response": "8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe7 16. h5 Rae8 17. hxg6 hxg6 18. Rh6 Qg7 19. Rdh1 Bf5 20. g4 Bxe4 21. Bxe4 Bf4 22. Qc4+ Rf7 23. Rxg6 Rxe4 24. Rxg7+ Kxg7 25. Qxe4 Be5 26. Rh7+ Kf8 27. Rxf7+ Kxf7 28. Qxb7 Ke6 29. Qxc7 Kd5 30. Qxa7 Ke4 31. Qe3+ Kd5 32. f4 Bf6 33. g5 Bd8 34. f5 Kc6 35. f6 Kd7 36. f7 Be7 37. g6 Bf8 38. Qe8+ Kc7 39. Qxf8 Kc6 40. Qxd6+ Kxd6 41. f8=Q+ Ke5 42. g7 Ke4 43. g8=Q Kd3 44. Qd5+ Ke2 45. Qff3+ Ke1 46. Qdd1# d4 e5 Qd6",
          "positional_tokens": {
            "prompt_tokens": 164,
            "completion_tokens": 342,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bd3",
            "Nc6",
            "Qe2",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Be6",
            "Kb1",
            "Qe7",
            "h5",
            "Rae8",
            "hxg6",
            "hxg6",
            "Rh6",
            "Qg7",
            "Rdh1",
            "Bf5",
            "g4",
            "Bxe4",
            "Bxe4",
            "Bf4",
            "Qc4+",
            "Rf7",
            "Rxg6",
            "Rxe4",
            "Rxg7+",
            "Kxg7",
            "Qxe4",
            "Be5",
            "Rh7+",
            "Kf8",
            "Rxf7+",
            "Kxf7",
            "Qxb7",
            "Ke6",
            "Qxc7",
            "Kd5",
            "Qxa7",
            "Ke4",
            "Qe3+",
            "Kd5",
            "f4",
            "Bf6",
            "g5",
            "Bd8",
            "f5",
            "Kc6",
            "f6",
            "Kd7",
            "f7",
            "Be7",
            "g6",
            "Bf8",
            "Qe8+",
            "Kc7",
            "Qxf8",
            "Kc6",
            "Qxd6+",
            "Kxd6",
            "f8=Q+",
            "Ke5",
            "g7",
            "Ke4",
            "g8=Q",
            "Kd3",
            "Qd5+",
            "Ke2",
            "Qff3+",
            "Ke1",
            "Qdd1#",
            "d4",
            "e5",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c3",
          "neutral_uci": "c2c3",
          "neutral_response": "8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe8 16. h5 Qa4 17. b3 Qa5 18. hxg6 hxg6 19. Ng5 Rae8 20. Nxe6 Rxe6 21. Bc4 Rfe8 22. Qg4 Kf7 23. Rh7+ Bg7 24. Bxe6+ Rxe6 25. Rxg7+ Kxg7 26. Qxe6 Qxc3 27. Qe7+ Kh6 28. Rh1+ 1-0\n\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe8 16. h5 Qa4 17. b3 Qa5 18. hxg6 hxg6 19. Ng5 Rae8 20. Nxe6 Rxe6 21. Bc4 Rfe8 22. Qg4 Kf7 23. Rh7+ Bg7 24. Bxe6+ Rxe6 25. Rxg7+ Kxg7 26. Qxe6 Qxc3 27. Qe7+ Kh6 28. Rh1+ 1-0 e6 d4 d5",
          "neutral_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 427,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bd3",
            "Nc6",
            "Qe2",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Be6",
            "Kb1",
            "Qe8",
            "h5",
            "Qa4",
            "b3",
            "Qa5",
            "hxg6",
            "hxg6",
            "Ng5",
            "Rae8",
            "Nxe6",
            "Rxe6",
            "Bc4",
            "Rfe8",
            "Qg4",
            "Kf7",
            "Rh7+",
            "Bg7",
            "Bxe6+",
            "Rxe6",
            "Rxg7+",
            "Kxg7",
            "Qxe6",
            "Qxc3",
            "Qe7+",
            "Kh6",
            "Rh1+",
            "e6",
            "d4",
            "d5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c3",
          "positional_uci": "c2c3",
          "neutral_uci": "c2c3",
          "consensus_move": "c2c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Bd3",
              "Nc6",
              "Qe2",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Be6",
              "Kb1",
              "Qe7",
              "h5",
              "g5",
              "h6",
              "Rae8",
              "Rh5",
              "Bf4",
              "g3",
              "Bf7",
              "gxf4",
              "Bxh5",
              "Qxh5",
              "Rxf4",
              "Nxg5",
              "Rxf2",
              "Bxh7+",
              "Kh8",
              "Bg6",
              "Ref8",
              "Nf7+",
              "R8xf7",
              "Bxf7",
              "Qxf7",
              "Qxf7",
              "Rxf7",
              "Re1",
              "Kh7",
              "Re6",
              "Rf1+",
              "Kc2",
              "Rf2+",
              "Kb3",
              "Rf7",
              "Kc4",
              "Rf4+",
              "Kd5",
              "Rf5+",
              "Ke4",
              "Rf7",
              "b4",
              "Rd7",
              "Kf5",
              "Rf7+",
              "Rf6",
              "Re7",
              "Kg5",
              "Re5+",
              "Rf5",
              "Re7",
              "Kf6",
              "Re3",
              "Kf7",
              "Rxc3",
              "Rf6",
              "Re3",
              "Kf8",
              "d5",
              "Rf7+",
              "Kxh6",
              "Rxc7",
              "d4",
              "Rxb7",
              "d3",
              "Rd7",
              "Kg6",
              "a4",
              "Kf6",
              "b5",
              "Re4",
              "a5",
              "Re5",
              "b6",
              "axb6",
              "axb6",
              "Rb5",
              "b7",
              "Ke6",
              "Rxd3",
              "Rxb7",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Bd3",
              "Nc6",
              "Qe2",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Be6",
              "Kb1",
              "Qe7",
              "h5",
              "Rae8",
              "hxg6",
              "hxg6",
              "Rh6",
              "Qg7",
              "Rdh1",
              "Bf5",
              "g4",
              "Bxe4",
              "Bxe4",
              "Bf4",
              "Qc4+",
              "Rf7",
              "Rxg6",
              "Rxe4",
              "Rxg7+",
              "Kxg7",
              "Qxe4",
              "Be5",
              "Rh7+",
              "Kf8",
              "Rxf7+",
              "Kxf7",
              "Qxb7",
              "Ke6",
              "Qxc7",
              "Kd5",
              "Qxa7",
              "Ke4",
              "Qe3+",
              "Kd5",
              "f4",
              "Bf6",
              "g5",
              "Bd8",
              "f5",
              "Kc6",
              "f6",
              "Kd7",
              "f7",
              "Be7",
              "g6",
              "Bf8",
              "Qe8+",
              "Kc7",
              "Qxf8",
              "Kc6",
              "Qxd6+",
              "Kxd6",
              "f8=Q+",
              "Ke5",
              "g7",
              "Ke4",
              "g8=Q",
              "Kd3",
              "Qd5+",
              "Ke2",
              "Qff3+",
              "Ke1",
              "Qdd1#",
              "d4",
              "e5",
              "Qd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Bd3",
              "Nc6",
              "Qe2",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Be6",
              "Kb1",
              "Qe8",
              "h5",
              "Qa4",
              "b3",
              "Qa5",
              "hxg6",
              "hxg6",
              "Ng5",
              "Rae8",
              "Nxe6",
              "Rxe6",
              "Bc4",
              "Rfe8",
              "Qg4",
              "Kf7",
              "Rh7+",
              "Bg7",
              "Bxe6+",
              "Rxe6",
              "Rxg7+",
              "Kxg7",
              "Qxe6",
              "Qxc3",
              "Qe7+",
              "Kh6",
              "Rh1+",
              "e6",
              "d4",
              "d5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 164,
            "completion_tokens": 640,
            "total_tokens": 804,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 164,
            "completion_tokens": 342,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 163,
            "completion_tokens": 427,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 491,
          "total_completion_tokens": 1409,
          "total_tokens": 1900
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 164,
            "completion_tokens": 640,
            "total_tokens": 804,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 164,
            "completion_tokens": 342,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 163,
            "completion_tokens": 427,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp4p/3ppbp1/5p2/3PP2P/5N2/PPPN1PP1/R2QKB1R w KQkq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bd3",
          "aggressive_uci": "f1d3",
          "aggressive_response": "9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. h5 Qf6 15. hxg6 hxg6 16. exf5 Bxf5 17. Bxf5 Qxf5 18. Qc4+ Qf7 19. Qh4 Qg7 20. Nf3 Bf6 21. Qc4+ Qf7 22. Qxf7+ Rxf7 23. Rde1 Kg7 24. Kc2 Rh8 25. Rxh8 Kxh8 26. Re8+ Kg7 27. Kd3 Re7 28. Rxe7+ Bxe7 29. Ke4 c6 30. Nd4 Kf6 31. f4 d5+ 32. Kf3 Bd6 33. g4 a6 34. g5+ Kf7 35. Kg4 c5 36. Ne2 b5 37. f5 gxf5+ 38. Kxf5 b4 39. cxb4 cxb4 40. b3 Bc5 41. Nf4 d4 42. g6+ Kg8 43. Nd3 Bf8 44. Kf6 Bg7+ 45. Ke6 a5 46. Kd5 Bf6 47. Kc5 Kg7 48. Kb5 Bd8 49. Ne5 Bc7 50. Nc6 d3 51. Nd4 d2 52. Ne6+ Kxg6 53. Nxc7 d1=Q 54. Kxa5 Qd8 55. Kxb4 Qxc7 56. a4 Kf6 57. Kb5 Ke6 58. b4 Kd6 59. a5 Qc6# 1-0 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. h5 Qf6 15. hxg6 hxg6 16. exf5 Bxf5 17. Bxf5 Qxf5 18. Qc4+ Qf7 19. Qh4 Qg7 20. Nf3 Bf6 21. Qc4+ Qf7 22. Qxf7+ Rxf7 23. Rde1 Kg7 24. Kc2 Rh8 25",
          "aggressive_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Qe2",
            "Nc6",
            "O-O-O",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "h5",
            "Qf6",
            "hxg6",
            "hxg6",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Qxf5",
            "Qc4+",
            "Qf7",
            "Qh4",
            "Qg7",
            "Nf3",
            "Bf6",
            "Qc4+",
            "Qf7",
            "Qxf7+",
            "Rxf7",
            "Rde1",
            "Kg7",
            "Kc2",
            "Rh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd3",
          "positional_uci": "f1d3",
          "positional_response": "9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. exf5 Bxf5 15. Bxf5 Rxf5 16. g3 Qf8 17. f4 Bg7 18. Rhe1 Kh8 19. Nf3 Ra5 20. Kb1 Qf5+ 21. Qe4 Qb5 22. Nd4 Qa4 23. a3 c5 24. Ne6 Bxc3 25. Qxa4 Rxa4 26. bxc3 Rxa3 27. Kb2 Ra6 28. Nc7 Rb6+ 29. Kc2 Rc8 30. Re7 Rc6 31. Nd5 b5 32. Nf6 R6c7 33. Rde1 b4 34. Rxc7 Rxc7 35. Ne8 Rc6 36. Re6 bxc3 37. Rxd6 Rxd6 38. Nxd6 Kg7 39. Kxc3 Kf6 40. Kc4 Ke6 41. Kxc5 a5 42. Nc4 a4 43. Kb4 Kf5 44. Ne3+ Ke4 45. Ng4 Kf3 46. Nf6 h5 47. Kxa4 Kxg3 48. Nd5 Kxh4 49. Kb4 Kg4 50. Kc4 h4 51. Kd3 h3 52. Ke2 h2 53. Ne3+ Kxf4 54. Ng2+ Kg3 55. Ne3 h1=Q 56. Nf1+ Kf4 57. Nd2 Qg2+ 58. Kd3 Qxd2+ 59. Kxd2 Kf3 60. Ke1 Kg2 61. Ke2 g5 62. Ke3 g4 63. Kf4 g3 64. Kg4 Kf2 65. Kh3 g2 66. Kh2 g1=Q+ 67. Kh3 Qg3# 0-1 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. exf5 Bxf5 15. Bxf5 Rxf5 16. g3 Qf8 17. f4 Bg7 18. Rhe1 Kh8",
          "positional_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Qe2",
            "Nc6",
            "O-O-O",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Rxf5",
            "g3",
            "Qf8",
            "f4",
            "Bg7",
            "Rhe1",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qc2",
          "neutral_uci": "d1c2",
          "neutral_response": "9. Qc2 O-O 10. O-O-O Nc6 11. Bd3 Ne7 12. h5 d5 13. hxg6 hxg6 14. exf5 exf5 15. Rde1 Qd6 16. Ne5 c5 17. Ndf3 c4 18. Be2 b5 19. Qd2 a5 20. Qg5 Ra6 21. Qh4 Re8 22. Qh7+ Kf8 23. Ng5 Qf6 24. f4 b4 25. Qh4 Kg8 26. Qh7+ Kf8 27. Qh4 Kg8 28. Qh7+ Kf8 29. Qh4 Kg8 30. Qh7+ Kf8 31. Qh4 Kg8 32. Qh7+ Kf8 33. Qh4 Kg8 34. Qh7+ Kf8 35. Qh4 Kg8 36. Qh7+ Kf8 37. Qh4 Kg8 38. Qh7+ Kf8 39. Qh4 Kg8 40. Qh7+ Kf8 41. Qh4 Kg8 42. Qh7+ Kf8 43. Qh4 Kg8 44. Qh7+ Kf8 45. Qh4 Kg8 46. Qh7+ Kf8 47. Qh4 Kg8 48. Qh7+ Kf8 49. Qh4 Kg8 50. Qh7+ Kf8 51. Qh4 Kg8 52. Qh7+ Kf8 53. Qh4 Kg8 54. Qh7+ Kf8 55. Qh4 Kg8 56. Qh7+ Kf8 57. Qh4 Kg8 58. Qh7+ Kf8 59. Qh4 Kg8 60. Qh7+ Kf8 61. Qh4 Kg8 62. Qh7+ Kf8 63. Qh4 Kg8 64. Qh7+ Kf8 65. Qh4 Kg8 66. Qh7+ Kf8 67. Qh4 Kg8 68. Qh7+ Kf8 69. Qh4 Kg8 70. Qh7+ Kf8 71. Qh4 Kg8 72. Qh7+ Kf8 73. Qh4 Kg8 74. Qh7+ Kf8 75. Qh4 Kg8 76. Qh7+ Kf8 77. Qh4 Kg8 78. Qh7+ Kf8 79. Qh4 Kg8 80. Qh7+ Kf8 81. Qh4 Kg",
          "neutral_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nc6",
            "Bd3",
            "Ne7",
            "h5",
            "d5",
            "hxg6",
            "hxg6",
            "exf5",
            "exf5",
            "Rde1",
            "Qd6",
            "Ne5",
            "c5",
            "Ndf3",
            "c4",
            "Be2",
            "b5",
            "Qd2",
            "a5",
            "Qg5",
            "Ra6",
            "Qh4",
            "Re8",
            "Qh7+",
            "Kf8",
            "Ng5",
            "Qf6",
            "f4",
            "b4",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d3",
          "positional_uci": "f1d3",
          "neutral_uci": "d1c2",
          "consensus_move": "f1d3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Qe2",
              "Nc6",
              "O-O-O",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "h5",
              "Qf6",
              "hxg6",
              "hxg6",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Qxf5",
              "Qc4+",
              "Qf7",
              "Qh4",
              "Qg7",
              "Nf3",
              "Bf6",
              "Qc4+",
              "Qf7",
              "Qxf7+",
              "Rxf7",
              "Rde1",
              "Kg7",
              "Kc2",
              "Rh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Qe2",
              "Nc6",
              "O-O-O",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Rxf5",
              "g3",
              "Qf8",
              "f4",
              "Bg7",
              "Rhe1",
              "Kh8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "O-O-O",
              "Nc6",
              "Bd3",
              "Ne7",
              "h5",
              "d5",
              "hxg6",
              "hxg6",
              "exf5",
              "exf5",
              "Rde1",
              "Qd6",
              "Ne5",
              "c5",
              "Ndf3",
              "c4",
              "Be2",
              "b5",
              "Qd2",
              "a5",
              "Qg5",
              "Ra6",
              "Qh4",
              "Re8",
              "Qh7+",
              "Kf8",
              "Ng5",
              "Qf6",
              "f4",
              "b4",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 515,
          "total_completion_tokens": 1920,
          "total_tokens": 2435
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp3bp/3pp1p1/5p2/3PP2P/2P2N2/PP1N1PP1/R2QKB1R w KQkq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2",
          "aggressive_uci": "d1e2",
          "aggressive_response": "10. Qe2 O-O 11. O-O-O Nf6 12. e5 Ng4 13. h5 dxe5 14. dxe5 Qe7 15. hxg6 hxg6 16. Nh4 Qf7 17. f4 Bd7 18. Ndf3 Bh6 19. g3 Bc6 20. Bc4 Rad8 21. Rxd8 Rxd8 22. Rd1 Rxd1+ 23. Kxd1 Qd7+ 24. Kc1 Kf7 25. Nd4 Bd5 26. Bxd5 Qxd5 27. Qf3 Qxf3 28. Nhxf3 c6 29. Kd2 Bf8 30. Ng5+ Ke7 31. Ngxe6 Bh6 32. Nc5 Nxe5 33. Nxb7 Nc4+ 34. Kc2 Ne3+ 35. Kd3 Nf1 36. Ne2 Nh2 37. Na5 Kd6 38. Nc4+ Kc5 39. b4+ Kb5 40. Nd6+ Ka4 41. Kc4 Bf8 42. Nc8 a5 43. Nb6+ Ka3 44. bxa5 Kxa2 45. a6 Kb2 46. a7 Kc2 47. a8=Q Kd2 48. Nd4 Ke3 49. Qxf8 Kf2 50. Qh6 Kxg3 51. Qxg6+ Kxf4 52. Qxf5+ Ke3 53. Qh3+ Kd2 54. Qxh2+ Kc1 55. Qc2# e5 56. Nb3# e4 57. Qxc1# e3 58. Qxe3# e2 59. Qxe2# e1=Q 60. Qxe1# e5 61. Qxe5# e4 62. Qxe4# e3 63. Qxe3# e2 64. Qxe2# e1=Q 65. Qxe1# e5 66. Qxe5# e4 67. Qxe4# e3 68. Qxe3# e2 69. Qxe2# e5 70. Qxe5# e4 71. Qxe4# e3 72. Qxe3# e2 73. Qxe2# e5 74. Qxe5# e4 75. Qxe4# e3 76. Qxe3# e2 77. Qxe2# e5 78. Qxe5# e4 79. Qxe4# e3 80. Qxe3# e2 81. Qxe2# e5 82. Qxe5",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nf6",
            "e5",
            "Ng4",
            "h5",
            "dxe5",
            "dxe5",
            "Qe7",
            "hxg6",
            "hxg6",
            "Nh4",
            "Qf7",
            "f4",
            "Bd7",
            "Ndf3",
            "Bh6",
            "g3",
            "Bc6",
            "Bc4",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Rd1",
            "Rxd1+",
            "Kxd1",
            "Qd7+",
            "Kc1",
            "Kf7",
            "Nd4",
            "Bd5",
            "Bxd5",
            "Qxd5",
            "Qf3",
            "Qxf3",
            "Nhxf3",
            "c6",
            "Kd2",
            "Bf8",
            "Ng5+",
            "Ke7",
            "Ngxe6",
            "Bh6",
            "Nc5",
            "Nxe5",
            "Nxb7",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd3",
            "Nf1",
            "Ne2",
            "Nh2",
            "Na5",
            "Kd6",
            "Nc4+",
            "Kc5",
            "b4+",
            "Kb5",
            "Nd6+",
            "Ka4",
            "Kc4",
            "Bf8",
            "Nc8",
            "a5",
            "Nb6+",
            "Ka3",
            "bxa5",
            "Kxa2",
            "a6",
            "Kb2",
            "a7",
            "Kc2",
            "a8=Q",
            "Kd2",
            "Nd4",
            "Ke3",
            "Qxf8",
            "Kf2",
            "Qh6",
            "Kxg3",
            "Qxg6+",
            "Kxf4",
            "Qxf5+",
            "Ke3",
            "Qh3+",
            "Kd2",
            "Qxh2+",
            "Kc1",
            "Qc2#",
            "e5",
            "Nb3#",
            "e4",
            "Qxc1#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e1=Q",
            "Qxe1#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e1=Q",
            "Qxe1#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2",
          "positional_uci": "d1e2",
          "positional_response": "10. Qe2 O-O 11. O-O-O Nf6 12. e5 Nh5 13. g3 d5 14. Ng5 Qe7 15. Rdg1 c5 16. f4\ncxd4 17. cxd4 Bd7 18. Kb1 Rfc8 19. Qe3 Qb4 20. g4 fxg4 21. Rxg4 Rc6 22. Nxh7\nKxh7 23. Bxg6+ Kh8 24. Bxh5 Rac8 25. Nb3 a5 26. Rhg1 a4 27. Rxg7 axb3 28. f5\nbxa2+ 29. Ka1 Rc1+ 30. Rxc1 Rxc1+ 31. Qxc1 Kxg7 32. Qg5+ Kf8 33. Qf6+ Kg8 34.\nBf7+ Kf8 35. Bxe6+ Ke8 36. Qf7+ Kd8 37. Qxd7# Qe1+ 38. Kxa2 Qa5+ 39. Kb3 Qb6+\n40. Kc3 Qa5+ 41. Kd3 Qa6+ 42. Ke3 Qc6 43. Qxc6 bxc6 44. h5 Ke7 45. h6 Kf8 46.\nf6 c5 47. h7 cxd4+ 48. Kxd4 Ke8 49. h8=Q# Qd8 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nf6",
            "e5",
            "Nh5",
            "g3",
            "d5",
            "Ng5",
            "Qe7",
            "Rdg1",
            "c5",
            "f4",
            "cxd4",
            "cxd4",
            "Bd7",
            "Kb1",
            "Rfc8",
            "Qe3",
            "Qb4",
            "g4",
            "fxg4",
            "Rxg4",
            "Rc6",
            "Nxh7",
            "Kxh7",
            "Bxg6+",
            "Kh8",
            "Bxh5",
            "Rac8",
            "Nb3",
            "a5",
            "Rhg1",
            "a4",
            "Rxg7",
            "axb3",
            "f5",
            "bxa2+",
            "Ka1",
            "Rc1+",
            "Rxc1",
            "Rxc1+",
            "Qxc1",
            "Kxg7",
            "Qg5+",
            "Kf8",
            "Qf6+",
            "Kg8",
            "Bf7+",
            "Kf8",
            "Bxe6+",
            "Ke8",
            "Qf7+",
            "Kd8",
            "Qxd7#",
            "Qe1+",
            "Kxa2",
            "Qa5+",
            "Kb3",
            "Qb6+",
            "Kc3",
            "Qa5+",
            "Kd3",
            "Qa6+",
            "Ke3",
            "Qc6",
            "Qxc6",
            "bxc6",
            "h5",
            "Ke7",
            "h6",
            "Kf8",
            "f6",
            "c5",
            "h7",
            "cxd4+",
            "Kxd4",
            "Ke8",
            "h8=Q#",
            "Qd8",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2",
          "neutral_uci": "d1e2",
          "neutral_response": "10. Qe2 O-O 11. O-O-O Nf6 12. e5 Ng4 13. h5 dxe5 14. dxe5 Nxe5 15. Nxe5 Bxe5 16. hxg6 hxg6 17. Nf3 Bf4+ 18. Kb1 Qf6 19. g3 Bd6 20. Rh6 Kg7 21. Rdh1 Rg8 22. Qe3 Bd7 23. Ng5 Kf8 24. Nh7+ Kf7 25. Nxf6 Kxf6 26. Rh7 Bc6 27. Re1 Rae8 28. Bc4 Be4+ 29. Ka1 g5 30. f3 Kg6 31. Reh1 Bf8 32. fxe4 f4 33. gxf4 g4 34. f5+ Kf6 35. Qd4+ Kg5 36. R1h5+ Kf4 37. e5+ Kf3 38. Qd3+ Kf4 39. Qd4+ Kf3 40. Rh3+ gxh3 41. Rxh3+ Kg2 42. Qh4 Bc5 43. Rh2+ Kf3 44. Be2+ Ke3 45. Qf2+ Ke4 46. Qxc5 Kxf5 47. Bd3+ Kg5 48. Qe3+ Kg4 49. Rg2+ Kh4 50. Qh6# O-O-O 51. Rxg8 Rxg8 52. Qh7 Rg1+ 53. Bb1 Kg3 54. Qg6+ Kf2 55. Qxe6 Ke3 56. Qd7 c5 57. e6 b5 58. e7 b4 59. e8=Q+ Kf2 60. Qdf7+ Kg2 61. Qeg8+ Kh1 62. Qfh7# c4 63. Qxg1+ Kxg1 64. Qxa7+ Kf1 65. cxb4 Ke2 66. Qd4 c3 67. bxc3 Kf3 68. c4 Ke2 69. c5 Kf3 70. c6 Ke2 71. c7 Kf3 72. c8=Q Ke2 73. Qe8+ Kf3 74. Qf6+ Kg4 75. Qg8+ Kh5 76. Qfh8# c5 77. Qg6+ Kh4 78. Qhh5# cxb4 79. Qgg4# c3 80. Qhh3# cxb2+ 81. Kxb2# c4 82. Qgg3# c3+",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nf6",
            "e5",
            "Ng4",
            "h5",
            "dxe5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "hxg6",
            "hxg6",
            "Nf3",
            "Bf4+",
            "Kb1",
            "Qf6",
            "g3",
            "Bd6",
            "Rh6",
            "Kg7",
            "Rdh1",
            "Rg8",
            "Qe3",
            "Bd7",
            "Ng5",
            "Kf8",
            "Nh7+",
            "Kf7",
            "Nxf6",
            "Kxf6",
            "Rh7",
            "Bc6",
            "Re1",
            "Rae8",
            "Bc4",
            "Be4+",
            "Ka1",
            "g5",
            "f3",
            "Kg6",
            "Reh1",
            "Bf8",
            "fxe4",
            "f4",
            "gxf4",
            "g4",
            "f5+",
            "Kf6",
            "Qd4+",
            "Kg5",
            "R1h5+",
            "Kf4",
            "e5+",
            "Kf3",
            "Qd3+",
            "Kf4",
            "Qd4+",
            "Kf3",
            "Rh3+",
            "gxh3",
            "Rxh3+",
            "Kg2",
            "Qh4",
            "Bc5",
            "Rh2+",
            "Kf3",
            "Be2+",
            "Ke3",
            "Qf2+",
            "Ke4",
            "Qxc5",
            "Kxf5",
            "Bd3+",
            "Kg5",
            "Qe3+",
            "Kg4",
            "Rg2+",
            "Kh4",
            "Qh6#",
            "O-O-O",
            "Rxg8",
            "Rxg8",
            "Qh7",
            "Rg1+",
            "Bb1",
            "Kg3",
            "Qg6+",
            "Kf2",
            "Qxe6",
            "Ke3",
            "Qd7",
            "c5",
            "e6",
            "b5",
            "e7",
            "b4",
            "e8=Q+",
            "Kf2",
            "Qdf7+",
            "Kg2",
            "Qeg8+",
            "Kh1",
            "Qfh7#",
            "c4",
            "Qxg1+",
            "Kxg1",
            "Qxa7+",
            "Kf1",
            "cxb4",
            "Ke2",
            "Qd4",
            "c3",
            "bxc3",
            "Kf3",
            "c4",
            "Ke2",
            "c5",
            "Kf3",
            "c6",
            "Ke2",
            "c7",
            "Kf3",
            "c8=Q",
            "Ke2",
            "Qe8+",
            "Kf3",
            "Qf6+",
            "Kg4",
            "Qg8+",
            "Kh5",
            "Qfh8#",
            "c5",
            "Qg6+",
            "Kh4",
            "Qhh5#",
            "cxb4",
            "Qgg4#",
            "c3",
            "Qhh3#",
            "cxb2+",
            "Kxb2#",
            "c4",
            "Qgg3#",
            "c3+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1e2",
          "positional_uci": "d1e2",
          "neutral_uci": "d1e2",
          "consensus_move": "d1e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "O-O-O",
              "Nf6",
              "e5",
              "Ng4",
              "h5",
              "dxe5",
              "dxe5",
              "Qe7",
              "hxg6",
              "hxg6",
              "Nh4",
              "Qf7",
              "f4",
              "Bd7",
              "Ndf3",
              "Bh6",
              "g3",
              "Bc6",
              "Bc4",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Rd1",
              "Rxd1+",
              "Kxd1",
              "Qd7+",
              "Kc1",
              "Kf7",
              "Nd4",
              "Bd5",
              "Bxd5",
              "Qxd5",
              "Qf3",
              "Qxf3",
              "Nhxf3",
              "c6",
              "Kd2",
              "Bf8",
              "Ng5+",
              "Ke7",
              "Ngxe6",
              "Bh6",
              "Nc5",
              "Nxe5",
              "Nxb7",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd3",
              "Nf1",
              "Ne2",
              "Nh2",
              "Na5",
              "Kd6",
              "Nc4+",
              "Kc5",
              "b4+",
              "Kb5",
              "Nd6+",
              "Ka4",
              "Kc4",
              "Bf8",
              "Nc8",
              "a5",
              "Nb6+",
              "Ka3",
              "bxa5",
              "Kxa2",
              "a6",
              "Kb2",
              "a7",
              "Kc2",
              "a8=Q",
              "Kd2",
              "Nd4",
              "Ke3",
              "Qxf8",
              "Kf2",
              "Qh6",
              "Kxg3",
              "Qxg6+",
              "Kxf4",
              "Qxf5+",
              "Ke3",
              "Qh3+",
              "Kd2",
              "Qxh2+",
              "Kc1",
              "Qc2#",
              "e5",
              "Nb3#",
              "e4",
              "Qxc1#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e1=Q",
              "Qxe1#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e1=Q",
              "Qxe1#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "O-O-O",
              "Nf6",
              "e5",
              "Nh5",
              "g3",
              "d5",
              "Ng5",
              "Qe7",
              "Rdg1",
              "c5",
              "f4",
              "cxd4",
              "cxd4",
              "Bd7",
              "Kb1",
              "Rfc8",
              "Qe3",
              "Qb4",
              "g4",
              "fxg4",
              "Rxg4",
              "Rc6",
              "Nxh7",
              "Kxh7",
              "Bxg6+",
              "Kh8",
              "Bxh5",
              "Rac8",
              "Nb3",
              "a5",
              "Rhg1",
              "a4",
              "Rxg7",
              "axb3",
              "f5",
              "bxa2+",
              "Ka1",
              "Rc1+",
              "Rxc1",
              "Rxc1+",
              "Qxc1",
              "Kxg7",
              "Qg5+",
              "Kf8",
              "Qf6+",
              "Kg8",
              "Bf7+",
              "Kf8",
              "Bxe6+",
              "Ke8",
              "Qf7+",
              "Kd8",
              "Qxd7#",
              "Qe1+",
              "Kxa2",
              "Qa5+",
              "Kb3",
              "Qb6+",
              "Kc3",
              "Qa5+",
              "Kd3",
              "Qa6+",
              "Ke3",
              "Qc6",
              "Qxc6",
              "bxc6",
              "h5",
              "Ke7",
              "h6",
              "Kf8",
              "f6",
              "c5",
              "h7",
              "cxd4+",
              "Kxd4",
              "Ke8",
              "h8=Q#",
              "Qd8",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "O-O-O",
              "Nf6",
              "e5",
              "Ng4",
              "h5",
              "dxe5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "hxg6",
              "hxg6",
              "Nf3",
              "Bf4+",
              "Kb1",
              "Qf6",
              "g3",
              "Bd6",
              "Rh6",
              "Kg7",
              "Rdh1",
              "Rg8",
              "Qe3",
              "Bd7",
              "Ng5",
              "Kf8",
              "Nh7+",
              "Kf7",
              "Nxf6",
              "Kxf6",
              "Rh7",
              "Bc6",
              "Re1",
              "Rae8",
              "Bc4",
              "Be4+",
              "Ka1",
              "g5",
              "f3",
              "Kg6",
              "Reh1",
              "Bf8",
              "fxe4",
              "f4",
              "gxf4",
              "g4",
              "f5+",
              "Kf6",
              "Qd4+",
              "Kg5",
              "R1h5+",
              "Kf4",
              "e5+",
              "Kf3",
              "Qd3+",
              "Kf4",
              "Qd4+",
              "Kf3",
              "Rh3+",
              "gxh3",
              "Rxh3+",
              "Kg2",
              "Qh4",
              "Bc5",
              "Rh2+",
              "Kf3",
              "Be2+",
              "Ke3",
              "Qf2+",
              "Ke4",
              "Qxc5",
              "Kxf5",
              "Bd3+",
              "Kg5",
              "Qe3+",
              "Kg4",
              "Rg2+",
              "Kh4",
              "Qh6#",
              "O-O-O",
              "Rxg8",
              "Rxg8",
              "Qh7",
              "Rg1+",
              "Bb1",
              "Kg3",
              "Qg6+",
              "Kf2",
              "Qxe6",
              "Ke3",
              "Qd7",
              "c5",
              "e6",
              "b5",
              "e7",
              "b4",
              "e8=Q+",
              "Kf2",
              "Qdf7+",
              "Kg2",
              "Qeg8+",
              "Kh1",
              "Qfh7#",
              "c4",
              "Qxg1+",
              "Kxg1",
              "Qxa7+",
              "Kf1",
              "cxb4",
              "Ke2",
              "Qd4",
              "c3",
              "bxc3",
              "Kf3",
              "c4",
              "Ke2",
              "c5",
              "Kf3",
              "c6",
              "Ke2",
              "c7",
              "Kf3",
              "c8=Q",
              "Ke2",
              "Qe8+",
              "Kf3",
              "Qf6+",
              "Kg4",
              "Qg8+",
              "Kh5",
              "Qfh8#",
              "c5",
              "Qg6+",
              "Kh4",
              "Qhh5#",
              "cxb4",
              "Qgg4#",
              "c3",
              "Qhh3#",
              "cxb2+",
              "Kxb2#",
              "c4",
              "Qgg3#",
              "c3+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1920,
          "total_tokens": 2456
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/pppn2bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1N1PP1/R2QK2R w KQkq - 3 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O-O",
          "aggressive_uci": "e1c1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O O-O 12. h5 g5 13. h6 Bf6 14. exf5 exf5 15.\nQxe7 Bxe7 16. Rde1 Bf6 17. Bxf5 Nb6 18. Bxc8 Raxc8 19. Ne4 g4 20. Nxf6+ Rxf6 21.\nNg5 Rxf2 22. Re7 Nd5 23. Rg7+ Kh8 24. Rxh7+ Kg8 25. Rg7+ Kh8 26. Nf7+ Rxf7 27.\nRxf7 Re8 28. Rhf1 Re2 29. Rg7 Re8 30. Rff7 Ne3 31. Rh7+ Kg8 32. Rfg7+ Kf8 33. Rh8#\n33. ... Ng8 34. Rf7#",
          "aggressive_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 285,
            "total_tokens": 473,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "h6",
            "Bf6",
            "exf5",
            "exf5",
            "Qxe7",
            "Bxe7",
            "Rde1",
            "Bf6",
            "Bxf5",
            "Nb6",
            "Bxc8",
            "Raxc8",
            "Ne4",
            "g4",
            "Nxf6+",
            "Rxf6",
            "Ng5",
            "Rxf2",
            "Re7",
            "Nd5",
            "Rg7+",
            "Kh8",
            "Rxh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Nf7+",
            "Rxf7",
            "Rxf7",
            "Re8",
            "Rhf1",
            "Re2",
            "Rg7",
            "Re8",
            "Rff7",
            "Ne3",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rh8#",
            "Ng8",
            "Rf7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O-O",
          "positional_uci": "e1c1",
          "positional_response": "11. O-O-O O-O 12. h5 g5 13. h6 Bf6 14. exf5 exf5 15. Qxe7 Bxe7 16. Rde1 Bf6 17. Bxf5 Nb6 18. Bxc8 Raxc8 19. Ne4 g4 20. Nxf6+ Rxf6 21. Ng5 Rxf2 22. Re7 Nd5 23. Rg7+ Kh8 24. Rxh7+ Kg8 25. Rg7+ Kh8 26. Nf7+ Rxf7 27. Rxf7 Re8 28. Rhf1 Re2 29. Rg7 Re8 30. Rff7 Ne3 31. Rh7+ Kg8 32. Rfg7+ Kf8 33. Rh8# Rg8 34. Rhxg8# Rg8 35. Rxg8# Rg8",
          "positional_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 217,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "h6",
            "Bf6",
            "exf5",
            "exf5",
            "Qxe7",
            "Bxe7",
            "Rde1",
            "Bf6",
            "Bxf5",
            "Nb6",
            "Bxc8",
            "Raxc8",
            "Ne4",
            "g4",
            "Nxf6+",
            "Rxf6",
            "Ng5",
            "Rxf2",
            "Re7",
            "Nd5",
            "Rg7+",
            "Kh8",
            "Rxh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Nf7+",
            "Rxf7",
            "Rxf7",
            "Re8",
            "Rhf1",
            "Re2",
            "Rg7",
            "Re8",
            "Rff7",
            "Ne3",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rh8#",
            "Rg8",
            "Rhxg8#",
            "Rg8",
            "Rxg8#",
            "Rg8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O-O",
          "neutral_uci": "e1c1",
          "neutral_response": "11. O-O-O O-O 12. h5 g5 13. h6 Bf6 14. exf5 exf5 15. Qxe7 Bxe7 16. Rde1 Bf6 17. Bxf5 Nb6 18. Bxc8 Raxc8 19. Ne4 g4 20. Nxf6+ Rxf6 21. Ng5 Rxf2 22. Re7 Nd5 23. Rg7+ Kh8 24. Rxh7+ Kg8 25. Rg7+ Kh8 26. Nf7+ Rxf7 27. Rxf7 Re8 28. Rhf1 Re2 29. Rg7 Re8 30. Rff7 Ne3 31. Rh7+ Kg8 32. Rfg7+ Kf8 33. Rh8# d4 e5 dxe5",
          "neutral_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 200,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "h6",
            "Bf6",
            "exf5",
            "exf5",
            "Qxe7",
            "Bxe7",
            "Rde1",
            "Bf6",
            "Bxf5",
            "Nb6",
            "Bxc8",
            "Raxc8",
            "Ne4",
            "g4",
            "Nxf6+",
            "Rxf6",
            "Ng5",
            "Rxf2",
            "Re7",
            "Nd5",
            "Rg7+",
            "Kh8",
            "Rxh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Nf7+",
            "Rxf7",
            "Rxf7",
            "Re8",
            "Rhf1",
            "Re2",
            "Rg7",
            "Re8",
            "Rff7",
            "Ne3",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rh8#",
            "d4",
            "e5",
            "dxe5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1c1",
          "positional_uci": "e1c1",
          "neutral_uci": "e1c1",
          "consensus_move": "e1c1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "h6",
              "Bf6",
              "exf5",
              "exf5",
              "Qxe7",
              "Bxe7",
              "Rde1",
              "Bf6",
              "Bxf5",
              "Nb6",
              "Bxc8",
              "Raxc8",
              "Ne4",
              "g4",
              "Nxf6+",
              "Rxf6",
              "Ng5",
              "Rxf2",
              "Re7",
              "Nd5",
              "Rg7+",
              "Kh8",
              "Rxh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Nf7+",
              "Rxf7",
              "Rxf7",
              "Re8",
              "Rhf1",
              "Re2",
              "Rg7",
              "Re8",
              "Rff7",
              "Ne3",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rh8#",
              "Ng8",
              "Rf7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "h6",
              "Bf6",
              "exf5",
              "exf5",
              "Qxe7",
              "Bxe7",
              "Rde1",
              "Bf6",
              "Bxf5",
              "Nb6",
              "Bxc8",
              "Raxc8",
              "Ne4",
              "g4",
              "Nxf6+",
              "Rxf6",
              "Ng5",
              "Rxf2",
              "Re7",
              "Nd5",
              "Rg7+",
              "Kh8",
              "Rxh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Nf7+",
              "Rxf7",
              "Rxf7",
              "Re8",
              "Rhf1",
              "Re2",
              "Rg7",
              "Re8",
              "Rff7",
              "Ne3",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rh8#",
              "Rg8",
              "Rhxg8#",
              "Rg8",
              "Rxg8#",
              "Rg8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "h6",
              "Bf6",
              "exf5",
              "exf5",
              "Qxe7",
              "Bxe7",
              "Rde1",
              "Bf6",
              "Bxf5",
              "Nb6",
              "Bxc8",
              "Raxc8",
              "Ne4",
              "g4",
              "Nxf6+",
              "Rxf6",
              "Ng5",
              "Rxf2",
              "Re7",
              "Nd5",
              "Rg7+",
              "Kh8",
              "Rxh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Nf7+",
              "Rxf7",
              "Rxf7",
              "Re8",
              "Rhf1",
              "Re2",
              "Rg7",
              "Re8",
              "Rff7",
              "Ne3",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rh8#",
              "d4",
              "e5",
              "dxe5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 188,
            "completion_tokens": 285,
            "total_tokens": 473,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 188,
            "completion_tokens": 217,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 187,
            "completion_tokens": 200,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 563,
          "total_completion_tokens": 702,
          "total_tokens": 1265
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 188,
            "completion_tokens": 285,
            "total_tokens": 473,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 188,
            "completion_tokens": 217,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 187,
            "completion_tokens": 200,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/pppnq1bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1NQPP1/R3K2R w KQkq - 5 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe4",
          "aggressive_uci": "d2e4",
          "aggressive_response": "12. Nxe4 Nf6 13. Neg5 Bd7 14. Rde1 O-O-O 15. Nxe6 Rde8 16. Nxg7 Qxg7 17. Qd2 Bc6 18. Rxe8+ Rxe8 19. Re1 Rxe1+ 20. Nxe1 Qe7 21. Qe2 Kd7 22. Qxe7+ Kxe7 23. Kd2 Ke6 24. Ke3 Ng4+ 25. Kf4 Nxf2 26. Bc2 Kf6 27. g4 h6 28. g5+ hxg5+ 29. hxg5+ Kg7 30. c4 Nh3+ 31. Kg4 Bd7+ 32. Kh4 Nf4 33. Be4 c6 34. Nd3 Ne2 35. d5 c5 36. Bf3 Nd4 37. Bg4 Bf5 38. Nf4 Kf7 39. Kg3 Bb1 40. a3 Nf5+ 41. Kf2 Nd4 42. Ke3 Bf5 43. Bd1 Ke7 44. b4 b6 45. bxc5 bxc5 46. Kd2 Kd7 47. Kc3 Kc7 48. Ba4 Kb6 49. Be8 Nf3 50. Bxg6 Bxg6 51. Nxg6 Nxg5 52. Ne7 Nf7 53. Nc8+ Kb7 54. Ne7 Kb6 55. Nc8+ Kb7 56. Ne7 Kb6 57. Nc8+ Kb7 58. Ne7 Kb6 59. Nc8+ Kb7 60. Ne7 Kb6 61. Nc8+ Kb7 62. Ne7 Kb6 63. Nc8+ Kb7 64. Ne7 Kb6 65. Nc8+ Kb7 66. Ne7 Kb6 67. Nc8+ Kb7 68. Ne7 Kb6 69. Nc8+ Kb7 70. Ne7 Kb6 71. Nc8+ Kb7 72. Ne7 Kb6 73. Nc8+ Kb7 74. Ne7 Kb6 75. Nc8+ Kb7 76. Ne7 Kb6 77. Nc8+ Kb7 78. Ne7 Kb6 79. Nc8+ Kb7 80. Ne7 Kb6 81. Nc8+ Kb7 82. Ne7 Kb6 83. Nc8+ Kb7 84. Ne7 Kb6 85. Nc8+ Kb7 86. Ne7 Kb6 87. Nc8+ Kb7 88. Ne7 Kb6 89. N",
          "aggressive_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 640,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Neg5",
            "Bd7",
            "Rde1",
            "O-O-O",
            "Nxe6",
            "Rde8",
            "Nxg7",
            "Qxg7",
            "Qd2",
            "Bc6",
            "Rxe8+",
            "Rxe8",
            "Re1",
            "Rxe1+",
            "Nxe1",
            "Qe7",
            "Qe2",
            "Kd7",
            "Qxe7+",
            "Kxe7",
            "Kd2",
            "Ke6",
            "Ke3",
            "Ng4+",
            "Kf4",
            "Nxf2",
            "Bc2",
            "Kf6",
            "g4",
            "h6",
            "g5+",
            "hxg5+",
            "hxg5+",
            "Kg7",
            "c4",
            "Nh3+",
            "Kg4",
            "Bd7+",
            "Kh4",
            "Nf4",
            "Be4",
            "c6",
            "Nd3",
            "Ne2",
            "d5",
            "c5",
            "Bf3",
            "Nd4",
            "Bg4",
            "Bf5",
            "Nf4",
            "Kf7",
            "Kg3",
            "Bb1",
            "a3",
            "Nf5+",
            "Kf2",
            "Nd4",
            "Ke3",
            "Bf5",
            "Bd1",
            "Ke7",
            "b4",
            "b6",
            "bxc5",
            "bxc5",
            "Kd2",
            "Kd7",
            "Kc3",
            "Kc7",
            "Ba4",
            "Kb6",
            "Be8",
            "Nf3",
            "Bxg6",
            "Bxg6",
            "Nxg6",
            "Nxg5",
            "Ne7",
            "Nf7",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe4",
          "positional_uci": "d2e4",
          "positional_response": "12. Nxe4 Nf6 13. Neg5 Bd7 14. Rde1 O-O-O 15. Nxe6 Rde8 16. Nxg7 Qxg7 17. Qd2 Bc6 18. Rxe8+ Rxe8 19. Re1 Rxe1+ 20. Nxe1 Qe7 21. Qe3 Qxe3+ 22. fxe3 Ng4 23. Kd2 Kd7 24. e4 Ke7 25. Nf3 Nf6 26. Ke3 Ng4+ 27. Kf4 Nf6 28. g4 h6 29. g5 hxg5+ 30. Nxg5 Nh5+ 31. Ke3 Bd7 32. e5 dxe5 33. dxe5 Be8 34. Be4 b6 35. Bd5 Ng7 36. Be4 Nh5 37. Kf3 Ng7 38. Kg4 Nh5 39. Bd3 Ng7 40. Bc4 Nh5 41. Ne6 Bd7 42. Kg5 Bxe6 43. Bxe6 Kxe6 44. Kxg6 Nf4+ 45. Kg5 Kxe5 46. h5 Nxh5 47. Kxh5 Ke4 48. Kg5 Kd3 49. Kf5 Kc2 50. Ke5 Kxb2 51. Kd5 Kxc3 52. Kc6 Kb2 53. Kxc7 Kxa2 54. Kb7 b5 55. Kxa7 b4 56. Kb6 b3 57. Kc5 b2 58. Kd4 b1=Q 59. Ke3 Qb4 60. Kd3 Kb3 61. Ke3 Qc4 62. Kf3 Qd4 63. Kg3 Qe4 64. Kf2 Qd3 65. Kg2 Qe3 66. Kh2 Qf3 67. Kg1 Qe2 68. Kh1 Kc3 69. Kg1 Kd3 70. Kh1 Ke3 71. Kg1 Kf3 72. Kh1 Qg2# e4 d5 Nc6",
          "positional_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 512,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Neg5",
            "Bd7",
            "Rde1",
            "O-O-O",
            "Nxe6",
            "Rde8",
            "Nxg7",
            "Qxg7",
            "Qd2",
            "Bc6",
            "Rxe8+",
            "Rxe8",
            "Re1",
            "Rxe1+",
            "Nxe1",
            "Qe7",
            "Qe3",
            "Qxe3+",
            "fxe3",
            "Ng4",
            "Kd2",
            "Kd7",
            "e4",
            "Ke7",
            "Nf3",
            "Nf6",
            "Ke3",
            "Ng4+",
            "Kf4",
            "Nf6",
            "g4",
            "h6",
            "g5",
            "hxg5+",
            "Nxg5",
            "Nh5+",
            "Ke3",
            "Bd7",
            "e5",
            "dxe5",
            "dxe5",
            "Be8",
            "Be4",
            "b6",
            "Bd5",
            "Ng7",
            "Be4",
            "Nh5",
            "Kf3",
            "Ng7",
            "Kg4",
            "Nh5",
            "Bd3",
            "Ng7",
            "Bc4",
            "Nh5",
            "Ne6",
            "Bd7",
            "Kg5",
            "Bxe6",
            "Bxe6",
            "Kxe6",
            "Kxg6",
            "Nf4+",
            "Kg5",
            "Kxe5",
            "h5",
            "Nxh5",
            "Kxh5",
            "Ke4",
            "Kg5",
            "Kd3",
            "Kf5",
            "Kc2",
            "Ke5",
            "Kxb2",
            "Kd5",
            "Kxc3",
            "Kc6",
            "Kb2",
            "Kxc7",
            "Kxa2",
            "Kb7",
            "b5",
            "Kxa7",
            "b4",
            "Kb6",
            "b3",
            "Kc5",
            "b2",
            "Kd4",
            "b1=Q",
            "Ke3",
            "Qb4",
            "Kd3",
            "Kb3",
            "Ke3",
            "Qc4",
            "Kf3",
            "Qd4",
            "Kg3",
            "Qe4",
            "Kf2",
            "Qd3",
            "Kg2",
            "Qe3",
            "Kh2",
            "Qf3",
            "Kg1",
            "Qe2",
            "Kh1",
            "Kc3",
            "Kg1",
            "Kd3",
            "Kh1",
            "Ke3",
            "Kg1",
            "Kf3",
            "Kh1",
            "Qg2#",
            "e4",
            "d5",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe4",
          "neutral_uci": "d2e4",
          "neutral_response": "12. Nxe4 Nf6 13. Neg5 Bd7 14. Rde1 O-O-O 15. Nxe6 Rde8 16. Nxg7 Qxg7 17. Qd2\nh6 18. Rxe8+ Rxe8 19. Re1 Rxe1+ 20. Qxe1 g5 21. hxg5 hxg5 22. Qe3 g4 23. Nh4\nNd5 24. Qe4 Qg5+ 25. Kc2 Nf6 26. Qg6 Qxh4 27. g3 Qh8 28. Bf5 Bxf5+ 29. Qxf5+\nKb8 30. a4 Qg7 31. b4 a6 32. b5 axb5 33. axb5 Qe7 34. Kd3 d5 35. f3 gxf3 36.\nQxf3 Qe4+ 37. Qxe4 Nxe4 38. g4 Kc8 39. c4 c6 40. bxc6 bxc6 41. cxd5 cxd5 42.\nKe3 Kd7 43. Kf4 Ke6 44. g5 Nd6 45. Kg4 Nf5 46. Kh5 Nxd4 47. Kh6 Nf5+ 48. Kh7\nd4 49. g6 d3 50. g7 Nxg7 51. Kxg7 d2 52. Kg6 d1=Q 53. Kg5 Qf3 54. Kg6 Qg4+ 55.\nKh6 Kf7 56. Kh7 Qh5# d3 d2 d1=Q",
          "neutral_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 393,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g4",
            "Kc8",
            "c4",
            "c6",
            "bxc6",
            "bxc6",
            "cxd5",
            "cxd5",
            "Ke3",
            "Kd7",
            "Kf4",
            "Ke6",
            "g5",
            "Nd6",
            "Kg4",
            "Nf5",
            "Kh5",
            "Nxd4",
            "Kh6",
            "Nf5+",
            "Kh7",
            "d4",
            "g6",
            "d3",
            "g7",
            "Nxg7",
            "Kxg7",
            "d2",
            "Kg6",
            "d1=Q",
            "Kg5",
            "Qf3",
            "Kg6",
            "Qg4+",
            "Kh6",
            "Kf7",
            "Kh7",
            "Qh5#",
            "d3",
            "d2",
            "d1=Q"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2e4",
          "positional_uci": "d2e4",
          "neutral_uci": "d2e4",
          "consensus_move": "d2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Neg5",
              "Bd7",
              "Rde1",
              "O-O-O",
              "Nxe6",
              "Rde8",
              "Nxg7",
              "Qxg7",
              "Qd2",
              "Bc6",
              "Rxe8+",
              "Rxe8",
              "Re1",
              "Rxe1+",
              "Nxe1",
              "Qe7",
              "Qe2",
              "Kd7",
              "Qxe7+",
              "Kxe7",
              "Kd2",
              "Ke6",
              "Ke3",
              "Ng4+",
              "Kf4",
              "Nxf2",
              "Bc2",
              "Kf6",
              "g4",
              "h6",
              "g5+",
              "hxg5+",
              "hxg5+",
              "Kg7",
              "c4",
              "Nh3+",
              "Kg4",
              "Bd7+",
              "Kh4",
              "Nf4",
              "Be4",
              "c6",
              "Nd3",
              "Ne2",
              "d5",
              "c5",
              "Bf3",
              "Nd4",
              "Bg4",
              "Bf5",
              "Nf4",
              "Kf7",
              "Kg3",
              "Bb1",
              "a3",
              "Nf5+",
              "Kf2",
              "Nd4",
              "Ke3",
              "Bf5",
              "Bd1",
              "Ke7",
              "b4",
              "b6",
              "bxc5",
              "bxc5",
              "Kd2",
              "Kd7",
              "Kc3",
              "Kc7",
              "Ba4",
              "Kb6",
              "Be8",
              "Nf3",
              "Bxg6",
              "Bxg6",
              "Nxg6",
              "Nxg5",
              "Ne7",
              "Nf7",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Neg5",
              "Bd7",
              "Rde1",
              "O-O-O",
              "Nxe6",
              "Rde8",
              "Nxg7",
              "Qxg7",
              "Qd2",
              "Bc6",
              "Rxe8+",
              "Rxe8",
              "Re1",
              "Rxe1+",
              "Nxe1",
              "Qe7",
              "Qe3",
              "Qxe3+",
              "fxe3",
              "Ng4",
              "Kd2",
              "Kd7",
              "e4",
              "Ke7",
              "Nf3",
              "Nf6",
              "Ke3",
              "Ng4+",
              "Kf4",
              "Nf6",
              "g4",
              "h6",
              "g5",
              "hxg5+",
              "Nxg5",
              "Nh5+",
              "Ke3",
              "Bd7",
              "e5",
              "dxe5",
              "dxe5",
              "Be8",
              "Be4",
              "b6",
              "Bd5",
              "Ng7",
              "Be4",
              "Nh5",
              "Kf3",
              "Ng7",
              "Kg4",
              "Nh5",
              "Bd3",
              "Ng7",
              "Bc4",
              "Nh5",
              "Ne6",
              "Bd7",
              "Kg5",
              "Bxe6",
              "Bxe6",
              "Kxe6",
              "Kxg6",
              "Nf4+",
              "Kg5",
              "Kxe5",
              "h5",
              "Nxh5",
              "Kxh5",
              "Ke4",
              "Kg5",
              "Kd3",
              "Kf5",
              "Kc2",
              "Ke5",
              "Kxb2",
              "Kd5",
              "Kxc3",
              "Kc6",
              "Kb2",
              "Kxc7",
              "Kxa2",
              "Kb7",
              "b5",
              "Kxa7",
              "b4",
              "Kb6",
              "b3",
              "Kc5",
              "b2",
              "Kd4",
              "b1=Q",
              "Ke3",
              "Qb4",
              "Kd3",
              "Kb3",
              "Ke3",
              "Qc4",
              "Kf3",
              "Qd4",
              "Kg3",
              "Qe4",
              "Kf2",
              "Qd3",
              "Kg2",
              "Qe3",
              "Kh2",
              "Qf3",
              "Kg1",
              "Qe2",
              "Kh1",
              "Kc3",
              "Kg1",
              "Kd3",
              "Kh1",
              "Ke3",
              "Kg1",
              "Kf3",
              "Kh1",
              "Qg2#",
              "e4",
              "d5",
              "Nc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "g4",
              "Kc8",
              "c4",
              "c6",
              "bxc6",
              "bxc6",
              "cxd5",
              "cxd5",
              "Ke3",
              "Kd7",
              "Kf4",
              "Ke6",
              "g5",
              "Nd6",
              "Kg4",
              "Nf5",
              "Kh5",
              "Nxd4",
              "Kh6",
              "Nf5+",
              "Kh7",
              "d4",
              "g6",
              "d3",
              "g7",
              "Nxg7",
              "Kxg7",
              "d2",
              "Kg6",
              "d1=Q",
              "Kg5",
              "Qf3",
              "Kg6",
              "Qg4+",
              "Kh6",
              "Kf7",
              "Kh7",
              "Qh5#",
              "d3",
              "d2",
              "d1=Q"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 197,
            "completion_tokens": 640,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 197,
            "completion_tokens": 512,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 196,
            "completion_tokens": 393,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 590,
          "total_completion_tokens": 1545,
          "total_tokens": 2135
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 197,
            "completion_tokens": 640,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 197,
            "completion_tokens": 512,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 196,
            "completion_tokens": 393,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/pppnq1bp/3pp1p1/8/3Pp2P/2PB1N2/PP1NQPP1/2KR3R w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf6+",
          "aggressive_uci": "e4f6",
          "aggressive_response": "13. Nxf6+ Bxf6 14. h5\ng5 15. h6 O-O 16. Rh5 Kh8 17. Qe3 Rg8 18. Re1 Bd7 19. Nh2 Rae8 20. Ng4 e5 21.\nNxf6 Qxf6 22. dxe5 Rxe5 23. Qd2 Rxe1+ 24. Qxe1 Re8 25. Qd2 Re5 26. g3 Bg4 27.\nRh1 Bf3 28. Re1 Qxh6 29. Rxe5 dxe5 30. Qe3 Qf6 31. Qxa7 Qd8 32. Qe3 Qf6 33. Be4\nBxe4 34. Qxe4 c6 35. f3 Kg7 36. Kd2 Qd6+ 37. Ke2 Qe6 38. b3 h5 39. Kf2 Qd6 40.\nQe3 Kf6 41. Kg2 Qd1 42. Qf2 Qd3 43. c4 Kf5 44. Kh2 Qd4 45. Qc2+ e4 46. fxe4+\nQxe4 47. Qf2+ Kg4 48. Qd2 h4 49. Qd1+ Qf3 50. Qd4+ Kh5 51. gxh4 Qf4+ 52. Qxf4\ngxf4 53. Kh3 f3 54. Kg3 f2 55. Kxf2 Kxh4 56. Ke3 Kg5 57. Kd4 Kf6 58. Kc5 Ke7 59.\nKb6 Kd6 60. Kxb7 Kc5 61. a4 Kb4 62. Kxc6 Kxb3 63. Kb5 Kc3 64. c5 Kd4 65. c6\nKd5 66. c7 Kd6 67. c8=Q Ke7 68. Qc6 Kd8 69. Qb7 Ke8 70. Kc6 Kf8 71. Kd6 Kg8\n72. Ke6 Kh8 73. Kf6 Kg8 74. Qg7# Kd8 75. Qb7 Ke8 76. Qe7# Kd8 77. Ke6 Kc8 78.\nKd6 Kb8 79. Kc6 Ka8 80. Qb7# Kd8 81. Qd7# Kxd8 82. Kb7 Kd7 83. a5 Kd6 84.\na6 Kc5 85. a7 Kb5 86. a8=Q Kc5 87. Qd8 Kb5 88. Q",
          "aggressive_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf6",
            "dxe5",
            "Rxe5",
            "Qd2",
            "Rxe1+",
            "Qxe1",
            "Re8",
            "Qd2",
            "Re5",
            "g3",
            "Bg4",
            "Rh1",
            "Bf3",
            "Re1",
            "Qxh6",
            "Rxe5",
            "dxe5",
            "Qe3",
            "Qf6",
            "Qxa7",
            "Qd8",
            "Qe3",
            "Qf6",
            "Be4",
            "Bxe4",
            "Qxe4",
            "c6",
            "f3",
            "Kg7",
            "Kd2",
            "Qd6+",
            "Ke2",
            "Qe6",
            "b3",
            "h5",
            "Kf2",
            "Qd6",
            "Qe3",
            "Kf6",
            "Kg2",
            "Qd1",
            "Qf2",
            "Qd3",
            "c4",
            "Kf5",
            "Kh2",
            "Qd4",
            "Qc2+",
            "e4",
            "fxe4+",
            "Qxe4",
            "Qf2+",
            "Kg4",
            "Qd2",
            "h4",
            "Qd1+",
            "Qf3",
            "Qd4+",
            "Kh5",
            "gxh4",
            "Qf4+",
            "Qxf4",
            "gxf4",
            "Kh3",
            "f3",
            "Kg3",
            "f2",
            "Kxf2",
            "Kxh4",
            "Ke3",
            "Kg5",
            "Kd4",
            "Kf6",
            "Kc5",
            "Ke7",
            "Kb6",
            "Kd6",
            "Kxb7",
            "Kc5",
            "a4",
            "Kb4",
            "Kxc6",
            "Kxb3",
            "Kb5",
            "Kc3",
            "c5",
            "Kd4",
            "c6",
            "Kd5",
            "c7",
            "Kd6",
            "c8=Q",
            "Ke7",
            "Qc6",
            "Kd8",
            "Qb7",
            "Ke8",
            "Kc6",
            "Kf8",
            "Kd6",
            "Kg8",
            "Ke6",
            "Kh8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Kd8",
            "Qb7",
            "Ke8",
            "Qe7#",
            "Kd8",
            "Ke6",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kxd8",
            "Kb7",
            "Kd7",
            "a5",
            "Kd6",
            "a6",
            "Kc5",
            "a7",
            "Kb5",
            "a8=Q",
            "Kc5",
            "Qd8",
            "Kb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Neg5",
          "positional_uci": "e4g5",
          "positional_response": "13. Neg5 O-O 14. Rde1 Re8 15. h5 Nxh5 16. Rxh5 gxh5 17. Bxh7+ Kh8 18. Bg6 Rf8 19. Rh1 Bh6 20. Rxh5 Kg7 21. Rxh6 Kxh6 22. Qe4 Kg7 23. Bh5 Rf5 24. Qg4 Kh6 25. Nf7+ Rxf7 26. Qg6# d4 e5 Qf6",
          "positional_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 124,
            "total_tokens": 330,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Rde1",
            "Re8",
            "h5",
            "Nxh5",
            "Rxh5",
            "gxh5",
            "Bxh7+",
            "Kh8",
            "Bg6",
            "Rf8",
            "Rh1",
            "Bh6",
            "Rxh5",
            "Kg7",
            "Rxh6",
            "Kxh6",
            "Qe4",
            "Kg7",
            "Bh5",
            "Rf5",
            "Qg4",
            "Kh6",
            "Nf7+",
            "Rxf7",
            "Qg6#",
            "d4",
            "e5",
            "Qf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Neg5",
          "neutral_uci": "e4g5",
          "neutral_response": "13. Neg5 O-O 14. h5 Nxh5 15. Nxh7 Kxh7 16. Rxh5+ Kg8 17. Bxg6 Rf6 18. Bh7+ Kf8 19. Rdh1 Bd7 20. Be4 d5 21. Bd3 Be8 22. Rh8+ Bxh8 23. Rxh8+ Kg7 24. Rh7+ Kf8 25. Rxe7 Kxe7 26. Ne5 Kd6 27. g4 c5 28. g5 Rf8 29. g6 cxd4 30. cxd4 Rc8+ 31. Kd2 Rg8 32. Qg4 Rc7 33. Qg5 Rcg7 34. Qd8+ Bd7 35. Nf7+ Kc6 36. Ne5+ Kd6 37. Qa5 b6 38. Qxa7 Bc6 39. Qxb6 Rc7 40. Bb5 Rgc8 41. Bxc6 Rxc6 42. Nxc6 Rxc6 43. Qxc6+ Kxc6 44. g7 Kd6 45. g8=Q e5 46. Qg6+ Kd7 47. dxe5 Ke7 48. Qd6+ Kf7 49. Qf6+ Ke8 50. e6 d4 51. Qf7+ Kd8 52. Qd7# O-O-O Nf3 Kc7 Qc5+ Kb8 Qc7#",
          "neutral_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 365,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "Nxh5",
            "Nxh7",
            "Kxh7",
            "Rxh5+",
            "Kg8",
            "Bxg6",
            "Rf6",
            "Bh7+",
            "Kf8",
            "Rdh1",
            "Bd7",
            "Be4",
            "d5",
            "Bd3",
            "Be8",
            "Rh8+",
            "Bxh8",
            "Rxh8+",
            "Kg7",
            "Rh7+",
            "Kf8",
            "Rxe7",
            "Kxe7",
            "Ne5",
            "Kd6",
            "g4",
            "c5",
            "g5",
            "Rf8",
            "g6",
            "cxd4",
            "cxd4",
            "Rc8+",
            "Kd2",
            "Rg8",
            "Qg4",
            "Rc7",
            "Qg5",
            "Rcg7",
            "Qd8+",
            "Bd7",
            "Nf7+",
            "Kc6",
            "Ne5+",
            "Kd6",
            "Qa5",
            "b6",
            "Qxa7",
            "Bc6",
            "Qxb6",
            "Rc7",
            "Bb5",
            "Rgc8",
            "Bxc6",
            "Rxc6",
            "Nxc6",
            "Rxc6",
            "Qxc6+",
            "Kxc6",
            "g7",
            "Kd6",
            "g8=Q",
            "e5",
            "Qg6+",
            "Kd7",
            "dxe5",
            "Ke7",
            "Qd6+",
            "Kf7",
            "Qf6+",
            "Ke8",
            "e6",
            "d4",
            "Qf7+",
            "Kd8",
            "Qd7#",
            "O-O-O",
            "Nf3",
            "Kc7",
            "Qc5+",
            "Kb8",
            "Qc7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f6",
          "positional_uci": "e4g5",
          "neutral_uci": "e4g5",
          "consensus_move": "e4g5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf6",
              "dxe5",
              "Rxe5",
              "Qd2",
              "Rxe1+",
              "Qxe1",
              "Re8",
              "Qd2",
              "Re5",
              "g3",
              "Bg4",
              "Rh1",
              "Bf3",
              "Re1",
              "Qxh6",
              "Rxe5",
              "dxe5",
              "Qe3",
              "Qf6",
              "Qxa7",
              "Qd8",
              "Qe3",
              "Qf6",
              "Be4",
              "Bxe4",
              "Qxe4",
              "c6",
              "f3",
              "Kg7",
              "Kd2",
              "Qd6+",
              "Ke2",
              "Qe6",
              "b3",
              "h5",
              "Kf2",
              "Qd6",
              "Qe3",
              "Kf6",
              "Kg2",
              "Qd1",
              "Qf2",
              "Qd3",
              "c4",
              "Kf5",
              "Kh2",
              "Qd4",
              "Qc2+",
              "e4",
              "fxe4+",
              "Qxe4",
              "Qf2+",
              "Kg4",
              "Qd2",
              "h4",
              "Qd1+",
              "Qf3",
              "Qd4+",
              "Kh5",
              "gxh4",
              "Qf4+",
              "Qxf4",
              "gxf4",
              "Kh3",
              "f3",
              "Kg3",
              "f2",
              "Kxf2",
              "Kxh4",
              "Ke3",
              "Kg5",
              "Kd4",
              "Kf6",
              "Kc5",
              "Ke7",
              "Kb6",
              "Kd6",
              "Kxb7",
              "Kc5",
              "a4",
              "Kb4",
              "Kxc6",
              "Kxb3",
              "Kb5",
              "Kc3",
              "c5",
              "Kd4",
              "c6",
              "Kd5",
              "c7",
              "Kd6",
              "c8=Q",
              "Ke7",
              "Qc6",
              "Kd8",
              "Qb7",
              "Ke8",
              "Kc6",
              "Kf8",
              "Kd6",
              "Kg8",
              "Ke6",
              "Kh8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Kd8",
              "Qb7",
              "Ke8",
              "Qe7#",
              "Kd8",
              "Ke6",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kxd8",
              "Kb7",
              "Kd7",
              "a5",
              "Kd6",
              "a6",
              "Kc5",
              "a7",
              "Kb5",
              "a8=Q",
              "Kc5",
              "Qd8",
              "Kb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Rde1",
              "Re8",
              "h5",
              "Nxh5",
              "Rxh5",
              "gxh5",
              "Bxh7+",
              "Kh8",
              "Bg6",
              "Rf8",
              "Rh1",
              "Bh6",
              "Rxh5",
              "Kg7",
              "Rxh6",
              "Kxh6",
              "Qe4",
              "Kg7",
              "Bh5",
              "Rf5",
              "Qg4",
              "Kh6",
              "Nf7+",
              "Rxf7",
              "Qg6#",
              "d4",
              "e5",
              "Qf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "h5",
              "Nxh5",
              "Nxh7",
              "Kxh7",
              "Rxh5+",
              "Kg8",
              "Bxg6",
              "Rf6",
              "Bh7+",
              "Kf8",
              "Rdh1",
              "Bd7",
              "Be4",
              "d5",
              "Bd3",
              "Be8",
              "Rh8+",
              "Bxh8",
              "Rxh8+",
              "Kg7",
              "Rh7+",
              "Kf8",
              "Rxe7",
              "Kxe7",
              "Ne5",
              "Kd6",
              "g4",
              "c5",
              "g5",
              "Rf8",
              "g6",
              "cxd4",
              "cxd4",
              "Rc8+",
              "Kd2",
              "Rg8",
              "Qg4",
              "Rc7",
              "Qg5",
              "Rcg7",
              "Qd8+",
              "Bd7",
              "Nf7+",
              "Kc6",
              "Ne5+",
              "Kd6",
              "Qa5",
              "b6",
              "Qxa7",
              "Bc6",
              "Qxb6",
              "Rc7",
              "Bb5",
              "Rgc8",
              "Bxc6",
              "Rxc6",
              "Nxc6",
              "Rxc6",
              "Qxc6+",
              "Kxc6",
              "g7",
              "Kd6",
              "g8=Q",
              "e5",
              "Qg6+",
              "Kd7",
              "dxe5",
              "Ke7",
              "Qd6+",
              "Kf7",
              "Qf6+",
              "Ke8",
              "e6",
              "d4",
              "Qf7+",
              "Kd8",
              "Qd7#",
              "O-O-O",
              "Nf3",
              "Kc7",
              "Qc5+",
              "Kb8",
              "Qc7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 206,
            "completion_tokens": 124,
            "total_tokens": 330,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 205,
            "completion_tokens": 365,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 617,
          "total_completion_tokens": 1129,
          "total_tokens": 1746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 206,
            "completion_tokens": 124,
            "total_tokens": 330,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 205,
            "completion_tokens": 365,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/ppp1q1bp/3ppnp1/8/3PN2P/2PB1N2/PP2QPP1/2KR3R w kq - 1 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rhe1",
          "aggressive_uci": "h1e1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1 Re8 15. Bc4 d5 16. Bd3 c6 17. Ne5 Kc7 18. f4 Bd7 19. g4 Rad8 20. h5 gxh5 21. gxh5 Bh6 22. Rg1 Rf8 23. Rdf1 Be8 24. Ng4 Nxg4 25. Qxg4 Bd7 26. Qg3 Qd6 27. Nh3 Rg8 28. Qh4 Rxg1 29. Rxg1 Rf8 30. Rf1 c5 31. dxc5 Qxc5 32. Kb1 Qe3 33. Bc2 e5 34. Ng5 Rxf4 35. Rxf4 Qxf4 36. Qxf4 exf4 37. Nf3 Bg4 38. Bd1 Bxh5 39. Kc2 Bg6+ 40. Kd2 Be4 41. Ke2 Kd6 42. Kf2 Bg7 43. Ng5 Bf6 44. Nf3 h5 45. Kg2 h4 46. Kh3 Bf5+ 47. Kg2 h3+ 48. Kh2 Be4 49. Kxh3 Bxf3 50. Bxf3 Ke5 51. Kg4 b5 52. Be2 a6 53. Kf3 d4 54. cxd4+ Kxd4 55. Kxf4 Be5+ 56. Kf3 Bd6 57. Kf2 Bc5 58. Ke1 Ke3 59. Kd1 Bd4 60. b3 Bc3 61. Bf1 Kd4 62. Kc2 Be1 63. a4 bxa4 64. bxa4 a5 65. Kb3 Bb4 66. Bb5 Kc5 67. Bc4 Kd4 68. Bb5 Kc5 69. Bc4 Kd4 70. Bb5 Kc5 71. Bc4 Kd4 72. Bb5 Kc5 73. Bc4 Kd4 74. Bb5 Kc5 75. Bc4 Kd4 76. Bb5 Kc5 77. Bc4 Kd",
          "aggressive_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re8",
            "Bc4",
            "d5",
            "Bd3",
            "c6",
            "Ne5",
            "Kc7",
            "f4",
            "Bd7",
            "g4",
            "Rad8",
            "h5",
            "gxh5",
            "gxh5",
            "Bh6",
            "Rg1",
            "Rf8",
            "Rdf1",
            "Be8",
            "Ng4",
            "Nxg4",
            "Qxg4",
            "Bd7",
            "Qg3",
            "Qd6",
            "Nh3",
            "Rg8",
            "Qh4",
            "Rxg1",
            "Rxg1",
            "Rf8",
            "Rf1",
            "c5",
            "dxc5",
            "Qxc5",
            "Kb1",
            "Qe3",
            "Bc2",
            "e5",
            "Ng5",
            "Rxf4",
            "Rxf4",
            "Qxf4",
            "Qxf4",
            "exf4",
            "Nf3",
            "Bg4",
            "Bd1",
            "Bxh5",
            "Kc2",
            "Bg6+",
            "Kd2",
            "Be4",
            "Ke2",
            "Kd6",
            "Kf2",
            "Bg7",
            "Ng5",
            "Bf6",
            "Nf3",
            "h5",
            "Kg2",
            "h4",
            "Kh3",
            "Bf5+",
            "Kg2",
            "h3+",
            "Kh2",
            "Be4",
            "Kxh3",
            "Bxf3",
            "Bxf3",
            "Ke5",
            "Kg4",
            "b5",
            "Be2",
            "a6",
            "Kf3",
            "d4",
            "cxd4+",
            "Kxd4",
            "Kxf4",
            "Be5+",
            "Kf3",
            "Bd6",
            "Kf2",
            "Bc5",
            "Ke1",
            "Ke3",
            "Kd1",
            "Bd4",
            "b3",
            "Bc3",
            "Bf1",
            "Kd4",
            "Kc2",
            "Be1",
            "a4",
            "bxa4",
            "bxa4",
            "a5",
            "Kb3",
            "Bb4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rhe1",
          "positional_uci": "h1e1",
          "positional_response": "14. Rhe1 Re8 15. Bc4 d5 16. Bd3 Bd7 17. Ne5 Kc8 18. Nxd7 Kxd7 19. Nxe6 Qxe6 20.\nQxe6+ Rxe6 21. Rxe6 Kxe6 22. Re1+ Kd6 23. f3 Re8 24. Rxe8 Nxe8 25. g4 Nf6 26.\nKd2 c5 27. dxc5+ Kxc5 28. b4+ Kd6 29. Ke3 Nd7 30. c4 dxc4 31. Bxc4 Ne5 32. Bg8\nh6 33. Ke4 Nc6 34. a3 Bb2 35. b5 Ne7 36. Bf7 Bxa3 37. f4 Bc1 38. f5 gxf5+ 39.\ngxf5 Bb2 40. h5 Bf6 41. Be6 Kc5 42. Bd7 a6 43. bxa6 bxa6 44. Kd3 a5 45. Kc2\nKb4 46. Kb1 a4 47. Ka2 a3 48. Be6 Nc6 49. Bd5 Nd4 50. Be4 Nb5 51. Bd3 Nc3+ 52.\nKa1 Kb3 53. Bc4+ Kxc4 54. 1/2-1/2\n\nKb3 a5 Ka4 a4 Kb5 a3 Ka6 a2 Kb7 a1=Q#",
          "positional_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 365,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Bc4",
            "d5",
            "Bd3",
            "Bd7",
            "Ne5",
            "Kc8",
            "Nxd7",
            "Kxd7",
            "Nxe6",
            "Qxe6",
            "Qxe6+",
            "Rxe6",
            "Rxe6",
            "Kxe6",
            "Re1+",
            "Kd6",
            "f3",
            "Re8",
            "Rxe8",
            "Nxe8",
            "g4",
            "Nf6",
            "Kd2",
            "c5",
            "dxc5+",
            "Kxc5",
            "b4+",
            "Kd6",
            "Ke3",
            "Nd7",
            "c4",
            "dxc4",
            "Bxc4",
            "Ne5",
            "Bg8",
            "h6",
            "Ke4",
            "Nc6",
            "a3",
            "Bb2",
            "b5",
            "Ne7",
            "Bf7",
            "Bxa3",
            "f4",
            "Bc1",
            "f5",
            "gxf5+",
            "gxf5",
            "Bb2",
            "h5",
            "Bf6",
            "Be6",
            "Kc5",
            "Bd7",
            "a6",
            "bxa6",
            "bxa6",
            "Kd3",
            "a5",
            "Kc2",
            "Kb4",
            "Kb1",
            "a4",
            "Ka2",
            "a3",
            "Be6",
            "Nc6",
            "Bd5",
            "Nd4",
            "Be4",
            "Nb5",
            "Bd3",
            "Nc3+",
            "Ka1",
            "Kb3",
            "Bc4+",
            "Kxc4",
            "Kb3",
            "a5",
            "Ka4",
            "a4",
            "Kb5",
            "a3",
            "Ka6",
            "a2",
            "Kb7",
            "a1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rhe1",
          "neutral_uci": "h1e1",
          "neutral_response": "14. Rhe1 Re8 15. Bc4 d5 16. Bd3 Bd7 17. Ne5 Kc8 18. Nxd7 Kxd7 19. Nxe6 Qxe6 20. Qxe6+ Rxe6 21. Rxe6 Kxe6 22. Re1+ Kd7 23. f3 Re8 24. Rxe8 Nxe8 25. g4 Nd6 26. Kd2 Ke6 27. Ke3 b6 28. b3 c5 29. dxc5 bxc5 30. c4 d4+ 31. Kf4 Be5+ 32. Kg5 Nf7# d4 d5 d6",
          "neutral_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 162,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Bc4",
            "d5",
            "Bd3",
            "Bd7",
            "Ne5",
            "Kc8",
            "Nxd7",
            "Kxd7",
            "Nxe6",
            "Qxe6",
            "Qxe6+",
            "Rxe6",
            "Rxe6",
            "Kxe6",
            "Re1+",
            "Kd7",
            "f3",
            "Re8",
            "Rxe8",
            "Nxe8",
            "g4",
            "Nd6",
            "Kd2",
            "Ke6",
            "Ke3",
            "b6",
            "b3",
            "c5",
            "dxc5",
            "bxc5",
            "c4",
            "d4+",
            "Kf4",
            "Be5+",
            "Kg5",
            "Nf7#",
            "d4",
            "d5",
            "d6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h1e1",
          "positional_uci": "h1e1",
          "neutral_uci": "h1e1",
          "consensus_move": "h1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re8",
              "Bc4",
              "d5",
              "Bd3",
              "c6",
              "Ne5",
              "Kc7",
              "f4",
              "Bd7",
              "g4",
              "Rad8",
              "h5",
              "gxh5",
              "gxh5",
              "Bh6",
              "Rg1",
              "Rf8",
              "Rdf1",
              "Be8",
              "Ng4",
              "Nxg4",
              "Qxg4",
              "Bd7",
              "Qg3",
              "Qd6",
              "Nh3",
              "Rg8",
              "Qh4",
              "Rxg1",
              "Rxg1",
              "Rf8",
              "Rf1",
              "c5",
              "dxc5",
              "Qxc5",
              "Kb1",
              "Qe3",
              "Bc2",
              "e5",
              "Ng5",
              "Rxf4",
              "Rxf4",
              "Qxf4",
              "Qxf4",
              "exf4",
              "Nf3",
              "Bg4",
              "Bd1",
              "Bxh5",
              "Kc2",
              "Bg6+",
              "Kd2",
              "Be4",
              "Ke2",
              "Kd6",
              "Kf2",
              "Bg7",
              "Ng5",
              "Bf6",
              "Nf3",
              "h5",
              "Kg2",
              "h4",
              "Kh3",
              "Bf5+",
              "Kg2",
              "h3+",
              "Kh2",
              "Be4",
              "Kxh3",
              "Bxf3",
              "Bxf3",
              "Ke5",
              "Kg4",
              "b5",
              "Be2",
              "a6",
              "Kf3",
              "d4",
              "cxd4+",
              "Kxd4",
              "Kxf4",
              "Be5+",
              "Kf3",
              "Bd6",
              "Kf2",
              "Bc5",
              "Ke1",
              "Ke3",
              "Kd1",
              "Bd4",
              "b3",
              "Bc3",
              "Bf1",
              "Kd4",
              "Kc2",
              "Be1",
              "a4",
              "bxa4",
              "bxa4",
              "a5",
              "Kb3",
              "Bb4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Bc4",
              "d5",
              "Bd3",
              "Bd7",
              "Ne5",
              "Kc8",
              "Nxd7",
              "Kxd7",
              "Nxe6",
              "Qxe6",
              "Qxe6+",
              "Rxe6",
              "Rxe6",
              "Kxe6",
              "Re1+",
              "Kd6",
              "f3",
              "Re8",
              "Rxe8",
              "Nxe8",
              "g4",
              "Nf6",
              "Kd2",
              "c5",
              "dxc5+",
              "Kxc5",
              "b4+",
              "Kd6",
              "Ke3",
              "Nd7",
              "c4",
              "dxc4",
              "Bxc4",
              "Ne5",
              "Bg8",
              "h6",
              "Ke4",
              "Nc6",
              "a3",
              "Bb2",
              "b5",
              "Ne7",
              "Bf7",
              "Bxa3",
              "f4",
              "Bc1",
              "f5",
              "gxf5+",
              "gxf5",
              "Bb2",
              "h5",
              "Bf6",
              "Be6",
              "Kc5",
              "Bd7",
              "a6",
              "bxa6",
              "bxa6",
              "Kd3",
              "a5",
              "Kc2",
              "Kb4",
              "Kb1",
              "a4",
              "Ka2",
              "a3",
              "Be6",
              "Nc6",
              "Bd5",
              "Nd4",
              "Be4",
              "Nb5",
              "Bd3",
              "Nc3+",
              "Ka1",
              "Kb3",
              "Bc4+",
              "Kxc4",
              "Kb3",
              "a5",
              "Ka4",
              "a4",
              "Kb5",
              "a3",
              "Ka6",
              "a2",
              "Kb7",
              "a1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re8",
              "Bc4",
              "d5",
              "Bd3",
              "Bd7",
              "Ne5",
              "Kc8",
              "Nxd7",
              "Kxd7",
              "Nxe6",
              "Qxe6",
              "Qxe6+",
              "Rxe6",
              "Rxe6",
              "Kxe6",
              "Re1+",
              "Kd7",
              "f3",
              "Re8",
              "Rxe8",
              "Nxe8",
              "g4",
              "Nd6",
              "Kd2",
              "Ke6",
              "Ke3",
              "b6",
              "b3",
              "c5",
              "dxc5",
              "bxc5",
              "c4",
              "d4+",
              "Kf4",
              "Be5+",
              "Kg5",
              "Nf7#",
              "d4",
              "d5",
              "d6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 214,
            "completion_tokens": 365,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 213,
            "completion_tokens": 162,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 641,
          "total_completion_tokens": 1167,
          "total_tokens": 1808
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 214,
            "completion_tokens": 365,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 213,
            "completion_tokens": 162,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk3r/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KR3R w - - 3 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxh7",
          "aggressive_uci": "g5h7",
          "aggressive_response": "15. Nxh7 Nxh7 16. Bxg6 Rh8 17. g4 Nf8 18. Bd3 Bd7 19. g5 Be8 20. Qe4 c6 21.\nQg4 Bh5 22. Qg3 Kc7 23. Rd2 Re8 24. Nh2 e5 25. f4 Qf7 26. f5 Qxa2 27. f6\nBxf6 28. gxf6 Nd7 29. dxe5 Nxe5 30. Bb1 Qf7 31. Rf2 Rhg8 32. Qf4 Nd3+ 33.\nBxd3 Rxe1+ 34. Kd2 Rd1+ 35. Kc2 Rgg1 36. Nf1 Qd5 37. f7 Rxd3 38. f8=Q Bd1+\n39. Kc1 Bb3 40. Qe7+ Kb6 41. Qd8+ Ka6 42. Rd2 Rxf1+ 43. Qxf1 Rxd2 44. Qxd3+\nQxd3 45. Qa5+ Kxa5 46. c4 Qc2# Qc2 Qd1#",
          "aggressive_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 283,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg6",
            "Rh8",
            "g4",
            "Nf8",
            "Bd3",
            "Bd7",
            "g5",
            "Be8",
            "Qe4",
            "c6",
            "Qg4",
            "Bh5",
            "Qg3",
            "Kc7",
            "Rd2",
            "Re8",
            "Nh2",
            "e5",
            "f4",
            "Qf7",
            "f5",
            "Qxa2",
            "f6",
            "Bxf6",
            "gxf6",
            "Nd7",
            "dxe5",
            "Nxe5",
            "Bb1",
            "Qf7",
            "Rf2",
            "Rhg8",
            "Qf4",
            "Nd3+",
            "Bxd3",
            "Rxe1+",
            "Kd2",
            "Rd1+",
            "Kc2",
            "Rgg1",
            "Nf1",
            "Qd5",
            "f7",
            "Rxd3",
            "f8=Q",
            "Bd1+",
            "Kc1",
            "Bb3",
            "Qe7+",
            "Kb6",
            "Qd8+",
            "Ka6",
            "Rd2",
            "Rxf1+",
            "Qxf1",
            "Rxd2",
            "Qxd3+",
            "Qxd3",
            "Qa5+",
            "Kxa5",
            "c4",
            "Qc2#",
            "Qc2",
            "Qd1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxh7",
          "positional_uci": "g5h7",
          "positional_response": "15. Nxh7 Nxh7 16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5\nNd5 21. Qf3 Qf7 22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Kc7 26. R1h7\nQxh7 27. Rxh7+ Kb6 28. c4 Nb4 29. Qb3 a5 30. a3 c5 31. dxc5+ dxc5 32. axb4\naxb4 33. Qe3 Bc6 34. Qxe6 Ra1+ 35. Kd2 Rb1 36. Kc2 Rg1 37. Qe3 Rg2+ 38. Kb3\nKa5 39. Qxc5+ Ka6 40. Qxb4 Rxg3+ 41. Ka2 Rg1 42. c5 Bd5+ 43. b3 Rg2+ 44. Ka3\nBc6 45. Qb6# g4 46. Qb4 g3 47. Qb6# g2 48. Qb4 g1=Q 49. Qb6# g3",
          "positional_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 308,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg6",
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Kc7",
            "R1h7",
            "Qxh7",
            "Rxh7+",
            "Kb6",
            "c4",
            "Nb4",
            "Qb3",
            "a5",
            "a3",
            "c5",
            "dxc5+",
            "dxc5",
            "axb4",
            "axb4",
            "Qe3",
            "Bc6",
            "Qxe6",
            "Ra1+",
            "Kd2",
            "Rb1",
            "Kc2",
            "Rg1",
            "Qe3",
            "Rg2+",
            "Kb3",
            "Ka5",
            "Qxc5+",
            "Ka6",
            "Qxb4",
            "Rxg3+",
            "Ka2",
            "Rg1",
            "c5",
            "Bd5+",
            "b3",
            "Rg2+",
            "Ka3",
            "Bc6",
            "Qb6#",
            "g4",
            "Qb4",
            "g3",
            "Qb6#",
            "g2",
            "Qb4",
            "g1=Q",
            "Qb6#",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxh7",
          "neutral_uci": "g5h7",
          "neutral_response": "15. Nxh7 Nxh7 16. Bxg6 Rh8 17. g4 Nf8 18. Bc2 Bd7 19. g5 c6 20. Rh1 Kc7\n21. h5 Nh7 22. Rdg1 Raf8 23. h6 Bxh6 24. Rxh6 Rfg8 25. Qe3 Nf8 26. Rxh8 Rxh8\n27. g6 Qg7 28. Qg5 Rh6 29. Nh4 Be8 30. f4 Bxg6 31. f5 exf5 32. Nxf5 Qh7 33. Nxh6\nBxc2 34. Qg7+ Qxg7 35. Rxg7+ Nd7 36. Kxc2 b5 37. Nf5 d5 38. b4 a6 39. Kd3 Kc8\n40. Ne7+ Kc7 41. Ke3 Kd6 42. Nc8+ Kc7 43. Kf4 Kxc8 44. Kf5 Kd8 45. Ke6 Nb6\n46. Kd6 Nc4+ 47. Kxc6 Ne3 48. Ra7 Nd1 49. Kd6 Kc8 50. Rc7+ Kb8 51. Rc5 Kb7\n52. Kxd5 Kb6 53. Ke6 Ne3 54. d5 Nc4 55. d6 Nxd6 56. Kxd6 a5 57. a3 axb4\n58. axb4 Ka6 59. Kc6 Ka7 60. Rxb5 Ka6 61. Ra5# Kxa5 62. b5 Ka4 63. b6 Kb3\n64. b7 Kxc3 65. b8=Q Kd4 66. Qd6+ Ke4 67. Qd5+ Kf4 68. Kd6 Ke3 69. Ke5 Kf2\n70. Qd3 Kg2 71. Kf4 Kf2 72. Qd2+ Kg1 73. Kg3 Kf1 74. Qf2# Kd1 75. Kf3 Kc1\n76. Ke3 Kb1 77. Kd3 Ka1 78. Kc3 Kb1 79. Qb2# Kc1 80. Qc2# Kc1 81. Qc1#\nKxc1 82. Kd3 Kb1 83. Kc3 Ka1 84. Kb3 Kb1 85. Ka3 Ka1 86. Kb3 Kb1 87. Kc3 Ka1\n88. Kd3 Kb1 89. Ke3 Ka1 90. Kf3 Kb1 91. Kg3 Ka",
          "neutral_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxg6",
            "Rh8",
            "g4",
            "Nf8",
            "Bc2",
            "Bd7",
            "g5",
            "c6",
            "Rh1",
            "Kc7",
            "h5",
            "Nh7",
            "Rdg1",
            "Raf8",
            "h6",
            "Bxh6",
            "Rxh6",
            "Rfg8",
            "Qe3",
            "Nf8",
            "Rxh8",
            "Rxh8",
            "g6",
            "Qg7",
            "Qg5",
            "Rh6",
            "Nh4",
            "Be8",
            "f4",
            "Bxg6",
            "f5",
            "exf5",
            "Nxf5",
            "Qh7",
            "Nxh6",
            "Bxc2",
            "Qg7+",
            "Qxg7",
            "Rxg7+",
            "Nd7",
            "Kxc2",
            "b5",
            "Nf5",
            "d5",
            "b4",
            "a6",
            "Kd3",
            "Kc8",
            "Ne7+",
            "Kc7",
            "Ke3",
            "Kd6",
            "Nc8+",
            "Kc7",
            "Kf4",
            "Kxc8",
            "Kf5",
            "Kd8",
            "Ke6",
            "Nb6",
            "Kd6",
            "Nc4+",
            "Kxc6",
            "Ne3",
            "Ra7",
            "Nd1",
            "Kd6",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rc5",
            "Kb7",
            "Kxd5",
            "Kb6",
            "Ke6",
            "Ne3",
            "d5",
            "Nc4",
            "d6",
            "Nxd6",
            "Kxd6",
            "a5",
            "a3",
            "axb4",
            "axb4",
            "Ka6",
            "Kc6",
            "Ka7",
            "Rxb5",
            "Ka6",
            "Ra5#",
            "Kxa5",
            "b5",
            "Ka4",
            "b6",
            "Kb3",
            "b7",
            "Kxc3",
            "b8=Q",
            "Kd4",
            "Qd6+",
            "Ke4",
            "Qd5+",
            "Kf4",
            "Kd6",
            "Ke3",
            "Ke5",
            "Kf2",
            "Qd3",
            "Kg2",
            "Kf4",
            "Kf2",
            "Qd2+",
            "Kg1",
            "Kg3",
            "Kf1",
            "Qf2#",
            "Kd1",
            "Kf3",
            "Kc1",
            "Ke3",
            "Kb1",
            "Kd3",
            "Ka1",
            "Kc3",
            "Kb1",
            "Qb2#",
            "Kc1",
            "Qc2#",
            "Kc1",
            "Qc1#",
            "Kxc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kb1",
            "Ka3",
            "Ka1",
            "Kb3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kd3",
            "Kb1",
            "Ke3",
            "Ka1",
            "Kf3",
            "Kb1",
            "Kg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h7",
          "positional_uci": "g5h7",
          "neutral_uci": "g5h7",
          "consensus_move": "g5h7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxg6",
              "Rh8",
              "g4",
              "Nf8",
              "Bd3",
              "Bd7",
              "g5",
              "Be8",
              "Qe4",
              "c6",
              "Qg4",
              "Bh5",
              "Qg3",
              "Kc7",
              "Rd2",
              "Re8",
              "Nh2",
              "e5",
              "f4",
              "Qf7",
              "f5",
              "Qxa2",
              "f6",
              "Bxf6",
              "gxf6",
              "Nd7",
              "dxe5",
              "Nxe5",
              "Bb1",
              "Qf7",
              "Rf2",
              "Rhg8",
              "Qf4",
              "Nd3+",
              "Bxd3",
              "Rxe1+",
              "Kd2",
              "Rd1+",
              "Kc2",
              "Rgg1",
              "Nf1",
              "Qd5",
              "f7",
              "Rxd3",
              "f8=Q",
              "Bd1+",
              "Kc1",
              "Bb3",
              "Qe7+",
              "Kb6",
              "Qd8+",
              "Ka6",
              "Rd2",
              "Rxf1+",
              "Qxf1",
              "Rxd2",
              "Qxd3+",
              "Qxd3",
              "Qa5+",
              "Kxa5",
              "c4",
              "Qc2#",
              "Qc2",
              "Qd1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxg6",
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Kc7",
              "R1h7",
              "Qxh7",
              "Rxh7+",
              "Kb6",
              "c4",
              "Nb4",
              "Qb3",
              "a5",
              "a3",
              "c5",
              "dxc5+",
              "dxc5",
              "axb4",
              "axb4",
              "Qe3",
              "Bc6",
              "Qxe6",
              "Ra1+",
              "Kd2",
              "Rb1",
              "Kc2",
              "Rg1",
              "Qe3",
              "Rg2+",
              "Kb3",
              "Ka5",
              "Qxc5+",
              "Ka6",
              "Qxb4",
              "Rxg3+",
              "Ka2",
              "Rg1",
              "c5",
              "Bd5+",
              "b3",
              "Rg2+",
              "Ka3",
              "Bc6",
              "Qb6#",
              "g4",
              "Qb4",
              "g3",
              "Qb6#",
              "g2",
              "Qb4",
              "g1=Q",
              "Qb6#",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxg6",
              "Rh8",
              "g4",
              "Nf8",
              "Bc2",
              "Bd7",
              "g5",
              "c6",
              "Rh1",
              "Kc7",
              "h5",
              "Nh7",
              "Rdg1",
              "Raf8",
              "h6",
              "Bxh6",
              "Rxh6",
              "Rfg8",
              "Qe3",
              "Nf8",
              "Rxh8",
              "Rxh8",
              "g6",
              "Qg7",
              "Qg5",
              "Rh6",
              "Nh4",
              "Be8",
              "f4",
              "Bxg6",
              "f5",
              "exf5",
              "Nxf5",
              "Qh7",
              "Nxh6",
              "Bxc2",
              "Qg7+",
              "Qxg7",
              "Rxg7+",
              "Nd7",
              "Kxc2",
              "b5",
              "Nf5",
              "d5",
              "b4",
              "a6",
              "Kd3",
              "Kc8",
              "Ne7+",
              "Kc7",
              "Ke3",
              "Kd6",
              "Nc8+",
              "Kc7",
              "Kf4",
              "Kxc8",
              "Kf5",
              "Kd8",
              "Ke6",
              "Nb6",
              "Kd6",
              "Nc4+",
              "Kxc6",
              "Ne3",
              "Ra7",
              "Nd1",
              "Kd6",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rc5",
              "Kb7",
              "Kxd5",
              "Kb6",
              "Ke6",
              "Ne3",
              "d5",
              "Nc4",
              "d6",
              "Nxd6",
              "Kxd6",
              "a5",
              "a3",
              "axb4",
              "axb4",
              "Ka6",
              "Kc6",
              "Ka7",
              "Rxb5",
              "Ka6",
              "Ra5#",
              "Kxa5",
              "b5",
              "Ka4",
              "b6",
              "Kb3",
              "b7",
              "Kxc3",
              "b8=Q",
              "Kd4",
              "Qd6+",
              "Ke4",
              "Qd5+",
              "Kf4",
              "Kd6",
              "Ke3",
              "Ke5",
              "Kf2",
              "Qd3",
              "Kg2",
              "Kf4",
              "Kf2",
              "Qd2+",
              "Kg1",
              "Kg3",
              "Kf1",
              "Qf2#",
              "Kd1",
              "Kf3",
              "Kc1",
              "Ke3",
              "Kb1",
              "Kd3",
              "Ka1",
              "Kc3",
              "Kb1",
              "Qb2#",
              "Kc1",
              "Qc2#",
              "Kc1",
              "Qc1#",
              "Kxc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kb1",
              "Ka3",
              "Ka1",
              "Kb3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kd3",
              "Kb1",
              "Ke3",
              "Ka1",
              "Kf3",
              "Kb1",
              "Kg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 222,
            "completion_tokens": 283,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 222,
            "completion_tokens": 308,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 665,
          "total_completion_tokens": 1231,
          "total_tokens": 1896
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 222,
            "completion_tokens": 283,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 222,
            "completion_tokens": 308,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bkr3/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KRR3 w - - 5 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxg6",
          "aggressive_uci": "d3g6",
          "aggressive_response": "16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5 Nd5 21. Qf3 Qf7\n22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Kc7 26. R1h7 Ne7 27. Rxf7 Bxf7\n28. Rxa8 Nc8 29. g4 Bg6 30. f5 exf5 31. gxf5 Bf7 32. g6 Bd5 33. Qxd5 cxd5\n34. Rxc8+ Kxc8 35. g7 Kd7 36. g8=Q Kc6 37. Qe6 b5 38. f6 a5 39. f7 b4\n40. f8=Q bxc3 41. Qfxd6+ Kb5 42. Qexd5+ Ka4 43. Qb3# Bb7 44. Qda3# Bc6\n45. Qxc3 Bb5 46. Qcb3# Bc6 47. Qxc6# Bb5 48. Qcxb5# Bc6 49. Q3a4# Bb5\n50. Qaxb5# Bc6 51. Q5xc6# Bb5 52. Qcxb5# Bc6 53. Q5xc6# Bb5 54. Qcxb5# Bc6\n55. Q5xc6# Bb5 56. Qcxb5# Bc6 57. Q5xc6# Bb5 58. Qcxb5# Bc6 59. Q5xc6# Bb5\n60. Qcxb5# Bc6 61. Q5xc6# Bb5 62. Qcxb5# Bc6 63. Q5xc6# Bb5 64. Qcxb5# Bc6\n65. Q5xc6# Bb5 66. Qcxb5# Bc6 67. Q5xc6# Bb5 68. Qcxb5# Bc6 69. Q5xc6# Bb5\n70. Qcxb5# Bc6 71. Q5xc6# Bb5 72. Qcxb5# Bc6 73. Q5xc6# Bb5 74. Qcxb5# Bc6\n75. Q5xc6# Bb5 76. Qcxb5# Bc6 77. Q5xc6# Bb5 78. Qcxb5# Bc6 79. Q5xc6# Bb5\n80. Qcxb5#",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Kc7",
            "R1h7",
            "Ne7",
            "Rxf7",
            "Bxf7",
            "Rxa8",
            "Nc8",
            "g4",
            "Bg6",
            "f5",
            "exf5",
            "gxf5",
            "Bf7",
            "g6",
            "Bd5",
            "Qxd5",
            "cxd5",
            "Rxc8+",
            "Kxc8",
            "g7",
            "Kd7",
            "g8=Q",
            "Kc6",
            "Qe6",
            "b5",
            "f6",
            "a5",
            "f7",
            "b4",
            "f8=Q",
            "bxc3",
            "Qfxd6+",
            "Kb5",
            "Qexd5+",
            "Ka4",
            "Qb3#",
            "Bb7",
            "Qda3#",
            "Bc6",
            "Qxc3",
            "Bb5",
            "Qcb3#",
            "Bc6",
            "Qxc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q3a4#",
            "Bb5",
            "Qaxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxg6",
          "positional_uci": "d3g6",
          "positional_response": "16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5 Nd5 21. Qf3 Qf7\n22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Kc7 26. R1h7 Ne7 27. Rxf7 Bxf7 28.\nRxa8 Nc8 29. f5 exf5 30. Qxf5 Bd5 31. Rxc8+ Kb6 32. g6 Bxa2 33. g7 a5 34. g8=Q\nBxg8 35. Rxg8 a4 36. Ra8 d5 37. Rxa4 Kb5 38. Rb4+ Ka5 39. Qc8 b5 40. Qxc6 *",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 209,
            "total_tokens": 440,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Kc7",
            "R1h7",
            "Ne7",
            "Rxf7",
            "Bxf7",
            "Rxa8",
            "Nc8",
            "f5",
            "exf5",
            "Qxf5",
            "Bd5",
            "Rxc8+",
            "Kb6",
            "g6",
            "Bxa2",
            "g7",
            "a5",
            "g8=Q",
            "Bxg8",
            "Rxg8",
            "a4",
            "Ra8",
            "d5",
            "Rxa4",
            "Kb5",
            "Rb4+",
            "Ka5",
            "Qc8",
            "b5",
            "Qxc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxg6",
          "neutral_uci": "d3g6",
          "neutral_response": "16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5 Nd5 21. Qf3 Qf7\n22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Ne7 26. R1h7 Qf5 27. g4 Qa5 28. f5\nexf5 29. gxf5 Qxa2 30. f6 Qa1+ 31. Kc2 Qa4+ 32. Kd2 Qb3 33. fxe7+ Kc7 34. Rxe8\nQxb2+ 35. Ke1 Rxe8 36. Qe3 Qb1+ 37. Kf2 Qxh7 38. Qe6 Rxe7 39. Qf6 Rf7 40. Kg3\nRxf6 41. gxf6 Qg6+ 42. Kf4 Qxf6+ 43. Ke4 d5+ 44. Kd3 Qf3+ 45. Kc2 Qe2+ 46. Kb3\nQc4+ 47. Kc2 a5 48. Kb2 a4 49. Kc2 a3 50. Kd2 a2 51. Ke3 a1=Q 52. Kf4 Qaxc3 53.\nKf5 Q3xd4 54. Ke6 Qe4+ 55. Kf7 Qf1+ 56. Kg7 Qeg2+ 57. Kh6 Qfh1# e4 g5 d3 Bg7 Bxg7 g6 d6 Bg7 Nd7 Qe7 O-O-O fxe4 Nxe4 Neg5 Kd8 Rhe1 Re8 Nxh7 Bxh6 f4 Bxg5 hxg5 Nd5 Qf3 Qa5 fxe7+ Kc7 R1e6 Qxa2 f6 Qa1+ Kc2 Qa4+ Kd2 Qb3 fxe8=Q Qxb2+ Ke1 Qc1+ Kf2 Qd2+ Kg3 Qd1 Qc7+ Kc8 Re8#",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 514,
            "total_tokens": 744,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Ne7",
            "R1h7",
            "Qf5",
            "g4",
            "Qa5",
            "f5",
            "exf5",
            "gxf5",
            "Qxa2",
            "f6",
            "Qa1+",
            "Kc2",
            "Qa4+",
            "Kd2",
            "Qb3",
            "fxe7+",
            "Kc7",
            "Rxe8",
            "Qxb2+",
            "Ke1",
            "Rxe8",
            "Qe3",
            "Qb1+",
            "Kf2",
            "Qxh7",
            "Qe6",
            "Rxe7",
            "Qf6",
            "Rf7",
            "Kg3",
            "Rxf6",
            "gxf6",
            "Qg6+",
            "Kf4",
            "Qxf6+",
            "Ke4",
            "d5+",
            "Kd3",
            "Qf3+",
            "Kc2",
            "Qe2+",
            "Kb3",
            "Qc4+",
            "Kc2",
            "a5",
            "Kb2",
            "a4",
            "Kc2",
            "a3",
            "Kd2",
            "a2",
            "Ke3",
            "a1=Q",
            "Kf4",
            "Qaxc3",
            "Kf5",
            "Q3xd4",
            "Ke6",
            "Qe4+",
            "Kf7",
            "Qf1+",
            "Kg7",
            "Qeg2+",
            "Kh6",
            "Qfh1#",
            "e4",
            "g5",
            "d3",
            "Bg7",
            "Bxg7",
            "g6",
            "d6",
            "Bg7",
            "Nd7",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Bxh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qa5",
            "fxe7+",
            "Kc7",
            "R1e6",
            "Qxa2",
            "f6",
            "Qa1+",
            "Kc2",
            "Qa4+",
            "Kd2",
            "Qb3",
            "fxe8=Q",
            "Qxb2+",
            "Ke1",
            "Qc1+",
            "Kf2",
            "Qd2+",
            "Kg3",
            "Qd1",
            "Qc7+",
            "Kc8",
            "Re8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3g6",
          "positional_uci": "d3g6",
          "neutral_uci": "d3g6",
          "consensus_move": "d3g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Kc7",
              "R1h7",
              "Ne7",
              "Rxf7",
              "Bxf7",
              "Rxa8",
              "Nc8",
              "g4",
              "Bg6",
              "f5",
              "exf5",
              "gxf5",
              "Bf7",
              "g6",
              "Bd5",
              "Qxd5",
              "cxd5",
              "Rxc8+",
              "Kxc8",
              "g7",
              "Kd7",
              "g8=Q",
              "Kc6",
              "Qe6",
              "b5",
              "f6",
              "a5",
              "f7",
              "b4",
              "f8=Q",
              "bxc3",
              "Qfxd6+",
              "Kb5",
              "Qexd5+",
              "Ka4",
              "Qb3#",
              "Bb7",
              "Qda3#",
              "Bc6",
              "Qxc3",
              "Bb5",
              "Qcb3#",
              "Bc6",
              "Qxc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q3a4#",
              "Bb5",
              "Qaxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Kc7",
              "R1h7",
              "Ne7",
              "Rxf7",
              "Bxf7",
              "Rxa8",
              "Nc8",
              "f5",
              "exf5",
              "Qxf5",
              "Bd5",
              "Rxc8+",
              "Kb6",
              "g6",
              "Bxa2",
              "g7",
              "a5",
              "g8=Q",
              "Bxg8",
              "Rxg8",
              "a4",
              "Ra8",
              "d5",
              "Rxa4",
              "Kb5",
              "Rb4+",
              "Ka5",
              "Qc8",
              "b5",
              "Qxc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Ne7",
              "R1h7",
              "Qf5",
              "g4",
              "Qa5",
              "f5",
              "exf5",
              "gxf5",
              "Qxa2",
              "f6",
              "Qa1+",
              "Kc2",
              "Qa4+",
              "Kd2",
              "Qb3",
              "fxe7+",
              "Kc7",
              "Rxe8",
              "Qxb2+",
              "Ke1",
              "Rxe8",
              "Qe3",
              "Qb1+",
              "Kf2",
              "Qxh7",
              "Qe6",
              "Rxe7",
              "Qf6",
              "Rf7",
              "Kg3",
              "Rxf6",
              "gxf6",
              "Qg6+",
              "Kf4",
              "Qxf6+",
              "Ke4",
              "d5+",
              "Kd3",
              "Qf3+",
              "Kc2",
              "Qe2+",
              "Kb3",
              "Qc4+",
              "Kc2",
              "a5",
              "Kb2",
              "a4",
              "Kc2",
              "a3",
              "Kd2",
              "a2",
              "Ke3",
              "a1=Q",
              "Kf4",
              "Qaxc3",
              "Kf5",
              "Q3xd4",
              "Ke6",
              "Qe4+",
              "Kf7",
              "Qf1+",
              "Kg7",
              "Qeg2+",
              "Kh6",
              "Qfh1#",
              "e4",
              "g5",
              "d3",
              "Bg7",
              "Bxg7",
              "g6",
              "d6",
              "Bg7",
              "Nd7",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Bxh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qa5",
              "fxe7+",
              "Kc7",
              "R1e6",
              "Qxa2",
              "f6",
              "Qa1+",
              "Kc2",
              "Qa4+",
              "Kd2",
              "Qb3",
              "fxe8=Q",
              "Qxb2+",
              "Ke1",
              "Qc1+",
              "Kf2",
              "Qd2+",
              "Kg3",
              "Qd1",
              "Qc7+",
              "Kc8",
              "Re8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 209,
            "total_tokens": 440,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 514,
            "total_tokens": 744,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 1363,
          "total_tokens": 2055
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 209,
            "total_tokens": 440,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 514,
            "total_tokens": 744,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bkr3/ppp1q1bn/3pp1p1/8/3P3P/2PB1N2/PP2QPP1/2KRR3 w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxh7",
          "aggressive_uci": "g6h7",
          "aggressive_response": "17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5\nQf7 23. Qh4+ Qf6 24. Qh1 c6 25. Rf1 Qe7 26. Rxf8+ Qxf8 27. Rf1 Qe7 28. Qh8+\nKc7 29. Qg8 Kb6 30. Rf7 Qh4 31. Qg2 Qe1+ 32. Kc2 d5 33. Bd3 e5 34. dxe5 Qxe5\n35. Qf2+ c5 36. b4 d4 37. bxc5+ Kxc5 38. cxd4+ Qxd4 39. Rc7+ Kd5 40. Bc4+ Ke5\n41. Re7+ Kd6 42. Qxd4+ Kxe7 43. Qe5+ Kd8 44. Qd6+ Bd7 45. Be6 Rc8+ 46. Kd2 Rc7\n47. Qf8+ Be8 48. Qf6+ Re7 49. Kc3 Bd7 50. Bxd7 Kxd7 51. Qd4+ Kc7 52. Qxa7 Re6\n53. Qc5+ Rc6 54. Kb4 Rxc5 55. Kxc5 b6+ 56. Kb5 Kb7 57. a4 Ka7 58. a5 bxa5\n59. Kxa5 1/2-1/2\n\nd4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxg5+\n20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qf6 24. Qh1 c6 25. Rf1 Qe7\n26. Rxf8+ Qxf8 27. Rf1 Qe7 28. Qh8+ Kc7 29. Qg8 Kb6",
          "aggressive_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh1",
            "c6",
            "Rf1",
            "Qe7",
            "Rxf8+",
            "Qxf8",
            "Rf1",
            "Qe7",
            "Qh8+",
            "Kc7",
            "Qg8",
            "Kb6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxh7",
          "positional_uci": "g6h7",
          "positional_response": "Re8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7\n20. Rh1 Qg7 21. f4 Bd7 22. Rh6 c6 23. Rdh1 Kc7 24. Rh7 Qg6 25. R1h6 Qf5 26. Rf6\nQxh7 27. g6 Qh1+ 28. Kc2 e5 29. dxe5 dxe5 30. fxe5 Rad8 31. g7 Qh7+ 32. Kb3\nQxg7 33. Qe3 Kb8 34. Qf4 Be6+ 35. Ka3 Qe7+ 36. b4 a5 37. g4 axb4+ 38. cxb4 Rd3+\n39. Ka4 b5+ 40. Ka5 Qa7# Qe7 41. g5 Qa7# Qe7 42. g5 Qa7# Qe7 43. g6 Qa7# Qe7\n44. g7 Qa7# Qe7 45. g8=Q Qa7# Qe7 46. Qxe8+ Qxe8 47. Rf8 Qxf8 48. Qxf8+ Kc7\n49. Qe7+ Bd7 50. e6 Rd6 51. exd7 Rxd7 52. Qe5+ Kb6 53. a4 bxa4 54. Kxa4 Rd5 55.\nQe3+ Kc7 56. c4 Rd7 57. Qe5+ Kc8 58. b5 cxb5+ 59. cxb5 Rc7 60. b6 Rc6 61. Qe8+\nKb7 62. Kb5 Rxb6+ 63. Kc5 Rc6+ 64. Qxc6+ Ka7 65. Qb5 Ka8 66. Kc6 Ka7 67. Qb7#\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7\n20. Rh1 Qg7 21.",
          "positional_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxh7",
          "neutral_uci": "g6h7",
          "neutral_response": "Re8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7\n20. Rh1 Qg7 21. f4 Bd7 22. Rh6 c6 23. Rdh1 Kc7 24. Rh7 Qg6 25. R1h6 Qf5 26. Rf6\nQxh7 27. g6 Qh1+ 28. Kc2 Rg8 29. Qg4 Raf8 30. Rxf8 Rxf8 31. g7 Rg8 32. Qg6\nQh8 33. gxh8=Q Rxh8 34. g4 Rf8 35. Qg5 * Rf8 36. Qh6 Rg8 37. g5 Be8 38. Qxe6\nBd7 39. Qxg8 * Rf8 40. Qxf8 * Rxf8 41. g6 Rxf4 42. g7 Rf2+ 43. Kb3 * Rg2 44.\nQf7 * Rg3 45. g8=Q * Rg7 46. Qgxg7 * Kb6 47. Qxd7 * Ka5 48. Qxb7 * c5 49. Qxa7+ *\nKb5 50. Qhb7# Kf5 51. Qf7+ * Kg4 52. Qg2+ * Kh4 53. Qh7# Kf4 54. Qf2+ * Kg4 55.\nQg6+ * Kh3 56. Qfg3# Kxg3 57. Qf5 * Kh4 58. Qg6 * Kh3 59. Qg5 * Kh2 60. Qg4 *\nKh1 61. Kc2 * Kh2 62. Kd2 * Kh1 63. Ke2 * Kh2 64. Kf2 * Kh1 65. Qg2# Kh2 66.\nQg3+ * Kh1 67. Qg1# Kh2 68. Qg2# Kh1 69. Qg1# Kh2 70. Qg2# Kh1 71. Qg1# Kh2\n72. Qg2# Kh1 73. Qg1# Kh2 74. Qg2# Kh1 75. Qg1# Kh2 76. Qg2# Kh1 77. Qg1# Kh2\n78. Qg2# Kh1 79. Qg1# Kh2 80. Qg2# Kh1 81. Qg1# Kh2 82. Qg2# Kh1 83. Qg1# Kh2\n84. Qg2# Kh1 85. Qg1# Kh2",
          "neutral_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg7",
            "f4",
            "Bd7",
            "Rh6",
            "c6",
            "Rdh1",
            "Kc7",
            "Rh7",
            "Qg6",
            "R1h6",
            "Qf5",
            "Rf6",
            "Qxh7",
            "g6",
            "Qh1+",
            "Kc2",
            "Rg8",
            "Qg4",
            "Raf8",
            "Rxf8",
            "Rxf8",
            "g7",
            "Rg8",
            "Qg6",
            "Qh8",
            "gxh8=Q",
            "Rxh8",
            "g4",
            "Rf8",
            "Qg5",
            "Rf8",
            "Qh6",
            "Rg8",
            "g5",
            "Be8",
            "Qxe6",
            "Bd7",
            "Qxg8",
            "Rf8",
            "Qxf8",
            "Rxf8",
            "g6",
            "Rxf4",
            "g7",
            "Rf2+",
            "Kb3",
            "Rg2",
            "Qf7",
            "Rg3",
            "g8=Q",
            "Rg7",
            "Qgxg7",
            "Kb6",
            "Qxd7",
            "Ka5",
            "Qxb7",
            "c5",
            "Qxa7+",
            "Kb5",
            "Qhb7#",
            "Kf5",
            "Qf7+",
            "Kg4",
            "Qg2+",
            "Kh4",
            "Qh7#",
            "Kf4",
            "Qf2+",
            "Kg4",
            "Qg6+",
            "Kh3",
            "Qfg3#",
            "Kxg3",
            "Qf5",
            "Kh4",
            "Qg6",
            "Kh3",
            "Qg5",
            "Kh2",
            "Qg4",
            "Kh1",
            "Kc2",
            "Kh2",
            "Kd2",
            "Kh1",
            "Ke2",
            "Kh2",
            "Kf2",
            "Kh1",
            "Qg2#",
            "Kh2",
            "Qg3+",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g6h7",
          "positional_uci": "g6h7",
          "neutral_uci": "g6h7",
          "consensus_move": "g6h7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh1",
              "c6",
              "Rf1",
              "Qe7",
              "Rxf8+",
              "Qxf8",
              "Rf1",
              "Qe7",
              "Qh8+",
              "Kc7",
              "Qg8",
              "Kb6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg7",
              "f4",
              "Bd7",
              "Rh6",
              "c6",
              "Rdh1",
              "Kc7",
              "Rh7",
              "Qg6",
              "R1h6",
              "Qf5",
              "Rf6",
              "Qxh7",
              "g6",
              "Qh1+",
              "Kc2",
              "Rg8",
              "Qg4",
              "Raf8",
              "Rxf8",
              "Rxf8",
              "g7",
              "Rg8",
              "Qg6",
              "Qh8",
              "gxh8=Q",
              "Rxh8",
              "g4",
              "Rf8",
              "Qg5",
              "Rf8",
              "Qh6",
              "Rg8",
              "g5",
              "Be8",
              "Qxe6",
              "Bd7",
              "Qxg8",
              "Rf8",
              "Qxf8",
              "Rxf8",
              "g6",
              "Rxf4",
              "g7",
              "Rf2+",
              "Kb3",
              "Rg2",
              "Qf7",
              "Rg3",
              "g8=Q",
              "Rg7",
              "Qgxg7",
              "Kb6",
              "Qxd7",
              "Ka5",
              "Qxb7",
              "c5",
              "Qxa7+",
              "Kb5",
              "Qhb7#",
              "Kf5",
              "Qf7+",
              "Kg4",
              "Qg2+",
              "Kh4",
              "Qh7#",
              "Kf4",
              "Qf2+",
              "Kg4",
              "Qg6+",
              "Kh3",
              "Qfg3#",
              "Kxg3",
              "Qf5",
              "Kh4",
              "Qg6",
              "Kh3",
              "Qg5",
              "Kh2",
              "Qg4",
              "Kh1",
              "Kc2",
              "Kh2",
              "Kd2",
              "Kh1",
              "Ke2",
              "Kh2",
              "Kf2",
              "Kh1",
              "Qg2#",
              "Kh2",
              "Qg3+",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 722,
          "total_completion_tokens": 1920,
          "total_tokens": 2642
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp1q1bn/3pp1B1/8/3P3P/2P2N2/PP2QPP1/2KRR3 w - - 1 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ng5",
          "aggressive_uci": "f3g5",
          "aggressive_response": "18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qf5 21. Qh5 Bd7 22. g4 Qf4+ 23. Kb1 Be8 24. g6 Rg8 25. Qh4+ Kd7 26. Qh7+ Kc6 27. Qxg8 Bxg6+ 28. Qxg6 Qxf2 29. Qxe6 Rf8 30. Qc4+ Kd7 31. Rh7+ Kd8 32. Qxc7+ Ke8 33. Qe7# Bg8",
          "aggressive_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 149,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qf5",
            "Qh5",
            "Bd7",
            "g4",
            "Qf4+",
            "Kb1",
            "Be8",
            "g6",
            "Rg8",
            "Qh4+",
            "Kd7",
            "Qh7+",
            "Kc6",
            "Qxg8",
            "Bxg6+",
            "Qxg6",
            "Qxf2",
            "Qxe6",
            "Rf8",
            "Qc4+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Qe7#",
            "Bg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ng5",
          "positional_uci": "f3g5",
          "positional_response": "18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qg6 21. Rh5 Bd7 22. Rdh1 c6 23. Rh6 Qxg5+ 24. Kb1 Kc7 25. Rh7 Qf5+ 26. Ka1 Rf7 27. R7h5 Qxf2 28. Qxf2 Rxf2 29. g4 Raf8 30. a3 Rf1+ 31. Rxf1 Rxf1+ 32. Ka2 Rg1 33. g5 e5 34. dxe5 Be6+ 35. b3 Rg2+ 36. Kb1 Bxb3 37. Rh7+ Kb6 38. exd6 Rxg5 39. d7 Rd5 40. Kb2 Bc4 41. a4 a5 42. Kc2 Kc7 43. d8=Q+ Kxd8 44. Rxb7 Rd7 45. Rb6 Kc7 46. Rb1 Bd3+ 47. Kb2 Bxb1 48. Kxb1 Rd2 49. Kc1 Rh2 50. Kb1 Kd6 51. Kc1 Kc5 52. Kb1 Kc4 53. Kc1 Kxc3 54. Kb1 c5 55. Ka1 Kb3 56. Kb1 Rh1#",
          "positional_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg6",
            "Rh5",
            "Bd7",
            "Rdh1",
            "c6",
            "Rh6",
            "Qxg5+",
            "Kb1",
            "Kc7",
            "Rh7",
            "Qf5+",
            "Ka1",
            "Rf7",
            "R7h5",
            "Qxf2",
            "Qxf2",
            "Rxf2",
            "g4",
            "Raf8",
            "a3",
            "Rf1+",
            "Rxf1",
            "Rxf1+",
            "Ka2",
            "Rg1",
            "g5",
            "e5",
            "dxe5",
            "Be6+",
            "b3",
            "Rg2+",
            "Kb1",
            "Bxb3",
            "Rh7+",
            "Kb6",
            "exd6",
            "Rxg5",
            "d7",
            "Rd5",
            "Kb2",
            "Bc4",
            "a4",
            "a5",
            "Kc2",
            "Kc7",
            "d8=Q+",
            "Kxd8",
            "Rxb7",
            "Rd7",
            "Rb6",
            "Kc7",
            "Rb1",
            "Bd3+",
            "Kb2",
            "Bxb1",
            "Kxb1",
            "Rd2",
            "Kc1",
            "Rh2",
            "Kb1",
            "Kd6",
            "Kc1",
            "Kc5",
            "Kb1",
            "Kc4",
            "Kc1",
            "Kxc3",
            "Kb1",
            "c5",
            "Ka1",
            "Kb3",
            "Kb1",
            "Rh1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ng5",
          "neutral_uci": "f3g5",
          "neutral_response": "18. Ng5 Bxg5+ 19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qe7\n24. Qh6 c6 25. Rf1 Rxf1 26. Rxf1 Bd7 27. Rf8+ Be8 28. Bg6 Kd7 29. Bxe8+ Rxe8\n30. Rf6 Rg8 31. a3 Rg7 32. Rxe6 Qh7+ 33. Qxh7 Rxh7 34. Rg6 Re7 35. Kc2 Re6\n36. Rg7+ Re7 37. Rg6 Re6 38. Rg7+ Re7 39. Rg6 Re6 40. Rg7+ Re7 41. Rg6 Re6\n42. Rg7+ Re7 43. Rg6 Re6 44. Rg7+ Re7 45. Rg6 Re6 46. Rg7+ Re7 47. Rg6 Re6\n48. Rg7+ Re7 49. Rg6 Re6 50. Rg7+ Re7 51. Rg6 Re6 52. Rg7+ Re7 53. Rg6 Re6\n54. Rg7+ Re7 55. Rg6 Re6 56. Rg7+ Re7 57. Rg6 Re6 58. Rg7+ Re7 59. Rg6 Re6\n60. Rg7+ Re7 61. Rg6 Re6 62. Rg7+ Re7 63. Rg6 Re6 64. Rg7+ Re7 65. Rg6 Re6\n66. Rg7+ Re7 67. Rg6 Re6 68. Rg7+ Re7 69. Rg6 Re6 70. Rg7+ Re7 71. Rg6 Re6\n72. Rg7+ Re7 73. Rg6 Re6 74. Rg7+ Re7 75. Rg6 Re6 76. Rg7+ Re7 77. Rg6 Re6\n78. Rg7+ Re7 79. Rg6 Re6 80. Rg7+ Re7 81. Rg6 Re6 82. Rg7+ Re7 83. Rg6 Re6\n84. Rg7+ Re7 85. Rg6 Re6 86. Rg7+ Re7 87. Rg6 Re6 88. Rg7+ Re7 89. Rg6 Re6\n90. Rg7+ Re7 91. Rg6 Re6",
          "neutral_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxg5+",
            "hxg5",
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qe7",
            "Qh6",
            "c6",
            "Rf1",
            "Rxf1",
            "Rxf1",
            "Bd7",
            "Rf8+",
            "Be8",
            "Bg6",
            "Kd7",
            "Bxe8+",
            "Rxe8",
            "Rf6",
            "Rg8",
            "a3",
            "Rg7",
            "Rxe6",
            "Qh7+",
            "Qxh7",
            "Rxh7",
            "Rg6",
            "Re7",
            "Kc2",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3g5",
          "positional_uci": "f3g5",
          "neutral_uci": "f3g5",
          "consensus_move": "f3g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qf5",
              "Qh5",
              "Bd7",
              "g4",
              "Qf4+",
              "Kb1",
              "Be8",
              "g6",
              "Rg8",
              "Qh4+",
              "Kd7",
              "Qh7+",
              "Kc6",
              "Qxg8",
              "Bxg6+",
              "Qxg6",
              "Qxf2",
              "Qxe6",
              "Rf8",
              "Qc4+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Qe7#",
              "Bg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg6",
              "Rh5",
              "Bd7",
              "Rdh1",
              "c6",
              "Rh6",
              "Qxg5+",
              "Kb1",
              "Kc7",
              "Rh7",
              "Qf5+",
              "Ka1",
              "Rf7",
              "R7h5",
              "Qxf2",
              "Qxf2",
              "Rxf2",
              "g4",
              "Raf8",
              "a3",
              "Rf1+",
              "Rxf1",
              "Rxf1+",
              "Ka2",
              "Rg1",
              "g5",
              "e5",
              "dxe5",
              "Be6+",
              "b3",
              "Rg2+",
              "Kb1",
              "Bxb3",
              "Rh7+",
              "Kb6",
              "exd6",
              "Rxg5",
              "d7",
              "Rd5",
              "Kb2",
              "Bc4",
              "a4",
              "a5",
              "Kc2",
              "Kc7",
              "d8=Q+",
              "Kxd8",
              "Rxb7",
              "Rd7",
              "Rb6",
              "Kc7",
              "Rb1",
              "Bd3+",
              "Kb2",
              "Bxb1",
              "Kxb1",
              "Rd2",
              "Kc1",
              "Rh2",
              "Kb1",
              "Kd6",
              "Kc1",
              "Kc5",
              "Kb1",
              "Kc4",
              "Kc1",
              "Kxc3",
              "Kb1",
              "c5",
              "Ka1",
              "Kb3",
              "Kb1",
              "Rh1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxg5+",
              "hxg5",
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qe7",
              "Qh6",
              "c6",
              "Rf1",
              "Rxf1",
              "Rxf1",
              "Bd7",
              "Rf8+",
              "Be8",
              "Bg6",
              "Kd7",
              "Bxe8+",
              "Rxe8",
              "Rf6",
              "Rg8",
              "a3",
              "Rg7",
              "Rxe6",
              "Qh7+",
              "Qxh7",
              "Rxh7",
              "Rg6",
              "Re7",
              "Kc2",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 251,
            "completion_tokens": 149,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 752,
          "total_completion_tokens": 1118,
          "total_tokens": 1870
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 251,
            "completion_tokens": 149,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp1q2B/3pp2b/8/3P3P/2P2N2/PP2QPP1/2KRR3 w - - 1 18"
    },
    {
      "turn": 37,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "hxg5",
          "aggressive_uci": "h4g5",
          "aggressive_response": "19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qxf2 Rxf2 23. Rh1 d5 24. Rh8+ Ke7\n25. Bd3 b6 26. Rg1 Bb7 27. Rh7+ Rf7 28. Rgg7 Rf8 29. Bg6 Rxg7 30. Rxg7+ Kd6\n31. Kc2 Ba6 32. Kb3 Bc4+ 33. Ka3 a5 34. b3 Bb5 35. Bc2 Rf2 36. Bb1 Rf3 37. Kb2\nRf2+ 38. Ka3 Rf3 39. Kb2 Rf2+ 40. Ka3 Rf3 41. Kb2 Rf2+ 42. Ka3 Rf3 43. Kb2 Rf2+ 44. Ka3 Rf3 45. Kb2 Rf2+ 46. Ka3 Rf3 47. Kb2 Rf2+ 48. Ka3 Rf3 49. Kb2 Rf2+ 50. Ka3 Rf3 51. Kb2 Rf2+ 52. Ka3 Rf3 53. Kb2 Rf2+ 54. Ka3 Rf3 55. Kb2 Rf2+ 56. Ka3 Rf3 57. Kb2 Rf2+ 58. Ka3 Rf3 59. Kb2 Rf2+ 60. Ka3 Rf3 61. Kb2 Rf2+ 62. Ka3 Rf3 63. Kb2 Rf2+ 64. Ka3 Rf3 65. Kb2 Rf2+ 66. Ka3 Rf3 67. Kb2 Rf2+ 68. Ka3 Rf3 69. Kb2 Rf2+ 70. Ka3 Rf3 71. Kb2 Rf2+ 72. Ka3 Rf3 73. Kb2 Rf2+ 74. Ka3 Rf3 75. Kb2 Rf2+ 76. Ka3 Rf3 77. Kb2 Rf2+ 78. Ka3 Rf3 79. Kb2 Rf2+ 80. Ka3 Rf3 81. Kb2 Rf2+ 82. Ka3 Rf3 83. Kb2 Rf2+ 84. Ka3 Rf3 85. Kb2 Rf2+ 86. Ka3 Rf3 87. Kb2 Rf2+ 88. Ka3 Rf3 89. Kb2 Rf2+ 90. Ka3 Rf3 91. Kb2 Rf2+ 92. Ka3 Rf3 93. Kb2 Rf2",
          "aggressive_tokens": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qxf2",
            "Rxf2",
            "Rh1",
            "d5",
            "Rh8+",
            "Ke7",
            "Bd3",
            "b6",
            "Rg1",
            "Bb7",
            "Rh7+",
            "Rf7",
            "Rgg7",
            "Rf8",
            "Bg6",
            "Rxg7",
            "Rxg7+",
            "Kd6",
            "Kc2",
            "Ba6",
            "Kb3",
            "Bc4+",
            "Ka3",
            "a5",
            "b3",
            "Bb5",
            "Bc2",
            "Rf2",
            "Bb1",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "hxg5",
          "positional_uci": "h4g5",
          "positional_response": "19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qf6 24. Qh7 Qf7 25. Qh4+ Qf6 26. Qh7 Qf7 27. Qh4+ Qf6 28. Qh7 Qf7 29. Qh4+ Qf6 30. Qh7 Qf7 31. Qh4+ Qf6 32. Qh7 Qf7 33. Qh4+ Qf6 34. Qh7 Qf7 35. Qh4+ Qf6 36. Qh7 Qf7 37. Qh4+ Qf6 38. Qh7 Qf7 39. Qh4+ Qf6 40. Qh7 Qf7 41. Qh4+ Qf6 42. Qh7 Qf7 43. Qh4+ Qf6 44. Qh7 Qf7 45. Qh4+ Qf6 46. Qh7 Qf7 47. Qh4+ Qf6 48. Qh7 Qf7 49. Qh4+ Qf6 50. Qh7 Qf7 51. Qh4+ Qf6 52. Qh7 Qf7 53. Qh4+ Qf6 54. Qh7 Qf7 55. Qh4+ Qf6 56. Qh7 Qf7 57. Qh4+ Qf6 58. Qh7 Qf7 59. Qh4+ Qf6 60. Qh7 Qf7 61. Qh4+ Qf6 62. Qh7 Qf7 63. Qh4+ Qf6 64. Qh7 Qf7 65. Qh4+ Qf6 66. Qh7 Qf7 67. Qh4+ Qf6 68. Qh7 Qf7 69. Qh4+ Qf6 70. Qh7 Qf7 71. Qh4+ Qf6 72. Qh7 Qf7 73. Qh4+ Qf6 74. Qh7 Qf7 75. Qh4+ Qf6 76. Qh7 Qf7 77. Qh4+ Qf6 78. Qh7 Qf7 79. Qh4+ Qf6 80. Qh7 Qf7 81. Qh4+ Qf6 82. Qh7 Qf7 83. Qh4+ Qf6 84. Qh7 Qf7 85. Qh4+ Qf6 86. Q",
          "positional_tokens": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "hxg5",
          "neutral_uci": "h4g5",
          "neutral_response": "19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qe7 24. Qh6\nQf6 25. Qh1 Qh8 26. Qg2 Qg8 27. Qh2 Qh8 28. Qg3 Qg8 29. Qh4+ Kd7 30. Rg1\nQh8 31. Qg5 Qf6 32. Qh5 Qh8 33. Qg6 Qf6 34. Qh7+ Qf7 35. Rg7 Ke8 36. Rxf7\nRxf7 37. Bg6 Kd7 38. Qxf7+ Kc6 39. Qe8+ Kb6 40. Bd3 c6 41. Qd8# e5 42. Qxd6\nexd4 43. Qd8+ Kc5 44. b4# Kd5 45. Bf5+ Ke5 46. Bxc8 dxc3 47. Qd4# Kf5 48.\nRf1+ Kg5 49. Qg4+ Kh6 50. Rh1# Kg7 51. Qg5# Kf7 52. Rh7+ Kf8 53. Qg7+ Ke8\n54. Qe7# Kf8 55. Qf7# Kg8 56. Qg7# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 260,
            "completion_tokens": 353,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qe7",
            "Qh6",
            "Qf6",
            "Qh1",
            "Qh8",
            "Qg2",
            "Qg8",
            "Qh2",
            "Qh8",
            "Qg3",
            "Qg8",
            "Qh4+",
            "Kd7",
            "Rg1",
            "Qh8",
            "Qg5",
            "Qf6",
            "Qh5",
            "Qh8",
            "Qg6",
            "Qf6",
            "Qh7+",
            "Qf7",
            "Rg7",
            "Ke8",
            "Rxf7",
            "Rxf7",
            "Bg6",
            "Kd7",
            "Qxf7+",
            "Kc6",
            "Qe8+",
            "Kb6",
            "Bd3",
            "c6",
            "Qd8#",
            "e5",
            "Qxd6",
            "exd4",
            "Qd8+",
            "Kc5",
            "b4#",
            "Kd5",
            "Bf5+",
            "Ke5",
            "Bxc8",
            "dxc3",
            "Qd4#",
            "Kf5",
            "Rf1+",
            "Kg5",
            "Qg4+",
            "Kh6",
            "Rh1#",
            "Kg7",
            "Qg5#",
            "Kf7",
            "Rh7+",
            "Kf8",
            "Qg7+",
            "Ke8",
            "Qe7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4g5",
          "positional_uci": "h4g5",
          "neutral_uci": "h4g5",
          "consensus_move": "h4g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qxf2",
              "Rxf2",
              "Rh1",
              "d5",
              "Rh8+",
              "Ke7",
              "Bd3",
              "b6",
              "Rg1",
              "Bb7",
              "Rh7+",
              "Rf7",
              "Rgg7",
              "Rf8",
              "Bg6",
              "Rxg7",
              "Rxg7+",
              "Kd6",
              "Kc2",
              "Ba6",
              "Kb3",
              "Bc4+",
              "Ka3",
              "a5",
              "b3",
              "Bb5",
              "Bc2",
              "Rf2",
              "Bb1",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qe7",
              "Qh6",
              "Qf6",
              "Qh1",
              "Qh8",
              "Qg2",
              "Qg8",
              "Qh2",
              "Qh8",
              "Qg3",
              "Qg8",
              "Qh4+",
              "Kd7",
              "Rg1",
              "Qh8",
              "Qg5",
              "Qf6",
              "Qh5",
              "Qh8",
              "Qg6",
              "Qf6",
              "Qh7+",
              "Qf7",
              "Rg7",
              "Ke8",
              "Rxf7",
              "Rxf7",
              "Bg6",
              "Kd7",
              "Qxf7+",
              "Kc6",
              "Qe8+",
              "Kb6",
              "Bd3",
              "c6",
              "Qd8#",
              "e5",
              "Qxd6",
              "exd4",
              "Qd8+",
              "Kc5",
              "b4#",
              "Kd5",
              "Bf5+",
              "Ke5",
              "Bxc8",
              "dxc3",
              "Qd4#",
              "Kf5",
              "Rf1+",
              "Kg5",
              "Qg4+",
              "Kh6",
              "Rh1#",
              "Kg7",
              "Qg5#",
              "Kf7",
              "Rh7+",
              "Kf8",
              "Qg7+",
              "Ke8",
              "Qe7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 260,
            "completion_tokens": 353,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 782,
          "total_completion_tokens": 1633,
          "total_tokens": 2415
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 260,
            "completion_tokens": 353,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp1q2B/3pp3/6b1/3P3P/2P5/PP2QPP1/2KRR3 w - - 0 19"
    },
    {
      "turn": 39,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh1",
          "aggressive_uci": "e1h1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qf5 21. Qh5 Bd7 22. g4 Qf4+ 23. Kb1 Be8",
          "aggressive_tokens": {
            "prompt_tokens": 271,
            "completion_tokens": 194,
            "total_tokens": 465,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf5",
            "Qh5",
            "Bd7",
            "g4",
            "Qf4+",
            "Kb1",
            "Be8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rh1",
          "positional_uci": "e1h1",
          "positional_response": "20. Rh1 Qf5 21. Qe3 Qxf2 22. Qxf2 Rxf2 23. Rh8+ Ke7 24. Rdh1 Kf7 25. R1h7+ Kg6 26. Rxc7 Kxg5 27. Rcxc8 Rxc8 28. Rxc8 Kf5 29. Rc7 Rxg2 30. Rxb7 Ke4 31. Rxa7 Kd3 32. b4 Kxc3 33. Rc7+ Kxb4 34. Rc6 Rxa2 35. Rxd6 Kc3 36. Kd1 Kd3 37. Ke1 Ke3 38. Rxe6+ Kxd4 39. Re2 Ra1+ 40. Kf2 Ra3 41. Rd2+ Ke4 42. Re2+ Kf4 43. Rd2 Rf3+ 44. Ke2 Re3+ 45. Kd1 Ra3 46. Kc2 Ra2+ 47. Kc3 Ra3+ 48. Kc2 Ra2+ 49. Kc3 Ra3+ 50. Kc2 Ra2+ 51. Kc3 Ra3+ 52. Kc2 Ra2+ 53. Kc3 Ra3+ 54. Kc2 Ra2+ 55. Kc3 Ra3+ 56. Kc2 Ra2+ 57. Kc3 Ra3+ 58. Kc2 Ra2+ 59. Kc3 Ra3+ 60. Kc2 Ra2+ 61. Kc3 Ra3+ 62. Kc2 Ra2+ 63. Kc3 Ra3+ 64. Kc2 Ra2+ 65. Kc3 Ra3+ 66. Kc2 Ra2+ 67. Kc3 Ra3+ 68. Kc2 Ra2+ 69. Kc3 Ra3+ 70. Kc2 Ra2+ 71. Kc3 Ra3+ 72. Kc2 Ra2+ 73. Kc3 Ra3+ 74. Kc2 Ra2+ 75. Kc3 Ra3+ 76. Kc2 Ra2+ 77. Kc3 Ra3+ 78. Kc2 Ra2+ 79. Kc3 Ra3+ 80. Kc2 Ra2+ 81. Kc3 Ra3+ 82. Kc2 Ra2+ 83. Kc3 Ra3+ 84. Kc2 Ra2+ 85. Kc3 Ra3+ 86. Kc2 Ra2+ 87. Kc3 Ra3+ 88. Kc2 Ra2+ 89. Kc3 Ra3+ 90. Kc2 Ra2+ 91. Kc3 Ra3+ 92",
          "positional_tokens": {
            "prompt_tokens": 271,
            "completion_tokens": 640,
            "total_tokens": 911,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qf5",
            "Qe3",
            "Qxf2",
            "Qxf2",
            "Rxf2",
            "Rh8+",
            "Ke7",
            "Rdh1",
            "Kf7",
            "R1h7+",
            "Kg6",
            "Rxc7",
            "Kxg5",
            "Rcxc8",
            "Rxc8",
            "Rxc8",
            "Kf5",
            "Rc7",
            "Rxg2",
            "Rxb7",
            "Ke4",
            "Rxa7",
            "Kd3",
            "b4",
            "Kxc3",
            "Rc7+",
            "Kxb4",
            "Rc6",
            "Rxa2",
            "Rxd6",
            "Kc3",
            "Kd1",
            "Kd3",
            "Ke1",
            "Ke3",
            "Rxe6+",
            "Kxd4",
            "Re2",
            "Ra1+",
            "Kf2",
            "Ra3",
            "Rd2+",
            "Ke4",
            "Re2+",
            "Kf4",
            "Rd2",
            "Rf3+",
            "Ke2",
            "Re3+",
            "Kd1",
            "Ra3",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rh1",
          "neutral_uci": "e1h1",
          "neutral_response": "20. Rh1 Qf5 21. Qh5 Bd7 22. g4 Qf4+ 23. Kb1 Be8 24. g6 Rg8 25. Qh4+ Kd7 26. Qh7+ Kc6 27. Qxg8 Bxg6+ 28. Qxg6 Qxf2 29. Qxe6 Qf3 30. d5+ Kb6 31. Rhf1 Qg3 32. Qe4 a5 33. Qd4+ Ka6 34. Qc4+ Kb6 35. Rf7 Rc8 36. a4 Qe3 37. Qb5+ Ka7 38. Qxa5+ Kb8 39. Qb4 Qe2 40. Rdf1 Qd3+ 41. Ka1 Qxd5 42. Rf8 Qe6 43. Rxc8+ Qxc8 44. g5 Qh3 45. Rf8+ Ka7 46. Qa5# Bf8 Qxf8+ Qb6 Qxb6#",
          "neutral_tokens": {
            "prompt_tokens": 270,
            "completion_tokens": 252,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf5",
            "Qh5",
            "Bd7",
            "g4",
            "Qf4+",
            "Kb1",
            "Be8",
            "g6",
            "Rg8",
            "Qh4+",
            "Kd7",
            "Qh7+",
            "Kc6",
            "Qxg8",
            "Bxg6+",
            "Qxg6",
            "Qxf2",
            "Qxe6",
            "Qf3",
            "d5+",
            "Kb6",
            "Rhf1",
            "Qg3",
            "Qe4",
            "a5",
            "Qd4+",
            "Ka6",
            "Qc4+",
            "Kb6",
            "Rf7",
            "Rc8",
            "a4",
            "Qe3",
            "Qb5+",
            "Ka7",
            "Qxa5+",
            "Kb8",
            "Qb4",
            "Qe2",
            "Rdf1",
            "Qd3+",
            "Ka1",
            "Qxd5",
            "Rf8",
            "Qe6",
            "Rxc8+",
            "Qxc8",
            "g5",
            "Qh3",
            "Rf8+",
            "Ka7",
            "Qa5#",
            "Bf8",
            "Qxf8+",
            "Qb6",
            "Qxb6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1h1",
          "positional_uci": "e1h1",
          "neutral_uci": "e1h1",
          "consensus_move": "e1h1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qf5",
              "Qh5",
              "Bd7",
              "g4",
              "Qf4+",
              "Kb1",
              "Be8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf5",
              "Qe3",
              "Qxf2",
              "Qxf2",
              "Rxf2",
              "Rh8+",
              "Ke7",
              "Rdh1",
              "Kf7",
              "R1h7+",
              "Kg6",
              "Rxc7",
              "Kxg5",
              "Rcxc8",
              "Rxc8",
              "Rxc8",
              "Kf5",
              "Rc7",
              "Rxg2",
              "Rxb7",
              "Ke4",
              "Rxa7",
              "Kd3",
              "b4",
              "Kxc3",
              "Rc7+",
              "Kxb4",
              "Rc6",
              "Rxa2",
              "Rxd6",
              "Kc3",
              "Kd1",
              "Kd3",
              "Ke1",
              "Ke3",
              "Rxe6+",
              "Kxd4",
              "Re2",
              "Ra1+",
              "Kf2",
              "Ra3",
              "Rd2+",
              "Ke4",
              "Re2+",
              "Kf4",
              "Rd2",
              "Rf3+",
              "Ke2",
              "Re3+",
              "Kd1",
              "Ra3",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qf5",
              "Qh5",
              "Bd7",
              "g4",
              "Qf4+",
              "Kb1",
              "Be8",
              "g6",
              "Rg8",
              "Qh4+",
              "Kd7",
              "Qh7+",
              "Kc6",
              "Qxg8",
              "Bxg6+",
              "Qxg6",
              "Qxf2",
              "Qxe6",
              "Qf3",
              "d5+",
              "Kb6",
              "Rhf1",
              "Qg3",
              "Qe4",
              "a5",
              "Qd4+",
              "Ka6",
              "Qc4+",
              "Kb6",
              "Rf7",
              "Rc8",
              "a4",
              "Qe3",
              "Qb5+",
              "Ka7",
              "Qxa5+",
              "Kb8",
              "Qb4",
              "Qe2",
              "Rdf1",
              "Qd3+",
              "Ka1",
              "Qxd5",
              "Rf8",
              "Qe6",
              "Rxc8+",
              "Qxc8",
              "g5",
              "Qh3",
              "Rf8+",
              "Ka7",
              "Qa5#",
              "Bf8",
              "Qxf8+",
              "Qb6",
              "Qxb6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 271,
            "completion_tokens": 194,
            "total_tokens": 465,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 271,
            "completion_tokens": 640,
            "total_tokens": 911,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 270,
            "completion_tokens": 252,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 812,
          "total_completion_tokens": 1086,
          "total_tokens": 1898
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 271,
            "completion_tokens": 194,
            "total_tokens": 465,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 271,
            "completion_tokens": 640,
            "total_tokens": 911,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 270,
            "completion_tokens": 252,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp4q/3pp3/6P1/3P4/2P5/PP2QPP1/2KRR3 w - - 0 20"
    },
    {
      "turn": 41,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh5",
          "aggressive_uci": "e2h5",
          "aggressive_response": "21. Qh5 Bd7 22. g6 Be8 23. Qg5+ Kc8 24. Rh6 b6 25. Rdh1 Kb7 26. f4 Bc6 27. Rh7\nRf5 28. Qe7 Rc8 29. g7 Rf7 30. Qg5 Be4 31. Rh8 Qxg7 32. Qxg7 Rxg7 33. Rxc8\nKxc8 34. Rh2 Rxg2 35. Rxg2 Bxg2 36. Kd2 Kd7 37. Ke3 Ke7 38. Kf2 Be4 39. Ke3\nd5 40. c4 Kf6 41. b4 Kf5 42. c5 bxc5 43. bxc5 a5 44. a3 a4 45. c6 Bc2 46. Kd2\nBb3 47. Ke3 Bc4 48. Kf3 Bb5 49. Ke3 Bxc6 50. Kf3 Bb5 51. Ke3 Bc4 52. Kf3 c6\n53. Ke3 Kg4 54. Kd2 Kxf4 55. Kc3 Ke4 56. Kb4 Kxd4 57. Kxa4 Kc5 58. Ka5 d4\n59. a4 Bb3 60. Ka6 Bxa4 61. Kb7 d3 62. Kc7 d2 63. Kd7 d1=Q+ 64. Kxe6 Qd5+ 65.\nKe7 Qd6+ 66. Kf7 Kd5 67. Kg7 Ke5 68. Kf7 Qe6+ 69. Kg7 Kf5 70. Kh7 Qg6+ 71.\nKh8 Qg5 72. Kh7 Kf6 73. Kh8 Qg7# d3 d2 d1=Q",
          "aggressive_tokens": {
            "prompt_tokens": 279,
            "completion_tokens": 452,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "g6",
            "Be8",
            "Qg5+",
            "Kc8",
            "Rh6",
            "b6",
            "Rdh1",
            "Kb7",
            "f4",
            "Bc6",
            "Rh7",
            "Rf5",
            "Qe7",
            "Rc8",
            "g7",
            "Rf7",
            "Qg5",
            "Be4",
            "Rh8",
            "Qxg7",
            "Qxg7",
            "Rxg7",
            "Rxc8",
            "Kxc8",
            "Rh2",
            "Rxg2",
            "Rxg2",
            "Bxg2",
            "Kd2",
            "Kd7",
            "Ke3",
            "Ke7",
            "Kf2",
            "Be4",
            "Ke3",
            "d5",
            "c4",
            "Kf6",
            "b4",
            "Kf5",
            "c5",
            "bxc5",
            "bxc5",
            "a5",
            "a3",
            "a4",
            "c6",
            "Bc2",
            "Kd2",
            "Bb3",
            "Ke3",
            "Bc4",
            "Kf3",
            "Bb5",
            "Ke3",
            "Bxc6",
            "Kf3",
            "Bb5",
            "Ke3",
            "Bc4",
            "Kf3",
            "c6",
            "Ke3",
            "Kg4",
            "Kd2",
            "Kxf4",
            "Kc3",
            "Ke4",
            "Kb4",
            "Kxd4",
            "Kxa4",
            "Kc5",
            "Ka5",
            "d4",
            "a4",
            "Bb3",
            "Ka6",
            "Bxa4",
            "Kb7",
            "d3",
            "Kc7",
            "d2",
            "Kd7",
            "d1=Q+",
            "Kxe6",
            "Qd5+",
            "Ke7",
            "Qd6+",
            "Kf7",
            "Kd5",
            "Kg7",
            "Ke5",
            "Kf7",
            "Qe6+",
            "Kg7",
            "Kf5",
            "Kh7",
            "Qg6+",
            "Kh8",
            "Qg5",
            "Kh7",
            "Kf6",
            "Kh8",
            "Qg7#",
            "d3",
            "d2",
            "d1=Q"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 22. Qh5 Bd7 23. g6 Ke7 24. Qg5+ Kf8 25. Qf6+ Qf7 26. Qxf7#",
          "positional_tokens": {
            "prompt_tokens": 279,
            "completion_tokens": 44,
            "total_tokens": 323,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5",
            "Bd7",
            "g6",
            "Ke7",
            "Qg5+",
            "Kf8",
            "Qf6+",
            "Qf7",
            "Qxf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Qf7 Qg6",
          "neutral_tokens": {
            "prompt_tokens": 278,
            "completion_tokens": 8,
            "total_tokens": 286,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf7",
            "Qg6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2h5",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "e2h5",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd7",
              "g6",
              "Be8",
              "Qg5+",
              "Kc8",
              "Rh6",
              "b6",
              "Rdh1",
              "Kb7",
              "f4",
              "Bc6",
              "Rh7",
              "Rf5",
              "Qe7",
              "Rc8",
              "g7",
              "Rf7",
              "Qg5",
              "Be4",
              "Rh8",
              "Qxg7",
              "Qxg7",
              "Rxg7",
              "Rxc8",
              "Kxc8",
              "Rh2",
              "Rxg2",
              "Rxg2",
              "Bxg2",
              "Kd2",
              "Kd7",
              "Ke3",
              "Ke7",
              "Kf2",
              "Be4",
              "Ke3",
              "d5",
              "c4",
              "Kf6",
              "b4",
              "Kf5",
              "c5",
              "bxc5",
              "bxc5",
              "a5",
              "a3",
              "a4",
              "c6",
              "Bc2",
              "Kd2",
              "Bb3",
              "Ke3",
              "Bc4",
              "Kf3",
              "Bb5",
              "Ke3",
              "Bxc6",
              "Kf3",
              "Bb5",
              "Ke3",
              "Bc4",
              "Kf3",
              "c6",
              "Ke3",
              "Kg4",
              "Kd2",
              "Kxf4",
              "Kc3",
              "Ke4",
              "Kb4",
              "Kxd4",
              "Kxa4",
              "Kc5",
              "Ka5",
              "d4",
              "a4",
              "Bb3",
              "Ka6",
              "Bxa4",
              "Kb7",
              "d3",
              "Kc7",
              "d2",
              "Kd7",
              "d1=Q+",
              "Kxe6",
              "Qd5+",
              "Ke7",
              "Qd6+",
              "Kf7",
              "Kd5",
              "Kg7",
              "Ke5",
              "Kf7",
              "Qe6+",
              "Kg7",
              "Kf5",
              "Kh7",
              "Qg6+",
              "Kh8",
              "Qg5",
              "Kh7",
              "Kf6",
              "Kh8",
              "Qg7#",
              "d3",
              "d2",
              "d1=Q"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh5",
              "Bd7",
              "g6",
              "Ke7",
              "Qg5+",
              "Kf8",
              "Qf6+",
              "Qf7",
              "Qxf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qf7",
              "Qg6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 279,
            "completion_tokens": 452,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 279,
            "completion_tokens": 44,
            "total_tokens": 323,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 278,
            "completion_tokens": 8,
            "total_tokens": 286,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 836,
          "total_completion_tokens": 504,
          "total_tokens": 1340
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 279,
            "completion_tokens": 452,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 279,
            "completion_tokens": 44,
            "total_tokens": 323,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 278,
            "completion_tokens": 8,
            "total_tokens": 286,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1rq1/ppp5/3pp3/6P1/3P4/2P5/PP2QPP1/2KR3R w - - 2 21"
    },
    {
      "turn": 43,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh4",
          "aggressive_uci": "h5h4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Kd7 23. Qe4 Rb8 24. Rh7+ Rf7 25. g6 Rxh7 26. gxh7 Qh8 27. Rh1 Bb7 28. Qg6 Rf8 29. Rh6 Bd5 30. b3 b5 31. f3 a5 32. Kd2 a4 33. bxa4 bxa4 34. a3 Bb3 35. Ke3 Bd5 36. Kd3 Bb3 37. c4 Re8 38. Qf7+ Re7 39. Qg8 Re8 40. Qf7+ Re7 41. Qg8 Re8 42. Qf7+ Re7 43. Qg8 Re8 44. Qf7+ Re7 45. Qg8 Re8 46. Qf7+ Re7 47. Qg8 Re8 48. Qf7+ Re7 49. Qg8 Re8 50. Qf7+ Re7 51. Qg8 Re8 52. Qf7+ Re7 53. Qg8 Re8 54. Qf7+ Re7 55. Qg8 Re8 56. Qf7+ Re7 57. Qg8 Re8 58. Qf7+ Re7 59. Qg8 Re8 60. Qf7+ Re7 61. Qg8 Re8 62. Qf7+ Re7 63. Qg8 Re8 64. Qf7+ Re7 65. Qg8 Re8 66. Qf7+ Re7 67. Qg8 Re8 68. Qf7+ Re7 69. Qg8 Re8 70. Qf7+ Re7 71. Qg8 Re8 72. Qf7+ Re7 73. Qg8 Re8 74. Qf7+ Re7 75. Qg8 Re8 76. Qf7+ Re7",
          "aggressive_tokens": {
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kd7",
            "Qe4",
            "Rb8",
            "Rh7+",
            "Rf7",
            "g6",
            "Rxh7",
            "gxh7",
            "Qh8",
            "Rh1",
            "Bb7",
            "Qg6",
            "Rf8",
            "Rh6",
            "Bd5",
            "b3",
            "b5",
            "f3",
            "a5",
            "Kd2",
            "a4",
            "bxa4",
            "bxa4",
            "a3",
            "Bb3",
            "Ke3",
            "Bd5",
            "Kd3",
            "Bb3",
            "c4",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g6",
          "positional_uci": "g5g6",
          "positional_response": "22. g6 Bb7 23. Qg5+ Kd7 24. Rh7+ Kc8 25. Qe7 Qxh7 26. gxh7 Rh8 27. Qg7\nRxh7 28. Qxh7 Bxg2 29. Rg1 Bd5 30. Rg8+ Kb7 31. Rxa8 Kxa8 32. Qxc7 Bxa2 33.\nQc8#",
          "positional_tokens": {
            "prompt_tokens": 287,
            "completion_tokens": 108,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "Qg5+",
            "Kd7",
            "Rh7+",
            "Kc8",
            "Qe7",
            "Qxh7",
            "gxh7",
            "Rh8",
            "Qg7",
            "Rxh7",
            "Qxh7",
            "Bxg2",
            "Rg1",
            "Bd5",
            "Rg8+",
            "Kb7",
            "Rxa8",
            "Kxa8",
            "Qxc7",
            "Bxa2",
            "Qc8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh4",
          "neutral_uci": "h5h4",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Kd7 23. Qe4 Rb8 24. Rh7+ Rf7 25. g6 Rxh7 26. gxh7 Qh8 27. Rh1 Bb7 28. Qg6 Re8 29. Rh6 Bd5 30. b3 b5 31. g4 Rf8 32. g5 Rxf2 33. Qg8 Rf8 34. Qxh8 Rxh8 35. g6 Be4 36. g7 Rxh7 37. Rxh7 Bxh7 38. Kd2 Ke7 39. Ke3 Kf7 40. Kf4 Kxg7 41. Kg5 Bb1 42. a3 Ba2 43. b4 Kf7 44. Kf4 Kf6 45. Ke4 Bb1+ 46. Kf4 e5+ 47. dxe5+ dxe5+ 48. Ke3 Kf5 49. Kf3 e4+ 50. Ke3 Ke5 51. Kd2 Kf4 52. Ke2 e3 53. Ke1 Kf3 54. Kf1 e2+ 55. Ke1 Ke3 56. c4 bxc4 57. b5 c3 58. b6 c2 59. bxc7 c1=Q# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 286,
            "completion_tokens": 500,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd7",
            "Qe4",
            "Rb8",
            "Rh7+",
            "Rf7",
            "g6",
            "Rxh7",
            "gxh7",
            "Qh8",
            "Rh1",
            "Bb7",
            "Qg6",
            "Re8",
            "Rh6",
            "Bd5",
            "b3",
            "b5",
            "g4",
            "Rf8",
            "g5",
            "Rxf2",
            "Qg8",
            "Rf8",
            "Qxh8",
            "Rxh8",
            "g6",
            "Be4",
            "g7",
            "Rxh7",
            "Rxh7",
            "Bxh7",
            "Kd2",
            "Ke7",
            "Ke3",
            "Kf7",
            "Kf4",
            "Kxg7",
            "Kg5",
            "Bb1",
            "a3",
            "Ba2",
            "b4",
            "Kf7",
            "Kf4",
            "Kf6",
            "Ke4",
            "Bb1+",
            "Kf4",
            "e5+",
            "dxe5+",
            "dxe5+",
            "Ke3",
            "Kf5",
            "Kf3",
            "e4+",
            "Ke3",
            "Ke5",
            "Kd2",
            "Kf4",
            "Ke2",
            "e3",
            "Ke1",
            "Kf3",
            "Kf1",
            "e2+",
            "Ke1",
            "Ke3",
            "c4",
            "bxc4",
            "b5",
            "c3",
            "b6",
            "c2",
            "bxc7",
            "c1=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h5h4",
          "positional_uci": "g5g6",
          "neutral_uci": "h5h4",
          "consensus_move": "h5h4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kd7",
              "Qe4",
              "Rb8",
              "Rh7+",
              "Rf7",
              "g6",
              "Rxh7",
              "gxh7",
              "Qh8",
              "Rh1",
              "Bb7",
              "Qg6",
              "Rf8",
              "Rh6",
              "Bd5",
              "b3",
              "b5",
              "f3",
              "a5",
              "Kd2",
              "a4",
              "bxa4",
              "bxa4",
              "a3",
              "Bb3",
              "Ke3",
              "Bd5",
              "Kd3",
              "Bb3",
              "c4",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Qg5+",
              "Kd7",
              "Rh7+",
              "Kc8",
              "Qe7",
              "Qxh7",
              "gxh7",
              "Rh8",
              "Qg7",
              "Rxh7",
              "Qxh7",
              "Bxg2",
              "Rg1",
              "Bd5",
              "Rg8+",
              "Kb7",
              "Rxa8",
              "Kxa8",
              "Qxc7",
              "Bxa2",
              "Qc8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd7",
              "Qe4",
              "Rb8",
              "Rh7+",
              "Rf7",
              "g6",
              "Rxh7",
              "gxh7",
              "Qh8",
              "Rh1",
              "Bb7",
              "Qg6",
              "Re8",
              "Rh6",
              "Bd5",
              "b3",
              "b5",
              "g4",
              "Rf8",
              "g5",
              "Rxf2",
              "Qg8",
              "Rf8",
              "Qxh8",
              "Rxh8",
              "g6",
              "Be4",
              "g7",
              "Rxh7",
              "Rxh7",
              "Bxh7",
              "Kd2",
              "Ke7",
              "Ke3",
              "Kf7",
              "Kf4",
              "Kxg7",
              "Kg5",
              "Bb1",
              "a3",
              "Ba2",
              "b4",
              "Kf7",
              "Kf4",
              "Kf6",
              "Ke4",
              "Bb1+",
              "Kf4",
              "e5+",
              "dxe5+",
              "dxe5+",
              "Ke3",
              "Kf5",
              "Kf3",
              "e4+",
              "Ke3",
              "Ke5",
              "Kd2",
              "Kf4",
              "Ke2",
              "e3",
              "Ke1",
              "Kf3",
              "Kf1",
              "e2+",
              "Ke1",
              "Ke3",
              "c4",
              "bxc4",
              "b5",
              "c3",
              "b6",
              "c2",
              "bxc7",
              "c1=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 287,
            "completion_tokens": 108,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 286,
            "completion_tokens": 500,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 860,
          "total_completion_tokens": 1248,
          "total_tokens": 2108
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 287,
            "completion_tokens": 108,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 286,
            "completion_tokens": 500,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1rq1/p1p5/1p1pp3/6PQ/3P4/2P5/PP3PP1/2KR3R w - - 0 22"
    },
    {
      "turn": 45,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": "h4h6",
          "aggressive_response": "23. Qh6 Qxh6 24. Rxh6 Ke7 25. Rh7+ Rf7 26. Rdh1 Bb7 27. g6 Rxh7 28. Rxh7+ Kf6\n29. Rxc7 Bxg2 30. g7 a5 31. Kd2 Rg8 32. Rd7 d5 33. Rb7 Rxg7 34. Rxb6 Bf1 35.\nb3 Rg2 36. Ke3 Rh2 37. Rb8 Rh3+ 38. Kd2 Rd3+ 39. Kc2 Rf3 40. Ra8 Rxf2+ 41. Kb1\nBd3+ 42. Ka1 Rc2 43. Rxa5 Rxc3 44. Kb2 Rc2+ 45. Ka3 Kf5 46. Ra8 Ke4 47. Re8 Rc6\n48. Kb4 Kxd4 49. a4 e5 50. a5 e4 51. Ka4 e3 52. b4 e2 53. b5 Rc4+ 54. Kb3 Be4\n55. b6 e1=Q 56. b7 Qb4+ 57. Ka2 Rc2+ 58. Ka1 Qb2# e4 d5 d4",
          "aggressive_tokens": {
            "prompt_tokens": 296,
            "completion_tokens": 304,
            "total_tokens": 600,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "Rxh6",
            "Ke7",
            "Rh7+",
            "Rf7",
            "Rdh1",
            "Bb7",
            "g6",
            "Rxh7",
            "Rxh7+",
            "Kf6",
            "Rxc7",
            "Bxg2",
            "g7",
            "a5",
            "Kd2",
            "Rg8",
            "Rd7",
            "d5",
            "Rb7",
            "Rxg7",
            "Rxb6",
            "Bf1",
            "b3",
            "Rg2",
            "Ke3",
            "Rh2",
            "Rb8",
            "Rh3+",
            "Kd2",
            "Rd3+",
            "Kc2",
            "Rf3",
            "Ra8",
            "Rxf2+",
            "Kb1",
            "Bd3+",
            "Ka1",
            "Rc2",
            "Rxa5",
            "Rxc3",
            "Kb2",
            "Rc2+",
            "Ka3",
            "Kf5",
            "Ra8",
            "Ke4",
            "Re8",
            "Rc6",
            "Kb4",
            "Kxd4",
            "a4",
            "e5",
            "a5",
            "e4",
            "Ka4",
            "e3",
            "b4",
            "e2",
            "b5",
            "Rc4+",
            "Kb3",
            "Be4",
            "b6",
            "e1=Q",
            "b7",
            "Qb4+",
            "Ka2",
            "Rc2+",
            "Ka1",
            "Qb2#",
            "e4",
            "d5",
            "d4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f4",
          "positional_uci": "f2f4",
          "positional_response": "23. f4 Bb7 24. Rh2 Kd7 25. g4 Rh8 26. Qg3 Rxh2 27. Qxh2 Qg7 28. Qg3 Rh8 29.\nRf1 Rh1 30. Rxh1 Bxh1 31. f5 exf5 32. gxf5 Be4 33. f6 Qg6 34. Qg4+ Bf5 35. Qg3\nBe6 36. Qf4 Bf7 37. Qg4+ Kd8 38. Qg2 Qf5 39. Qa8+ Kd7 40. Qg2 Qf4+ 41. Kc2\nBg6+ 42. Kb3 Qe4 43. Qh3+ Qe6+ 44. Qxe6+ Kxe6 45. c4 Kf5 46. Kb4 Kxg5 47. Kb5\nBe8+ 48. Ka6 Kxf6 49. Kxa7 Ke7 50. Kb7 Kd7 51. b4 Bf7 52. c5 dxc5 53. dxc5 bxc5\n54. bxc5 Bxa2 55. c6+ Kd6 56. Ka6 Kxc6 57. Ka5 Kc5 58. Ka4 Kc4 59. Ka3 Kc3\n60. Kxa2 c5 61. Kb1 c4 62. Kc1 Kd3 63. Kd1 c3 64. Kc1 c2 65. Kb2 Kd2 66. Kb3\nc1=Q 67. Kb4 Qc6 68. Kb3 Qc5 69. Kb2 Qc4 70. Kb1 Qb3+ 71. Ka1 Qb4 72. Ka2 Kc2\n73. Ka1 Qb2# d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh4 b6 Qh4 Qg6 f4 Bb7 Rh2 Kd7 g4 Rh8 Qg3 Rxh2 Qxh2 Qg7 Qg3 Rh8 Rf1 Rh1 Rxh1 Bxh1 f5 exf5 gxf5 Be4 f6 Qg6 Qg4+ Bf5 Qg3 Bb1 Qg2 Qf5 Qg7",
          "positional_tokens": {
            "prompt_tokens": 296,
            "completion_tokens": 640,
            "total_tokens": 936,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Rh2",
            "Kd7",
            "g4",
            "Rh8",
            "Qg3",
            "Rxh2",
            "Qxh2",
            "Qg7",
            "Qg3",
            "Rh8",
            "Rf1",
            "Rh1",
            "Rxh1",
            "Bxh1",
            "f5",
            "exf5",
            "gxf5",
            "Be4",
            "f6",
            "Qg6",
            "Qg4+",
            "Bf5",
            "Qg3",
            "Bb1",
            "Qg2",
            "Qf5",
            "Qg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": "h4h6",
          "neutral_response": "Re1 Re8 24. Rxe8+ Kxe8 25. Qh8+ Kd7 26. Rh7+\nKc6 27. Qg7 Qxg7 28. Rxg7 Bd7 29. Kd2 Rf8 30. Ke3 e5 31. dxe5 dxe5 32. f3 Kd6\n33. g4 Bc6 34. Rg6+ Kd7 35. Rf6 Rxf6 36. gxf6 Ke6 37. g5 Kf5 38. f7 Kxg5 39.\nf8=Q * Bb7 Bc6 41. Qe7+ Kf5 42. Qxc7 Bd5 43. Qxa7 b5 44. Qc5 Bxa2 45. Qxb5\nBe6 46. f4 Kf6 47. Qxe5+ Kf7 48. f5 Bd7 49. f6 Be6 50. Kf4 Bb3 51. Kg5 Be6\n52. Qc7+ Kf8 53. Qe7+ Kg8 54. Qg7# Bf7 56. Kh6 *\n\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Bb7 25. f3 Ke7 26. Rh3\nRh8 27. Rdh1 Rag8 28. R1h2 Rg6 29. Kd2 e5 30. dxe5 dxe5 31. Ke3 Kf6 32. g4\nBc6 33. Rh5 Bd7 34. R2h4 Be6 35. b3 c5 36. c4 a6 37. Ke4 Rg5 38. Rxg5 Kxg5\n39. Rh5+ Kf6 40. g5+ Kg6 41. Rh2 Bf5+ 42. Kxe5 Kxg5 43. f4+",
          "neutral_tokens": {
            "prompt_tokens": 295,
            "completion_tokens": 640,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxh6",
            "gxh6",
            "Bb7",
            "f3",
            "Ke7",
            "Rh3",
            "Rh8",
            "Rdh1",
            "Rag8",
            "R1h2",
            "Rg6",
            "Kd2",
            "e5",
            "dxe5",
            "dxe5",
            "Ke3",
            "Kf6",
            "g4",
            "Bc6",
            "Rh5",
            "Bd7",
            "R2h4",
            "Be6",
            "b3",
            "c5",
            "c4",
            "a6",
            "Ke4",
            "Rg5",
            "Rxg5",
            "Kxg5",
            "Rh5+",
            "Kf6",
            "g5+",
            "Kg6",
            "Rh2",
            "Bf5+",
            "Kxe5",
            "Kxg5",
            "f4+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4h6",
          "positional_uci": "f2f4",
          "neutral_uci": "h4h6",
          "consensus_move": "h4h6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxh6",
              "Rxh6",
              "Ke7",
              "Rh7+",
              "Rf7",
              "Rdh1",
              "Bb7",
              "g6",
              "Rxh7",
              "Rxh7+",
              "Kf6",
              "Rxc7",
              "Bxg2",
              "g7",
              "a5",
              "Kd2",
              "Rg8",
              "Rd7",
              "d5",
              "Rb7",
              "Rxg7",
              "Rxb6",
              "Bf1",
              "b3",
              "Rg2",
              "Ke3",
              "Rh2",
              "Rb8",
              "Rh3+",
              "Kd2",
              "Rd3+",
              "Kc2",
              "Rf3",
              "Ra8",
              "Rxf2+",
              "Kb1",
              "Bd3+",
              "Ka1",
              "Rc2",
              "Rxa5",
              "Rxc3",
              "Kb2",
              "Rc2+",
              "Ka3",
              "Kf5",
              "Ra8",
              "Ke4",
              "Re8",
              "Rc6",
              "Kb4",
              "Kxd4",
              "a4",
              "e5",
              "a5",
              "e4",
              "Ka4",
              "e3",
              "b4",
              "e2",
              "b5",
              "Rc4+",
              "Kb3",
              "Be4",
              "b6",
              "e1=Q",
              "b7",
              "Qb4+",
              "Ka2",
              "Rc2+",
              "Ka1",
              "Qb2#",
              "e4",
              "d5",
              "d4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Rh2",
              "Kd7",
              "g4",
              "Rh8",
              "Qg3",
              "Rxh2",
              "Qxh2",
              "Qg7",
              "Qg3",
              "Rh8",
              "Rf1",
              "Rh1",
              "Rxh1",
              "Bxh1",
              "f5",
              "exf5",
              "gxf5",
              "Be4",
              "f6",
              "Qg6",
              "Qg4+",
              "Bf5",
              "Qg3",
              "Bb1",
              "Qg2",
              "Qf5",
              "Qg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxh6",
              "gxh6",
              "Bb7",
              "f3",
              "Ke7",
              "Rh3",
              "Rh8",
              "Rdh1",
              "Rag8",
              "R1h2",
              "Rg6",
              "Kd2",
              "e5",
              "dxe5",
              "dxe5",
              "Ke3",
              "Kf6",
              "g4",
              "Bc6",
              "Rh5",
              "Bd7",
              "R2h4",
              "Be6",
              "b3",
              "c5",
              "c4",
              "a6",
              "Ke4",
              "Rg5",
              "Rxg5",
              "Kxg5",
              "Rh5+",
              "Kf6",
              "g5+",
              "Kg6",
              "Rh2",
              "Bf5+",
              "Kxe5",
              "Kxg5",
              "f4+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 296,
            "completion_tokens": 304,
            "total_tokens": 600,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 296,
            "completion_tokens": 640,
            "total_tokens": 936,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 295,
            "completion_tokens": 640,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 887,
          "total_completion_tokens": 1584,
          "total_tokens": 2471
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 296,
            "completion_tokens": 304,
            "total_tokens": 600,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 296,
            "completion_tokens": 640,
            "total_tokens": 936,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 295,
            "completion_tokens": 640,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/p1p5/1p1pp1q1/6P1/3P3Q/2P5/PP3PP1/2KR3R w - - 2 23"
    },
    {
      "turn": 47,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "gxh6",
          "aggressive_uci": "g5h6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Bb7 25. Rh2 Ke7 26. g4\nRf4 27. g5 Be4 28. Re1 d5 29. Kd2 Rg8 30. Rg1 Bh7 31. Ke3 Rf5 32. f4 c5 33.\ndxc5 bxc5 34. b4 cxb4 35. cxb4 e5 36. fxe5 Rxe5+ 37. Kd4 Rexg5 38. Rxg5 Rxg5\n39. a4 Kd6 40. Rh4 Rg1 41. Kc3 Rg3+ 42. Kd2 Ra3 43. a5 Ke5 44. Rh5+ Kd4 45.\nRh4+ Be4 46. h7 Ra2+ 47. Kc1 Kc3 48. Rh3+ Bd3 49. Rxd3+ Kxd3 50. h8=Q Rc2+\n51. Kb1 Rc4 52. Qh3+ Kd4 53. Qg4+ Kc3 54. Qf3+ Kxb4 55. Qxd5 Rc5 56. Qd4+\nRc4 57. Qxa7 Kb5 58. Qb6+ Ka4 59. a6 Rb4+ 60. Qxb4+ Kxb4 61. a7 Kc5 62. a8=Q\nKd6 63. Qa5 Ke6 64. Kc2 Kd6 65. Kd3 Ke6 66. Ke4 Kd6 67. Qb6+ Kd7 68. Ke5 Ke7\n69. Qc7+ Kf8 70. Kf6 Kg8 71. Qg7# Qd8 72. Qg7# Qd8 73. Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 306,
            "completion_tokens": 629,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "Rh2",
            "Ke7",
            "g4",
            "Rf4",
            "g5",
            "Be4",
            "Re1",
            "d5",
            "Kd2",
            "Rg8",
            "Rg1",
            "Bh7",
            "Ke3",
            "Rf5",
            "f4",
            "c5",
            "dxc5",
            "bxc5",
            "b4",
            "cxb4",
            "cxb4",
            "e5",
            "fxe5",
            "Rxe5+",
            "Kd4",
            "Rexg5",
            "Rxg5",
            "Rxg5",
            "a4",
            "Kd6",
            "Rh4",
            "Rg1",
            "Kc3",
            "Rg3+",
            "Kd2",
            "Ra3",
            "a5",
            "Ke5",
            "Rh5+",
            "Kd4",
            "Rh4+",
            "Be4",
            "h7",
            "Ra2+",
            "Kc1",
            "Kc3",
            "Rh3+",
            "Bd3",
            "Rxd3+",
            "Kxd3",
            "h8=Q",
            "Rc2+",
            "Kb1",
            "Rc4",
            "Qh3+",
            "Kd4",
            "Qg4+",
            "Kc3",
            "Qf3+",
            "Kxb4",
            "Qxd5",
            "Rc5",
            "Qd4+",
            "Rc4",
            "Qxa7",
            "Kb5",
            "Qb6+",
            "Ka4",
            "a6",
            "Rb4+",
            "Qxb4+",
            "Kxb4",
            "a7",
            "Kc5",
            "a8=Q",
            "Kd6",
            "Qa5",
            "Ke6",
            "Kc2",
            "Kd6",
            "Kd3",
            "Ke6",
            "Ke4",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Ke5",
            "Ke7",
            "Qc7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Qd8",
            "Qg7#",
            "Qd8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "gxh6",
          "positional_uci": "g5h6",
          "positional_response": "24. gxh6 Ke7 25. g4 Bb7 26. Rh2 Rf4 27. g5 Be4 28. Rg1 Bg6 29. Kd2 Raf8 30. Ke1\nRf3 31. Rg3 Rxg3 32. fxg3 Rf3 33. Rh3 Kf7 34. Ke2 Rf5 35. g4 Rxg5 36. Kf3 Kg8\n37. Kf4 Ra5 38. a3 Kh7 39. g5 Rf5+ 40. Kg4 Rf2 41. Re3 Bf5+ 42. Kh5 Rh2+ 43. Rh3\nRxh3#",
          "positional_tokens": {
            "prompt_tokens": 306,
            "completion_tokens": 166,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g4",
            "Bb7",
            "Rh2",
            "Rf4",
            "g5",
            "Be4",
            "Rg1",
            "Bg6",
            "Kd2",
            "Raf8",
            "Ke1",
            "Rf3",
            "Rg3",
            "Rxg3",
            "fxg3",
            "Rf3",
            "Rh3",
            "Kf7",
            "Ke2",
            "Rf5",
            "g4",
            "Rxg5",
            "Kf3",
            "Kg8",
            "Kf4",
            "Ra5",
            "a3",
            "Kh7",
            "g5",
            "Rf5+",
            "Kg4",
            "Rf2",
            "Re3",
            "Bf5+",
            "Kh5",
            "Rh2+",
            "Rh3",
            "Rxh3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxh6",
          "neutral_uci": "h1h6",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. Rxh6 Ke7 25. Rh7+ Rf7 26. Rdh1\nBb7 27. g6 Rxh7 28. Rxh7+ Kf6 29. Rxc7 Bxg2 30. g7 Rg8 31. Rxa7 Rxg7 32. Ra6\nRb7 33. Kd2 Kf5 34. Ke3 Bf1 35. Ra8 e5 36. Rf8+ Ke6 37. Re8+ Kd5 38. dxe5 dxe5\n39. Rd8+ Ke6 40. Re8+ Re7 41. Rb8 b5 42. Rb6+ Kf5 43. Rh6 Rd7 44. Rh5+ Kf6 45.\nRh6+ Kg5 46. Rh1 Bg2 47. Rg1 Kf5 48. Rxg2 Ra7 49. a3 Rd7 50. f3 Rd1 51. Rd2\nRe1+ 52. Kf2 Rb1 53. Ke3 Re1+ 54. Re2 Rd1 55. Rh2 Re1+ 56. Kd2 Rb1 57. Kc2\nRf1 58. Rh5+ Kf4 59. Rh4+ Kxf3 60. Rh5 Ke4 61. Rh4+ Kd5 62. Rh5 Rf2+ 63. Kb3\nRf3 64. Kb4 Rf2 65. b3 Rf4+ 66. Kxb5 Rf3 67. c4+ Kd4 68. Rh4+ e4 69. Kb4 Rf8\n70. c5 Rb8+ 71. Ka4 Kd3 72. b4 e3 73. Rh3 Kd2 74. Rxe3 Kxe3 75. c6 Kd4 76",
          "neutral_tokens": {
            "prompt_tokens": 305,
            "completion_tokens": 640,
            "total_tokens": 945,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke7",
            "Rh7+",
            "Rf7",
            "Rdh1",
            "Bb7",
            "g6",
            "Rxh7",
            "Rxh7+",
            "Kf6",
            "Rxc7",
            "Bxg2",
            "g7",
            "Rg8",
            "Rxa7",
            "Rxg7",
            "Ra6",
            "Rb7",
            "Kd2",
            "Kf5",
            "Ke3",
            "Bf1",
            "Ra8",
            "e5",
            "Rf8+",
            "Ke6",
            "Re8+",
            "Kd5",
            "dxe5",
            "dxe5",
            "Rd8+",
            "Ke6",
            "Re8+",
            "Re7",
            "Rb8",
            "b5",
            "Rb6+",
            "Kf5",
            "Rh6",
            "Rd7",
            "Rh5+",
            "Kf6",
            "Rh6+",
            "Kg5",
            "Rh1",
            "Bg2",
            "Rg1",
            "Kf5",
            "Rxg2",
            "Ra7",
            "a3",
            "Rd7",
            "f3",
            "Rd1",
            "Rd2",
            "Re1+",
            "Kf2",
            "Rb1",
            "Ke3",
            "Re1+",
            "Re2",
            "Rd1",
            "Rh2",
            "Re1+",
            "Kd2",
            "Rb1",
            "Kc2",
            "Rf1",
            "Rh5+",
            "Kf4",
            "Rh4+",
            "Kxf3",
            "Rh5",
            "Ke4",
            "Rh4+",
            "Kd5",
            "Rh5",
            "Rf2+",
            "Kb3",
            "Rf3",
            "Kb4",
            "Rf2",
            "b3",
            "Rf4+",
            "Kxb5",
            "Rf3",
            "c4+",
            "Kd4",
            "Rh4+",
            "e4",
            "Kb4",
            "Rf8",
            "c5",
            "Rb8+",
            "Ka4",
            "Kd3",
            "b4",
            "e3",
            "Rh3",
            "Kd2",
            "Rxe3",
            "Kxe3",
            "c6",
            "Kd4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h6",
          "positional_uci": "g5h6",
          "neutral_uci": "h1h6",
          "consensus_move": "g5h6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb7",
              "Rh2",
              "Ke7",
              "g4",
              "Rf4",
              "g5",
              "Be4",
              "Re1",
              "d5",
              "Kd2",
              "Rg8",
              "Rg1",
              "Bh7",
              "Ke3",
              "Rf5",
              "f4",
              "c5",
              "dxc5",
              "bxc5",
              "b4",
              "cxb4",
              "cxb4",
              "e5",
              "fxe5",
              "Rxe5+",
              "Kd4",
              "Rexg5",
              "Rxg5",
              "Rxg5",
              "a4",
              "Kd6",
              "Rh4",
              "Rg1",
              "Kc3",
              "Rg3+",
              "Kd2",
              "Ra3",
              "a5",
              "Ke5",
              "Rh5+",
              "Kd4",
              "Rh4+",
              "Be4",
              "h7",
              "Ra2+",
              "Kc1",
              "Kc3",
              "Rh3+",
              "Bd3",
              "Rxd3+",
              "Kxd3",
              "h8=Q",
              "Rc2+",
              "Kb1",
              "Rc4",
              "Qh3+",
              "Kd4",
              "Qg4+",
              "Kc3",
              "Qf3+",
              "Kxb4",
              "Qxd5",
              "Rc5",
              "Qd4+",
              "Rc4",
              "Qxa7",
              "Kb5",
              "Qb6+",
              "Ka4",
              "a6",
              "Rb4+",
              "Qxb4+",
              "Kxb4",
              "a7",
              "Kc5",
              "a8=Q",
              "Kd6",
              "Qa5",
              "Ke6",
              "Kc2",
              "Kd6",
              "Kd3",
              "Ke6",
              "Ke4",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Ke5",
              "Ke7",
              "Qc7+",
              "Kf8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Qd8",
              "Qg7#",
              "Qd8",
              "Qg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "g4",
              "Bb7",
              "Rh2",
              "Rf4",
              "g5",
              "Be4",
              "Rg1",
              "Bg6",
              "Kd2",
              "Raf8",
              "Ke1",
              "Rf3",
              "Rg3",
              "Rxg3",
              "fxg3",
              "Rf3",
              "Rh3",
              "Kf7",
              "Ke2",
              "Rf5",
              "g4",
              "Rxg5",
              "Kf3",
              "Kg8",
              "Kf4",
              "Ra5",
              "a3",
              "Kh7",
              "g5",
              "Rf5+",
              "Kg4",
              "Rf2",
              "Re3",
              "Bf5+",
              "Kh5",
              "Rh2+",
              "Rh3",
              "Rxh3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke7",
              "Rh7+",
              "Rf7",
              "Rdh1",
              "Bb7",
              "g6",
              "Rxh7",
              "Rxh7+",
              "Kf6",
              "Rxc7",
              "Bxg2",
              "g7",
              "Rg8",
              "Rxa7",
              "Rxg7",
              "Ra6",
              "Rb7",
              "Kd2",
              "Kf5",
              "Ke3",
              "Bf1",
              "Ra8",
              "e5",
              "Rf8+",
              "Ke6",
              "Re8+",
              "Kd5",
              "dxe5",
              "dxe5",
              "Rd8+",
              "Ke6",
              "Re8+",
              "Re7",
              "Rb8",
              "b5",
              "Rb6+",
              "Kf5",
              "Rh6",
              "Rd7",
              "Rh5+",
              "Kf6",
              "Rh6+",
              "Kg5",
              "Rh1",
              "Bg2",
              "Rg1",
              "Kf5",
              "Rxg2",
              "Ra7",
              "a3",
              "Rd7",
              "f3",
              "Rd1",
              "Rd2",
              "Re1+",
              "Kf2",
              "Rb1",
              "Ke3",
              "Re1+",
              "Re2",
              "Rd1",
              "Rh2",
              "Re1+",
              "Kd2",
              "Rb1",
              "Kc2",
              "Rf1",
              "Rh5+",
              "Kf4",
              "Rh4+",
              "Kxf3",
              "Rh5",
              "Ke4",
              "Rh4+",
              "Kd5",
              "Rh5",
              "Rf2+",
              "Kb3",
              "Rf3",
              "Kb4",
              "Rf2",
              "b3",
              "Rf4+",
              "Kxb5",
              "Rf3",
              "c4+",
              "Kd4",
              "Rh4+",
              "e4",
              "Kb4",
              "Rf8",
              "c5",
              "Rb8+",
              "Ka4",
              "Kd3",
              "b4",
              "e3",
              "Rh3",
              "Kd2",
              "Rxe3",
              "Kxe3",
              "c6",
              "Kd4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 306,
            "completion_tokens": 629,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 306,
            "completion_tokens": 166,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 305,
            "completion_tokens": 640,
            "total_tokens": 945,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 917,
          "total_completion_tokens": 1435,
          "total_tokens": 2352
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 306,
            "completion_tokens": 629,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 306,
            "completion_tokens": 166,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 305,
            "completion_tokens": 640,
            "total_tokens": 945,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/p1p5/1p1pp2q/6P1/3P4/2P5/PP3PP1/2KR3R w - - 0 24"
    },
    {
      "turn": 49,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf6",
          "aggressive_uci": null,
          "aggressive_response": "Re1 Re7 Rxe7 Kxe7 Kd2\nKf6 Ke3 Kg5 f4+ Kxh6 Kf4 Kg7 g4 Kf7 g5 Kg7 Kg4 Kf7 f5 Kg7 f6+ Kf7 Kf5 Kg8 g6 Kf8 Ke6 Kg8 Ke7 Kh8 f7 Kg7 f8=Q+ Kxf8 Kf6 Kg8 g7 Kh7 Kf7 Kh6 g8=Q Kh5 Qg3 Kh6 Qg6# Kg5 Qg5# Kg6 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8",
          "aggressive_tokens": {
            "prompt_tokens": 314,
            "completion_tokens": 640,
            "total_tokens": 954,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg8",
            "g7",
            "Kh7",
            "Kf7",
            "Kh6",
            "g8=Q",
            "Kh5",
            "Qg3",
            "Kh6",
            "Qg6#",
            "Kg5",
            "Qg5#",
            "Kg6",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g4",
          "positional_uci": "g2g4",
          "positional_response": "25. g4 Ke7 26. g5 Kf7 27. Rdg1 Kg6",
          "positional_tokens": {
            "prompt_tokens": 314,
            "completion_tokens": 23,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g5",
            "Kf7",
            "Rdg1",
            "Kg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kf2",
          "neutral_uci": null,
          "neutral_response": "Re1 Re7 Rxe7 Kxe7 Kd2\nKf6 Ke3 Kg5 Kf3 Rxh6 Rxh6 Rxh6 g4+ Kg6 Kg3 Rh1 f4 Rb1 b3 Rxb2 f5+ Kf6 Kf4 Rxa2\ng5+ Kf7 Ke5 Re2+ Kf4 a5 g6+ Kf6 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2\nRe4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 K",
          "neutral_tokens": {
            "prompt_tokens": 313,
            "completion_tokens": 640,
            "total_tokens": 953,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g2g4",
          "neutral_uci": null,
          "consensus_move": "g2g4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg8",
              "g7",
              "Kh7",
              "Kf7",
              "Kh6",
              "g8=Q",
              "Kh5",
              "Qg3",
              "Kh6",
              "Qg6#",
              "Kg5",
              "Qg5#",
              "Kg6",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "g5",
              "Kf7",
              "Rdg1",
              "Kg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 314,
            "completion_tokens": 640,
            "total_tokens": 954,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 314,
            "completion_tokens": 23,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 313,
            "completion_tokens": 640,
            "total_tokens": 953,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 941,
          "total_completion_tokens": 1303,
          "total_tokens": 2244
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 314,
            "completion_tokens": 640,
            "total_tokens": 954,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 314,
            "completion_tokens": 23,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 313,
            "completion_tokens": 640,
            "total_tokens": 953,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk3r/p1p5/1p1pp2P/8/3P4/2P5/PP3PP1/2KR3R w - - 1 25"
    },
    {
      "turn": 51,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh5",
          "aggressive_uci": "h1h5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke7 27. g5 Rag8 28. f4 Bf3 29. Rh4 Bxd1 30. Kxd1 Kf7 31. Ke2 Kg6 32. Kf3 Rf8 33. Kg4 Rf5 34. Rh2 e5 35. dxe5 dxe5 36. fxe5 Rxg5+ 37. Kf4 Rxh6 38. Rd2 Rh4+ 39. Kf3 Rxe5 40. Rd7 Rh7 41. Rd8 Rf7+ 42. Kg4 Rg5+ 43. Kh4 Rh7# 0-1\n25... Bb7 26. Rh5 Ke7 27. g4 Rfg8",
          "aggressive_tokens": {
            "prompt_tokens": 322,
            "completion_tokens": 386,
            "total_tokens": 708,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g4",
            "Rfg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rh4",
          "positional_uci": "h1h4",
          "positional_response": "26. Rh4 Ke7 27. g5 Rag8 28. f4 Be4 29. Re1 d5 30. Kd2 Kf7 31. Ke3 Kg6 32. Kf2\nRh7 33. Kg3 Rf8 34. Rh2 c5 35. dxc5 bxc5 36. Rd2 Rhf7 37. Rf2 e5 38. Ref1\nexf4+ 39. Rxf4 Rxf4 40. Rxf4 Rxf4 41. Kxf4 Bb1 42. a3 a5 43. b4 cxb4 44. cxb4\naxb4 45. axb4 d4 46. b5 d3 47. Ke3 Kxg5 48. h7 d2 49. Kxd2 Bxh7 50. b6 Be4\n51. b7 Bxb7 52. *\nd5 d4 d3",
          "positional_tokens": {
            "prompt_tokens": 322,
            "completion_tokens": 221,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g5",
            "Rag8",
            "f4",
            "Be4",
            "Re1",
            "d5",
            "Kd2",
            "Kf7",
            "Ke3",
            "Kg6",
            "Kf2",
            "Rh7",
            "Kg3",
            "Rf8",
            "Rh2",
            "c5",
            "dxc5",
            "bxc5",
            "Rd2",
            "Rhf7",
            "Rf2",
            "e5",
            "Ref1",
            "exf4+",
            "Rxf4",
            "Rxf4",
            "Rxf4",
            "Rxf4",
            "Kxf4",
            "Bb1",
            "a3",
            "a5",
            "b4",
            "cxb4",
            "cxb4",
            "axb4",
            "axb4",
            "d4",
            "b5",
            "d3",
            "Ke3",
            "Kxg5",
            "h7",
            "d2",
            "Kxd2",
            "Bxh7",
            "b6",
            "Be4",
            "b7",
            "Bxb7",
            "d5",
            "d4",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rh5",
          "neutral_uci": "h1h5",
          "neutral_response": "Re8\n26. Rh5 Ke7 27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3\nRh7 33. Rgh1 Rfh8 34. R1h2 Kf7 35. Rg2 Bg6 36. Rgh2 Ke7 37. Rg2 Kd7 38. Rgh2\nKc6 39. Rg2 Kd5 40. Rgh2 c5 41. dxc5 bxc5 42. Rd2+ Kc6 43. Rdh2 d5 44. R4h3\nKd6 45. Rh4 a5 46. R4h3 a4 47. Rh4 Rb8 48. Rd2 a3 49. b3 Rf8 50. Rf2 e5 51.\nfxe5+ Kxe5 52. Rxf8 d4+ 53. cxd4+ cxd4+ 54. Rxd4 Re7 55. Rf6 Bb1 56. Rd2 Bxa2\n57. Rxa2 Kd5+ 58. Kd3 Kc5 59. Rxa3 Kb4 60. Ra4+ Kxb3 61. Re4 Rd7+ 62. Ke3 Kc3\n63. Rc6+ Kb3 64. g6 Ka3 65. g7 Kb3 66. g8=Q+ Ka3 67. Ra6+ Kb2 68. Qa2+ Kc3\n69. Rc4# Kd3 70. Qc2# Kd5 71. Qe4# Kd6 72. Rc6# Kd7 73. Qe6# Kd8 74. Rc8# Kxc8\n75. Qxd7+ Kxd7 76. h7 Ke7 77. h8=Q Kf7 78. Qh7+ Kf8 79. Rg8# Kxg8 80. Qe7\nKh8 81. Kf4 Kg8 82. Kg5 Kh8 83. Kg6 Kg8 84. Qg7# Kd8 85. Qb7 Ke8 86. Qc7 Kf8\n87. Qd7 Kg8 88. Qe7 Kh8 89. Qf8# Kxh7 90. Qf7+ Kh8 91. Qg7# Kg8 92. Qf7+ Kh8\n93. Qf8# Kxh7 94. Qf7+ Kh8 95. Qf8# Kxh7 96. Qf7+ Kh8 97. Qf8# Kxh7 98.",
          "neutral_tokens": {
            "prompt_tokens": 321,
            "completion_tokens": 640,
            "total_tokens": 961,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke7",
            "g5",
            "Kf7",
            "Rg1",
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "Rh7",
            "Rgh1",
            "Rfh8",
            "R1h2",
            "Kf7",
            "Rg2",
            "Bg6",
            "Rgh2",
            "Ke7",
            "Rg2",
            "Kd7",
            "Rgh2",
            "Kc6",
            "Rg2",
            "Kd5",
            "Rgh2",
            "c5",
            "dxc5",
            "bxc5",
            "Rd2+",
            "Kc6",
            "Rdh2",
            "d5",
            "R4h3",
            "Kd6",
            "Rh4",
            "a5",
            "R4h3",
            "a4",
            "Rh4",
            "Rb8",
            "Rd2",
            "a3",
            "b3",
            "Rf8",
            "Rf2",
            "e5",
            "fxe5+",
            "Kxe5",
            "Rxf8",
            "d4+",
            "cxd4+",
            "cxd4+",
            "Rxd4",
            "Re7",
            "Rf6",
            "Bb1",
            "Rd2",
            "Bxa2",
            "Rxa2",
            "Kd5+",
            "Kd3",
            "Kc5",
            "Rxa3",
            "Kb4",
            "Ra4+",
            "Kxb3",
            "Re4",
            "Rd7+",
            "Ke3",
            "Kc3",
            "Rc6+",
            "Kb3",
            "g6",
            "Ka3",
            "g7",
            "Kb3",
            "g8=Q+",
            "Ka3",
            "Ra6+",
            "Kb2",
            "Qa2+",
            "Kc3",
            "Rc4#",
            "Kd3",
            "Qc2#",
            "Kd5",
            "Qe4#",
            "Kd6",
            "Rc6#",
            "Kd7",
            "Qe6#",
            "Kd8",
            "Rc8#",
            "Kxc8",
            "Qxd7+",
            "Kxd7",
            "h7",
            "Ke7",
            "h8=Q",
            "Kf7",
            "Qh7+",
            "Kf8",
            "Rg8#",
            "Kxg8",
            "Qe7",
            "Kh8",
            "Kf4",
            "Kg8",
            "Kg5",
            "Kh8",
            "Kg6",
            "Kg8",
            "Qg7#",
            "Kd8",
            "Qb7",
            "Ke8",
            "Qc7",
            "Kf8",
            "Qd7",
            "Kg8",
            "Qe7",
            "Kh8",
            "Qf8#",
            "Kxh7",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kxh7",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kxh7",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kxh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h1h5",
          "positional_uci": "h1h4",
          "neutral_uci": "h1h5",
          "consensus_move": "h1h5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ke7",
              "g4",
              "Rfg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "g5",
              "Rag8",
              "f4",
              "Be4",
              "Re1",
              "d5",
              "Kd2",
              "Kf7",
              "Ke3",
              "Kg6",
              "Kf2",
              "Rh7",
              "Kg3",
              "Rf8",
              "Rh2",
              "c5",
              "dxc5",
              "bxc5",
              "Rd2",
              "Rhf7",
              "Rf2",
              "e5",
              "Ref1",
              "exf4+",
              "Rxf4",
              "Rxf4",
              "Rxf4",
              "Rxf4",
              "Kxf4",
              "Bb1",
              "a3",
              "a5",
              "b4",
              "cxb4",
              "cxb4",
              "axb4",
              "axb4",
              "d4",
              "b5",
              "d3",
              "Ke3",
              "Kxg5",
              "h7",
              "d2",
              "Kxd2",
              "Bxh7",
              "b6",
              "Be4",
              "b7",
              "Bxb7",
              "d5",
              "d4",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke7",
              "g5",
              "Kf7",
              "Rg1",
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "Rh7",
              "Rgh1",
              "Rfh8",
              "R1h2",
              "Kf7",
              "Rg2",
              "Bg6",
              "Rgh2",
              "Ke7",
              "Rg2",
              "Kd7",
              "Rgh2",
              "Kc6",
              "Rg2",
              "Kd5",
              "Rgh2",
              "c5",
              "dxc5",
              "bxc5",
              "Rd2+",
              "Kc6",
              "Rdh2",
              "d5",
              "R4h3",
              "Kd6",
              "Rh4",
              "a5",
              "R4h3",
              "a4",
              "Rh4",
              "Rb8",
              "Rd2",
              "a3",
              "b3",
              "Rf8",
              "Rf2",
              "e5",
              "fxe5+",
              "Kxe5",
              "Rxf8",
              "d4+",
              "cxd4+",
              "cxd4+",
              "Rxd4",
              "Re7",
              "Rf6",
              "Bb1",
              "Rd2",
              "Bxa2",
              "Rxa2",
              "Kd5+",
              "Kd3",
              "Kc5",
              "Rxa3",
              "Kb4",
              "Ra4+",
              "Kxb3",
              "Re4",
              "Rd7+",
              "Ke3",
              "Kc3",
              "Rc6+",
              "Kb3",
              "g6",
              "Ka3",
              "g7",
              "Kb3",
              "g8=Q+",
              "Ka3",
              "Ra6+",
              "Kb2",
              "Qa2+",
              "Kc3",
              "Rc4#",
              "Kd3",
              "Qc2#",
              "Kd5",
              "Qe4#",
              "Kd6",
              "Rc6#",
              "Kd7",
              "Qe6#",
              "Kd8",
              "Rc8#",
              "Kxc8",
              "Qxd7+",
              "Kxd7",
              "h7",
              "Ke7",
              "h8=Q",
              "Kf7",
              "Qh7+",
              "Kf8",
              "Rg8#",
              "Kxg8",
              "Qe7",
              "Kh8",
              "Kf4",
              "Kg8",
              "Kg5",
              "Kh8",
              "Kg6",
              "Kg8",
              "Qg7#",
              "Kd8",
              "Qb7",
              "Ke8",
              "Qc7",
              "Kf8",
              "Qd7",
              "Kg8",
              "Qe7",
              "Kh8",
              "Qf8#",
              "Kxh7",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kxh7",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kxh7",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kxh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 322,
            "completion_tokens": 386,
            "total_tokens": 708,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 322,
            "completion_tokens": 221,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 321,
            "completion_tokens": 640,
            "total_tokens": 961,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 965,
          "total_completion_tokens": 1247,
          "total_tokens": 2212
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 322,
            "completion_tokens": 386,
            "total_tokens": 708,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 322,
            "completion_tokens": 221,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 321,
            "completion_tokens": 640,
            "total_tokens": 961,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2k3r/pbp5/1p1pp2P/8/3P2P1/2P5/PP3P2/2KR3R w - - 1 26"
    },
    {
      "turn": 53,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g5",
          "aggressive_uci": "g4g5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8.\nc3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Rf7 32. Ke3 d5 33. c4\nc6 34. b4 a6 35. a4 b5 36. axb5 axb5 37. c5 Ra7 38. Rh2 Ra3+ 39. Kd2 Ra2+ 40.\nKc3 Rxh2 41. Ra1 Rc2+ 42. Kb3 Rc4 43. Ra6 Bc2+ 44. Kb2 Ba4 45. Rxc6 Rxb4+ 46.\nKc3 Rc4+ 47. Kd3 Bc2+ 48. Ke3 Bf5 49. Rb6 b4 50. c6 Rc3+ 51. Kd2 Rd3+ 52. Ke2\nRxd4 53. c7 Rc4 54. Rb7 Rc8 55. Ke3 R8xc7 56. Rb8 Rc3+ 57. Kd4 R7c4+ 58. Ke5\nRe3+ 59. Kd6 Rxf4 60. Rg8+ Kh5 61. Rg7 b3 62. h7 Bxh7 63. Rxh7+ Kxg5 64. Rg7+\nKf6 65. Rb7 Rc4 66. Rb8 Rc2 67. Rf8+ Kg7 68. Rb8 b2 69. Rb7+ Kf6 70. Rb8 Re1\n71. Rf8+ Kg7 72. Rb8 b1=Q 73. Rxb1 Rxb1 74. Kxe6 d4 75. Ke5 d3 76. Ke4 d",
          "aggressive_tokens": {
            "prompt_tokens": 330,
            "completion_tokens": 640,
            "total_tokens": 970,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf7",
            "Rg1",
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Rf7",
            "Ke3",
            "d5",
            "c4",
            "c6",
            "b4",
            "a6",
            "a4",
            "b5",
            "axb5",
            "axb5",
            "c5",
            "Ra7",
            "Rh2",
            "Ra3+",
            "Kd2",
            "Ra2+",
            "Kc3",
            "Rxh2",
            "Ra1",
            "Rc2+",
            "Kb3",
            "Rc4",
            "Ra6",
            "Bc2+",
            "Kb2",
            "Ba4",
            "Rxc6",
            "Rxb4+",
            "Kc3",
            "Rc4+",
            "Kd3",
            "Bc2+",
            "Ke3",
            "Bf5",
            "Rb6",
            "b4",
            "c6",
            "Rc3+",
            "Kd2",
            "Rd3+",
            "Ke2",
            "Rxd4",
            "c7",
            "Rc4",
            "Rb7",
            "Rc8",
            "Ke3",
            "R8xc7",
            "Rb8",
            "Rc3+",
            "Kd4",
            "R7c4+",
            "Ke5",
            "Re3+",
            "Kd6",
            "Rxf4",
            "Rg8+",
            "Kh5",
            "Rg7",
            "b3",
            "h7",
            "Bxh7",
            "Rxh7+",
            "Kxg5",
            "Rg7+",
            "Kf6",
            "Rb7",
            "Rc4",
            "Rb8",
            "Rc2",
            "Rf8+",
            "Kg7",
            "Rb8",
            "b2",
            "Rb7+",
            "Kf6",
            "Rb8",
            "Re1",
            "Rf8+",
            "Kg7",
            "Rb8",
            "b1=Q",
            "Rxb1",
            "Rxb1",
            "Kxe6",
            "d4",
            "Ke5",
            "d3",
            "Ke4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d4d5",
          "positional_response": "27. d5 exd5 28. g5 Kf7 29. f4 Kg6",
          "positional_tokens": {
            "prompt_tokens": 330,
            "completion_tokens": 23,
            "total_tokens": 353,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exd5",
            "g5",
            "Kf7",
            "f4",
            "Kg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g5",
          "neutral_uci": "g4g5",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8.\nc3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3 Rh7 33. Rgh1\nRfh8 34. R1h2 c5 35. dxc5 bxc5 36. Rd2 d5 37. b4 cxb4 38. cxb4 Rc8 39. Rhh2 Rc3+\n40. Kd4 Rc4+ 41. Ke5 Re4+ 42. Kd6 Rxf4 43. Rdg2 Rxb4 44. Rh1 Rb6+ 45. Ke5 Rc6\n46. Rhh2 a5 47. Rg3 a4 48. Rh1 Rc4 49. Rh2 Re4+ 50. Kd6 Rg4 51. Rxg4 Bxg4 52.\nRg2 Kxg5 53. Ke5 Rxh6 54. Rg3 Rh3 55. Rg2 Re3+ 56. Kd4 Re4+ 57. Kd3 Kf4 58.\nRf2+ Bf3 59. Rh2 Kg3 60. Rh8 Kf2 61. Rh2+ Bg2 62. Rh8 Re3+ 63. Kd4 e5+ 64. Kc5\nd4 65. Rf8+ Bf3 66. Kb4 a3 67. Rf7 Ke2 68. Rg7 d3 69. Kxa3 d2+ 70. Kb2 d1=Q\n71. Rg2+ Bxg2 72. a4 Rb3+ 73. Ka2 Qb1#",
          "neutral_tokens": {
            "prompt_tokens": 329,
            "completion_tokens": 618,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf7",
            "Rg1",
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "Rh7",
            "Rgh1",
            "Rfh8",
            "R1h2",
            "c5",
            "dxc5",
            "bxc5",
            "Rd2",
            "d5",
            "b4",
            "cxb4",
            "cxb4",
            "Rc8",
            "Rhh2",
            "Rc3+",
            "Kd4",
            "Rc4+",
            "Ke5",
            "Re4+",
            "Kd6",
            "Rxf4",
            "Rdg2",
            "Rxb4",
            "Rh1",
            "Rb6+",
            "Ke5",
            "Rc6",
            "Rhh2",
            "a5",
            "Rg3",
            "a4",
            "Rh1",
            "Rc4",
            "Rh2",
            "Re4+",
            "Kd6",
            "Rg4",
            "Rxg4",
            "Bxg4",
            "Rg2",
            "Kxg5",
            "Ke5",
            "Rxh6",
            "Rg3",
            "Rh3",
            "Rg2",
            "Re3+",
            "Kd4",
            "Re4+",
            "Kd3",
            "Kf4",
            "Rf2+",
            "Bf3",
            "Rh2",
            "Kg3",
            "Rh8",
            "Kf2",
            "Rh2+",
            "Bg2",
            "Rh8",
            "Re3+",
            "Kd4",
            "e5+",
            "Kc5",
            "d4",
            "Rf8+",
            "Bf3",
            "Kb4",
            "a3",
            "Rf7",
            "Ke2",
            "Rg7",
            "d3",
            "Kxa3",
            "d2+",
            "Kb2",
            "d1=Q",
            "Rg2+",
            "Bxg2",
            "a4",
            "Rb3+",
            "Ka2",
            "Qb1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4g5",
          "positional_uci": "d4d5",
          "neutral_uci": "g4g5",
          "consensus_move": "g4g5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf7",
              "Rg1",
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Rf7",
              "Ke3",
              "d5",
              "c4",
              "c6",
              "b4",
              "a6",
              "a4",
              "b5",
              "axb5",
              "axb5",
              "c5",
              "Ra7",
              "Rh2",
              "Ra3+",
              "Kd2",
              "Ra2+",
              "Kc3",
              "Rxh2",
              "Ra1",
              "Rc2+",
              "Kb3",
              "Rc4",
              "Ra6",
              "Bc2+",
              "Kb2",
              "Ba4",
              "Rxc6",
              "Rxb4+",
              "Kc3",
              "Rc4+",
              "Kd3",
              "Bc2+",
              "Ke3",
              "Bf5",
              "Rb6",
              "b4",
              "c6",
              "Rc3+",
              "Kd2",
              "Rd3+",
              "Ke2",
              "Rxd4",
              "c7",
              "Rc4",
              "Rb7",
              "Rc8",
              "Ke3",
              "R8xc7",
              "Rb8",
              "Rc3+",
              "Kd4",
              "R7c4+",
              "Ke5",
              "Re3+",
              "Kd6",
              "Rxf4",
              "Rg8+",
              "Kh5",
              "Rg7",
              "b3",
              "h7",
              "Bxh7",
              "Rxh7+",
              "Kxg5",
              "Rg7+",
              "Kf6",
              "Rb7",
              "Rc4",
              "Rb8",
              "Rc2",
              "Rf8+",
              "Kg7",
              "Rb8",
              "b2",
              "Rb7+",
              "Kf6",
              "Rb8",
              "Re1",
              "Rf8+",
              "Kg7",
              "Rb8",
              "b1=Q",
              "Rxb1",
              "Rxb1",
              "Kxe6",
              "d4",
              "Ke5",
              "d3",
              "Ke4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "exd5",
              "g5",
              "Kf7",
              "f4",
              "Kg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf7",
              "Rg1",
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "Rh7",
              "Rgh1",
              "Rfh8",
              "R1h2",
              "c5",
              "dxc5",
              "bxc5",
              "Rd2",
              "d5",
              "b4",
              "cxb4",
              "cxb4",
              "Rc8",
              "Rhh2",
              "Rc3+",
              "Kd4",
              "Rc4+",
              "Ke5",
              "Re4+",
              "Kd6",
              "Rxf4",
              "Rdg2",
              "Rxb4",
              "Rh1",
              "Rb6+",
              "Ke5",
              "Rc6",
              "Rhh2",
              "a5",
              "Rg3",
              "a4",
              "Rh1",
              "Rc4",
              "Rh2",
              "Re4+",
              "Kd6",
              "Rg4",
              "Rxg4",
              "Bxg4",
              "Rg2",
              "Kxg5",
              "Ke5",
              "Rxh6",
              "Rg3",
              "Rh3",
              "Rg2",
              "Re3+",
              "Kd4",
              "Re4+",
              "Kd3",
              "Kf4",
              "Rf2+",
              "Bf3",
              "Rh2",
              "Kg3",
              "Rh8",
              "Kf2",
              "Rh2+",
              "Bg2",
              "Rh8",
              "Re3+",
              "Kd4",
              "e5+",
              "Kc5",
              "d4",
              "Rf8+",
              "Bf3",
              "Kb4",
              "a3",
              "Rf7",
              "Ke2",
              "Rg7",
              "d3",
              "Kxa3",
              "d2+",
              "Kb2",
              "d1=Q",
              "Rg2+",
              "Bxg2",
              "a4",
              "Rb3+",
              "Ka2",
              "Qb1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 330,
            "completion_tokens": 640,
            "total_tokens": 970,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 330,
            "completion_tokens": 23,
            "total_tokens": 353,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 329,
            "completion_tokens": 618,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 989,
          "total_completion_tokens": 1281,
          "total_tokens": 2270
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 330,
            "completion_tokens": 640,
            "total_tokens": 970,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 330,
            "completion_tokens": 23,
            "total_tokens": 353,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 329,
            "completion_tokens": 618,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3k2r/pbp5/1p1pp2P/7R/3P2P1/2P5/PP3P2/2KR4 w - - 3 27"
    },
    {
      "turn": 55,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "f4",
          "aggressive_uci": "f2f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. f4 Kg6 29. Rh4 Raf8 30. Re1 Bc8 31. Kd2 Rf5 32. Ke3 e5 33. dxe5\ndxe5 34. Rd1 exf4+ 35. Rxf4 Re8+ 36. Re4 Rxe4+ 37. Kxe4 Rxg5 38. Rd8 Bf5+ 39.\nKf4 Rg4+ 40. Ke5 Re4+ 41. Kd5 Kxh6 42. Rf8 Bg6 43. Rf6 Re2 44. b4 Rxa2 45.\nKc6 Rc2 46. Kxc7 Rxc3+ 47. Kb7 Ra3 48. b5 Kg5 49. Rd6 Be4+ 50. Kb8 Kf5 51. Rd7\nRa5 52. Rxa7 Rxa7 53. Kxa7 Ke5 54. Kxb6 Kd6 55. Ka7 Kc7 56. b6+ Kc8 57. Ka6 Kb8\n58. Kb5 Kb7 59. Kc5 Bc6 60. Kd6 Kxb6 61. Ke5 Kc5 62. Kf4 Kd4 63. Kg3 Ke3 64.\nKh2 Kf2 65. Kh3 Bd7+ 66. Kh2 Be6 67. Kh1 Kg3 68. Kg1 Bc4 69. Kh1 Kf2 70. Kh2\nBe6 71. Kh1 Kg3 72. Kg1 Bc4 73. Kh1 Kf2 74. Kh2 Be6 75. Kh1 Kg3 76. Kg1 Bc4 77.\nKh1 Kf2 78. Kh",
          "aggressive_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg6",
            "Rh4",
            "Raf8",
            "Re1",
            "Bc8",
            "Kd2",
            "Rf5",
            "Ke3",
            "e5",
            "dxe5",
            "dxe5",
            "Rd1",
            "exf4+",
            "Rxf4",
            "Re8+",
            "Re4",
            "Rxe4+",
            "Kxe4",
            "Rxg5",
            "Rd8",
            "Bf5+",
            "Kf4",
            "Rg4+",
            "Ke5",
            "Re4+",
            "Kd5",
            "Kxh6",
            "Rf8",
            "Bg6",
            "Rf6",
            "Re2",
            "b4",
            "Rxa2",
            "Kc6",
            "Rc2",
            "Kxc7",
            "Rxc3+",
            "Kb7",
            "Ra3",
            "b5",
            "Kg5",
            "Rd6",
            "Be4+",
            "Kb8",
            "Kf5",
            "Rd7",
            "Ra5",
            "Rxa7",
            "Rxa7",
            "Kxa7",
            "Ke5",
            "Kxb6",
            "Kd6",
            "Ka7",
            "Kc7",
            "b6+",
            "Kc8",
            "Ka6",
            "Kb8",
            "Kb5",
            "Kb7",
            "Kc5",
            "Bc6",
            "Kd6",
            "Kxb6",
            "Ke5",
            "Kc5",
            "Kf4",
            "Kd4",
            "Kg3",
            "Ke3",
            "Kh2",
            "Kf2",
            "Kh3",
            "Bd7+",
            "Kh2",
            "Be6",
            "Kh1",
            "Kg3",
            "Kg1",
            "Bc4",
            "Kh1",
            "Kf2",
            "Kh2",
            "Be6",
            "Kh1",
            "Kg3",
            "Kg1",
            "Bc4",
            "Kh1",
            "Kf2",
            "Kh2",
            "Be6",
            "Kh1",
            "Kg3",
            "Kg1",
            "Bc4",
            "Kh1",
            "Kf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rg1",
          "positional_uci": "d1g1",
          "positional_response": "28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3 c5 33. Rd1 c4 34. d5\ne5 35. fxe5 dxe5 36. Rxc4 Kxg5 37. Rc7 Rxh6 38. Rxa7 Rh3+ 39. Kd2 Rh2+ 40. Ke3\nRfh8 41. Rg1+ Kf6 42. Rg3 Rxb2 43. d6 Rhh2 44. d7 Rhe2+ 45. Kf3 Rf2+ 46. Ke3\nRbe2# d4 e5 dxe5",
          "positional_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 169,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf6",
            "Rg3",
            "Rxb2",
            "d6",
            "Rhh2",
            "d7",
            "Rhe2+",
            "Kf3",
            "Rf2+",
            "Ke3",
            "Rbe2#",
            "d4",
            "e5",
            "dxe5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rg1",
          "neutral_uci": "d1g1",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3 c5 33. Rd1\nd5 34. Rd2 c4 35. b3 b5 36. b4 a5 37. a3 axb4 38. axb4 Ra8 39. Rhh2 Ra3 40. Ra2\nRxc3+ 41. Kd2 Rd3+ 42. Ke2 Rxd4 43. Ra7 Rh7 44. Ra8 Rxf4 45. Rg8+ Kf7 46. Rb8\nKg6 47. Rg8+ Kf7 48. Rb8 Re4+ 49. Kf3 Kg6 50. Rg8+ Kf7 51. Rb8 Kg6 52. Rg8+\nKf7 53. Rb8 Kg6 54. Rg8+ Kf7 55. Rb8 Kg6 56. Rg8+ Kf7 57. Rb8 Kg6 58. Rg8+\nKf7 59. Rb8 Kg6 60. Rg8+ Kf7 61. Rb8 Kg6 62. Rg8+ Kf7 63. Rb8 Kg6 64. Rg8+\nKf7 65. Rb8 Kg6 66. Rg8+ Kf7 67. Rb8 Kg6 68. Rg8+ Kf7 69. Rb8 Kg6 70. Rg8+\nKf7 71. Rb8 Kg6 72. Rg8+ Kf7 73. Rb8 Kg6 74. Rg8+ Kf7 75. Rb8",
          "neutral_tokens": {
            "prompt_tokens": 336,
            "completion_tokens": 640,
            "total_tokens": 976,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "c5",
            "Rd1",
            "d5",
            "Rd2",
            "c4",
            "b3",
            "b5",
            "b4",
            "a5",
            "a3",
            "axb4",
            "axb4",
            "Ra8",
            "Rhh2",
            "Ra3",
            "Ra2",
            "Rxc3+",
            "Kd2",
            "Rd3+",
            "Ke2",
            "Rxd4",
            "Ra7",
            "Rh7",
            "Ra8",
            "Rxf4",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Re4+",
            "Kf3",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f2f4",
          "positional_uci": "d1g1",
          "neutral_uci": "d1g1",
          "consensus_move": "d1g1",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg6",
              "Rh4",
              "Raf8",
              "Re1",
              "Bc8",
              "Kd2",
              "Rf5",
              "Ke3",
              "e5",
              "dxe5",
              "dxe5",
              "Rd1",
              "exf4+",
              "Rxf4",
              "Re8+",
              "Re4",
              "Rxe4+",
              "Kxe4",
              "Rxg5",
              "Rd8",
              "Bf5+",
              "Kf4",
              "Rg4+",
              "Ke5",
              "Re4+",
              "Kd5",
              "Kxh6",
              "Rf8",
              "Bg6",
              "Rf6",
              "Re2",
              "b4",
              "Rxa2",
              "Kc6",
              "Rc2",
              "Kxc7",
              "Rxc3+",
              "Kb7",
              "Ra3",
              "b5",
              "Kg5",
              "Rd6",
              "Be4+",
              "Kb8",
              "Kf5",
              "Rd7",
              "Ra5",
              "Rxa7",
              "Rxa7",
              "Kxa7",
              "Ke5",
              "Kxb6",
              "Kd6",
              "Ka7",
              "Kc7",
              "b6+",
              "Kc8",
              "Ka6",
              "Kb8",
              "Kb5",
              "Kb7",
              "Kc5",
              "Bc6",
              "Kd6",
              "Kxb6",
              "Ke5",
              "Kc5",
              "Kf4",
              "Kd4",
              "Kg3",
              "Ke3",
              "Kh2",
              "Kf2",
              "Kh3",
              "Bd7+",
              "Kh2",
              "Be6",
              "Kh1",
              "Kg3",
              "Kg1",
              "Bc4",
              "Kh1",
              "Kf2",
              "Kh2",
              "Be6",
              "Kh1",
              "Kg3",
              "Kg1",
              "Bc4",
              "Kh1",
              "Kf2",
              "Kh2",
              "Be6",
              "Kh1",
              "Kg3",
              "Kg1",
              "Bc4",
              "Kh1",
              "Kf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf6",
              "Rg3",
              "Rxb2",
              "d6",
              "Rhh2",
              "d7",
              "Rhe2+",
              "Kf3",
              "Rf2+",
              "Ke3",
              "Rbe2#",
              "d4",
              "e5",
              "dxe5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "c5",
              "Rd1",
              "d5",
              "Rd2",
              "c4",
              "b3",
              "b5",
              "b4",
              "a5",
              "a3",
              "axb4",
              "axb4",
              "Ra8",
              "Rhh2",
              "Ra3",
              "Ra2",
              "Rxc3+",
              "Kd2",
              "Rd3+",
              "Ke2",
              "Rxd4",
              "Ra7",
              "Rh7",
              "Ra8",
              "Rxf4",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Re4+",
              "Kf3",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 337,
            "completion_tokens": 169,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 336,
            "completion_tokens": 640,
            "total_tokens": 976,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1010,
          "total_completion_tokens": 1449,
          "total_tokens": 2459
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 337,
            "completion_tokens": 169,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 336,
            "completion_tokens": 640,
            "total_tokens": 976,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r6r/pbp2k2/1p1pp2P/6PR/3P4/2P5/PP3P2/2KR4 w - - 1 28"
    },
    {
      "turn": 57,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh4",
          "aggressive_uci": "h5h4",
          "aggressive_response": "29. Rh4 Kg6 30. Rf4 Rf8 31. Rxf8 Rxf8 32. Kd2 Rxf2+ 33. Ke3 Rf3+ 34. Ke2 Rf8 35. Ke3 Bd5 36. b3 b5 37. Rg3 a5 38. Kd3 a4 39. c4 bxc4+ 40. bxc4 Bc6 41. Kc3 Rf3+ 42. Rxf3 Bxf3 43. Kb4 Bd1 44. Kb5 e5 45. dxe5 dxe5 46. Kc6 e4 47. Kxc7 e3 48. c5 e2 49. c6 e1=Q 50. Kb8 Qb4+ 51. Kc8 Bg4+ 52. Kd8 Qd6+ 53. Ke8 Qxc6+ 54. Kf8 Qd7 55. Kg8 Qe8# e4 e5 e6",
          "aggressive_tokens": {
            "prompt_tokens": 345,
            "completion_tokens": 236,
            "total_tokens": 581,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg6",
            "Rf4",
            "Rf8",
            "Rxf8",
            "Rxf8",
            "Kd2",
            "Rxf2+",
            "Ke3",
            "Rf3+",
            "Ke2",
            "Rf8",
            "Ke3",
            "Bd5",
            "b3",
            "b5",
            "Rg3",
            "a5",
            "Kd3",
            "a4",
            "c4",
            "bxc4+",
            "bxc4",
            "Bc6",
            "Kc3",
            "Rf3+",
            "Rxf3",
            "Bxf3",
            "Kb4",
            "Bd1",
            "Kb5",
            "e5",
            "dxe5",
            "dxe5",
            "Kc6",
            "e4",
            "Kxc7",
            "e3",
            "c5",
            "e2",
            "c6",
            "e1=Q",
            "Kb8",
            "Qb4+",
            "Kc8",
            "Bg4+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qxc6+",
            "Kf8",
            "Qd7",
            "Kg8",
            "Qe8#",
            "e4",
            "e5",
            "e6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g6+",
          "positional_uci": "g5g6",
          "positional_response": "29. g6+ Rxg6 30. Rxg6 Kxg6 31. Rh3 Rxh6 32. Rg3+ Kf7 33. Kd2 Rf6 34. Ke3 e5 35. dxe5 dxe5 36. Rh3 Ke6 37. Rh7 Rf7 38. Rh6+ Kd5 39. b3 Kc5 40. Rh5 Rf3+ 41. Ke2 Rxc3 42. Rxe5+ Kd6 43. Rh5 Rc2+ 44. Ke3 Rxa2 45. f4 Ra3 46. Rh6+ Kc5 47. Rh5+ Kb4 48. f5 Rxb3+ 49. Kd4 c5+ 50. Ke5 Re3+ 51. Kd6 Rf3 52. Kc7 Be4 53. Kb8 a5 54. Ka7 b5 55. Kb6 a4 56. Rh4 Rxf5 57. Rxe4+ c4 58. Re1 a3 59. Rb1+ Ka4 60. Ra1 b4 61. Rc1 c3 62. Rh1 a2 63. Rh8 Kb3 64. Ra8 c2 65. Rc8 a1=Q 66. Rc7 Qa5+ 67. Kb7 Qxc7+ 68. Kxc7 c1=Q+ 69. Kb6 Qc5+ 70. Kb7 Rf7+ 71. Kb8 Qf8#",
          "positional_tokens": {
            "prompt_tokens": 345,
            "completion_tokens": 358,
            "total_tokens": 703,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxg6",
            "Rxg6",
            "Kxg6",
            "Rh3",
            "Rxh6",
            "Rg3+",
            "Kf7",
            "Kd2",
            "Rf6",
            "Ke3",
            "e5",
            "dxe5",
            "dxe5",
            "Rh3",
            "Ke6",
            "Rh7",
            "Rf7",
            "Rh6+",
            "Kd5",
            "b3",
            "Kc5",
            "Rh5",
            "Rf3+",
            "Ke2",
            "Rxc3",
            "Rxe5+",
            "Kd6",
            "Rh5",
            "Rc2+",
            "Ke3",
            "Rxa2",
            "f4",
            "Ra3",
            "Rh6+",
            "Kc5",
            "Rh5+",
            "Kb4",
            "f5",
            "Rxb3+",
            "Kd4",
            "c5+",
            "Ke5",
            "Re3+",
            "Kd6",
            "Rf3",
            "Kc7",
            "Be4",
            "Kb8",
            "a5",
            "Ka7",
            "b5",
            "Kb6",
            "a4",
            "Rh4",
            "Rxf5",
            "Rxe4+",
            "c4",
            "Re1",
            "a3",
            "Rb1+",
            "Ka4",
            "Ra1",
            "b4",
            "Rc1",
            "c3",
            "Rh1",
            "a2",
            "Rh8",
            "Kb3",
            "Ra8",
            "c2",
            "Rc8",
            "a1=Q",
            "Rc7",
            "Qa5+",
            "Kb7",
            "Qxc7+",
            "Kxc7",
            "c1=Q+",
            "Kb6",
            "Qc5+",
            "Kb7",
            "Rf7+",
            "Kb8",
            "Qf8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rh4",
          "neutral_uci": "h5h4",
          "neutral_response": "29. Rh4 Kg6 30. Rf4 Rf8 31. Rxf8 Rxf8 32. Kd2 Rxf2+ 33. Ke3 Rf3+ 34. Ke2 Rf8 35. Ke3 Bd5 36. b3 b5 37. Rg3 a5 38. Kd3 a4 39. c4 bxc4+ 40. bxc4 Bc6 41. Kc3 Rf3+ 42. Rxf3 Bxf3 43. Kb4 Bc6 44. Ka5 e5 45. dxe5 dxe5 46. Kb4 e4 47. Kc3 Bd7 48. Kd4 Bf5 49. Ke3 c5 50. Kf4 a3 51. Ke3 Kxg5 52. h7 Bxh7 53. Kd2 Kf4 54. Kc3 e3 55. Kb3 e2 56. Kxa3 e1=Q 57. Kb3 Qb4# e4 e5 e6",
          "neutral_tokens": {
            "prompt_tokens": 344,
            "completion_tokens": 249,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg6",
            "Rf4",
            "Rf8",
            "Rxf8",
            "Rxf8",
            "Kd2",
            "Rxf2+",
            "Ke3",
            "Rf3+",
            "Ke2",
            "Rf8",
            "Ke3",
            "Bd5",
            "b3",
            "b5",
            "Rg3",
            "a5",
            "Kd3",
            "a4",
            "c4",
            "bxc4+",
            "bxc4",
            "Bc6",
            "Kc3",
            "Rf3+",
            "Rxf3",
            "Bxf3",
            "Kb4",
            "Bc6",
            "Ka5",
            "e5",
            "dxe5",
            "dxe5",
            "Kb4",
            "e4",
            "Kc3",
            "Bd7",
            "Kd4",
            "Bf5",
            "Ke3",
            "c5",
            "Kf4",
            "a3",
            "Ke3",
            "Kxg5",
            "h7",
            "Bxh7",
            "Kd2",
            "Kf4",
            "Kc3",
            "e3",
            "Kb3",
            "e2",
            "Kxa3",
            "e1=Q",
            "Kb3",
            "Qb4#",
            "e4",
            "e5",
            "e6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h5h4",
          "positional_uci": "g5g6",
          "neutral_uci": "h5h4",
          "consensus_move": "h5h4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg6",
              "Rf4",
              "Rf8",
              "Rxf8",
              "Rxf8",
              "Kd2",
              "Rxf2+",
              "Ke3",
              "Rf3+",
              "Ke2",
              "Rf8",
              "Ke3",
              "Bd5",
              "b3",
              "b5",
              "Rg3",
              "a5",
              "Kd3",
              "a4",
              "c4",
              "bxc4+",
              "bxc4",
              "Bc6",
              "Kc3",
              "Rf3+",
              "Rxf3",
              "Bxf3",
              "Kb4",
              "Bd1",
              "Kb5",
              "e5",
              "dxe5",
              "dxe5",
              "Kc6",
              "e4",
              "Kxc7",
              "e3",
              "c5",
              "e2",
              "c6",
              "e1=Q",
              "Kb8",
              "Qb4+",
              "Kc8",
              "Bg4+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qxc6+",
              "Kf8",
              "Qd7",
              "Kg8",
              "Qe8#",
              "e4",
              "e5",
              "e6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxg6",
              "Rxg6",
              "Kxg6",
              "Rh3",
              "Rxh6",
              "Rg3+",
              "Kf7",
              "Kd2",
              "Rf6",
              "Ke3",
              "e5",
              "dxe5",
              "dxe5",
              "Rh3",
              "Ke6",
              "Rh7",
              "Rf7",
              "Rh6+",
              "Kd5",
              "b3",
              "Kc5",
              "Rh5",
              "Rf3+",
              "Ke2",
              "Rxc3",
              "Rxe5+",
              "Kd6",
              "Rh5",
              "Rc2+",
              "Ke3",
              "Rxa2",
              "f4",
              "Ra3",
              "Rh6+",
              "Kc5",
              "Rh5+",
              "Kb4",
              "f5",
              "Rxb3+",
              "Kd4",
              "c5+",
              "Ke5",
              "Re3+",
              "Kd6",
              "Rf3",
              "Kc7",
              "Be4",
              "Kb8",
              "a5",
              "Ka7",
              "b5",
              "Kb6",
              "a4",
              "Rh4",
              "Rxf5",
              "Rxe4+",
              "c4",
              "Re1",
              "a3",
              "Rb1+",
              "Ka4",
              "Ra1",
              "b4",
              "Rc1",
              "c3",
              "Rh1",
              "a2",
              "Rh8",
              "Kb3",
              "Ra8",
              "c2",
              "Rc8",
              "a1=Q",
              "Rc7",
              "Qa5+",
              "Kb7",
              "Qxc7+",
              "Kxc7",
              "c1=Q+",
              "Kb6",
              "Qc5+",
              "Kb7",
              "Rf7+",
              "Kb8",
              "Qf8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg6",
              "Rf4",
              "Rf8",
              "Rxf8",
              "Rxf8",
              "Kd2",
              "Rxf2+",
              "Ke3",
              "Rf3+",
              "Ke2",
              "Rf8",
              "Ke3",
              "Bd5",
              "b3",
              "b5",
              "Rg3",
              "a5",
              "Kd3",
              "a4",
              "c4",
              "bxc4+",
              "bxc4",
              "Bc6",
              "Kc3",
              "Rf3+",
              "Rxf3",
              "Bxf3",
              "Kb4",
              "Bc6",
              "Ka5",
              "e5",
              "dxe5",
              "dxe5",
              "Kb4",
              "e4",
              "Kc3",
              "Bd7",
              "Kd4",
              "Bf5",
              "Ke3",
              "c5",
              "Kf4",
              "a3",
              "Ke3",
              "Kxg5",
              "h7",
              "Bxh7",
              "Kd2",
              "Kf4",
              "Kc3",
              "e3",
              "Kb3",
              "e2",
              "Kxa3",
              "e1=Q",
              "Kb3",
              "Qb4#",
              "e4",
              "e5",
              "e6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 345,
            "completion_tokens": 236,
            "total_tokens": 581,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 345,
            "completion_tokens": 358,
            "total_tokens": 703,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 344,
            "completion_tokens": 249,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1034,
          "total_completion_tokens": 843,
          "total_tokens": 1877
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 345,
            "completion_tokens": 236,
            "total_tokens": 581,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 345,
            "completion_tokens": 358,
            "total_tokens": 703,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 344,
            "completion_tokens": 249,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6rr/pbp2k2/1p1pp2P/6PR/3P4/2P5/PP3P2/2K3R1 w - - 3 29"
    },
    {
      "turn": 59,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf4+",
          "aggressive_uci": "h4f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Kg6 31. Rf6+ Kh5 32. f4 Be4 33. Rxe6 Bf5 34. Rf6 Rf8 35. Rxf8 Rxf8 36. Kd2 Bg6 37. Ke3 Re8+ 38. Kf3 Be4+ 39. Kg3 Kg6 40. Re1 d5 41. c4 c6 42. cxd5 cxd5 43. Rc1 Re6 44. Rc7 Bf5 45. Rg7+ Kh5 46. h7 Re8 47. Rg8 Re3+ 48. Kf2 Bxh7 49. Rh8 Re7 50. Kg3 Kg6 51. Kg4 Kg7 52. Rb8 Re6 53. f5 Re4+ 54. Kh5 Bxf5 55. Rb7+ Kf8 56. g6 Rxd4 57. g7+ Kg8 58. Kg5 Be6 59. Kf6 Re4 60. Rb8+ Kh7 61. Rh8# Bg8 62. Rh5# Bf7 63. Kxf7 Rf4+ 64. Ke6 Kg6 65. g8=Q+ Kxh5 66. h7 Re4+ 67. Kxd5 Rg4 68. h8=Q# Kg3 69. Qe5+ Kf3 70. Qf7+ Kg2 71. Qe2+ Kh3 72. Qh5+ Kg3 73. Qhxg4# Kg1 74. Qgxg2# Bxg2 75. Qxg2# Kxg",
          "aggressive_tokens": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke6",
            "Kg6",
            "g8=Q+",
            "Kxh5",
            "h7",
            "Re4+",
            "Kxd5",
            "Rg4",
            "h8=Q#",
            "Kg3",
            "Qe5+",
            "Kf3",
            "Qf7+",
            "Kg2",
            "Qe2+",
            "Kh3",
            "Qh5+",
            "Kg3",
            "Qhxg4#",
            "Kg1",
            "Qgxg2#",
            "Bxg2",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 31. Rf4+ Kg8 32. Rf6 Rh7 33. f4 Be4 34.\nKd2 Bf5 35. Ke3 Rf8 36. Rxf8+ Kxf8 37. Kf3 Kf7 38. Kg3 Kg6 39. Kh4 Re7 40. Re1\nc5 41. dxc5 bxc5 42. Rd1 d5 43. b4 cxb4 44. cxb4 Rc7 45. Rd4 Rc3 46. a4 Rh3#\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 * Re8 31. Rf4+ Kg8 32. Rf6 Rh7 33. f4 Be4 34.\nKd2 Bf5 35. Ke3 Rf8 36. Rxf8+ Kxf8 37. Kf3 Kf7 38. Kg3 Kg6 39. Kh4 Re7 40. Re1\nc5 41. dxc5 bxc5 42. Rd1 d5 43. b4 cxb4 44. cxb4 Rc7 45. Rd4 Rc3 46. a4 Rh3# 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17",
          "positional_tokens": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": null,
          "neutral_response": "a6 b3 c4",
          "neutral_tokens": {
            "prompt_tokens": 351,
            "completion_tokens": 6,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4f4",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "h4f4",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ke6",
              "Kg6",
              "g8=Q+",
              "Kxh5",
              "h7",
              "Re4+",
              "Kxd5",
              "Rg4",
              "h8=Q#",
              "Kg3",
              "Qe5+",
              "Kf3",
              "Qf7+",
              "Kg2",
              "Qe2+",
              "Kh3",
              "Qh5+",
              "Kg3",
              "Qhxg4#",
              "Kg1",
              "Qgxg2#",
              "Bxg2",
              "Qxg2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "b3",
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 351,
            "completion_tokens": 6,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1055,
          "total_completion_tokens": 1286,
          "total_tokens": 2341
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 351,
            "completion_tokens": 6,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6rr/1bp2k2/pp1pp2P/6P1/3P3R/2P5/PP3P2/2K3R1 w - - 0 30"
    },
    {
      "turn": 61,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8",
          "aggressive_uci": null,
          "aggressive_response": "Re8 Rg6 Rg7",
          "aggressive_tokens": {
            "prompt_tokens": 361,
            "completion_tokens": 8,
            "total_tokens": 369,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg6",
            "Rg7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf6",
          "positional_uci": "f4f6",
          "positional_response": "31. Rf6 Bd5 32. b3 b5 33. Kd2 Ke7 34. Ke3 a5 35. f4 a4 36. bxa4 bxa4 37. a3\nBb3 38. Kd3 Ba2 39. c4 Bb3 40. Kc3 Ba2 41. Re1 Kd7 42. Rexe6 Bb1 43. d5\nBh7 44. Rf7+ Kc8 45. Ree7 Bb1 46. Rxc7+ Kb8 47. Rb7+ Ka8 48. Rxb1 Rb8 49.\nRxb8+ Kxb8 50. h7 Kc8 51. g6 Kd8 52. g7 Ke8 53. Ra7 Rxh7 54. g8=Q#",
          "positional_tokens": {
            "prompt_tokens": 361,
            "completion_tokens": 199,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd5",
            "b3",
            "b5",
            "Kd2",
            "Ke7",
            "Ke3",
            "a5",
            "f4",
            "a4",
            "bxa4",
            "bxa4",
            "a3",
            "Bb3",
            "Kd3",
            "Ba2",
            "c4",
            "Bb3",
            "Kc3",
            "Ba2",
            "Re1",
            "Kd7",
            "Rexe6",
            "Bb1",
            "d5",
            "Bh7",
            "Rf7+",
            "Kc8",
            "Ree7",
            "Bb1",
            "Rxc7+",
            "Kb8",
            "Rb7+",
            "Ka8",
            "Rxb1",
            "Rb8",
            "Rxb8+",
            "Kxb8",
            "h7",
            "Kc8",
            "g6",
            "Kd8",
            "g7",
            "Ke8",
            "Ra7",
            "Rxh7",
            "g8=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg6 Rg7",
          "neutral_tokens": {
            "prompt_tokens": 360,
            "completion_tokens": 8,
            "total_tokens": 368,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg6",
            "Rg7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "f4f6",
          "neutral_uci": null,
          "consensus_move": "f4f6",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg6",
              "Rg7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd5",
              "b3",
              "b5",
              "Kd2",
              "Ke7",
              "Ke3",
              "a5",
              "f4",
              "a4",
              "bxa4",
              "bxa4",
              "a3",
              "Bb3",
              "Kd3",
              "Ba2",
              "c4",
              "Bb3",
              "Kc3",
              "Ba2",
              "Re1",
              "Kd7",
              "Rexe6",
              "Bb1",
              "d5",
              "Bh7",
              "Rf7+",
              "Kc8",
              "Ree7",
              "Bb1",
              "Rxc7+",
              "Kb8",
              "Rb7+",
              "Ka8",
              "Rxb1",
              "Rb8",
              "Rxb8+",
              "Kxb8",
              "h7",
              "Kc8",
              "g6",
              "Kd8",
              "g7",
              "Ke8",
              "Ra7",
              "Rxh7",
              "g8=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg6",
              "Rg7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 361,
            "completion_tokens": 8,
            "total_tokens": 369,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 361,
            "completion_tokens": 199,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 360,
            "completion_tokens": 8,
            "total_tokens": 368,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1082,
          "total_completion_tokens": 215,
          "total_tokens": 1297
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 361,
            "completion_tokens": 8,
            "total_tokens": 369,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 361,
            "completion_tokens": 199,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 360,
            "completion_tokens": 8,
            "total_tokens": 368,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4k1rr/1bp5/pp1pp2P/6P1/3P1R2/2P5/PP3P2/2K3R1 w - - 2 31"
    },
    {
      "turn": 63,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 f4 e5 dxe5 dxe5 fxe5 Bxe5 Bxe5 Qxe5 Qxe5 Rxe5 Rxe5 Rxe5 Re8 Rxe8 Kxe8 Kd2 Kf7 Ke3 Kg6 Kf4 c5 dxc5 bxc5 b4 cxb4 cxb4 Kxh6 a4 Kg5 a5 Kf6 a6 Ke7 a7 Kd7 a8=Q Kc7 Qa6 Kd7 Qb6 Ke7 Qc6 Kf7 Qd6 Kg7 Qe6 Kh7 Qf6 Kg8 Qe7 Kh8 Kg6 Kg8 Qg7# 1-0\n\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 * e4 d5 f4 e5 dxe5 dxe5 fxe5 Bxe5 Bxe5 Qxe5 Qxe5 Rxe5 Rxe5 Rxe5 Re8 Rxe8 Kxe8 Kd2 Kf7 Ke3 Kg6 Kf4 c5 dxc5 bxc5 b4 cxb4 cxb4 Kxh6 a4 Kg5 a5 Kf6 a6 Ke7 a7 Kd7 Qa6 Kc7 Qb6+ Kd7 Qc6+ Ke7 Qd6+ Kf7 Qe6+ Kg7 Qf6+ Kh7 Qg6+ Kh8 Qg7# 1-0 e4 d5 f4 e5 dxe5 dxe5 fxe5 Bxe5 Bxe5 Qxe5 Qxe5 Rxe5 Re8 Rxe8 Kxe8 Kd2 Kf7 Ke3 Kg6 Kf4 c5 dxc5 bxc5 b4 cxb4 cxb4 Kxh6 a4 Kg5",
          "aggressive_tokens": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "f4",
            "e5",
            "dxe5",
            "dxe5",
            "fxe5",
            "Bxe5",
            "Bxe5",
            "Qxe5",
            "Qxe5",
            "Rxe5",
            "Re8",
            "Rxe8",
            "Kxe8",
            "Kd2",
            "Kf7",
            "Ke3",
            "Kg6",
            "Kf4",
            "c5",
            "dxc5",
            "bxc5",
            "b4",
            "cxb4",
            "cxb4",
            "Kxh6",
            "a4",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "g1e1",
          "positional_response": "32. Re1 Bd5 33. f4 Rf8 34. Rxf8 Kxf8 35. b3 b5 36. Kd2 Kf7 37. Ke3 Kg6 38. Kf2\nKf5 39. Kg3 Be4 40. Re2 d5 41. Rh2 Kg6 42. Kg4 Bf5+ 43. Kg3 Rh7 44. Re2 c6 45.\nRe1 a5 46. Re2 Ra7 47. Rh2 Kh7 48. Kh4 a4 49. b4 a3 50. Kh5 Bg6+ 51. Kg4 Rf7 52.\nRe2 Bf5+ 53. Kh5 Bg6+ 54. Kg4 Re7 55. Re5 Bf5+ 56. Kh5 Bg6+ 57. Kg4 Bf5+ 58.\nKh5 Bg6+ 59. Kg4 Bf5+ 60. Kh5 Bg6+ 61. Kg4 Bf5+ 62. Kh5 Bg6+ 63. Kg4 Bf5+ 64.\nKh5 Bg6+ 65. Kg4 Bf5+ 66. Kh5 Bg6+ 67. Kg4 Bf5+ 68. Kh5 Bg6+ 69. Kg4 Bf5+ 70.\nKh5 Bg6+ 71. Kg4 Bf5+ 72. Kh5 Bg6+ 73. Kg4 Bf5+ 74. Kh5 Bg6+ 75. Kg4 Bf5+ 76.\nKh5 Bg6+ 77. Kg4 Bf5+ 78. Kh5 Bg6+ 79. Kg4 Bf5+ 80. Kh5 Bg6+ 81. Kg4 Bf5+ 82.\nKh5 Bg6+ 83. Kg4 Bf5+ 84. Kh5 Bg6+ 85. Kg4 Bf5+ 86. Kh5 Bg6+ 87. Kg4 Bf5+ 88.\nKh5 Bg6+ 89. Kg4 Bf5+ 90. Kh5 Bg6+ 91. Kg4 Bf5+ 92. Kh5 Bg6+ 93. Kg4 Bf5+ 94.\nKh5 Bg6+ 95. Kg4 Bf5+ 96. Kh5 Bg6+ 97. Kg4 Bf5+ 98. Kh5 Bg6+ 99. Kg4 Bf5+ 100.\nKh5 Bg6+ 101. Kg4 Bf5+ 102. Kh5 Bg6+ 103. Kg4 Bf5+ 104. Kh5 Bg6+ 105. Kg4 Bf5+ 106.",
          "positional_tokens": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a5",
            "Re2",
            "Ra7",
            "Rh2",
            "Kh7",
            "Kh4",
            "a4",
            "b4",
            "a3",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Rf7",
            "Re2",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Re7",
            "Re5",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rg3",
          "neutral_uci": "g1g3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Bc6 33. Kd2 Be8 34. Ke3 Bg6 35. f4 Bf5 36. Kf2 Rf8 37. Rxf8 Kxf8 38. Re3 Kf7 39. Kg3 Kg6 40. Kh4 Re8 41. Re1 c5 42. dxc5 bxc5 43. Rd1 d5 44. b4 cxb4 45. cxb4 Rc8 46. Rd4 Rc3 47. a4 Rh3#",
          "neutral_tokens": {
            "prompt_tokens": 368,
            "completion_tokens": 387,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc6",
            "Kd2",
            "Be8",
            "Ke3",
            "Bg6",
            "f4",
            "Bf5",
            "Kf2",
            "Rf8",
            "Rxf8",
            "Kxf8",
            "Re3",
            "Kf7",
            "Kg3",
            "Kg6",
            "Kh4",
            "Re8",
            "Re1",
            "c5",
            "dxc5",
            "bxc5",
            "Rd1",
            "d5",
            "b4",
            "cxb4",
            "cxb4",
            "Rc8",
            "Rd4",
            "Rc3",
            "a4",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g1e1",
          "neutral_uci": "g1g3",
          "consensus_move": "g1g3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "f4",
              "e5",
              "dxe5",
              "dxe5",
              "fxe5",
              "Bxe5",
              "Bxe5",
              "Qxe5",
              "Qxe5",
              "Rxe5",
              "Re8",
              "Rxe8",
              "Kxe8",
              "Kd2",
              "Kf7",
              "Ke3",
              "Kg6",
              "Kf4",
              "c5",
              "dxc5",
              "bxc5",
              "b4",
              "cxb4",
              "cxb4",
              "Kxh6",
              "a4",
              "Kg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "a5",
              "Re2",
              "Ra7",
              "Rh2",
              "Kh7",
              "Kh4",
              "a4",
              "b4",
              "a3",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Rf7",
              "Re2",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Re7",
              "Re5",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bc6",
              "Kd2",
              "Be8",
              "Ke3",
              "Bg6",
              "f4",
              "Bf5",
              "Kf2",
              "Rf8",
              "Rxf8",
              "Kxf8",
              "Re3",
              "Kf7",
              "Kg3",
              "Kg6",
              "Kh4",
              "Re8",
              "Re1",
              "c5",
              "dxc5",
              "bxc5",
              "Rd1",
              "d5",
              "b4",
              "cxb4",
              "cxb4",
              "Rc8",
              "Rd4",
              "Rc3",
              "a4",
              "Rh3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 368,
            "completion_tokens": 387,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1106,
          "total_completion_tokens": 1667,
          "total_tokens": 2773
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 368,
            "completion_tokens": 387,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6rr/1bp1k3/pp1ppR1P/6P1/3P4/2P5/PP3P2/2K3R1 w - - 4 32"
    },
    {
      "turn": 65,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxg5",
          "aggressive_uci": "g3g5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33. Rxg5 Kxf6 34. Rg7 Rxh6 35. Rxc7 Bd5 36. c4 Be4 37. Ra7 Rh2 38. Rxa6 Rxf2 39. Rxb6 Rc2+ 40. Kd1 Rxc4 41. Rxd6 Bd5 42. b3 Rxd4+ 43. Kc1 Ke5 44. Rd8 Rh4 45. Kb2 Kd4 46. a4 Rh2+ 47. Ka3 Rh3 48. Rb8 e5 49. a5 e4 50. a6 e3 51. a7 e2 52. Re8 Re3 53. Rd8 e1=Q 54. a8=Q Qa1+ 55. Kb4 Qxa8 56. Rxa8 Bxa8 57. Ka4 Kc5 58. b4+ Kc4 59. Ka5 Ra3+ 60. Kb6 Kxb4 61. Kc7 Kc5 62. Kd7 Ra6 63. Ke7 Kd5 64. Kf7 Ke5 65. Kg7 Kf5 66. Kh7 Kg5 67. Kg7 Ra7+ 68. Kf8 Kf6 69. Ke8 Bc6+ 70. Kd8 Ke6 71. Kc8 Kd6 72. Kb8 Ra8# 0-1\nd4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7",
          "aggressive_tokens": {
            "prompt_tokens": 378,
            "completion_tokens": 640,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf6",
            "Rg7",
            "Rxh6",
            "Rxc7",
            "Bd5",
            "c4",
            "Be4",
            "Ra7",
            "Rh2",
            "Rxa6",
            "Rxf2",
            "Rxb6",
            "Rc2+",
            "Kd1",
            "Rxc4",
            "Rxd6",
            "Bd5",
            "b3",
            "Rxd4+",
            "Kc1",
            "Ke5",
            "Rd8",
            "Rh4",
            "Kb2",
            "Kd4",
            "a4",
            "Rh2+",
            "Ka3",
            "Rh3",
            "Rb8",
            "e5",
            "a5",
            "e4",
            "a6",
            "e3",
            "a7",
            "e2",
            "Re8",
            "Re3",
            "Rd8",
            "e1=Q",
            "a8=Q",
            "Qa1+",
            "Kb4",
            "Qxa8",
            "Rxa8",
            "Bxa8",
            "Ka4",
            "Kc5",
            "b4+",
            "Kc4",
            "Ka5",
            "Ra3+",
            "Kb6",
            "Kxb4",
            "Kc7",
            "Kc5",
            "Kd7",
            "Ra6",
            "Ke7",
            "Kd5",
            "Kf7",
            "Ke5",
            "Kg7",
            "Kf5",
            "Kh7",
            "Kg5",
            "Kg7",
            "Ra7+",
            "Kf8",
            "Kf6",
            "Ke8",
            "Bc6+",
            "Kd8",
            "Ke6",
            "Kc8",
            "Kd6",
            "Kb8",
            "Ra8#",
            "d4",
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxg5",
          "positional_uci": "g3g5",
          "positional_response": "33. Rxg5 Kxf6 34. Rg7 Rc8 35. Rd7 Bc6 36. Rg7 Be4 37. Kd2 Bg6 38. Ke3 Kg5 39. h7\nKf6 40. Rd7 Bf7 41. Kf4 Kg7 42. Kg5 Rf8 43. Rxc7 Kxh7 44. Kf6 Kg8 45. Ke7 e5\n46. Kxd6 exd4 47. cxd4 Bxa2 48. Rc6 Rf6+ 49. Kc7 Rxc6+ 50. Kxc6 b5 51. Kb6 Bc4\n52. Kxa6 Kf7 53. Kb6 Ke6 54. Kc5 Kf5 55. d5 Ke5 56. d6 Ke6 57. Kc6 Bd5+ 58. Kc7\nBc6 59. Kxc6 b4 60. d7 b3 61. d8=Q Ke5 62. Qd3 Kf4 63. Qxb3 Ke4 64. Qe3+ Kf5\n65. Kd5 Kf6 66. Qe5+ Kf7 67. Qe6+ Kg7 68. Ke5 Kf8 69. Qd7 Kg8 70. Kf6 Kh8 71.\nQg7# Kd8 72. Ke6 Kc8 73. Kd6 Kb8 74. Kc6 Ka8 75. Qb7# Kd8 76. Qd7# Kxd7 77.\nKb7 Kd6 78. b4 Kd5 79. b5 Kc5 80. b6 Kb5 81. Kc7 Ka6 82. b7 Ka7 83. b8=Q+ Ka6",
          "positional_tokens": {
            "prompt_tokens": 378,
            "completion_tokens": 432,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxf6",
            "Rg7",
            "Rc8",
            "Rd7",
            "Bc6",
            "Rg7",
            "Be4",
            "Kd2",
            "Bg6",
            "Ke3",
            "Kg5",
            "h7",
            "Kf6",
            "Rd7",
            "Bf7",
            "Kf4",
            "Kg7",
            "Kg5",
            "Rf8",
            "Rxc7",
            "Kxh7",
            "Kf6",
            "Kg8",
            "Ke7",
            "e5",
            "Kxd6",
            "exd4",
            "cxd4",
            "Bxa2",
            "Rc6",
            "Rf6+",
            "Kc7",
            "Rxc6+",
            "Kxc6",
            "b5",
            "Kb6",
            "Bc4",
            "Kxa6",
            "Kf7",
            "Kb6",
            "Ke6",
            "Kc5",
            "Kf5",
            "d5",
            "Ke5",
            "d6",
            "Ke6",
            "Kc6",
            "Bd5+",
            "Kc7",
            "Bc6",
            "Kxc6",
            "b4",
            "d7",
            "b3",
            "d8=Q",
            "Ke5",
            "Qd3",
            "Kf4",
            "Qxb3",
            "Ke4",
            "Qe3+",
            "Kf5",
            "Kd5",
            "Kf6",
            "Qe5+",
            "Kf7",
            "Qe6+",
            "Kg7",
            "Ke5",
            "Kf8",
            "Qd7",
            "Kg8",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kd8",
            "Ke6",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kxd7",
            "Kb7",
            "Kd6",
            "b4",
            "Kd5",
            "b5",
            "Kc5",
            "b6",
            "Kb5",
            "Kc7",
            "Ka6",
            "b7",
            "Ka7",
            "b8=Q+",
            "Ka6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxg5",
          "neutral_uci": "g3g5",
          "neutral_response": "33. Rxg5 Kxf6 34. Rg7 Rc8 35. Kd2 Be4 36. Ke3 Bf5 37. Kf4 e5+ 38. dxe5+ dxe5+ 39. Ke3 a5 40. f4 exf4+ 41. Kxf4 c6 42. Rb7 b5 43. Ra7 a4 44. b3 axb3 45. axb3 Bc2 46. c4 bxc4 47. bxc4 Kg6 48. h7 Rh8 49. Rc7 Ba4 50. Ke5 Rxh7 51. Rxh7 Kxh7 52. Kd6 Kg6 53. Kc5 Kf5 54. Kb4 Bd1 55. Kc5 Bf3 56. Kd4 Kf4 57. Kc5 Ke3 58. Kb4 Kd4 59. Kb3 Be2 60. Kb4 Bxc4 61. Ka3 Kc3 62. Ka4 c5 63. Ka3 Bb5 64. Ka2 c4 65. Kb1 Kd2 66. Kb2 c3+ 67. Kb3 c2 68. Kb4 c1=Q 69. Kxb5 Kd3 70. Kb4 Qc4+ 71. Ka5 Qb3 72. Ka6 Kc4 73. Ka7 Kc5 74. Ka8 Kc6 75. Ka7 Qb7# 1-0\nd4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 * 33. Rxg5 Kxf6 34. Rg7 Rc8",
          "neutral_tokens": {
            "prompt_tokens": 377,
            "completion_tokens": 640,
            "total_tokens": 1017,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf6",
            "Rg7",
            "Rc8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3g5",
          "positional_uci": "g3g5",
          "neutral_uci": "g3g5",
          "consensus_move": "g3g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxf6",
              "Rg7",
              "Rxh6",
              "Rxc7",
              "Bd5",
              "c4",
              "Be4",
              "Ra7",
              "Rh2",
              "Rxa6",
              "Rxf2",
              "Rxb6",
              "Rc2+",
              "Kd1",
              "Rxc4",
              "Rxd6",
              "Bd5",
              "b3",
              "Rxd4+",
              "Kc1",
              "Ke5",
              "Rd8",
              "Rh4",
              "Kb2",
              "Kd4",
              "a4",
              "Rh2+",
              "Ka3",
              "Rh3",
              "Rb8",
              "e5",
              "a5",
              "e4",
              "a6",
              "e3",
              "a7",
              "e2",
              "Re8",
              "Re3",
              "Rd8",
              "e1=Q",
              "a8=Q",
              "Qa1+",
              "Kb4",
              "Qxa8",
              "Rxa8",
              "Bxa8",
              "Ka4",
              "Kc5",
              "b4+",
              "Kc4",
              "Ka5",
              "Ra3+",
              "Kb6",
              "Kxb4",
              "Kc7",
              "Kc5",
              "Kd7",
              "Ra6",
              "Ke7",
              "Kd5",
              "Kf7",
              "Ke5",
              "Kg7",
              "Kf5",
              "Kh7",
              "Kg5",
              "Kg7",
              "Ra7+",
              "Kf8",
              "Kf6",
              "Ke8",
              "Bc6+",
              "Kd8",
              "Ke6",
              "Kc8",
              "Kd6",
              "Kb8",
              "Ra8#",
              "d4",
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxf6",
              "Rg7",
              "Rc8",
              "Rd7",
              "Bc6",
              "Rg7",
              "Be4",
              "Kd2",
              "Bg6",
              "Ke3",
              "Kg5",
              "h7",
              "Kf6",
              "Rd7",
              "Bf7",
              "Kf4",
              "Kg7",
              "Kg5",
              "Rf8",
              "Rxc7",
              "Kxh7",
              "Kf6",
              "Kg8",
              "Ke7",
              "e5",
              "Kxd6",
              "exd4",
              "cxd4",
              "Bxa2",
              "Rc6",
              "Rf6+",
              "Kc7",
              "Rxc6+",
              "Kxc6",
              "b5",
              "Kb6",
              "Bc4",
              "Kxa6",
              "Kf7",
              "Kb6",
              "Ke6",
              "Kc5",
              "Kf5",
              "d5",
              "Ke5",
              "d6",
              "Ke6",
              "Kc6",
              "Bd5+",
              "Kc7",
              "Bc6",
              "Kxc6",
              "b4",
              "d7",
              "b3",
              "d8=Q",
              "Ke5",
              "Qd3",
              "Kf4",
              "Qxb3",
              "Ke4",
              "Qe3+",
              "Kf5",
              "Kd5",
              "Kf6",
              "Qe5+",
              "Kf7",
              "Qe6+",
              "Kg7",
              "Ke5",
              "Kf8",
              "Qd7",
              "Kg8",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kd8",
              "Ke6",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kxd7",
              "Kb7",
              "Kd6",
              "b4",
              "Kd5",
              "b5",
              "Kc5",
              "b6",
              "Kb5",
              "Kc7",
              "Ka6",
              "b7",
              "Ka7",
              "b8=Q+",
              "Ka6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxf6",
              "Rg7",
              "Rc8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 378,
            "completion_tokens": 640,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 378,
            "completion_tokens": 432,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 377,
            "completion_tokens": 640,
            "total_tokens": 1017,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1133,
          "total_completion_tokens": 1712,
          "total_tokens": 2845
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 378,
            "completion_tokens": 640,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 378,
            "completion_tokens": 432,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 377,
            "completion_tokens": 640,
            "total_tokens": 1017,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/1bp1k3/pp1ppR1P/6r1/3P4/2P3R1/PP3P2/2K5 w - - 0 33"
    },
    {
      "turn": 67,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rg7",
          "aggressive_uci": "g5g7",
          "aggressive_response": "34. Rg7 Rxh6 35. Rxc7 Be4 36. Ra7 Bd3 37. Kd2 Bf1 38. Rb7 Rh2 39. Ke1 Rh1 40.\nRxb6 Bc4+ 41. Kd2 Bxa2 42. Rxa6 Bc4 43. Rxd6 Rf1 44. Ke3 Re1+ 45. Kf3 Kf5 46.\nRd8 Bd5+ 47. Kg3 Rg1+ 48. Kh3 Kf4 49. Rf8+ Ke4 50. Kh2 Rb1 51. b4 Kd3 52. Rc8\nKe2 53. Kg3 Rg1+ 54. Kf4 Kxf2 55. c4 Bf3 56. Ke5 Re1+ 57. Kd6 Ke3 58. Kxe6 Kxd4+\n59. Kd6 Rb1 60. b5 Be2 61. Rc7 Bxc4 62. Kc6 Bxb5+ 63. Kd6 Bc4 64. Rc8 Rb6+ 65.\nKc7 Kc5 66. Rb8 Rh6 67. Rd8 Bd5 68. Rf8 Rh7+ 69. Kd8 Kd6 70. Rf6+ Be6 71. Rf8\nRa7 72. Ke8 Ra8# e4 d5 c4",
          "aggressive_tokens": {
            "prompt_tokens": 387,
            "completion_tokens": 338,
            "total_tokens": 725,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh6",
            "Rxc7",
            "Be4",
            "Ra7",
            "Bd3",
            "Kd2",
            "Bf1",
            "Rb7",
            "Rh2",
            "Ke1",
            "Rh1",
            "Rxb6",
            "Bc4+",
            "Kd2",
            "Bxa2",
            "Rxa6",
            "Bc4",
            "Rxd6",
            "Rf1",
            "Ke3",
            "Re1+",
            "Kf3",
            "Kf5",
            "Rd8",
            "Bd5+",
            "Kg3",
            "Rg1+",
            "Kh3",
            "Kf4",
            "Rf8+",
            "Ke4",
            "Kh2",
            "Rb1",
            "b4",
            "Kd3",
            "Rc8",
            "Ke2",
            "Kg3",
            "Rg1+",
            "Kf4",
            "Kxf2",
            "c4",
            "Bf3",
            "Ke5",
            "Re1+",
            "Kd6",
            "Ke3",
            "Kxe6",
            "Kxd4+",
            "Kd6",
            "Rb1",
            "b5",
            "Be2",
            "Rc7",
            "Bxc4",
            "Kc6",
            "Bxb5+",
            "Kd6",
            "Bc4",
            "Rc8",
            "Rb6+",
            "Kc7",
            "Kc5",
            "Rb8",
            "Rh6",
            "Rd8",
            "Bd5",
            "Rf8",
            "Rh7+",
            "Kd8",
            "Kd6",
            "Rf6+",
            "Be6",
            "Rf8",
            "Ra7",
            "Ke8",
            "Ra8#",
            "e4",
            "d5",
            "c4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra1#",
          "positional_uci": null,
          "positional_response": "Re8 35. Rg7 Re7 36. Rg8 Rh7 37. Rb8 Bf3 38. Rf8+ Rf7 39. Rh8 Kg6\n40. Kd2 Rh7 41. Rf8 Bd5 42. b3 Rxh6 43. c4 Bc6 44. Rc8 Rh7 45. Ke3 Kf5 46. Rf8+\nKg6 47. Rc8 Rf7 48. f4 Kf5 49. Rg8 Kf6 50. Rc8 Bb7 51. Rb8 c5 52. dxc5 dxc5\n53. Rd8 Ke7 54. Rb8 Kd6 55. Rd8+ Kc7 56. Re8 Bc8 57. Ke4 Bd7 58. Ra8 Kb7 59.\nRd8 b5 60. cxb5 axb5 61. Ke5 Kc7 62. Ra8 Rf5+ 63. Ke4 Bc6+ 64. Ke3 Bxa8 65.\na4 bxa4 66. bxa4 Kb6 67. Kd3 Rxf4 68. Kc3 Rxa4 69. Kb3 Kb5 70. Kc3 Ra3+ 71.\nKb2 Kb4 72. Kc2 Be4+ 73. Kb2 c4 74. Kc1 Kc3 75. Kd1 Bd3 76. Ke1 Ra2 77. Kd1\nRa1# 0-1",
          "positional_tokens": {
            "prompt_tokens": 387,
            "completion_tokens": 361,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rg7",
          "neutral_uci": "g5g7",
          "neutral_response": "34. Rg7 Rxh6 35. Rxc7 Be4 36. Ra7 Rh2 37. Rxa6 Rxf2 38. Rxb6 Rc2+ 39. Kd1\nd5 40. a4 Rh2 41. a5 Bd3 42. a6 Rh1+ 43. Kd2 Bc4 44. a7 Ra1 45. Rb7 Kf5 46.\nb3 Ra2+ 47. Kc1 Bd3 48. b4 Ke4 49. b5 Ke3 50. b6 Rc2+ 51. Kd1 Rb2 52. Kc1\nRb1# Kd2 Rb2+ Kc1 Rb1#",
          "neutral_tokens": {
            "prompt_tokens": 386,
            "completion_tokens": 170,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh6",
            "Rxc7",
            "Be4",
            "Ra7",
            "Rh2",
            "Rxa6",
            "Rxf2",
            "Rxb6",
            "Rc2+",
            "Kd1",
            "d5",
            "a4",
            "Rh2",
            "a5",
            "Bd3",
            "a6",
            "Rh1+",
            "Kd2",
            "Bc4",
            "a7",
            "Ra1",
            "Rb7",
            "Kf5",
            "b3",
            "Ra2+",
            "Kc1",
            "Bd3",
            "b4",
            "Ke4",
            "b5",
            "Ke3",
            "b6",
            "Rc2+",
            "Kd1",
            "Rb2",
            "Kc1",
            "Rb1#",
            "Kd2",
            "Rb2+",
            "Kc1",
            "Rb1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5g7",
          "positional_uci": null,
          "neutral_uci": "g5g7",
          "consensus_move": "g5g7",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Rxc7",
              "Be4",
              "Ra7",
              "Bd3",
              "Kd2",
              "Bf1",
              "Rb7",
              "Rh2",
              "Ke1",
              "Rh1",
              "Rxb6",
              "Bc4+",
              "Kd2",
              "Bxa2",
              "Rxa6",
              "Bc4",
              "Rxd6",
              "Rf1",
              "Ke3",
              "Re1+",
              "Kf3",
              "Kf5",
              "Rd8",
              "Bd5+",
              "Kg3",
              "Rg1+",
              "Kh3",
              "Kf4",
              "Rf8+",
              "Ke4",
              "Kh2",
              "Rb1",
              "b4",
              "Kd3",
              "Rc8",
              "Ke2",
              "Kg3",
              "Rg1+",
              "Kf4",
              "Kxf2",
              "c4",
              "Bf3",
              "Ke5",
              "Re1+",
              "Kd6",
              "Ke3",
              "Kxe6",
              "Kxd4+",
              "Kd6",
              "Rb1",
              "b5",
              "Be2",
              "Rc7",
              "Bxc4",
              "Kc6",
              "Bxb5+",
              "Kd6",
              "Bc4",
              "Rc8",
              "Rb6+",
              "Kc7",
              "Kc5",
              "Rb8",
              "Rh6",
              "Rd8",
              "Bd5",
              "Rf8",
              "Rh7+",
              "Kd8",
              "Kd6",
              "Rf6+",
              "Be6",
              "Rf8",
              "Ra7",
              "Ke8",
              "Ra8#",
              "e4",
              "d5",
              "c4"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxh6",
              "Rxc7",
              "Be4",
              "Ra7",
              "Rh2",
              "Rxa6",
              "Rxf2",
              "Rxb6",
              "Rc2+",
              "Kd1",
              "d5",
              "a4",
              "Rh2",
              "a5",
              "Bd3",
              "a6",
              "Rh1+",
              "Kd2",
              "Bc4",
              "a7",
              "Ra1",
              "Rb7",
              "Kf5",
              "b3",
              "Ra2+",
              "Kc1",
              "Bd3",
              "b4",
              "Ke4",
              "b5",
              "Ke3",
              "b6",
              "Rc2+",
              "Kd1",
              "Rb2",
              "Kc1",
              "Rb1#",
              "Kd2",
              "Rb2+",
              "Kc1",
              "Rb1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 387,
            "completion_tokens": 338,
            "total_tokens": 725,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 387,
            "completion_tokens": 361,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 386,
            "completion_tokens": 170,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1160,
          "total_completion_tokens": 869,
          "total_tokens": 2029
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 387,
            "completion_tokens": 338,
            "total_tokens": 725,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 387,
            "completion_tokens": 361,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 386,
            "completion_tokens": 170,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "7r/1bp5/pp1ppk1P/6R1/3P4/2P5/PP3P2/2K5 w - - 0 34"
    },
    {
      "turn": 69,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc7",
          "aggressive_uci": "g7c7",
          "aggressive_response": "35. Rxc7 Rxh6 36. Ra7 Rh2 37. Rxa6 Rxf2 38. Rxb6 Rc2+ 39. Kd1 Ke7 40. a4 Kd7 41. a5 Kc7 42. Rb4 Rh2 43. a6 Rh8 44. Kd2 Ra8 45. Ra4 Kb6 46. Ke3 Bc6 47. Ra3 Rxa6 48. Rxa6+ Kxa6 49. c4 Ka5 50. Kd3 Kb4 51. c5 d5 52. Kc2 Kc4 53. b3+ Kxd4 54. b4 Kc4 55. b5 Bxb5 56. c6 Bxc6 57. Kd2 d4 58. Kc2 d3+ 59. Kd2 Kd4 60. Kd1 Ke3 61. Ke1 d2+ 62. Kd1 Ba4#",
          "aggressive_tokens": {
            "prompt_tokens": 395,
            "completion_tokens": 229,
            "total_tokens": 624,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh6",
            "Ra7",
            "Rh2",
            "Rxa6",
            "Rxf2",
            "Rxb6",
            "Rc2+",
            "Kd1",
            "Ke7",
            "a4",
            "Kd7",
            "a5",
            "Kc7",
            "Rb4",
            "Rh2",
            "a6",
            "Rh8",
            "Kd2",
            "Ra8",
            "Ra4",
            "Kb6",
            "Ke3",
            "Bc6",
            "Ra3",
            "Rxa6",
            "Rxa6+",
            "Kxa6",
            "c4",
            "Ka5",
            "Kd3",
            "Kb4",
            "c5",
            "d5",
            "Kc2",
            "Kc4",
            "b3+",
            "Kxd4",
            "b4",
            "Kc4",
            "b5",
            "Bxb5",
            "c6",
            "Bxc6",
            "Kd2",
            "d4",
            "Kc2",
            "d3+",
            "Kd2",
            "Kd4",
            "Kd1",
            "Ke3",
            "Ke1",
            "d2+",
            "Kd1",
            "Ba4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Nf6 Rg8 Rxg8 Kxf6 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg",
          "positional_tokens": {
            "prompt_tokens": 395,
            "completion_tokens": 640,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Rg8",
            "Rxg8",
            "Kxf6",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc7",
          "neutral_uci": "g7c7",
          "neutral_response": "35. Rxc7 Rxh6 36. Ra7 Rh1+ 37. Kd2 Rb1 38. Ke3 d5 39.\nRxa6 Rxb2 40. a4 Rb3 41. Kd2 Kf5 42. a5 bxa5 43. Rxa5 Rb2+ 44. Ke3 Rc2 45. Rc5\nKg4 46. Rc6 Bf5 47. Rc8 Kh3 48. Kf3 Kh2 49. Rh8+ Kg1 50. Rg8+ Kf1 51. Ke3 Rxc3+\n52. Kd2 Rd3+ 53. Kc1 Rxd4 54. Rg3 Kxf2 55. Rc3 Rc4 56. Rxc4 dxc4 57. Kd2 e5\n58. Kc3 e4 59. Kxc4 e3 60. Kd4 e2 61. Ke5 e1=Q+ 62. Kxf5 Qe3 63. Kg4 Qf3+ 64.\nKg5 Ke3 65. Kg6 Ke4 66. Kg5 Qf4+ 67. Kg6 Ke5 68. Kg7 Qf6+ 69. Kg8 Qe7 70. Kh8\nKf6 71. Kg8 Qg7# 72. Kxg7 * 72... Kg5 73. Kf7 Kf5 74. Ke7 Ke5 75. Kd7 Kd5 76.\nKc7 Kc5 77. Kb7 Kb5 78. Ka7 Ka5 79. Kb7 Kb5 80. Ka7 Ka5 81. Kb7 Kb5 82. Ka7\nKc6 83. Kb8 Kb6 84. Ka8 Kc7 85. Ka7 Kc6 86. Ka6 Kc5 87. Ka5 Kc4 88. Ka4 Kc3 89.\nKa3 Kc2 90. Ka2 Kc1 91. Ka1 Kc2 92. Ka2 Kc3 93. Ka3 Kc4 94. Ka4 Kc5 95. Ka5\nKc6 96. Ka6 Kc7 97. Ka7 Kc8 98. Ka8 Kc7 99. Ka7 Kc6 100. Ka6 Kc5 101. Ka5 Kc4\n102. Ka4 Kc3 103. Ka3 Kc2 104. Ka2 Kc1 105. Ka1 Kc2 106. Ka2 Kc3 107. Ka3 Kc4\n108. Ka4 Kc5 109. Ka5 Kc6 110. Ka6 Kc7 111. Ka7 Kc8 112. Ka8 K",
          "neutral_tokens": {
            "prompt_tokens": 394,
            "completion_tokens": 640,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Ra7",
            "Rh1+",
            "Kd2",
            "Rb1",
            "Ke3",
            "d5",
            "Rxa6",
            "Rxb2",
            "a4",
            "Rb3",
            "Kd2",
            "Kf5",
            "a5",
            "bxa5",
            "Rxa5",
            "Rb2+",
            "Ke3",
            "Rc2",
            "Rc5",
            "Kg4",
            "Rc6",
            "Bf5",
            "Rc8",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rh8+",
            "Kg1",
            "Rg8+",
            "Kf1",
            "Ke3",
            "Rxc3+",
            "Kd2",
            "Rd3+",
            "Kc1",
            "Rxd4",
            "Rg3",
            "Kxf2",
            "Rc3",
            "Rc4",
            "Rxc4",
            "dxc4",
            "Kd2",
            "e5",
            "Kc3",
            "e4",
            "Kxc4",
            "e3",
            "Kd4",
            "e2",
            "Ke5",
            "e1=Q+",
            "Kxf5",
            "Qe3",
            "Kg4",
            "Qf3+",
            "Kg5",
            "Ke3",
            "Kg6",
            "Ke4",
            "Kg5",
            "Qf4+",
            "Kg6",
            "Ke5",
            "Kg7",
            "Qf6+",
            "Kg8",
            "Qe7",
            "Kh8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Kxg7",
            "Kg5",
            "Kf7",
            "Kf5",
            "Ke7",
            "Ke5",
            "Kd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kb5",
            "Ka7",
            "Ka5",
            "Kb7",
            "Kb5",
            "Ka7",
            "Ka5",
            "Kb7",
            "Kb5",
            "Ka7",
            "Kc6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc6",
            "Ka6",
            "Kc5",
            "Ka5",
            "Kc4",
            "Ka4",
            "Kc3",
            "Ka3",
            "Kc2",
            "Ka2",
            "Kc1",
            "Ka1",
            "Kc2",
            "Ka2",
            "Kc3",
            "Ka3",
            "Kc4",
            "Ka4",
            "Kc5",
            "Ka5",
            "Kc6",
            "Ka6",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc6",
            "Ka6",
            "Kc5",
            "Ka5",
            "Kc4",
            "Ka4",
            "Kc3",
            "Ka3",
            "Kc2",
            "Ka2",
            "Kc1",
            "Ka1",
            "Kc2",
            "Ka2",
            "Kc3",
            "Ka3",
            "Kc4",
            "Ka4",
            "Kc5",
            "Ka5",
            "Kc6",
            "Ka6",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g7c7",
          "positional_uci": null,
          "neutral_uci": "g7c7",
          "consensus_move": "g7c7",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Ra7",
              "Rh2",
              "Rxa6",
              "Rxf2",
              "Rxb6",
              "Rc2+",
              "Kd1",
              "Ke7",
              "a4",
              "Kd7",
              "a5",
              "Kc7",
              "Rb4",
              "Rh2",
              "a6",
              "Rh8",
              "Kd2",
              "Ra8",
              "Ra4",
              "Kb6",
              "Ke3",
              "Bc6",
              "Ra3",
              "Rxa6",
              "Rxa6+",
              "Kxa6",
              "c4",
              "Ka5",
              "Kd3",
              "Kb4",
              "c5",
              "d5",
              "Kc2",
              "Kc4",
              "b3+",
              "Kxd4",
              "b4",
              "Kc4",
              "b5",
              "Bxb5",
              "c6",
              "Bxc6",
              "Kd2",
              "d4",
              "Kc2",
              "d3+",
              "Kd2",
              "Kd4",
              "Kd1",
              "Ke3",
              "Ke1",
              "d2+",
              "Kd1",
              "Ba4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Rg8",
              "Rxg8",
              "Kxf6",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxh6",
              "Ra7",
              "Rh1+",
              "Kd2",
              "Rb1",
              "Ke3",
              "d5",
              "Rxa6",
              "Rxb2",
              "a4",
              "Rb3",
              "Kd2",
              "Kf5",
              "a5",
              "bxa5",
              "Rxa5",
              "Rb2+",
              "Ke3",
              "Rc2",
              "Rc5",
              "Kg4",
              "Rc6",
              "Bf5",
              "Rc8",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rh8+",
              "Kg1",
              "Rg8+",
              "Kf1",
              "Ke3",
              "Rxc3+",
              "Kd2",
              "Rd3+",
              "Kc1",
              "Rxd4",
              "Rg3",
              "Kxf2",
              "Rc3",
              "Rc4",
              "Rxc4",
              "dxc4",
              "Kd2",
              "e5",
              "Kc3",
              "e4",
              "Kxc4",
              "e3",
              "Kd4",
              "e2",
              "Ke5",
              "e1=Q+",
              "Kxf5",
              "Qe3",
              "Kg4",
              "Qf3+",
              "Kg5",
              "Ke3",
              "Kg6",
              "Ke4",
              "Kg5",
              "Qf4+",
              "Kg6",
              "Ke5",
              "Kg7",
              "Qf6+",
              "Kg8",
              "Qe7",
              "Kh8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Kxg7",
              "Kg5",
              "Kf7",
              "Kf5",
              "Ke7",
              "Ke5",
              "Kd7",
              "Kd5",
              "Kc7",
              "Kc5",
              "Kb7",
              "Kb5",
              "Ka7",
              "Ka5",
              "Kb7",
              "Kb5",
              "Ka7",
              "Ka5",
              "Kb7",
              "Kb5",
              "Ka7",
              "Kc6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc6",
              "Ka6",
              "Kc5",
              "Ka5",
              "Kc4",
              "Ka4",
              "Kc3",
              "Ka3",
              "Kc2",
              "Ka2",
              "Kc1",
              "Ka1",
              "Kc2",
              "Ka2",
              "Kc3",
              "Ka3",
              "Kc4",
              "Ka4",
              "Kc5",
              "Ka5",
              "Kc6",
              "Ka6",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc6",
              "Ka6",
              "Kc5",
              "Ka5",
              "Kc4",
              "Ka4",
              "Kc3",
              "Ka3",
              "Kc2",
              "Ka2",
              "Kc1",
              "Ka1",
              "Kc2",
              "Ka2",
              "Kc3",
              "Ka3",
              "Kc4",
              "Ka4",
              "Kc5",
              "Ka5",
              "Kc6",
              "Ka6",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 395,
            "completion_tokens": 229,
            "total_tokens": 624,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 395,
            "completion_tokens": 640,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 394,
            "completion_tokens": 640,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1184,
          "total_completion_tokens": 1509,
          "total_tokens": 2693
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 395,
            "completion_tokens": 229,
            "total_tokens": 624,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 395,
            "completion_tokens": 640,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 394,
            "completion_tokens": 640,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/2p3R1/pp1ppk1P/8/3Pb3/2P5/PP3P2/2K5 w - - 2 35"
    },
    {
      "turn": 71,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ra7",
          "aggressive_uci": "c7a7",
          "aggressive_response": "36. Ra7 Rxh6 37. Rxa6 Rh1+ 38. Kd2 Rb1 39.\nb3 Rb2+ 40. Ke3 Bb1 41. Rxd6 Bxa2 42. d5 Bxb3 43. Rxe6+ Kf5 44. Rd6 Bc4 45.\nRd8 Re2+ 46. Kd4 Rd2+ 47. Kc5 Ke5 48. Re8+ Kf6 49. d6 Rd5+ 50. Kc6 Rd3 51. d7\nRxc3 52. d8=Q+ Kf5 53. Rf8+ Ke4 54. Qh4+ Kd3 55. Rf3+ Kc2 56. Qe4+ Kb3 57.\nRxc3+ Kxc3 58. Kc5 Kb3 59. Qb1+ Kc3 60. Qb4+ Kd3 61. Qe1 Kc2 62. Kb4 Kd3 63.\nQe3+ Kc2 64. Qc3+ Kd1 65. Qb2 Ke1 66. f4 Kd1 67. Kc3 Ke1 68. Qg2 Kd1 69. Qd2#\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 * 36. Ra7 Rxh6 37. Rxa6 Rh1+ 38. Kd2 Rb1 39.\nb3 Rb2+ 40. Ke3 Bb1",
          "aggressive_tokens": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rxa6",
            "Rh1+",
            "Kd2",
            "Rb1",
            "b3",
            "Rb2+",
            "Ke3",
            "Bb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra7",
          "positional_uci": "c7a7",
          "positional_response": "36. Ra7 Rxh6 37. Rxa6 Rh1+ 38. Kd2 Rb1 39. b3 Rb2+ 40. Ke3 Bb1 41. Rxd6 Bxa2 42. d5 Bxb3 43. Rxe6+ Kf5 44. Rd6 Bc4 45. Rd8 Re2+ 46. Kd4 Rd2+ 47. Kc5 Ke5 48. Re8+ Kf6 49. d6 Rd5+ 50. Kc6 Rd3 51. d7 Bd5+ 52. Kxb5 Bf7 53. d8=Q+ Rxd8 54. Rxd8 Ke7 55. Rd4 Be8+ 56. Kb6 Ke6 57. c4 Ke5 58. Rd8 Bf7 59. c5 Bd5 60. c6 Bxc6 61. Kxc6 Ke4 62. Kc5 Kf3 63. Re8 Kxf2 64. Kd4 Kf3 65. Re7 Kf4 66. Rf7+ Kg5 67. Ke4 Kg6 68. Rf1 Kg5 69. Rf2 Kg6 70. Ke5 Kg7 71. Ke6 Kg8 72. Ke7 Kg7 73. Rg2+ Kh6 74. Kf7 Kh5 75. Kf6 Kh4 76. Kf5 Kh3 77. Rg8 Kh4 78. Rg7 Kh3 79. Kf4 Kh2 80. Kf3 Kh1 81. Kf2 Kh2 82. Rh7# Bg4 83. Rh8# Bf5 84. Rh5# Bg4 85. Rh4# Bf5 86. Rh5# Bg4 87. Rh4# Bf5 88. Rh5# Bg4 89. Rh4# Bf5 90. Rh5# Bg4 91. Rh4# Bf5 92. Rh5# Bg4 93. Rh4# Bf5 94. Rh5# Bg4 95. Rh4# Bf5 96. Rh5# Bg4 97. Rh4# Bf5 98. Rh5# Bg4 99. Rh4# Bf5 100. Rh5# Bg4 101. Rh4# Bf5 102. Rh5# Bg4 103. Rh4# Bf5 104. Rh5# Bg4 105. Rh4# Bf5 106. Rh5# Bg4 107. Rh4# Bf5 108. Rh5# Bg4 109. Rh4# Bf5 110. Rh5# Bg4 111",
          "positional_tokens": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rxa6",
            "Rh1+",
            "Kd2",
            "Rb1",
            "b3",
            "Rb2+",
            "Ke3",
            "Bb1",
            "Rxd6",
            "Bxa2",
            "d5",
            "Bxb3",
            "Rxe6+",
            "Kf5",
            "Rd6",
            "Bc4",
            "Rd8",
            "Re2+",
            "Kd4",
            "Rd2+",
            "Kc5",
            "Ke5",
            "Re8+",
            "Kf6",
            "d6",
            "Rd5+",
            "Kc6",
            "Rd3",
            "d7",
            "Bd5+",
            "Kxb5",
            "Bf7",
            "d8=Q+",
            "Rxd8",
            "Rxd8",
            "Ke7",
            "Rd4",
            "Be8+",
            "Kb6",
            "Ke6",
            "c4",
            "Ke5",
            "Rd8",
            "Bf7",
            "c5",
            "Bd5",
            "c6",
            "Bxc6",
            "Kxc6",
            "Ke4",
            "Kc5",
            "Kf3",
            "Re8",
            "Kxf2",
            "Kd4",
            "Kf3",
            "Re7",
            "Kf4",
            "Rf7+",
            "Kg5",
            "Ke4",
            "Kg6",
            "Rf1",
            "Kg5",
            "Rf2",
            "Kg6",
            "Ke5",
            "Kg7",
            "Ke6",
            "Kg8",
            "Ke7",
            "Kg7",
            "Rg2+",
            "Kh6",
            "Kf7",
            "Kh5",
            "Kf6",
            "Kh4",
            "Kf5",
            "Kh3",
            "Rg8",
            "Kh4",
            "Rg7",
            "Kh3",
            "Kf4",
            "Kh2",
            "Kf3",
            "Kh1",
            "Kf2",
            "Kh2",
            "Rh7#",
            "Bg4",
            "Rh8#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 d5 Nf6",
          "neutral_tokens": {
            "prompt_tokens": 402,
            "completion_tokens": 8,
            "total_tokens": 410,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7a7",
          "positional_uci": "c7a7",
          "neutral_uci": null,
          "consensus_move": "c7a7",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Rxa6",
              "Rh1+",
              "Kd2",
              "Rb1",
              "b3",
              "Rb2+",
              "Ke3",
              "Bb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh6",
              "Rxa6",
              "Rh1+",
              "Kd2",
              "Rb1",
              "b3",
              "Rb2+",
              "Ke3",
              "Bb1",
              "Rxd6",
              "Bxa2",
              "d5",
              "Bxb3",
              "Rxe6+",
              "Kf5",
              "Rd6",
              "Bc4",
              "Rd8",
              "Re2+",
              "Kd4",
              "Rd2+",
              "Kc5",
              "Ke5",
              "Re8+",
              "Kf6",
              "d6",
              "Rd5+",
              "Kc6",
              "Rd3",
              "d7",
              "Bd5+",
              "Kxb5",
              "Bf7",
              "d8=Q+",
              "Rxd8",
              "Rxd8",
              "Ke7",
              "Rd4",
              "Be8+",
              "Kb6",
              "Ke6",
              "c4",
              "Ke5",
              "Rd8",
              "Bf7",
              "c5",
              "Bd5",
              "c6",
              "Bxc6",
              "Kxc6",
              "Ke4",
              "Kc5",
              "Kf3",
              "Re8",
              "Kxf2",
              "Kd4",
              "Kf3",
              "Re7",
              "Kf4",
              "Rf7+",
              "Kg5",
              "Ke4",
              "Kg6",
              "Rf1",
              "Kg5",
              "Rf2",
              "Kg6",
              "Ke5",
              "Kg7",
              "Ke6",
              "Kg8",
              "Ke7",
              "Kg7",
              "Rg2+",
              "Kh6",
              "Kf7",
              "Kh5",
              "Kf6",
              "Kh4",
              "Kf5",
              "Kh3",
              "Rg8",
              "Kh4",
              "Rg7",
              "Kh3",
              "Kf4",
              "Kh2",
              "Kf3",
              "Kh1",
              "Kf2",
              "Kh2",
              "Rh7#",
              "Bg4",
              "Rh8#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 402,
            "completion_tokens": 8,
            "total_tokens": 410,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1208,
          "total_completion_tokens": 1288,
          "total_tokens": 2496
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 402,
            "completion_tokens": 8,
            "total_tokens": 410,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "7r/2R5/p2ppk1P/1p6/3Pb3/2P5/PP3P2/2K5 w - - 0 36"
    },
    {
      "turn": 73,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxa6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Rxh6 38. Rb6 Rh1+ 39. Kd2 Rf1 40. Rxb5 Rxf2+ 41. Ke3 Rf3+ 42. Kd2 Rf2+ 43. Ke3 Rf3+ 44. Kd2 Rf2+ 45. Ke3 Rf3+ 46. Kd2 Rf2+ 47. Ke3 Rf3+ 48. Kd2 Rf2+ 49. Ke3 Rf3+ 50. Kd2 Rf2+ 51. Ke3 Rf3+ 52. Kd2 Rf2+ 53. Ke3 Rf3+ 54. Kd2 Rf2+ 55. Ke3 Rf3+ 56. Kd2 Rf2+ 57. Ke3 Rf3+ 58. Kd2 Rf2+ 59. Ke3 Rf3+ 60. Kd2 Rf2+ 61. Ke3 Rf3+ 62. Kd2 Rf2+ 63. Ke3 Rf3+ 64. Kd2 Rf2+ 65. Ke3 Rf3+ 66. Kd2 Rf2+ 67. Ke3 Rf3+ 68. Kd2 Rf2+ 69. Ke3 Rf3+ 70. Kd2 Rf2+ 71. Ke3 Rf3+ 72. Kd2 Rf",
          "aggressive_tokens": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rb6",
            "Rh1+",
            "Kd2",
            "Rf1",
            "Rxb5",
            "Rxf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxa6",
          "positional_uci": "a7a6",
          "positional_response": "37. Rxa6 Rxh6 38. Rb6 Rh1+ 39. Kd2 Rf1 40. Ke2 Rb1 41. Rxb5 Bc2 42. Kd2 Ba4 43. Rb4 Be8 44. a4 Ra1 45. b3 Ra2+ 46. Ke3 Rc2 47. c4 dxc4 48. bxc4 Ra2 49. c5 Bxa4 50. Rb6 Ra3+ 51. Kf4 Rd3 52. Ke4 Bc2 53. Rd6 Rh3+ 54. Kf4 Rh4+ 55. Ke3 Re4+ 56. Kd2 Bb3 57. Kc3 Bd5 58. c6 Ke7 59. c7 Bb7 60. Rd8 Rf4 61. c8=Q Bxc8 62. Rxc8 Rxf2 63. Rc7+ Kd6 64. Rc5 Rf3+ 65. Kc4 Rf4 66. Re5 Rf1 67. Kd3 Rd1+ 68. Kc3 Rc1+ 69. Kd3 Rd1+ 70. Kc3 Rc1+ 71. Kd3 Rd1+ 72. Kc3 Rc1+ 73. Kd3 Rd1+ 74. Kc3 Rc1+ 75. Kd3 Rd1+ 76. Kc3 Rc1+ 77. Kd3 Rd1+ 78. Kc3 Rc1+ 79. Kd3 Rd1+ 80. Kc3 Rc1+ 81. Kd3 Rd1+ 82. Kc3 Rc1+ 83. Kd3 Rd1+ 84. Kc3 Rc1+ 85. Kd3 Rd1+ 86. Kc3 Rc1+ 87. Kd3 Rd1+ 88. Kc3 Rc1+ 89. Kd3 Rd1+ 90. Kc3 Rc1+ 91. Kd3 Rd1+ 92. Kc3 Rc1+ 93. Kd3 Rd1+ 94. Kc3 Rc1+ 95. Kd3 Rd1+ 96. Kc3 Rc1+ 97. Kd3 Rd1+ 98. Kc3 Rc1+ 99. Kd3 Rd1+ 100. Kc3 Rc1+ 101. Kd3 Rd1+ 102. Kc3 Rc1+ 103. Kd3 Rd1+ 104. Kc3 Rc1+ 105. Kd3 Rd1+ 106. Kc3 Rc1+ 107. Kd3 Rd1+ 108. Kc3 Rc1+ 109. Kd3 Rd1+ 110.",
          "positional_tokens": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rb6",
            "Rh1+",
            "Kd2",
            "Rf1",
            "Ke2",
            "Rb1",
            "Rxb5",
            "Bc2",
            "Kd2",
            "Ba4",
            "Rb4",
            "Be8",
            "a4",
            "Ra1",
            "b3",
            "Ra2+",
            "Ke3",
            "Rc2",
            "c4",
            "dxc4",
            "bxc4",
            "Ra2",
            "c5",
            "Bxa4",
            "Rb6",
            "Ra3+",
            "Kf4",
            "Rd3",
            "Ke4",
            "Bc2",
            "Rd6",
            "Rh3+",
            "Kf4",
            "Rh4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Bb3",
            "Kc3",
            "Bd5",
            "c6",
            "Ke7",
            "c7",
            "Bb7",
            "Rd8",
            "Rf4",
            "c8=Q",
            "Bxc8",
            "Rxc8",
            "Rxf2",
            "Rc7+",
            "Kd6",
            "Rc5",
            "Rf3+",
            "Kc4",
            "Rf4",
            "Re5",
            "Rf1",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8 Rg3",
          "neutral_tokens": {
            "prompt_tokens": 409,
            "completion_tokens": 8,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": null,
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Rb6",
              "Rh1+",
              "Kd2",
              "Rf1",
              "Rxb5",
              "Rxf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh6",
              "Rb6",
              "Rh1+",
              "Kd2",
              "Rf1",
              "Ke2",
              "Rb1",
              "Rxb5",
              "Bc2",
              "Kd2",
              "Ba4",
              "Rb4",
              "Be8",
              "a4",
              "Ra1",
              "b3",
              "Ra2+",
              "Ke3",
              "Rc2",
              "c4",
              "dxc4",
              "bxc4",
              "Ra2",
              "c5",
              "Bxa4",
              "Rb6",
              "Ra3+",
              "Kf4",
              "Rd3",
              "Ke4",
              "Bc2",
              "Rd6",
              "Rh3+",
              "Kf4",
              "Rh4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Bb3",
              "Kc3",
              "Bd5",
              "c6",
              "Ke7",
              "c7",
              "Bb7",
              "Rd8",
              "Rf4",
              "c8=Q",
              "Bxc8",
              "Rxc8",
              "Rxf2",
              "Rc7+",
              "Kd6",
              "Rc5",
              "Rf3+",
              "Kc4",
              "Rf4",
              "Re5",
              "Rf1",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8",
              "Rg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 409,
            "completion_tokens": 8,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1229,
          "total_completion_tokens": 1288,
          "total_tokens": 2517
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 409,
            "completion_tokens": 8,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "7r/R7/p3pk1P/1p1p4/3Pb3/2P5/PP3P2/2K5 w - - 0 37"
    },
    {
      "turn": 75,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kd2",
          "aggressive_uci": "c1d2",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf5 39. Rb6 Rxh6 40. Rxb5 Rh2 41. Ke3 Rh3+ 42. Kd2 Rd3+ 43. Ke2 Rh3 44. Kd2 Rh2 45. Ke3 Rh3+ 46. Kd2 Rd3+ 47. Ke2 Rh3 48. Kd2 Rd3+ 49. Ke2 Rh3 50. Kd2 Rd3+ 51. Ke2 Rh3 52. Kd2 Rd3+ 53. Ke2 Rh3 54. Kd2 Rd3+ 55. Ke2 Rh3 56. Kd2 Rd3+ 57. Ke2 Rh3 58. Kd2 Rd3+ 59. Ke2 Rh3 60. Kd2 Rd3+ 61. Ke2 Rh3 62. Kd2 Rd3+ 63. Ke2 Rh3 64. Kd2 Rd3+ 65. Ke2 Rh3 66. Kd2 Rd3+ 67. Ke2 Rh3 68. Kd2 Rd3+ 69. Ke2 Rh3 70. Kd2 Rd3+ 71. Ke2 Rh3 72. Kd2 Rd3+ 73. Ke2 Rh3 74. Kd2 Rd3+ 75. Ke2 Rh3 76. Kd2 Rd3+ 77. Ke2 Rh3 78. Kd2 Rd3+",
          "aggressive_tokens": {
            "prompt_tokens": 418,
            "completion_tokens": 640,
            "total_tokens": 1058,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rd3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kd2",
          "positional_uci": "c1d2",
          "positional_response": "38. Kd2 Bf5 39. Rb6 Rxh6 40. Rxb5 Rh2 41. Ke3 Rh3+ 42. Kd2 Rd3+ 43. Ke2 Rh3 44.\nKd2 Kg5 45. a4 Kf4 46. a5 Rh2 47. Ke1 Kf3 48. a6 Rxf2 49. a7 Ke3 50. a8=Q Bd3\n51. Qf8 Rxf8 52. Rxd5 Rf1#",
          "positional_tokens": {
            "prompt_tokens": 418,
            "completion_tokens": 124,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg5",
            "a4",
            "Kf4",
            "a5",
            "Rh2",
            "Ke1",
            "Kf3",
            "a6",
            "Rxf2",
            "a7",
            "Ke3",
            "a8=Q",
            "Bd3",
            "Qf8",
            "Rxf8",
            "Rxd5",
            "Rf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxa6",
          "neutral_uci": null,
          "neutral_response": "Re8 Bc4 Bb5\nRxa6 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 K",
          "neutral_tokens": {
            "prompt_tokens": 417,
            "completion_tokens": 640,
            "total_tokens": 1057,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1d2",
          "positional_uci": "c1d2",
          "neutral_uci": null,
          "consensus_move": "c1d2",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rd3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg5",
              "a4",
              "Kf4",
              "a5",
              "Rh2",
              "Ke1",
              "Kf3",
              "a6",
              "Rxf2",
              "a7",
              "Ke3",
              "a8=Q",
              "Bd3",
              "Qf8",
              "Rxf8",
              "Rxd5",
              "Rf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 418,
            "completion_tokens": 640,
            "total_tokens": 1058,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 418,
            "completion_tokens": 124,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 417,
            "completion_tokens": 640,
            "total_tokens": 1057,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1253,
          "total_completion_tokens": 1404,
          "total_tokens": 2657
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 418,
            "completion_tokens": 640,
            "total_tokens": 1058,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 418,
            "completion_tokens": 124,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 417,
            "completion_tokens": 640,
            "total_tokens": 1057,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/8/R3pk1P/1p1p4/3P4/2Pb4/PP3P2/2K5 w - - 1 38"
    },
    {
      "turn": 77,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ke3",
          "aggressive_uci": "d2e3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRxh6 40. a4 bxa4 41. Rxa4 Rh3+ 42. Kd2 Rf3 43. Ke1 Bc4 44. Ra8 Ke7 45. Ra7+ Kd6\n46. Ra8 Kc6 47. Ra7 Kb6 48. Ra8 Kb7 49. Ra4 Rh3 50. Rb4+ Kc6 51. Ra4 Rh1+ 52.\nKd2 Rf1 53. Ke3 Re1+ 54. Kf3 Rb1 55. Rb4 Bb5 56. Ke3 Kb6 57. Kd2 Ka5 58. Kc2\nRf1 59. Kb3 Rxf2 60. Ka3 Bc4 61. Ra4+ Kb5 62. Rb4+ Kc6 63. Ra4 Kd6 64. Ra8\nRf1 65. Rd8+ Ke7 66. Rh8 Ra1+ 67. Kb4 Ra2 68. b3 Rb2 69. Rh7+ Kd6 70. Rh8 Rxb3+\n71. Ka4 Rxc3 72. Rd8+ Ke7 73. Rh8 Rd3 74. Rh7+ Kd6 75. Rh8 Rxd4 76. Rd8+ Ke5\n77. Rh8 Rd1 78",
          "aggressive_tokens": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb6",
            "Kd2",
            "Ka5",
            "Kc2",
            "Rf1",
            "Kb3",
            "Rxf2",
            "Ka3",
            "Bc4",
            "Ra4+",
            "Kb5",
            "Rb4+",
            "Kc6",
            "Ra4",
            "Kd6",
            "Ra8",
            "Rf1",
            "Rd8+",
            "Ke7",
            "Rh8",
            "Ra1+",
            "Kb4",
            "Ra2",
            "b3",
            "Rb2",
            "Rh7+",
            "Kd6",
            "Rh8",
            "Rxb3+",
            "Ka4",
            "Rxc3",
            "Rd8+",
            "Ke7",
            "Rh8",
            "Rd3",
            "Rh7+",
            "Kd6",
            "Rh8",
            "Rxd4",
            "Rd8+",
            "Ke5",
            "Rh8",
            "Rd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ke1",
          "positional_uci": "d2e1",
          "positional_response": "39. Ke1 Bd3 40. Kd2 Bf1 41. Ke1 Bd3 42. Kd2 Bf1 43. Ke1 Bd3 44. Kd2 Bf1 45. Ke1 Bd3 46. Kd2 Bf1 47. Ke1 Bd3 48. Kd2 Bf1 49. Ke1 Bd3 50. Kd2 Bf1 51. Ke1 Bd3 52. Kd2 Bf1 53. Ke1 Bd3 54. Kd2 Bf1 55. Ke1 Bd3 56. Kd2 Bf1 57. Ke1 Bd3 58. Kd2 Bf1 59. Ke1 Bd3 60. Kd2 Bf1 61. Ke1 Bd3 62. Kd2 Bf1 63. Ke1 Bd3 64. Kd2 Bf1 65. Ke1 Bd3 66. Kd2 Bf1 67. Ke1 Bd3 68. Kd2 Bf1 69. Ke1 Bd3 70. Kd2 Bf1 71. Ke1 Bd3 72. Kd2 Bf1 73. Ke1 Bd3 74. Kd2 Bf1 75. Ke1 Bd3 76. Kd2 Bf1 77. Ke1 Bd3 78. Kd2 Bf1 79. Ke1 Bd3 80. Kd2 Bf1 81. Ke1 Bd3 82. Kd2 Bf1 83. Ke1 Bd3 84. Kd2 Bf1 85. Ke1 Bd3 86. Kd2 Bf1 87. Ke1 Bd3 88. Kd2 Bf1 89. Ke1 Bd3 90. Kd2 Bf1 91. Ke1 Bd3 92. Kd2 Bf1 93. Ke1 Bd3 94. Kd2 Bf1 95. Ke1 Bd3 96. Kd2 Bf1 97. Ke1 Bd3 98. Kd2 Bf1 99. Ke1 Bd3 100. Kd2 Bf1 101. Ke1 Bd3 102. Kd2 Bf1 103. Ke1 Bd3 104. Kd2 Bf1 105. Ke1 Bd3 106. Kd2 Bf1 107. Ke1 Bd3 108. Kd2 Bf1 109. Ke1 Bd3 110. Kd2 Bf1 111. Ke1 Bd3 112. Kd2 Bf1 113. Ke1 Bd3 114. Kd2 Bf1 115. Ke1 Bd3 116. Kd2 Bf1 117. Ke1 Bd3 118. Kd2 Bf1",
          "positional_tokens": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "Kd2",
            "Bf1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ke3",
          "neutral_uci": "d2e3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRxh6 40. a4 bxa4 41. Rxa4 Rh3+ 42. Kd2 Rf3 43. Ke1 Bc4 44. Ra8 Ke7 45. Ra7+ Kd6\n46. Ra8 Kc6 47. Ra7 Kb6 48. Ra8 Kb5 49. Ra7 Rh3 50. Kd2 Rh2 51. Ke3 Rh1 52. Kd2\nRb1 53. Kc2 Rf1 54. Kd2 Rxf2+ 55. Kc1 Bb3 56. Ra8 Rc2+ 57. Kb1 Rd2 58. Kc1 Rd1#\nd5 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxh7 Qh5 b6 Qg6 Qxh6 Qg8 b5 Qg6 Qxh6 gxh6 Rh1 b4 Rxh6 bxc3 bxc3 Kc7 Kc2 Kd6 Rg3",
          "neutral_tokens": {
            "prompt_tokens": 426,
            "completion_tokens": 640,
            "total_tokens": 1066,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rh1",
            "Kd2",
            "Rb1",
            "Kc2",
            "Rf1",
            "Kd2",
            "Rxf2+",
            "Kc1",
            "Bb3",
            "Ra8",
            "Rc2+",
            "Kb1",
            "Rd2",
            "Kc1",
            "Rd1#",
            "d5",
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Qh5",
            "b6",
            "Qg6",
            "Qxh6",
            "Qg8",
            "b5",
            "Qg6",
            "Qxh6",
            "gxh6",
            "Rh1",
            "b4",
            "Rxh6",
            "bxc3",
            "bxc3",
            "Kc7",
            "Kc2",
            "Kd6",
            "Rg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2e3",
          "positional_uci": "d2e1",
          "neutral_uci": "d2e3",
          "consensus_move": "d2e3",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kb6",
              "Kd2",
              "Ka5",
              "Kc2",
              "Rf1",
              "Kb3",
              "Rxf2",
              "Ka3",
              "Bc4",
              "Ra4+",
              "Kb5",
              "Rb4+",
              "Kc6",
              "Ra4",
              "Kd6",
              "Ra8",
              "Rf1",
              "Rd8+",
              "Ke7",
              "Rh8",
              "Ra1+",
              "Kb4",
              "Ra2",
              "b3",
              "Rb2",
              "Rh7+",
              "Kd6",
              "Rh8",
              "Rxb3+",
              "Ka4",
              "Rxc3",
              "Rd8+",
              "Ke7",
              "Rh8",
              "Rd3",
              "Rh7+",
              "Kd6",
              "Rh8",
              "Rxd4",
              "Rd8+",
              "Ke5",
              "Rh8",
              "Rd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd3",
              "Kd2",
              "Bf1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rh1",
              "Kd2",
              "Rb1",
              "Kc2",
              "Rf1",
              "Kd2",
              "Rxf2+",
              "Kc1",
              "Bb3",
              "Ra8",
              "Rc2+",
              "Kb1",
              "Rd2",
              "Kc1",
              "Rd1#",
              "d5",
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Qh5",
              "b6",
              "Qg6",
              "Qxh6",
              "Qg8",
              "b5",
              "Qg6",
              "Qxh6",
              "gxh6",
              "Rh1",
              "b4",
              "Rxh6",
              "bxc3",
              "bxc3",
              "Kc7",
              "Kc2",
              "Kd6",
              "Rg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 426,
            "completion_tokens": 640,
            "total_tokens": 1066,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1280,
          "total_completion_tokens": 1920,
          "total_tokens": 3200
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 426,
            "completion_tokens": 640,
            "total_tokens": 1066,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/8/R3pk1P/1p1p4/3P4/2P5/PP1K1P2/5b2 w - - 3 39"
    },
    {
      "turn": 79,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf4",
          "aggressive_uci": "e3f4",
          "aggressive_response": "40. Kf4 Bd3 41. Ke3 Bf1 42. Kf4 Bd3 43. Ke3 Bf1 44. Kf4 Bd3 45. Ke3 Bf1 46. Kf4 Bd3 47. Ke3 Bf1 48. Kf4 Bd3 49. Ke3 Bf1 50. Kf4 Bd3 51. Ke3 Bf1 52. Kf4 Bd3 53. Ke3 Bf1 54. Kf4 Bd3 55. Ke3 Bf1 56. Kf4 Bd3 57. Ke3 Bf1 58. Kf4 Bd3 59. Ke3 Bf1 60. Kf4 Bd3 61. Ke3 Bf1 62. Kf4 Bd3 63. Ke3 Bf1 64. Kf4 Bd3 65. Ke3 Bf1 66. Kf4 Bd3 67. Ke3 Bf1 68. Kf4 Bd3 69. Ke3 Bf1 70. Kf4 Bd3 71. Ke3 Bf1 72. Kf4 Bd3 73. Ke3 Bf1 74. Kf4 Bd3 75. Ke3 Bf1 76. Kf4 Bd3 77. Ke3 Bf1 78. Kf4 Bd3 79. Ke3 Bf1 80. Kf4 Bd3 81. Ke3 Bf1 82. Kf4 Bd3 83. Ke3 Bf1 84. Kf4 Bd3 85. Ke3 Bf1 86. Kf4 Bd3 87. Ke3 Bf1 88. Kf4 Bd3 89. Ke3 Bf1 90. Kf4 Bd3 91. Ke3 Bf1 92. Kf4 Bd3 93. Ke3 Bf1 94. Kf4 Bd3 95. Ke3 Bf1 96. Kf4 Bd3 97. Ke3 Bf1 98. Kf4 Bd3 99. Ke3 Bf1 100. Kf4 Bd3 101. Ke3 Bf1 102. Kf4 Bd3 103. Ke3 Bf1 104. Kf4 Bd3 105. Ke3 Bf1 106. Kf4 Bd3 107. Ke3 Bf1 108. Kf4 Bd3 109. Ke3 Bf1 110. Kf4 Bd3 111. Ke3 Bf1 112. Kf4 Bd3 113. Ke3 Bf1 114. Kf4 Bd3 115. Ke3 Bf1 116. Kf4 Bd3 117. Ke3 Bf1 118. Kf4 Bd3 119. Ke3 Bf1",
          "aggressive_tokens": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "Ke3",
            "Bf1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b3",
          "positional_uci": "b2b3",
          "positional_response": "40. b3 Rxh6 41. a4 bxa4 42. Rxa4 Rh3+ 43. Kd2 Rd3+ 44. Kc2 Rf3 45. c4 Rxf2+ 46. Kc3 Rf3+ 47. Kb4 dxc4 48. bxc4 Rf4 49. Kc5 Kf5 50. d5 exd5 51. Kxd5 Bg2+ 52. Kd6 Rd4+ 53. Kc5 Ke5 54. Ra7 Bf1 55. Re7+ Kf6 56. Kxd4 Kxe7 57. c5 Kd7 58. Kd5 Bg2+ 59. Kd4 Kc6 60. Kc4 Bd5+ 61. Kd4 Bf7 62. Ke5 Kxc5 63. Kf6 Bc4 64. Ke5 Bd3 65. Kf6 Kd6 66. Kg5 Ke5 67. Kg4 Be4 68. Kg5 Bf5 69. Kh6 Kf6 70. Kh5 Be6 71. Kh6 Bg8 72. Kh5 Kf5 73. Kh6 Kf6 74. Kh5 Be6 75. Kh6 Bf5 76. Kh5 Be4 77. Kh6 Bf3 78. Kh7 Be4+ 79. Kh6 Bf5 80. Kh5 Be6 81. Kh6 Bf7 82. Kh7 Bg6+ 83. Kh6 Bf7 84. Kh7 Be6 85. Kh6 Bf5 86. Kh5 Be4 87. Kh6 Bf3 88. Kh7 Be4+ 89. Kh6 Bf5 90. Kh5 Be6 91. Kh6 Bf7 92. Kh7 Bg6+ 93. Kh6 Bf7 94. Kh7 Be6 95. Kh6 Bf5 96. Kh5 Be4 97. Kh6 Bf3 98. Kh7 Be4+ 99. Kh6 Bf5 100. Kh5 Be6 101. Kh6 Bf7 102. Kh7 Bg6+ 103. Kh6 Bf7 104. Kh7 Be6 105. Kh6 Bf5 106. Kh5 Be4 107. Kh6 Bf3 108. Kh7 Be4+ 109. Kh6 Bf5 110. Kh5 Be6 111. Kh6 Bf7 112. Kh7 Bg6+ 113. Kh6 Bf7 114. Kh7 Be6 115. Kh6 Bf5 116. Kh5 Be4 117. Kh6 Bf3 118. Kh7 Be4+ 119",
          "positional_tokens": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "a4",
            "bxa4",
            "Rxa4",
            "Rh3+",
            "Kd2",
            "Rd3+",
            "Kc2",
            "Rf3",
            "c4",
            "Rxf2+",
            "Kc3",
            "Rf3+",
            "Kb4",
            "dxc4",
            "bxc4",
            "Rf4",
            "Kc5",
            "Kf5",
            "d5",
            "exd5",
            "Kxd5",
            "Bg2+",
            "Kd6",
            "Rd4+",
            "Kc5",
            "Ke5",
            "Ra7",
            "Bf1",
            "Re7+",
            "Kf6",
            "Kxd4",
            "Kxe7",
            "c5",
            "Kd7",
            "Kd5",
            "Bg2+",
            "Kd4",
            "Kc6",
            "Kc4",
            "Bd5+",
            "Kd4",
            "Bf7",
            "Ke5",
            "Kxc5",
            "Kf6",
            "Bc4",
            "Ke5",
            "Bd3",
            "Kf6",
            "Kd6",
            "Kg5",
            "Ke5",
            "Kg4",
            "Be4",
            "Kg5",
            "Bf5",
            "Kh6",
            "Kf6",
            "Kh5",
            "Be6",
            "Kh6",
            "Bg8",
            "Kh5",
            "Kf5",
            "Kh6",
            "Kf6",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kf4",
          "neutral_uci": "e3f4",
          "neutral_response": "40. Kf4 Rxh6 41. Ra8 Rh4+ 42. Kg3 Rh3+ 43. Kg4 Rd3 44. Rf8+ Ke7 45. Rb8 Rd2\n46. b3 Rxa2 47. f4 Rc2 48. Rc8 b4 49. Rc7+ Kd6 50. Rb7 bxc3 51. Rb6+ Kd7 52.\nRb7+ Kc6 53. Re7 Re2 54. f5 c2 55. f6 c1=Q 56. f7 Rg2+ 57. Kh5 Qg5# Bg7+ 59. Kh4\nBf6+ 60. Kh3 Qg4# Bxg4+ 62. Kxg4 Bxe7 63. Kf4 Rf2+ 64. Ke5 Kd7 65. f8=N+ Bxf8\n66. b4 Bg7# Bxg7+ 68. Kxg7 Ke7 69. b5 Rg2+ 70. Kh6 Kf6 71. Kh5 Kf5 72. Kh4\nRg8 73. b6 Kf4 74. Kh5 Rb8 75. Kg6 Rxb6 76. Kf6 Ke4 77. Ke7 Kxd4 78. Kd7 e5\n79. Kc7 Rh6 80. Kd7 e4 81. Ke7 e3 82. Kf7 e2 83. Kg7 Ra6 84. Kf7 e1=Q 85. Kg7\nQe7+ 86. Kg8 Ra8# e4 e3 e2 e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=",
          "neutral_tokens": {
            "prompt_tokens": 434,
            "completion_tokens": 640,
            "total_tokens": 1074,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh5",
            "Rb8",
            "Kg6",
            "Rxb6",
            "Kf6",
            "Ke4",
            "Ke7",
            "Kxd4",
            "Kd7",
            "e5",
            "Kc7",
            "Rh6",
            "Kd7",
            "e4",
            "Ke7",
            "e3",
            "Kf7",
            "e2",
            "Kg7",
            "Ra6",
            "Kf7",
            "e1=Q",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Ra8#",
            "e4",
            "e3",
            "e2",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e3f4",
          "positional_uci": "b2b3",
          "neutral_uci": "e3f4",
          "consensus_move": "e3f4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd3",
              "Ke3",
              "Bf1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh6",
              "a4",
              "bxa4",
              "Rxa4",
              "Rh3+",
              "Kd2",
              "Rd3+",
              "Kc2",
              "Rf3",
              "c4",
              "Rxf2+",
              "Kc3",
              "Rf3+",
              "Kb4",
              "dxc4",
              "bxc4",
              "Rf4",
              "Kc5",
              "Kf5",
              "d5",
              "exd5",
              "Kxd5",
              "Bg2+",
              "Kd6",
              "Rd4+",
              "Kc5",
              "Ke5",
              "Ra7",
              "Bf1",
              "Re7+",
              "Kf6",
              "Kxd4",
              "Kxe7",
              "c5",
              "Kd7",
              "Kd5",
              "Bg2+",
              "Kd4",
              "Kc6",
              "Kc4",
              "Bd5+",
              "Kd4",
              "Bf7",
              "Ke5",
              "Kxc5",
              "Kf6",
              "Bc4",
              "Ke5",
              "Bd3",
              "Kf6",
              "Kd6",
              "Kg5",
              "Ke5",
              "Kg4",
              "Be4",
              "Kg5",
              "Bf5",
              "Kh6",
              "Kf6",
              "Kh5",
              "Be6",
              "Kh6",
              "Bg8",
              "Kh5",
              "Kf5",
              "Kh6",
              "Kf6",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh5",
              "Rb8",
              "Kg6",
              "Rxb6",
              "Kf6",
              "Ke4",
              "Ke7",
              "Kxd4",
              "Kd7",
              "e5",
              "Kc7",
              "Rh6",
              "Kd7",
              "e4",
              "Ke7",
              "e3",
              "Kf7",
              "e2",
              "Kg7",
              "Ra6",
              "Kf7",
              "e1=Q",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Ra8#",
              "e4",
              "e3",
              "e2",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 434,
            "completion_tokens": 640,
            "total_tokens": 1074,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1304,
          "total_completion_tokens": 1920,
          "total_tokens": 3224
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 434,
            "completion_tokens": 640,
            "total_tokens": 1074,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/7r/R3pk1P/1p1p4/3P4/2P1K3/PP3P2/5b2 w - - 5 40"
    },
    {
      "turn": 81,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1 Re8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8 27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33. Rxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3 Rh7 40. Kf4 Rxh6",
          "aggressive_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 333,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4",
            "Qg6",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Rh8",
            "g4",
            "Bb7",
            "Rh5",
            "Ke8",
            "g5",
            "Kf7",
            "Rg1",
            "Rag8",
            "Rh4",
            "a6",
            "Rf4+",
            "Ke8",
            "Rf6",
            "Ke7",
            "Rg3",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Rxa6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rg7",
          "positional_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8 Rg3",
          "neutral_tokens": {
            "prompt_tokens": 443,
            "completion_tokens": 8,
            "total_tokens": 451,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4",
              "Qg6",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Rh8",
              "g4",
              "Bb7",
              "Rh5",
              "Ke8",
              "g5",
              "Kf7",
              "Rg1",
              "Rag8",
              "Rh4",
              "a6",
              "Rf4+",
              "Ke8",
              "Rf6",
              "Ke7",
              "Rg3",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Rxa6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8",
              "Rg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 444,
            "completion_tokens": 333,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 443,
            "completion_tokens": 8,
            "total_tokens": 451,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1331,
          "total_completion_tokens": 349,
          "total_tokens": 1680
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 444,
            "completion_tokens": 333,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 443,
            "completion_tokens": 8,
            "total_tokens": 451,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/R3pk1r/1p1p4/3P1K2/2P5/PP3P2/5b2 w - - 0 41"
    },
    {
      "turn": 81,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "a4",
          "aggressive_uci": "a2a4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 bxa4 42. Rxa4 Rh4+ 43. Kg3 Rh3+ 44. Kg4 Rd3 45. Ra1 Be2+ 46. Kh4 Kf5 47. Re1 Bg4 48. Re5+ Kf4 49. Re3 Rxe3 50. fxe3+ Kf5 51. b4 Be2 52. Kg3 Ke4 53. Kf2 Bb5 54. Ke1 Kxe3 55. Kd1 Kd3 56. Kc1 Kxc3 57. Kd1 Kxd4 58. Kd2 Kc4 59. Ke3 Kxb4 60. Kd4 Bc4 61. Ke5 Kc3 62. Kxe6 d4+ 63. Ke5 d3 64. Ke4 d2 65. Ke3 d1=Q 66. Kf4 Qe2 67. Kf5 Qe3 68. Kf6 Qe4 69. Kg5 Qf3 70. Kg6 Qf4 71. Kg7 Qf5 72. Kh6 Qg4 73. Kh7 Qg5 74. Kh8 Qg8# 0-1\nd5 e6 c4 d6 Nc3 Nf6 Bg5",
          "aggressive_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 640,
            "total_tokens": 1084,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "bxa4",
            "Rxa4",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kg4",
            "Rd3",
            "Ra1",
            "Be2+",
            "Kh4",
            "Kf5",
            "Re1",
            "Bg4",
            "Re5+",
            "Kf4",
            "Re3",
            "Rxe3",
            "fxe3+",
            "Kf5",
            "b4",
            "Be2",
            "Kg3",
            "Ke4",
            "Kf2",
            "Bb5",
            "Ke1",
            "Kxe3",
            "Kd1",
            "Kd3",
            "Kc1",
            "Kxc3",
            "Kd1",
            "Kxd4",
            "Kd2",
            "Kc4",
            "Ke3",
            "Kxb4",
            "Kd4",
            "Bc4",
            "Ke5",
            "Kc3",
            "Kxe6",
            "d4+",
            "Ke5",
            "d3",
            "Ke4",
            "d2",
            "Ke3",
            "d1=Q",
            "Kf4",
            "Qe2",
            "Kf5",
            "Qe3",
            "Kf6",
            "Qe4",
            "Kg5",
            "Qf3",
            "Kg6",
            "Qf4",
            "Kg7",
            "Qf5",
            "Kh6",
            "Qg4",
            "Kh7",
            "Qg5",
            "Kh8",
            "Qg8#",
            "d5",
            "e6",
            "c4",
            "d6",
            "Nc3",
            "Nf6",
            "Bg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rg7",
          "positional_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a4",
          "neutral_uci": "a2a4",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 bxa4 42. Rxa4 Rh4+ 43. Kg3 Rh3+ 44. Kg4 Rd3 45. Ra1 Be2+ 46. Kh4 Kf5 47. Re1 Bg4 48. Re5+ Kf4 49. Re3 Rxe3 50. fxe3+ Kf5 51. b4 Be2 52. Kg3 Ke4 53. Kf2 Bb5 54. Ke1 Kxe3 55. Kd1 Kd3 56. Kc1 Kxc3 57. Kd1 Kxd4 58. Kd2 Kc4 59. Ke3 Kxb4 60. Kd4 Bc4 61. Ke5 Kc3 62. Kxe6 d4+ 63. Ke5 d3 64. Ke4 d2 65. Ke3 d1=Q 66. Ke4 Qd5+ 67. Ke3 Qd4+ 68. Kf3 Bd5+ 69. Ke2 Qd3+ 70. Kf2 Qf3+ 71. Ke1 Qg2 72. Kd1 Qd2# d5 d4 d3",
          "neutral_tokens": {
            "prompt_tokens": 443,
            "completion_tokens": 612,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxa4",
            "Rxa4",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kg4",
            "Rd3",
            "Ra1",
            "Be2+",
            "Kh4",
            "Kf5",
            "Re1",
            "Bg4",
            "Re5+",
            "Kf4",
            "Re3",
            "Rxe3",
            "fxe3+",
            "Kf5",
            "b4",
            "Be2",
            "Kg3",
            "Ke4",
            "Kf2",
            "Bb5",
            "Ke1",
            "Kxe3",
            "Kd1",
            "Kd3",
            "Kc1",
            "Kxc3",
            "Kd1",
            "Kxd4",
            "Kd2",
            "Kc4",
            "Ke3",
            "Kxb4",
            "Kd4",
            "Bc4",
            "Ke5",
            "Kc3",
            "Kxe6",
            "d4+",
            "Ke5",
            "d3",
            "Ke4",
            "d2",
            "Ke3",
            "d1=Q",
            "Ke4",
            "Qd5+",
            "Ke3",
            "Qd4+",
            "Kf3",
            "Bd5+",
            "Ke2",
            "Qd3+",
            "Kf2",
            "Qf3+",
            "Ke1",
            "Qg2",
            "Kd1",
            "Qd2#",
            "d5",
            "d4",
            "d3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a2a4",
          "positional_uci": null,
          "neutral_uci": "a2a4",
          "consensus_move": "a2a4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "bxa4",
              "Rxa4",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kg4",
              "Rd3",
              "Ra1",
              "Be2+",
              "Kh4",
              "Kf5",
              "Re1",
              "Bg4",
              "Re5+",
              "Kf4",
              "Re3",
              "Rxe3",
              "fxe3+",
              "Kf5",
              "b4",
              "Be2",
              "Kg3",
              "Ke4",
              "Kf2",
              "Bb5",
              "Ke1",
              "Kxe3",
              "Kd1",
              "Kd3",
              "Kc1",
              "Kxc3",
              "Kd1",
              "Kxd4",
              "Kd2",
              "Kc4",
              "Ke3",
              "Kxb4",
              "Kd4",
              "Bc4",
              "Ke5",
              "Kc3",
              "Kxe6",
              "d4+",
              "Ke5",
              "d3",
              "Ke4",
              "d2",
              "Ke3",
              "d1=Q",
              "Kf4",
              "Qe2",
              "Kf5",
              "Qe3",
              "Kf6",
              "Qe4",
              "Kg5",
              "Qf3",
              "Kg6",
              "Qf4",
              "Kg7",
              "Qf5",
              "Kh6",
              "Qg4",
              "Kh7",
              "Qg5",
              "Kh8",
              "Qg8#",
              "d5",
              "e6",
              "c4",
              "d6",
              "Nc3",
              "Nf6",
              "Bg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "bxa4",
              "Rxa4",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kg4",
              "Rd3",
              "Ra1",
              "Be2+",
              "Kh4",
              "Kf5",
              "Re1",
              "Bg4",
              "Re5+",
              "Kf4",
              "Re3",
              "Rxe3",
              "fxe3+",
              "Kf5",
              "b4",
              "Be2",
              "Kg3",
              "Ke4",
              "Kf2",
              "Bb5",
              "Ke1",
              "Kxe3",
              "Kd1",
              "Kd3",
              "Kc1",
              "Kxc3",
              "Kd1",
              "Kxd4",
              "Kd2",
              "Kc4",
              "Ke3",
              "Kxb4",
              "Kd4",
              "Bc4",
              "Ke5",
              "Kc3",
              "Kxe6",
              "d4+",
              "Ke5",
              "d3",
              "Ke4",
              "d2",
              "Ke3",
              "d1=Q",
              "Ke4",
              "Qd5+",
              "Ke3",
              "Qd4+",
              "Kf3",
              "Bd5+",
              "Ke2",
              "Qd3+",
              "Kf2",
              "Qf3+",
              "Ke1",
              "Qg2",
              "Kd1",
              "Qd2#",
              "d5",
              "d4",
              "d3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 444,
            "completion_tokens": 640,
            "total_tokens": 1084,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 443,
            "completion_tokens": 612,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1331,
          "total_completion_tokens": 1260,
          "total_tokens": 2591
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 444,
            "completion_tokens": 640,
            "total_tokens": 1084,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 443,
            "completion_tokens": 612,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/R3pk1r/1p1p4/3P1K2/2P5/PP3P2/5b2 w - - 0 41"
    },
    {
      "turn": 83,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg3",
          "aggressive_uci": "f4g3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6\nBxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4\nNf6 13. Neg5 Kd8 14. Rhe1 Re8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5\nBxg5+ 19. hxg5 Qxh7 20. Rh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8\n25. g4 Bb7 26. Rh5 Ke8 27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6\nKe7 32. Rg3 Rxg5 33. Rxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3\n38. Kd2 Bf1 39. Ke3 Rh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rg2+ 43. Kf3 bxa4 44.\nRxa4 Rg7 45. Ra1 Bd3 46. Ke3 Bc4 47. Ra3 Rb7 48. b4 Rh7 49. Ra8 Rh3+ 50. Kd2\nRd3+ 51. Kc2 Rf3 52. Rf8+ * 42. Kg3 Rg2+ 43. Kf3 bxa4 44. Rxa4 Rg7 45. Ra1 Bd3\n46. Ke3 Bc4 47. Ra3 Rb7 48. b4 Rh7 49. Ra8 Rh3+ 50. Kd2 Rf3 51. Rf8+",
          "aggressive_tokens": {
            "prompt_tokens": 451,
            "completion_tokens": 518,
            "total_tokens": 969,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg2+",
            "Kf3",
            "bxa4",
            "Rxa4",
            "Rg7",
            "Ra1",
            "Bd3",
            "Ke3",
            "Bc4",
            "Ra3",
            "Rb7",
            "b4",
            "Rh7",
            "Ra8",
            "Rh3+",
            "Kd2",
            "Rf3",
            "Rf8+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg3",
          "positional_uci": "f4g3",
          "positional_response": "42. Kg3 Rg2+ 43. Kf3 bxa4 44. Rxa4 Rg8 45. Ra1 Bd3 46. Ke3 Bc4 47. Ra3 Rb8 48.\nb4 Rh8 49. Ra7 Rh3+ 50. Kd2 Rd3+ 51. Kc2 Rf3 52. Ra8 Rxf2+ 53. Kc1 Kf5 54. Rf8+\nKe4 55. Rxf2 Kd3 56. Rf3+ Ke2 57. Rh3 Kf2 58. Kd2 Kg2 59. Re3 Kf2 60. Rxe6 Kf3\n61. Re5 Kf4 62. Kc2 Kf3 63. Kb2 Kf4 64. Ka3 Kf3 65. Ka4 Kf4 66. b5 Kf3 67. b6\nKf4 68. b7 Kf3 69. b8=Q Kf4 70. Qf8+ Kg4 71. Re7 Kg5 72. Rg7+ Kh6 73. Qh8# Kf5\n74. Qe8 Kf4 75. Rf7+ Kg5 76. Qg8+ Kh6 77. Rh7# Kxh7 78. Qf7+ Kh6 79. Qf6+ Kh7\n80. Qf5+ Kh6 81. Qf4+ Kh7 82. Qf3 Kh6 83. Qf2 Kh7 84. Qf1 Kh6 85. Qg1 Kh7 86.\nQg2 Kh6 87. Qg3 Kh7 88. Qg4 Kh6 89. Qg5+ Kh7 90. Qg6+ Kh8 91. Qg7+ Kxg7 92.\nKb4 Kf6 93. Kc5 Kf5 94. Kd6 Ke4 95. Kc5 Kd3 96. Kb4 Kc2 97. Kc5 Kxc3 98. Kd6\nKxd4 99. Ke6 Ke4 100. Kf6 d4 101. Kg5 d3 102. Kg4 d2 103. Kg3 d1=Q 104. Kf2 Qf3+\n105. Kg1 Qe2 106. Kh1 Kf3 107. Kg1 Qg2#",
          "positional_tokens": {
            "prompt_tokens": 451,
            "completion_tokens": 564,
            "total_tokens": 1015,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d1=Q",
            "Kf2",
            "Qf3+",
            "Kg1",
            "Qe2",
            "Kh1",
            "Kf3",
            "Kg1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg3",
          "neutral_uci": "f4g3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kg4 bxa4 44. Rxa4 Rh2 45. Kg3 Rh8\n46. Ra1 Bd3 47. Kf4 Rh4+ 48. Ke3 Bc4 49. Ra3 Rh3+ 50. Kf4 Rd3 51. b4 Bb5 52.\nRa5 Bc4 53. Ra3 Ke7 54. Ke5 Kd7 55. Ra7+ Kc6 56. Kxe6 Rxc3 57. f4 Re3+ 58. Kf6\nRe4 59. f5 Rxd4 60. Ke5 Re4+ 61. Kf6 d4 62. Ra8 d3 63. Rd8 Bd5 64. b5+ Kc5 65.\nb6 d2 66. b7 d1=Q 67. b8=Q Qd4+ 68. Kg6 Rg4+ 69. Kh5 Rh4+ 70. Kg6 Qg4+ 71. Kf6\nRh6+ 72. Ke7 Qg7+ 73. Ke8 Rh8#",
          "neutral_tokens": {
            "prompt_tokens": 450,
            "completion_tokens": 606,
            "total_tokens": 1056,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rh8",
            "Ra1",
            "Bd3",
            "Kf4",
            "Rh4+",
            "Ke3",
            "Bc4",
            "Ra3",
            "Rh3+",
            "Kf4",
            "Rd3",
            "b4",
            "Bb5",
            "Ra5",
            "Bc4",
            "Ra3",
            "Ke7",
            "Ke5",
            "Kd7",
            "Ra7+",
            "Kc6",
            "Kxe6",
            "Rxc3",
            "f4",
            "Re3+",
            "Kf6",
            "Re4",
            "f5",
            "Rxd4",
            "Ke5",
            "Re4+",
            "Kf6",
            "d4",
            "Ra8",
            "d3",
            "Rd8",
            "Bd5",
            "b5+",
            "Kc5",
            "b6",
            "d2",
            "b7",
            "d1=Q",
            "b8=Q",
            "Qd4+",
            "Kg6",
            "Rg4+",
            "Kh5",
            "Rh4+",
            "Kg6",
            "Qg4+",
            "Kf6",
            "Rh6+",
            "Ke7",
            "Qg7+",
            "Ke8",
            "Rh8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f4g3",
          "positional_uci": "f4g3",
          "neutral_uci": "f4g3",
          "consensus_move": "f4g3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg2+",
              "Kf3",
              "bxa4",
              "Rxa4",
              "Rg7",
              "Ra1",
              "Bd3",
              "Ke3",
              "Bc4",
              "Ra3",
              "Rb7",
              "b4",
              "Rh7",
              "Ra8",
              "Rh3+",
              "Kd2",
              "Rf3",
              "Rf8+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d1=Q",
              "Kf2",
              "Qf3+",
              "Kg1",
              "Qe2",
              "Kh1",
              "Kf3",
              "Kg1",
              "Qg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rh8",
              "Ra1",
              "Bd3",
              "Kf4",
              "Rh4+",
              "Ke3",
              "Bc4",
              "Ra3",
              "Rh3+",
              "Kf4",
              "Rd3",
              "b4",
              "Bb5",
              "Ra5",
              "Bc4",
              "Ra3",
              "Ke7",
              "Ke5",
              "Kd7",
              "Ra7+",
              "Kc6",
              "Kxe6",
              "Rxc3",
              "f4",
              "Re3+",
              "Kf6",
              "Re4",
              "f5",
              "Rxd4",
              "Ke5",
              "Re4+",
              "Kf6",
              "d4",
              "Ra8",
              "d3",
              "Rd8",
              "Bd5",
              "b5+",
              "Kc5",
              "b6",
              "d2",
              "b7",
              "d1=Q",
              "b8=Q",
              "Qd4+",
              "Kg6",
              "Rg4+",
              "Kh5",
              "Rh4+",
              "Kg6",
              "Qg4+",
              "Kf6",
              "Rh6+",
              "Ke7",
              "Qg7+",
              "Ke8",
              "Rh8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 451,
            "completion_tokens": 518,
            "total_tokens": 969,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 451,
            "completion_tokens": 564,
            "total_tokens": 1015,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 450,
            "completion_tokens": 606,
            "total_tokens": 1056,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1352,
          "total_completion_tokens": 1688,
          "total_tokens": 3040
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 451,
            "completion_tokens": 518,
            "total_tokens": 969,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 451,
            "completion_tokens": 564,
            "total_tokens": 1015,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 450,
            "completion_tokens": 606,
            "total_tokens": 1056,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/1p1p4/P2P1K2/2P5/1P3P1r/5b2 w - - 1 42"
    },
    {
      "turn": 85,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8",
          "aggressive_uci": null,
          "aggressive_response": "Re8 Rg8+ Kh7",
          "aggressive_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8+ Kh7",
          "positional_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8+ Kh7 Rg7+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh",
          "neutral_tokens": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8+",
            "Kh7",
            "Rg7+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8+",
              "Kh7",
              "Rg7+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1376,
          "total_completion_tokens": 656,
          "total_tokens": 2032
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/1p1p4/P2P4/2P3Kr/1P3P2/5b2 w - - 3 43"
    },
    {
      "turn": 85,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf4",
          "aggressive_uci": "g3f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Rc6 bxc3 45. bxc3 Rh4+ 46. Kg3 Rh3+ 47. Kf4 Rh2 48. Kg3 Rh3+ 49. Kf4 Rh2 50. Kg3 Rh3+ 51. Kf4 Rh2 52. Kg3 Rh3+ 53. Kf4 Rh2 54. Kg3 Rh3+ 55. Kf4 Rh2 56. Kg3 Rh3+ 57. Kf4 Rh2 58. Kg3 Rh3+ 59. Kf4 Rh2 60. Kg3 Rh3+ 61. Kf4 Rh2 62. Kg3 Rh3+ 63. Kf4 Rh2 64. Kg3 Rh3+ 65. Kf4 Rh2 66. Kg3 Rh3+ 67. Kf4 Rh2 68. Kg3 Rh3+ 69. Kf4 Rh2 70. Kg3 Rh3+ 71. Kf4 Rh2 72. Kg3 Rh3+ 73. Kf4 Rh2 74. Kg3 Rh3+ 75. Kf4 Rh2 76. Kg3 Rh3+ 77. Kf4 Rh2 78. Kg3 Rh3+",
          "aggressive_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 640,
            "total_tokens": 1099,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rh2",
            "Kg3",
            "Rh3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8+ Kh7",
          "positional_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8+ Kh7 Rf7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg",
          "neutral_tokens": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8+",
            "Kh7",
            "Rf7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3f4",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "g3f4",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rh2",
              "Kg3",
              "Rh3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8+",
              "Kh7",
              "Rf7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 459,
            "completion_tokens": 640,
            "total_tokens": 1099,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1376,
          "total_completion_tokens": 1288,
          "total_tokens": 2664
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 459,
            "completion_tokens": 640,
            "total_tokens": 1099,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/1p1p4/P2P4/2P3Kr/1P3P2/5b2 w - - 3 43"
    },
    {
      "turn": 87,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ra8",
          "aggressive_uci": "a6a8",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3 46. a5 Rc4 47. Ke3 Rc3+ 48. Kd2 Rd3+ 49. Ke1 Bg2 50. a6 Bf3 51. a7 Rd1#",
          "aggressive_tokens": {
            "prompt_tokens": 467,
            "completion_tokens": 423,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxc3",
            "bxc3",
            "Rxc3",
            "a5",
            "Rc4",
            "Ke3",
            "Rc3+",
            "Kd2",
            "Rd3+",
            "Ke1",
            "Bg2",
            "a6",
            "Bf3",
            "a7",
            "Rd1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra8",
          "positional_uci": "a6a8",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3\n46. a5 Ra3 47. Rf8+ Ke7 48. Ra8 Kd6 49. Rd8+ Kc7 50. Ra8 Kb7 51. Re8 Bh3 52.\nRh8 Bf5 53. Ke5 Rxa5 54. Rh1 Ra2 55. f4 Kc6 56. Rc1+ Rc2 57. Ra1 Re2+ 58. Kf6\nRe4 59. Ra6+ Kb5 60. Ra8 Rxf4 61. Ke5 Re4+ 62. Kd6 Rxd4 63. Rb8+ Kc4 64. Rc8+\nKd3 65. Ke5 Re4+ 66. Kf6 d4 67. Rc1 Kd2 68. Ra1 d3 69. Ra2+ Ke3 70. Ra3 Ke2\n71. Ra2+ d2 72. Rb2 Ke1 73. Rxd2 Kxd2 74. Kg5 Ke3 75. Kf6 Kf4 76. Ke7 Rd4 77.\nKf6 e5 78. Ke7 e4",
          "positional_tokens": {
            "prompt_tokens": 467,
            "completion_tokens": 640,
            "total_tokens": 1107,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxf4",
            "Ke5",
            "Re4+",
            "Kd6",
            "Rxd4",
            "Rb8+",
            "Kc4",
            "Rc8+",
            "Kd3",
            "Ke5",
            "Re4+",
            "Kf6",
            "d4",
            "Rc1",
            "Kd2",
            "Ra1",
            "d3",
            "Ra2+",
            "Ke3",
            "Ra3",
            "Ke2",
            "Ra2+",
            "d2",
            "Rb2",
            "Ke1",
            "Rxd2",
            "Kxd2",
            "Kg5",
            "Ke3",
            "Kf6",
            "Kf4",
            "Ke7",
            "Rd4",
            "Kf6",
            "e5",
            "Ke7",
            "e4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ra8",
          "neutral_uci": "a6a8",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3\n46. a5 Ra3 47. Rf8+ Ke7 48. Ra8 Kd6 49. Rd8+ Kc7 50. Ra8 Kb7 51. Re8 Bh3 52.\nRh8 Bf5 53. Ke5 Rxa5 54. Rh1 Ra2 55. f4 Kc6 56. Rc1+ Rc2 57. Ra1 Re2+ 58. Kf6\nRe4 59. Ra6+ Kb5 60. Ra8 Rxf4 61. Ke5 Re4+ 62. Kd6 Rxd4 63. Rb8+ Kc4 64. Rc8+\nKd3 65. Ke5 Rc4 66. Ra8 d4 67. Ra3+ Rc3 68. Ra4 Rc5+ 69. Kf4 Kc3 70. Ra3+ Kb4\n71. Ra1 d3 72. Ke3 Rc2 73. Rb1+ Kc3 74. Rb8 Re2+ 75. Kf3 Be4+ 76. Kf4 d2 77.\nRc8+ Kd3 78.",
          "neutral_tokens": {
            "prompt_tokens": 466,
            "completion_tokens": 640,
            "total_tokens": 1106,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Ra3+",
            "Rc3",
            "Ra4",
            "Rc5+",
            "Kf4",
            "Kc3",
            "Ra3+",
            "Kb4",
            "Ra1",
            "d3",
            "Ke3",
            "Rc2",
            "Rb1+",
            "Kc3",
            "Rb8",
            "Re2+",
            "Kf3",
            "Be4+",
            "Kf4",
            "d2",
            "Rc8+",
            "Kd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a6a8",
          "positional_uci": "a6a8",
          "neutral_uci": "a6a8",
          "consensus_move": "a6a8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "bxc3",
              "bxc3",
              "Rxc3",
              "a5",
              "Rc4",
              "Ke3",
              "Rc3+",
              "Kd2",
              "Rd3+",
              "Ke1",
              "Bg2",
              "a6",
              "Bf3",
              "a7",
              "Rd1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf4",
              "Ke5",
              "Re4+",
              "Kd6",
              "Rxd4",
              "Rb8+",
              "Kc4",
              "Rc8+",
              "Kd3",
              "Ke5",
              "Re4+",
              "Kf6",
              "d4",
              "Rc1",
              "Kd2",
              "Ra1",
              "d3",
              "Ra2+",
              "Ke3",
              "Ra3",
              "Ke2",
              "Ra2+",
              "d2",
              "Rb2",
              "Ke1",
              "Rxd2",
              "Kxd2",
              "Kg5",
              "Ke3",
              "Kf6",
              "Kf4",
              "Ke7",
              "Rd4",
              "Kf6",
              "e5",
              "Ke7",
              "e4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "Ra3+",
              "Rc3",
              "Ra4",
              "Rc5+",
              "Kf4",
              "Kc3",
              "Ra3+",
              "Kb4",
              "Ra1",
              "d3",
              "Ke3",
              "Rc2",
              "Rb1+",
              "Kc3",
              "Rb8",
              "Re2+",
              "Kf3",
              "Be4+",
              "Kf4",
              "d2",
              "Rc8+",
              "Kd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 467,
            "completion_tokens": 423,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 467,
            "completion_tokens": 640,
            "total_tokens": 1107,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 466,
            "completion_tokens": 640,
            "total_tokens": 1106,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1400,
          "total_completion_tokens": 1703,
          "total_tokens": 3103
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 467,
            "completion_tokens": 423,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 467,
            "completion_tokens": 640,
            "total_tokens": 1107,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 466,
            "completion_tokens": 640,
            "total_tokens": 1106,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/3p4/Pp1P1K2/2P4r/1P3P2/5b2 w - - 0 44"
    },
    {
      "turn": 89,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 dxe4",
          "aggressive_tokens": {
            "prompt_tokens": 475,
            "completion_tokens": 7,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "bxc3",
          "positional_uci": "b2c3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3 46. a5 Rc4 47. Ke3 Rc3+ 48. Kd2 Rd3+ 49. Ke1 Bg2 50. a6 Rxd4 51. a7 Re4+ 52. Kd2 Rd4+ 53. Ke3 Re4+ 54. Kd2 Rd4+ 55. Ke3 Re4+ 56. Kd2 Rd4+ 57. Ke3 Re4+ 58. Kd2 Rd4+ 59. Ke3 Re4+ 60. Kd2 Rd4+ 61. Ke3 Re4+ 62. Kd2 Rd4+ 63. Ke3 Re4+ 64. Kd2 Rd4+ 65. Ke3 Re4+ 66. Kd2 Rd4+ 67. Ke3 Re4+ 68. Kd2 Rd4+ 69. Ke3 Re4+ 70. Kd2 Rd4+ 71. Ke3 Re4+ 72. Kd2 Rd4+ 73. Ke3 Re4+ 74. Kd2 Rd4+ 75. Ke3 Re4+ 76. Kd2 Rd4+ 77. Ke",
          "positional_tokens": {
            "prompt_tokens": 475,
            "completion_tokens": 640,
            "total_tokens": 1115,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxc3",
            "a5",
            "Rc4",
            "Ke3",
            "Rc3+",
            "Kd2",
            "Rd3+",
            "Ke1",
            "Bg2",
            "a6",
            "Rxd4",
            "a7",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "bxc3",
          "neutral_uci": "b2c3",
          "neutral_response": "Re8+ Bxe8\n45. bxc3 Rxc3 46. a5 Ra3 47. a6 Bb5 48. a7 Bc6 49. Rf8+ Ke7 50. Rh8 Rxa7 51.\nRh7+ Kd6 52. Rxa7 Bb5 53. Kg5 Bd3 54. f4 Bf5 55. Kf6 Kc6 56. Ra6+ Kb5 57. Rxe6\nBxe6 58. Kxe6 Kc4 59. Ke5 Kd3 60. f5 Ke3 61. f6 Kf3 62. f7 Ke3 63. f8=Q Kd3 64.\nKxd5 Kc3 65. Qf3+ Kb4 66. Qd3 Ka5 67. Kc5 Ka4 68. Qh3 Ka5 69. Qa3# Kf3 Kd2\n70. Ke4 Ke2 71. Qb2+ Kf1 72. Kf3 Ke1 73. Qe2# Kd1 74. Qb2 Ke1 75. Qe2# Kd1\n76. Qb2 Ke1 77. Qe2# Kd1 78. Qb2 Ke1 79. Qe2# Kd1 80. Qb2 Ke1 81. Qe2# Kd1\n82. Qb2 Ke1 83. Qe2# Kd1 84. Qb2 Ke1 85. Qe2# Kd1 86. Qb2 Ke1 87. Qe2# Kd1\n88. Qb2 Ke1 89. Qe2# Kd1 90. Qb2 Ke1 91. Qe2# Kd1 92. Qb2 Ke1 93. Qe2# Kd1\n94. Qb2 Ke1 95. Qe2# Kd1 96. Qb2 Ke1 97. Qe2# Kd1 98. Qb2 Ke1 99. Qe2# Kd1\n100. Qb2 Ke1 101. Qe2# Kd1 102. Qb2 Ke1 103. Qe2# Kd1 104. Qb2 Ke1 105. Qe2# Kd1 106. Qb2 Ke1 107. Qe2# Kd1 108. Qb2 Ke1 109. Qe2# Kd1 110. Qb2 Ke1 111. Qe2# Kd1 112. Qb2 Ke1 113. Qe2# Kd1 114. Qb2 Ke1 115. Qe2# Kd1 116. Qb2 Ke1",
          "neutral_tokens": {
            "prompt_tokens": 474,
            "completion_tokens": 640,
            "total_tokens": 1114,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxc3",
            "a5",
            "Ra3",
            "a6",
            "Bb5",
            "a7",
            "Bc6",
            "Rf8+",
            "Ke7",
            "Rh8",
            "Rxa7",
            "Rh7+",
            "Kd6",
            "Rxa7",
            "Bb5",
            "Kg5",
            "Bd3",
            "f4",
            "Bf5",
            "Kf6",
            "Kc6",
            "Ra6+",
            "Kb5",
            "Rxe6",
            "Bxe6",
            "Kxe6",
            "Kc4",
            "Ke5",
            "Kd3",
            "f5",
            "Ke3",
            "f6",
            "Kf3",
            "f7",
            "Ke3",
            "f8=Q",
            "Kd3",
            "Kxd5",
            "Kc3",
            "Qf3+",
            "Kb4",
            "Qd3",
            "Ka5",
            "Kc5",
            "Ka4",
            "Qh3",
            "Ka5",
            "Qa3#",
            "Kf3",
            "Kd2",
            "Ke4",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Kf3",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "b2c3",
          "neutral_uci": "b2c3",
          "consensus_move": "b2c3",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "dxe4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxc3",
              "a5",
              "Rc4",
              "Ke3",
              "Rc3+",
              "Kd2",
              "Rd3+",
              "Ke1",
              "Bg2",
              "a6",
              "Rxd4",
              "a7",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxc3",
              "a5",
              "Ra3",
              "a6",
              "Bb5",
              "a7",
              "Bc6",
              "Rf8+",
              "Ke7",
              "Rh8",
              "Rxa7",
              "Rh7+",
              "Kd6",
              "Rxa7",
              "Bb5",
              "Kg5",
              "Bd3",
              "f4",
              "Bf5",
              "Kf6",
              "Kc6",
              "Ra6+",
              "Kb5",
              "Rxe6",
              "Bxe6",
              "Kxe6",
              "Kc4",
              "Ke5",
              "Kd3",
              "f5",
              "Ke3",
              "f6",
              "Kf3",
              "f7",
              "Ke3",
              "f8=Q",
              "Kd3",
              "Kxd5",
              "Kc3",
              "Qf3+",
              "Kb4",
              "Qd3",
              "Ka5",
              "Kc5",
              "Ka4",
              "Qh3",
              "Ka5",
              "Qa3#",
              "Kf3",
              "Kd2",
              "Ke4",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Kf3",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 475,
            "completion_tokens": 7,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 475,
            "completion_tokens": 640,
            "total_tokens": 1115,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 474,
            "completion_tokens": 640,
            "total_tokens": 1114,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1424,
          "total_completion_tokens": 1287,
          "total_tokens": 2711
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 475,
            "completion_tokens": 7,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 475,
            "completion_tokens": 640,
            "total_tokens": 1115,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 474,
            "completion_tokens": 640,
            "total_tokens": 1114,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P1K2/2p4r/1P3P2/5b2 w - - 0 45"
    },
    {
      "turn": 91,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4 Qg6 Qh6 Qxh6 gxh6 Rh8 g4 Bb7 Rh7 Rg1 Rxg5 Rxg5 Kxf6 Rg7 Be4 Rxc7 b5 Ra7 d5 Ra6 Bd3 Kd2 Bf1 Ke3 Rh7 Kf4 Rxh6 a4 Rh2 Kg3 Rh3+ Kf4 b4 Ra8 bxc3 bxc3 Rh4+ Kg3 Rh3+ Kf4 bxc3 Ra7 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+",
          "aggressive_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4",
            "Qg6",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Rh8",
            "g4",
            "Bb7",
            "Rh7",
            "Rg1",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Ra6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6",
            "a4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "b4",
            "Ra8",
            "bxc3",
            "bxc3",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kf4",
            "bxc3",
            "Ra7",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4 Qg6 Qh6 Qxh6 gxh6 Rh8 Bb7 Rh7 Ke8 g4 a6 Rf6 Ke7 Rg6 Rxg5 Rxg5 Kxf6 Rg7 Be4 Rxc7 b5 a4 bxc3 bxc3 Rh4 Kg3 Rh6 f4 Rh1 a5 Rg1+ Kf2 Rh1 a6 Rg1 a7 Rg2+ Ke3 Rg3+ Kd2 Rg2+ Kc1 Rg1+ Kb2 Rg2+ Kb3 Rg3 a8=Q Rg1 Qf8+ Kg2 Qf7+ Kh3 Qf3+ Kh4 Qf4+ Kh5 Qf5+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf",
          "positional_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4",
            "Qg6",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Rh8",
            "Bb7",
            "Rh7",
            "Ke8",
            "g4",
            "a6",
            "Rf6",
            "Ke7",
            "Rg6",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "a4",
            "bxc3",
            "bxc3",
            "Rh4",
            "Kg3",
            "Rh6",
            "f4",
            "Rh1",
            "a5",
            "Rg1+",
            "Kf2",
            "Rh1",
            "a6",
            "Rg1",
            "a7",
            "Rg2+",
            "Ke3",
            "Rg3+",
            "Kd2",
            "Rg2+",
            "Kc1",
            "Rg1+",
            "Kb2",
            "Rg2+",
            "Kb3",
            "Rg3",
            "a8=Q",
            "Rg1",
            "Qf8+",
            "Kg2",
            "Qf7+",
            "Kh3",
            "Qf3+",
            "Kh4",
            "Qf4+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg3",
          "neutral_uci": "f4g3",
          "neutral_response": "46. Kg3 Rh3+ 47. Kf4 Rxc3 48. a5 Ra3 49. Ra7 Ra4 50. Ke3 Ra3+ 51. Kf4 Be2 52.\nRa8 Rf3+ 53. Kg4 Rxf2+ 54. Kg3 Rf3+ 55. Kg2 Ra3 56. Kf2 Bc4 57. Ke1 Kf5 58.\nKd2 Ke4 59. Re8 Kxd4 60. Rxe6 Ra2+ 61. Kc1 Kc3 62. Kb1 Rxa5 63. Re3+ Bd3+ 64.\nRxd3+ Kxd3 65. Kb2 Rb5+ 66. Ka3 Kc4 67. Ka4 d4 68. Ka3 d3 69. Ka2 d2 70. Ka3\nd1=Q 71. Ka2 Qa4# d4 d3 d2",
          "neutral_tokens": {
            "prompt_tokens": 483,
            "completion_tokens": 222,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rf3+",
            "Kg2",
            "Ra3",
            "Kf2",
            "Bc4",
            "Ke1",
            "Kf5",
            "Kd2",
            "Ke4",
            "Re8",
            "Kxd4",
            "Rxe6",
            "Ra2+",
            "Kc1",
            "Kc3",
            "Kb1",
            "Rxa5",
            "Re3+",
            "Bd3+",
            "Rxd3+",
            "Kxd3",
            "Kb2",
            "Rb5+",
            "Ka3",
            "Kc4",
            "Ka4",
            "d4",
            "Ka3",
            "d3",
            "Ka2",
            "d2",
            "Ka3",
            "d1=Q",
            "Ka2",
            "Qa4#",
            "d4",
            "d3",
            "d2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "f4g3",
          "consensus_move": "f4g3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4",
              "Qg6",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Rh8",
              "g4",
              "Bb7",
              "Rh7",
              "Rg1",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Ra6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6",
              "a4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "b4",
              "Ra8",
              "bxc3",
              "bxc3",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kf4",
              "bxc3",
              "Ra7",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4",
              "Qg6",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Rh8",
              "Bb7",
              "Rh7",
              "Ke8",
              "g4",
              "a6",
              "Rf6",
              "Ke7",
              "Rg6",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "a4",
              "bxc3",
              "bxc3",
              "Rh4",
              "Kg3",
              "Rh6",
              "f4",
              "Rh1",
              "a5",
              "Rg1+",
              "Kf2",
              "Rh1",
              "a6",
              "Rg1",
              "a7",
              "Rg2+",
              "Ke3",
              "Rg3+",
              "Kd2",
              "Rg2+",
              "Kc1",
              "Rg1+",
              "Kb2",
              "Rg2+",
              "Kb3",
              "Rg3",
              "a8=Q",
              "Rg1",
              "Qf8+",
              "Kg2",
              "Qf7+",
              "Kh3",
              "Qf3+",
              "Kh4",
              "Qf4+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rf3+",
              "Kg2",
              "Ra3",
              "Kf2",
              "Bc4",
              "Ke1",
              "Kf5",
              "Kd2",
              "Ke4",
              "Re8",
              "Kxd4",
              "Rxe6",
              "Ra2+",
              "Kc1",
              "Kc3",
              "Kb1",
              "Rxa5",
              "Re3+",
              "Bd3+",
              "Rxd3+",
              "Kxd3",
              "Kb2",
              "Rb5+",
              "Ka3",
              "Kc4",
              "Ka4",
              "d4",
              "Ka3",
              "d3",
              "Ka2",
              "d2",
              "Ka3",
              "d1=Q",
              "Ka2",
              "Qa4#",
              "d4",
              "d3",
              "d2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 483,
            "completion_tokens": 222,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1451,
          "total_completion_tokens": 1502,
          "total_tokens": 2953
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 483,
            "completion_tokens": 222,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P1K1r/2P5/5P2/5b2 w - - 1 46"
    },
    {
      "turn": 93,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf4",
          "aggressive_uci": "g3f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kf4 Rxc3 48. a5 Rc4 49. Ke3 Rc3+ 50. Kf4 Ra3 51. Ra7 Ra4 52.\nKe3 Ra3+ 53. Kf4 Ra4 54. Ke3 Ra3+ 55. Kf4 Ra4 56. Ke3 Ra3+ 57. Kf4 Ra4 58. Ke3 Ra3+ 59. Kf4 Ra4 60. Ke3 Ra3+ 61. Kf4 Ra4 62. Ke3 Ra3+ 63. Kf4 Ra4 64. Ke3 Ra3+ 65. Kf4 Ra4 66. Ke3 Ra3+ 67. Kf4 Ra4 68. Ke3 Ra3+ 69. Kf4 Ra4 70. Ke3 Ra3+ 71. Kf4 Ra4 72. Ke3 Ra3+ 73. Kf4 Ra4 74. Ke3 Ra3+ 75. Kf4 Ra4 76. Ke3 Ra3+ 77. Kf4 Ra4 78. Ke3 Ra3+ 79.",
          "aggressive_tokens": {
            "prompt_tokens": 491,
            "completion_tokens": 640,
            "total_tokens": 1131,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ra4",
            "Ke3",
            "Ra3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8+ Kh7",
          "positional_tokens": {
            "prompt_tokens": 491,
            "completion_tokens": 8,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg4",
          "neutral_uci": "g3g4",
          "neutral_response": "47. Kg4 Rxc3 48. a5 Be2+ 49. Kh4 Kf5 50. Rf8+ Ke4 51. Re8 Kxd4 52. Rxe6 Bf1 53. a6 Ra3 54. f4 Rxa6 55. Rxa6 Bxa6 56. f5 Ke5 57. Kg5 d4 58. f6 Bc4 59. Kg6 d3 60. f7 Bxf7+ 61. Kxf7 d2 62. Ke7 d1=Q 63. Kf7 Qd7+ 64. Kg6 Qe7 65. Kh6 Kf5 66. Kh5 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 490,
            "completion_tokens": 164,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc3",
            "a5",
            "Be2+",
            "Kh4",
            "Kf5",
            "Rf8+",
            "Ke4",
            "Re8",
            "Kxd4",
            "Rxe6",
            "Bf1",
            "a6",
            "Ra3",
            "f4",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "f5",
            "Ke5",
            "Kg5",
            "d4",
            "f6",
            "Bc4",
            "Kg6",
            "d3",
            "f7",
            "Bxf7+",
            "Kxf7",
            "d2",
            "Ke7",
            "d1=Q",
            "Kf7",
            "Qd7+",
            "Kg6",
            "Qe7",
            "Kh6",
            "Kf5",
            "Kh5",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3f4",
          "positional_uci": null,
          "neutral_uci": "g3g4",
          "consensus_move": "g3g4",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ra4",
              "Ke3",
              "Ra3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxc3",
              "a5",
              "Be2+",
              "Kh4",
              "Kf5",
              "Rf8+",
              "Ke4",
              "Re8",
              "Kxd4",
              "Rxe6",
              "Bf1",
              "a6",
              "Ra3",
              "f4",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "f5",
              "Ke5",
              "Kg5",
              "d4",
              "f6",
              "Bc4",
              "Kg6",
              "d3",
              "f7",
              "Bxf7+",
              "Kxf7",
              "d2",
              "Ke7",
              "d1=Q",
              "Kf7",
              "Qd7+",
              "Kg6",
              "Qe7",
              "Kh6",
              "Kf5",
              "Kh5",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 491,
            "completion_tokens": 640,
            "total_tokens": 1131,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 491,
            "completion_tokens": 8,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 490,
            "completion_tokens": 164,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1472,
          "total_completion_tokens": 812,
          "total_tokens": 2284
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 491,
            "completion_tokens": 640,
            "total_tokens": 1131,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 491,
            "completion_tokens": 8,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 490,
            "completion_tokens": 164,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P4/2P3Kr/5P2/5b2 w - - 3 47"
    },
    {
      "turn": 95,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf8+",
          "aggressive_uci": "a8f8",
          "aggressive_response": "48. Rf8+ Ke7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1\n52. Ke3 Rxa4 53. Kd3 Kd6 54. f4 Ra1 55. Ke3 Rd1 56. Ke2 Rc1 57. Kd2 Rf1 58.\nKe3 Kc6 59. Ke2 Rxf4 60. Ke3 Rf1 61. Ke2 Rc1 62. Kd2 Rf1 63. Ke2 Rf8 64. Ke3\nKb5 65. Kd3 Rf3+ 66. Kd2 Kc4 67. Ke2 Rxc3 68. Kd2 Kxd4 69. Ke2 Rd3 70. Kf2\nRe3 71. Kg2 Ke4 72. Kf2 d4 73. Kg2 d3 74. Kf2 d2 75. Kg2 d1=Q 76. Kf2 Qd2+ 77.\nKf1 Re1# d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ng5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4+ Kd7 Qh6 Bb7 Qh7+ Qxh7 Rxh7+ Kc6 Be4+ d5 Bf3 Rf6 Re1 Re8 Nxh7 Rf5 Bg4 Rf4 Rxe6+ Rxe6 Bxe6 Kd6 Bg4 Bc6 f4 Bd7 Bxd7 Kxd7 g4 Ke6 Ke3 Kf6 Kf3 Kg6 Kg3 Kxh7 Kh4 Kg6 f5+ Kf6 Kh5 c5 Kh6 cxd4 cxd4 b5 g5+ Kxf5 g6 d3 g7 d2 g8=Q d1=Q Qf8+ Ke5 Qe8+ Kd4 Qh8+ Kc4 Qxa1 Qd5 Qxa7+ Kc3 Qa3+ b4 Qa4+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc",
          "aggressive_tokens": {
            "prompt_tokens": 498,
            "completion_tokens": 640,
            "total_tokens": 1138,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4+",
            "Kd7",
            "Qh6",
            "Bb7",
            "Qh7+",
            "Qxh7",
            "Rxh7+",
            "Kc6",
            "Be4+",
            "d5",
            "Bf3",
            "Rf6",
            "Re1",
            "Re8",
            "Nxh7",
            "Rf5",
            "Bg4",
            "Rf4",
            "Rxe6+",
            "Rxe6",
            "Bxe6",
            "Kd6",
            "Bg4",
            "Bc6",
            "f4",
            "Bd7",
            "Bxd7",
            "Kxd7",
            "g4",
            "Ke6",
            "Ke3",
            "Kf6",
            "Kf3",
            "Kg6",
            "Kg3",
            "Kxh7",
            "Kh4",
            "Kg6",
            "f5+",
            "Kf6",
            "Kh5",
            "c5",
            "Kh6",
            "cxd4",
            "cxd4",
            "b5",
            "g5+",
            "Kxf5",
            "g6",
            "d3",
            "g7",
            "d2",
            "g8=Q",
            "d1=Q",
            "Qf8+",
            "Ke5",
            "Qe8+",
            "Kd4",
            "Qh8+",
            "Kc4",
            "Qxa1",
            "Qd5",
            "Qxa7+",
            "Kc3",
            "Qa3+",
            "b4",
            "Qa4+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf8+",
          "positional_uci": "a8f8",
          "positional_response": "48. Rf8+ Ke7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52. Ke3 Rxa4 53. Kd3 Kd6 54. f4\nRa3 55. Kc2 Kc6 56. Kb2 Ra8 57. Kb3 Kb5 58. Kc2 Kc4 59. Kd2 Ra2+ 60. Ke3 Kxc3\n61. Kf3 Kxd4 62. Kg4 Ke4 63. Kg5 Rg2+ 64. Kf6 Kxf4 65. Kxe6 d4 66. Kd5 d3\n67. Kc4 d2 68. Kc3 d1=Q 69. Kc4 Rc2+ 70. Kb3 Qb1+ 71. Ka3 Ra2#",
          "positional_tokens": {
            "prompt_tokens": 498,
            "completion_tokens": 201,
            "total_tokens": 699,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "Rf3",
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kd6",
            "f4",
            "Ra3",
            "Kc2",
            "Kc6",
            "Kb2",
            "Ra8",
            "Kb3",
            "Kb5",
            "Kc2",
            "Kc4",
            "Kd2",
            "Ra2+",
            "Ke3",
            "Kxc3",
            "Kf3",
            "Kxd4",
            "Kg4",
            "Ke4",
            "Kg5",
            "Rg2+",
            "Kf6",
            "Kxf4",
            "Kxe6",
            "d4",
            "Kd5",
            "d3",
            "Kc4",
            "d2",
            "Kc3",
            "d1=Q",
            "Kc4",
            "Rc2+",
            "Kb3",
            "Qb1+",
            "Ka3",
            "Ra2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a5",
          "neutral_uci": "a4a5",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. a5 Be2+ 49. Kg3 Ra1 50. Kf4 Ra3 51. Rf8+ Ke7 52.\nRa8 Rxc3 53. a6 Ra3 54. a7 Kf7 55. Ke5 Ra6 56. f4 Bd3 57. f5 Bxf5 58. Kf4\nKg7 59. Ke5 Bg4 60. Kf4 Bh5 61. Ke5 Bf7 62. Kf4 Kf6 63. Ke3 Ra3+ 64. Kf4 Bg6\n65. Rf8+ Ke7 66. a8=Q Rxa8 67. Rxa8 Kd6 68. Ra6+ Kd7 69. Ke5 Bf5 70. Ra7+ Kc6\n71. Ra6+ Kb5 72. Rxe6 Bxe6 73. Kxe6 Kc4 74. Ke5 Kb5 75. Kxd5 Kb6 76. Kd6 Kb7\n77. Kd7 Kb6 78.",
          "neutral_tokens": {
            "prompt_tokens": 497,
            "completion_tokens": 640,
            "total_tokens": 1137,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be2+",
            "Kg3",
            "Ra1",
            "Kf4",
            "Ra3",
            "Rf8+",
            "Ke7",
            "Ra8",
            "Rxc3",
            "a6",
            "Ra3",
            "a7",
            "Kf7",
            "Ke5",
            "Ra6",
            "f4",
            "Bd3",
            "f5",
            "Bxf5",
            "Kf4",
            "Kg7",
            "Ke5",
            "Bg4",
            "Kf4",
            "Bh5",
            "Ke5",
            "Bf7",
            "Kf4",
            "Kf6",
            "Ke3",
            "Ra3+",
            "Kf4",
            "Bg6",
            "Rf8+",
            "Ke7",
            "a8=Q",
            "Rxa8",
            "Rxa8",
            "Kd6",
            "Ra6+",
            "Kd7",
            "Ke5",
            "Bf5",
            "Ra7+",
            "Kc6",
            "Ra6+",
            "Kb5",
            "Rxe6",
            "Bxe6",
            "Kxe6",
            "Kc4",
            "Ke5",
            "Kb5",
            "Kxd5",
            "Kb6",
            "Kd6",
            "Kb7",
            "Kd7",
            "Kb6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a8f8",
          "positional_uci": "a8f8",
          "neutral_uci": "a4a5",
          "consensus_move": "a8f8",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4+",
              "Kd7",
              "Qh6",
              "Bb7",
              "Qh7+",
              "Qxh7",
              "Rxh7+",
              "Kc6",
              "Be4+",
              "d5",
              "Bf3",
              "Rf6",
              "Re1",
              "Re8",
              "Nxh7",
              "Rf5",
              "Bg4",
              "Rf4",
              "Rxe6+",
              "Rxe6",
              "Bxe6",
              "Kd6",
              "Bg4",
              "Bc6",
              "f4",
              "Bd7",
              "Bxd7",
              "Kxd7",
              "g4",
              "Ke6",
              "Ke3",
              "Kf6",
              "Kf3",
              "Kg6",
              "Kg3",
              "Kxh7",
              "Kh4",
              "Kg6",
              "f5+",
              "Kf6",
              "Kh5",
              "c5",
              "Kh6",
              "cxd4",
              "cxd4",
              "b5",
              "g5+",
              "Kxf5",
              "g6",
              "d3",
              "g7",
              "d2",
              "g8=Q",
              "d1=Q",
              "Qf8+",
              "Ke5",
              "Qe8+",
              "Kd4",
              "Qh8+",
              "Kc4",
              "Qxa1",
              "Qd5",
              "Qxa7+",
              "Kc3",
              "Qa3+",
              "b4",
              "Qa4+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "Rf3",
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kd6",
              "f4",
              "Ra3",
              "Kc2",
              "Kc6",
              "Kb2",
              "Ra8",
              "Kb3",
              "Kb5",
              "Kc2",
              "Kc4",
              "Kd2",
              "Ra2+",
              "Ke3",
              "Kxc3",
              "Kf3",
              "Kxd4",
              "Kg4",
              "Ke4",
              "Kg5",
              "Rg2+",
              "Kf6",
              "Kxf4",
              "Kxe6",
              "d4",
              "Kd5",
              "d3",
              "Kc4",
              "d2",
              "Kc3",
              "d1=Q",
              "Kc4",
              "Rc2+",
              "Kb3",
              "Qb1+",
              "Ka3",
              "Ra2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be2+",
              "Kg3",
              "Ra1",
              "Kf4",
              "Ra3",
              "Rf8+",
              "Ke7",
              "Ra8",
              "Rxc3",
              "a6",
              "Ra3",
              "a7",
              "Kf7",
              "Ke5",
              "Ra6",
              "f4",
              "Bd3",
              "f5",
              "Bxf5",
              "Kf4",
              "Kg7",
              "Ke5",
              "Bg4",
              "Kf4",
              "Bh5",
              "Ke5",
              "Bf7",
              "Kf4",
              "Kf6",
              "Ke3",
              "Ra3+",
              "Kf4",
              "Bg6",
              "Rf8+",
              "Ke7",
              "a8=Q",
              "Rxa8",
              "Rxa8",
              "Kd6",
              "Ra6+",
              "Kd7",
              "Ke5",
              "Bf5",
              "Ra7+",
              "Kc6",
              "Ra6+",
              "Kb5",
              "Rxe6",
              "Bxe6",
              "Kxe6",
              "Kc4",
              "Ke5",
              "Kb5",
              "Kxd5",
              "Kb6",
              "Kd6",
              "Kb7",
              "Kd7",
              "Kb6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 498,
            "completion_tokens": 640,
            "total_tokens": 1138,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 498,
            "completion_tokens": 201,
            "total_tokens": 699,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 497,
            "completion_tokens": 640,
            "total_tokens": 1137,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1493,
          "total_completion_tokens": 1481,
          "total_tokens": 2974
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 498,
            "completion_tokens": 640,
            "total_tokens": 1138,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 498,
            "completion_tokens": 201,
            "total_tokens": 699,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 497,
            "completion_tokens": 640,
            "total_tokens": 1137,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P2K1/2P5/5P2/5b1r w - - 5 48"
    },
    {
      "turn": 97,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf3",
          "aggressive_uci": "f8f3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kb2\nKe3 59. Kc2 Ke2 60. Kb3 Kd3 61. Kb2 Rxc3 62. Kb1 Kxd4 63. Kb2 Kc4 64. Kb1 Kb3 65.\nKa1 Rc1#",
          "aggressive_tokens": {
            "prompt_tokens": 507,
            "completion_tokens": 535,
            "total_tokens": 1042,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kb2",
            "Ke3",
            "Kc2",
            "Ke2",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf3",
          "positional_uci": "f8f3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kc2\nKe3 59. Kb3 Kd3 60. Kb2 Rxc3 61. Kb1 Kxd4 62. Kb2 Kc4 63. Kb1 Kb3 64. Ka1 Rc1#",
          "positional_tokens": {
            "prompt_tokens": 507,
            "completion_tokens": 528,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kc2",
            "Ke3",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rf3",
          "neutral_uci": "f8f3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kc2\nKe3 59. Kb3 Kd3 60. Kb2 Rxc3 61. Kb1 Kxd4 62. Kb2 Kc4 63. Kb1 Kb3 64. Ka1 Rc1#",
          "neutral_tokens": {
            "prompt_tokens": 506,
            "completion_tokens": 528,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kc2",
            "Ke3",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8f3",
          "positional_uci": "f8f3",
          "neutral_uci": "f8f3",
          "consensus_move": "f8f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kb2",
              "Ke3",
              "Kc2",
              "Ke2",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kc2",
              "Ke3",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kc2",
              "Ke3",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 507,
            "completion_tokens": 535,
            "total_tokens": 1042,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 507,
            "completion_tokens": 528,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 506,
            "completion_tokens": 528,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1520,
          "total_completion_tokens": 1591,
          "total_tokens": 3111
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 507,
            "completion_tokens": 535,
            "total_tokens": 1042,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 507,
            "completion_tokens": 528,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 506,
            "completion_tokens": 528,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5R2/6k1/4p3/3p4/P2P2K1/2P5/5P2/5b1r w - - 7 49"
    },
    {
      "turn": 99,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg3",
          "aggressive_uci": "g4g3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kc2\nKe3 59. Kb3 Kd3 60. Kb2 Rxc3 61. Kb1 Kxd4 62. Kb2 Kc4 63. Kb1 Kb3 64. Ka1 Rc1#",
          "aggressive_tokens": {
            "prompt_tokens": 515,
            "completion_tokens": 528,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kc2",
            "Ke3",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg3",
          "positional_uci": "g4g3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Ra2 55. f3 Kf5 56. c4 Ra3+ 57. Ke2 dxc4 58. Kd2\nRxf3 59. Ke2 Ke4 60. Kd2 Kxd4 61. Ke2 Rf4 62. Kd2 Rf2+ 63. Ke1 Ke3 64. Kd1 Kd3\n65. Ke1 Rf3 66. Kd1 Rf1#",
          "positional_tokens": {
            "prompt_tokens": 515,
            "completion_tokens": 549,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Ra2",
            "f3",
            "Kf5",
            "c4",
            "Ra3+",
            "Ke2",
            "dxc4",
            "Kd2",
            "Rxf3",
            "Ke2",
            "Ke4",
            "Kd2",
            "Kxd4",
            "Ke2",
            "Rf4",
            "Kd2",
            "Rf2+",
            "Ke1",
            "Ke3",
            "Kd1",
            "Kd3",
            "Ke1",
            "Rf3",
            "Kd1",
            "Rf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": null,
          "neutral_response": "Re8+ Kf7 Rf8+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+",
          "neutral_tokens": {
            "prompt_tokens": 514,
            "completion_tokens": 640,
            "total_tokens": 1154,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf7",
            "Rf8+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4g3",
          "positional_uci": "g4g3",
          "neutral_uci": null,
          "consensus_move": "g4g3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kc2",
              "Ke3",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Ra2",
              "f3",
              "Kf5",
              "c4",
              "Ra3+",
              "Ke2",
              "dxc4",
              "Kd2",
              "Rxf3",
              "Ke2",
              "Ke4",
              "Kd2",
              "Kxd4",
              "Ke2",
              "Rf4",
              "Kd2",
              "Rf2+",
              "Ke1",
              "Ke3",
              "Kd1",
              "Kd3",
              "Ke1",
              "Rf3",
              "Kd1",
              "Rf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf7",
              "Rf8+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 515,
            "completion_tokens": 528,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 515,
            "completion_tokens": 549,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 514,
            "completion_tokens": 640,
            "total_tokens": 1154,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1544,
          "total_completion_tokens": 1717,
          "total_tokens": 3261
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 515,
            "completion_tokens": 528,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 515,
            "completion_tokens": 549,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 514,
            "completion_tokens": 640,
            "total_tokens": 1154,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/6k1/4p3/3p4/P2P2K1/2P2R2/4bP2/7r w - - 9 50"
    },
    {
      "turn": 101,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 Nf3 Nc6 Bb5 Bf5 Bxf6 gxf6 e5 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ne5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxh7 Rh8 Qh6 Qxh6 gxh6 Bb7 Rh5 d5 Bd3 Ke8 Rg3 Rxg5 Rxg5 Kxf6 Rg7 Be4 Rxc7 b5 Ra7 d5 Ra6 Bd3 Kd2 Bf1 Ke3 Rh7 Kf4 Rxh6 a4 Rh2 Kg3 Rh3+ Kf4 b4 Ra8 bxc3 bxc3 Rh4+ Kg3 Rh3+ Kg4 Rh1 Rf8+ Kg7 Rf3 Bf1 *",
          "aggressive_tokens": {
            "prompt_tokens": 524,
            "completion_tokens": 205,
            "total_tokens": 729,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bf5",
            "Bxf6",
            "gxf6",
            "e5",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Ne5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh8",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Bb7",
            "Rh5",
            "d5",
            "Bd3",
            "Ke8",
            "Rg3",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Ra6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6",
            "a4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "b4",
            "Ra8",
            "bxc3",
            "bxc3",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kg4",
            "Rh1",
            "Rf8+",
            "Kg7",
            "Rf3",
            "Bf1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh2",
          "positional_uci": "g3h2",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Rg1+ 51. Kh2 Bxf3 52. Kxg1 Be2 53. Kg2 Kf6 54. Kg3 Kf5 55. f3 Bd3 56. a5 Bc4 57. Kf2 Kf4 58. Kg2 Ke3 59. Kg3 Kd3 60. Kf4 Kxc3 61. Ke5 Kd3 62. Kxe6 Kxd4 63. f4 Ke4 64. f5 d4+ 65. Kd6 d3 66. f6 d2 67. Kc5 d1=Q 68. Kxc4 Qd5+ 69. Kb4 Kd4 70. a6 Qc5+ 71. Ka4 Kc4 72. f7 Qb4#",
          "positional_tokens": {
            "prompt_tokens": 524,
            "completion_tokens": 597,
            "total_tokens": 1121,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf3",
            "Kxg1",
            "Be2",
            "Kg2",
            "Kf6",
            "Kg3",
            "Kf5",
            "f3",
            "Bd3",
            "a5",
            "Bc4",
            "Kf2",
            "Kf4",
            "Kg2",
            "Ke3",
            "Kg3",
            "Kd3",
            "Kf4",
            "Kxc3",
            "Ke5",
            "Kd3",
            "Kxe6",
            "Kxd4",
            "f4",
            "Ke4",
            "f5",
            "d4+",
            "Kd6",
            "d3",
            "f6",
            "d2",
            "Kc5",
            "d1=Q",
            "Kxc4",
            "Qd5+",
            "Kb4",
            "Kd4",
            "a6",
            "Qc5+",
            "Ka4",
            "Kc4",
            "f7",
            "Qb4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": null,
          "neutral_response": "Re8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg",
          "neutral_tokens": {
            "prompt_tokens": 523,
            "completion_tokens": 640,
            "total_tokens": 1163,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g3h2",
          "neutral_uci": null,
          "consensus_move": "g3h2",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bf5",
              "Bxf6",
              "gxf6",
              "e5",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Ne5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh8",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Bb7",
              "Rh5",
              "d5",
              "Bd3",
              "Ke8",
              "Rg3",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Ra6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6",
              "a4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "b4",
              "Ra8",
              "bxc3",
              "bxc3",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kg4",
              "Rh1",
              "Rf8+",
              "Kg7",
              "Rf3",
              "Bf1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf3",
              "Kxg1",
              "Be2",
              "Kg2",
              "Kf6",
              "Kg3",
              "Kf5",
              "f3",
              "Bd3",
              "a5",
              "Bc4",
              "Kf2",
              "Kf4",
              "Kg2",
              "Ke3",
              "Kg3",
              "Kd3",
              "Kf4",
              "Kxc3",
              "Ke5",
              "Kd3",
              "Kxe6",
              "Kxd4",
              "f4",
              "Ke4",
              "f5",
              "d4+",
              "Kd6",
              "d3",
              "f6",
              "d2",
              "Kc5",
              "d1=Q",
              "Kxc4",
              "Qd5+",
              "Kb4",
              "Kd4",
              "a6",
              "Qc5+",
              "Ka4",
              "Kc4",
              "f7",
              "Qb4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 524,
            "completion_tokens": 205,
            "total_tokens": 729,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 524,
            "completion_tokens": 597,
            "total_tokens": 1121,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 523,
            "completion_tokens": 640,
            "total_tokens": 1163,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1571,
          "total_completion_tokens": 1442,
          "total_tokens": 3013
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 524,
            "completion_tokens": 205,
            "total_tokens": 729,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 524,
            "completion_tokens": 597,
            "total_tokens": 1121,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 523,
            "completion_tokens": 640,
            "total_tokens": 1163,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/6k1/4p3/3p4/P2P4/2P2RK1/4bP2/6r1 w - - 11 51"
    },
    {
      "turn": 103,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rg3",
          "aggressive_uci": "f3g3",
          "aggressive_response": "51... Rg6 52. Rg3 Rxg3 53. Kxg3 Kf6",
          "aggressive_tokens": {
            "prompt_tokens": 532,
            "completion_tokens": 25,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxg3",
            "Kxg3",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re3",
          "positional_uci": "f3e3",
          "positional_response": "52. Re3 Bc4 53. a5 Kf6 54. Rf3+ Ke7 55. Rg3 Rf6 56. Kg2 Kd6 57. Rg8 Kc6 58.\nRb8 Rf7 59. Rb6+ Kd7 60. Rb7+ Ke8 61. Rb8+ Ke7 62. Rb7+ Kf6 63. Rb6 Ra7 64.\na6 Rxa6 65. Rxa6 Bxa6 66. Kf3 Kf5 67. Ke3 Bc4 68. Kf3 Bb3 69. Ke3 Bd1 70. Kd2\nBf3 71. Ke3 Kg4 72. Kd2 Kf4 73. Kd3 Bg4 74. c4 Bf5+ 75. Kc3 Kf3 76. cxd5 exd5\n77. Kb4 Kxf2 78. Kc5 Be4 79. Kb4 Ke3 80. Kc3 Bf5 81. Kb2 Kxd4 82. Kc1 Kc3 83.\nKd1 d4 84. Kc1 d3 85. Kd1 Bg4+ 86. Ke1 d2+ 87. Kf2 d1=Q 88. Kg3 Qf3+ 89. Kh4\nBf5 90. Kg5 Be4 91. Kh4 Qg2 92. Kh5 Bf5 93. Kh6 Qg6#",
          "positional_tokens": {
            "prompt_tokens": 532,
            "completion_tokens": 361,
            "total_tokens": 893,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "a5",
            "Kf6",
            "Rf3+",
            "Ke7",
            "Rg3",
            "Rf6",
            "Kg2",
            "Kd6",
            "Rg8",
            "Kc6",
            "Rb8",
            "Rf7",
            "Rb6+",
            "Kd7",
            "Rb7+",
            "Ke8",
            "Rb8+",
            "Ke7",
            "Rb7+",
            "Kf6",
            "Rb6",
            "Ra7",
            "a6",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "Kf3",
            "Kf5",
            "Ke3",
            "Bc4",
            "Kf3",
            "Bb3",
            "Ke3",
            "Bd1",
            "Kd2",
            "Bf3",
            "Ke3",
            "Kg4",
            "Kd2",
            "Kf4",
            "Kd3",
            "Bg4",
            "c4",
            "Bf5+",
            "Kc3",
            "Kf3",
            "cxd5",
            "exd5",
            "Kb4",
            "Kxf2",
            "Kc5",
            "Be4",
            "Kb4",
            "Ke3",
            "Kc3",
            "Bf5",
            "Kb2",
            "Kxd4",
            "Kc1",
            "Kc3",
            "Kd1",
            "d4",
            "Kc1",
            "d3",
            "Kd1",
            "Bg4+",
            "Ke1",
            "d2+",
            "Kf2",
            "d1=Q",
            "Kg3",
            "Qf3+",
            "Kh4",
            "Bf5",
            "Kg5",
            "Be4",
            "Kh4",
            "Qg2",
            "Kh5",
            "Bf5",
            "Kh6",
            "Qg6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re3",
          "neutral_uci": "f3e3",
          "neutral_response": "51... Rg6 52. Re3 Bc4 53. a5 Kf7",
          "neutral_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 22,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "a5",
            "Kf7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3g3",
          "positional_uci": "f3e3",
          "neutral_uci": "f3e3",
          "consensus_move": "f3e3",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxg3",
              "Kxg3",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bc4",
              "a5",
              "Kf6",
              "Rf3+",
              "Ke7",
              "Rg3",
              "Rf6",
              "Kg2",
              "Kd6",
              "Rg8",
              "Kc6",
              "Rb8",
              "Rf7",
              "Rb6+",
              "Kd7",
              "Rb7+",
              "Ke8",
              "Rb8+",
              "Ke7",
              "Rb7+",
              "Kf6",
              "Rb6",
              "Ra7",
              "a6",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "Kf3",
              "Kf5",
              "Ke3",
              "Bc4",
              "Kf3",
              "Bb3",
              "Ke3",
              "Bd1",
              "Kd2",
              "Bf3",
              "Ke3",
              "Kg4",
              "Kd2",
              "Kf4",
              "Kd3",
              "Bg4",
              "c4",
              "Bf5+",
              "Kc3",
              "Kf3",
              "cxd5",
              "exd5",
              "Kb4",
              "Kxf2",
              "Kc5",
              "Be4",
              "Kb4",
              "Ke3",
              "Kc3",
              "Bf5",
              "Kb2",
              "Kxd4",
              "Kc1",
              "Kc3",
              "Kd1",
              "d4",
              "Kc1",
              "d3",
              "Kd1",
              "Bg4+",
              "Ke1",
              "d2+",
              "Kf2",
              "d1=Q",
              "Kg3",
              "Qf3+",
              "Kh4",
              "Bf5",
              "Kg5",
              "Be4",
              "Kh4",
              "Qg2",
              "Kh5",
              "Bf5",
              "Kh6",
              "Qg6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bc4",
              "a5",
              "Kf7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 532,
            "completion_tokens": 25,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 532,
            "completion_tokens": 361,
            "total_tokens": 893,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 531,
            "completion_tokens": 22,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1595,
          "total_completion_tokens": 408,
          "total_tokens": 2003
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 532,
            "completion_tokens": 25,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 532,
            "completion_tokens": 361,
            "total_tokens": 893,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 531,
            "completion_tokens": 22,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6k1/4p1r1/3p4/P2P4/2P2R2/4bP1K/8 w - - 13 52"
    },
    {
      "turn": 105,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a5",
          "aggressive_uci": "a4a5",
          "aggressive_response": "53. a5 Kf6 54. Re1 Bf3 55. Rg1 Rh6+ 56. Kg3 Rg6+ 57. Kh2 Rxg1 58. Kxg1\nBe2 59. Kg2 Kf5 60. Kg3 Ke4 61. f4 Kd3 62. a6 Kxc3 63. a7 Kxd4 64. a8=Q Ke3 65.\nQa7+ Kd2 66. Qd4+ Bd3 67. Kf2 Kc2 68. Ke3 Bf5 69. Qd2+ Kb3 70. Kd4 Ka4 71. Qb2\nKa5 72. Kc5 Ka6 73. Qb6# Kd7 74. Qb7+ Ke8 75. Kd6 Kf8 76. Ke5 Kg8 77. Kf6 Kh8\n78. Qg7# Kd8 79. Qe7+ Kc8 80. Ke5 Kb8 81. Kd6 Ka8 82. Kc6 Kb8 83. Qb7# Kc8\n84. Qc7# Kd8 85. Kd6 Ke8 86. Qe7# Kf8 87. Ke5 Kg8 88. Kf6 Kh8 89. Qg7# Kg8\n90. Qg5+ Kf8 91. Qg7+ Ke8 92. Qe7# Kd8 93. Ke5 Kc8 94. Kd6 Kb8 95. Kc6 Ka8\n96. Qb7# Kd8 97. Qd7# Kc8 98. Qc7# Kd8 99. Qd7# Kc8 100. Qc7# Kd8 101. Qd7# Kc8 102. Qc7# Kd8 103. Qd7# Kc8 104. Qc7# Kd8 105. Qd7# Kc8 106. Qc7# Kd8 107. Qd7# Kc8 108. Qc7# Kd8 109. Qd7# Kc8 110. Qc7# Kd8 111. Qd7# Kc8 112. Qc7# Kd8 113. Qd7# Kc8 114. Qc7# Kd8 115. Qd7# Kc8 116. Qc7# Kd8 117. Qd7# Kc8 118. Qc7# Kd8 119. Qd7# Kc8 120. Qc7# Kd8 121. Qd7# Kc8 122. Qc7# Kd",
          "aggressive_tokens": {
            "prompt_tokens": 539,
            "completion_tokens": 640,
            "total_tokens": 1179,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf6",
            "Re1",
            "Bf3",
            "Rg1",
            "Rh6+",
            "Kg3",
            "Rg6+",
            "Kh2",
            "Rxg1",
            "Kxg1",
            "Be2",
            "Kg2",
            "Kf5",
            "Kg3",
            "Ke4",
            "f4",
            "Kd3",
            "a6",
            "Kxc3",
            "a7",
            "Kxd4",
            "a8=Q",
            "Ke3",
            "Qa7+",
            "Kd2",
            "Qd4+",
            "Bd3",
            "Kf2",
            "Kc2",
            "Ke3",
            "Bf5",
            "Qd2+",
            "Kb3",
            "Kd4",
            "Ka4",
            "Qb2",
            "Ka5",
            "Kc5",
            "Ka6",
            "Qb6#",
            "Kd7",
            "Qb7+",
            "Ke8",
            "Kd6",
            "Kf8",
            "Ke5",
            "Kg8",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kd8",
            "Qe7+",
            "Kc8",
            "Ke5",
            "Kb8",
            "Kd6",
            "Ka8",
            "Kc6",
            "Kb8",
            "Qb7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Kd6",
            "Ke8",
            "Qe7#",
            "Kf8",
            "Ke5",
            "Kg8",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qg5+",
            "Kf8",
            "Qg7+",
            "Ke8",
            "Qe7#",
            "Kd8",
            "Ke5",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a5",
          "positional_uci": "a4a5",
          "positional_response": "53. a5 Kf6 54. Re1 Bf3 55. Re3 Be4 56. f3 Bf5 57. Re1 Rg7 58. Ra1 Bd3 59. Ra2\nKf5 60. Rg2 Rxg2+ 61. Kxg2 Kf4 62. Kf2 Bc4 63. Kg2 Ke3 64. Kg3 Kd3 65. Kf4\nKxc3 66. Ke5 Kd3 67. Kxe6 Kxd4 68. f4 Ke4 69. f5 d4+ 70. Kf6 d3 71. Kg6 d2 72.\nf6 d1=Q 73. f7 Qg4+ 74. Kf6 Qf5+ 75. Ke7 Qxf7+ 76. Kd6 Qd5+ 77. Kc7 Qxa5+ 78.\nKd6 Qd5+ 79. Kc7 Qe6 80. Kb7 Qd6 81. Ka7 Qc6 82. Kb8 Qd7 83. Ka8 Bd5+ 84. Kb8\nQb7# d4 e5 dxe5",
          "positional_tokens": {
            "prompt_tokens": 539,
            "completion_tokens": 281,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf6",
            "Re1",
            "Bf3",
            "Re3",
            "Be4",
            "f3",
            "Bf5",
            "Re1",
            "Rg7",
            "Ra1",
            "Bd3",
            "Ra2",
            "Kf5",
            "Rg2",
            "Rxg2+",
            "Kxg2",
            "Kf4",
            "Kf2",
            "Bc4",
            "Kg2",
            "Ke3",
            "Kg3",
            "Kd3",
            "Kf4",
            "Kxc3",
            "Ke5",
            "Kd3",
            "Kxe6",
            "Kxd4",
            "f4",
            "Ke4",
            "f5",
            "d4+",
            "Kf6",
            "d3",
            "Kg6",
            "d2",
            "f6",
            "d1=Q",
            "f7",
            "Qg4+",
            "Kf6",
            "Qf5+",
            "Ke7",
            "Qxf7+",
            "Kd6",
            "Qd5+",
            "Kc7",
            "Qxa5+",
            "Kd6",
            "Qd5+",
            "Kc7",
            "Qe6",
            "Kb7",
            "Qd6",
            "Ka7",
            "Qc6",
            "Kb8",
            "Qd7",
            "Ka8",
            "Bd5+",
            "Kb8",
            "Qb7#",
            "d4",
            "e5",
            "dxe5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a5",
          "neutral_uci": "a4a5",
          "neutral_response": "53. a5 Kf6 54. Re1 Bf3 55. Rg1 Rh6+ 56. Kg3 Rg6+ 57. Kh2 Rxg1 58. Kxg1\nBe2 59. Kg2 Kf5 60. Kg3 Ke4 61. f4 Kd3 62. a6 Kxc3 63. a7 Kxd4 64. a8=Q Ke3 65.\nQa7+ Kd2 66. Qd4+ Bd3 67. Kf2 Kc2 68. Ke3 Bf5 69. Qd2+ Kb3 70. Kd4 Ka4 71. Qb2\nKa5 72. Kc5 Ka6 73. Qb6# Kd7 74. Qd6+ Ke8 75. Qc7 Kf8 76. Kd6 Kg8 77. Ke5 Kf8\n78. Kf6 Kg8 79. Qg7# Kd8 80. Ke5 Kc8 81. Kd6 Kb8 82. Kc6 Ka8 83. Qb7# Kd8\n84. Qd7# Kd8 85. Kd6 *",
          "neutral_tokens": {
            "prompt_tokens": 538,
            "completion_tokens": 283,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf6",
            "Re1",
            "Bf3",
            "Rg1",
            "Rh6+",
            "Kg3",
            "Rg6+",
            "Kh2",
            "Rxg1",
            "Kxg1",
            "Be2",
            "Kg2",
            "Kf5",
            "Kg3",
            "Ke4",
            "f4",
            "Kd3",
            "a6",
            "Kxc3",
            "a7",
            "Kxd4",
            "a8=Q",
            "Ke3",
            "Qa7+",
            "Kd2",
            "Qd4+",
            "Bd3",
            "Kf2",
            "Kc2",
            "Ke3",
            "Bf5",
            "Qd2+",
            "Kb3",
            "Kd4",
            "Ka4",
            "Qb2",
            "Ka5",
            "Kc5",
            "Ka6",
            "Qb6#",
            "Kd7",
            "Qd6+",
            "Ke8",
            "Qc7",
            "Kf8",
            "Kd6",
            "Kg8",
            "Ke5",
            "Kf8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Kd8",
            "Ke5",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Kd6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a4a5",
          "positional_uci": "a4a5",
          "neutral_uci": "a4a5",
          "consensus_move": "a4a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf6",
              "Re1",
              "Bf3",
              "Rg1",
              "Rh6+",
              "Kg3",
              "Rg6+",
              "Kh2",
              "Rxg1",
              "Kxg1",
              "Be2",
              "Kg2",
              "Kf5",
              "Kg3",
              "Ke4",
              "f4",
              "Kd3",
              "a6",
              "Kxc3",
              "a7",
              "Kxd4",
              "a8=Q",
              "Ke3",
              "Qa7+",
              "Kd2",
              "Qd4+",
              "Bd3",
              "Kf2",
              "Kc2",
              "Ke3",
              "Bf5",
              "Qd2+",
              "Kb3",
              "Kd4",
              "Ka4",
              "Qb2",
              "Ka5",
              "Kc5",
              "Ka6",
              "Qb6#",
              "Kd7",
              "Qb7+",
              "Ke8",
              "Kd6",
              "Kf8",
              "Ke5",
              "Kg8",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kd8",
              "Qe7+",
              "Kc8",
              "Ke5",
              "Kb8",
              "Kd6",
              "Ka8",
              "Kc6",
              "Kb8",
              "Qb7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Kd6",
              "Ke8",
              "Qe7#",
              "Kf8",
              "Ke5",
              "Kg8",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qg5+",
              "Kf8",
              "Qg7+",
              "Ke8",
              "Qe7#",
              "Kd8",
              "Ke5",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf6",
              "Re1",
              "Bf3",
              "Re3",
              "Be4",
              "f3",
              "Bf5",
              "Re1",
              "Rg7",
              "Ra1",
              "Bd3",
              "Ra2",
              "Kf5",
              "Rg2",
              "Rxg2+",
              "Kxg2",
              "Kf4",
              "Kf2",
              "Bc4",
              "Kg2",
              "Ke3",
              "Kg3",
              "Kd3",
              "Kf4",
              "Kxc3",
              "Ke5",
              "Kd3",
              "Kxe6",
              "Kxd4",
              "f4",
              "Ke4",
              "f5",
              "d4+",
              "Kf6",
              "d3",
              "Kg6",
              "d2",
              "f6",
              "d1=Q",
              "f7",
              "Qg4+",
              "Kf6",
              "Qf5+",
              "Ke7",
              "Qxf7+",
              "Kd6",
              "Qd5+",
              "Kc7",
              "Qxa5+",
              "Kd6",
              "Qd5+",
              "Kc7",
              "Qe6",
              "Kb7",
              "Qd6",
              "Ka7",
              "Qc6",
              "Kb8",
              "Qd7",
              "Ka8",
              "Bd5+",
              "Kb8",
              "Qb7#",
              "d4",
              "e5",
              "dxe5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf6",
              "Re1",
              "Bf3",
              "Rg1",
              "Rh6+",
              "Kg3",
              "Rg6+",
              "Kh2",
              "Rxg1",
              "Kxg1",
              "Be2",
              "Kg2",
              "Kf5",
              "Kg3",
              "Ke4",
              "f4",
              "Kd3",
              "a6",
              "Kxc3",
              "a7",
              "Kxd4",
              "a8=Q",
              "Ke3",
              "Qa7+",
              "Kd2",
              "Qd4+",
              "Bd3",
              "Kf2",
              "Kc2",
              "Ke3",
              "Bf5",
              "Qd2+",
              "Kb3",
              "Kd4",
              "Ka4",
              "Qb2",
              "Ka5",
              "Kc5",
              "Ka6",
              "Qb6#",
              "Kd7",
              "Qd6+",
              "Ke8",
              "Qc7",
              "Kf8",
              "Kd6",
              "Kg8",
              "Ke5",
              "Kf8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Kd8",
              "Ke5",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Kd6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 539,
            "completion_tokens": 640,
            "total_tokens": 1179,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 539,
            "completion_tokens": 281,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 538,
            "completion_tokens": 283,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1616,
          "total_completion_tokens": 1204,
          "total_tokens": 2820
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 104,
            "turn_number": 53,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 539,
            "completion_tokens": 640,
            "total_tokens": 1179,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 104,
            "turn_number": 53,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 539,
            "completion_tokens": 281,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 104,
            "turn_number": 53,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 538,
            "completion_tokens": 283,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6k1/4p1r1/3p4/P2P4/2P1R3/5P1K/3b4 w - - 15 53"
    },
    {
      "turn": 107,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 Nc3 Nf6 Bg5 e6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4\nNxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxh7 Bh6+ Ng5 Bxg5 hxg5 Qxh7 Rh8\nQh6 Qxh6 gxh6 Rxh6 Bg7 Bh6 Bh7 Bxg7 Bh6+ Kg8 b6 d5 b7 d4 b8=Q+ Kg7 Qb7+ Kg8 Qf7#",
          "aggressive_tokens": {
            "prompt_tokens": 547,
            "completion_tokens": 139,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "gxh6",
            "Rxh6",
            "Bg7",
            "Bh6",
            "Bh7",
            "Bxg7",
            "Bh6+",
            "Kg8",
            "b6",
            "d5",
            "b7",
            "d4",
            "b8=Q+",
            "Kg7",
            "Qb7+",
            "Kg8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a5a6",
          "positional_response": "54. a6 Rg7 55. Re1 Bf3 56. Ra1 Ra7 57. Kg3 Be2 58. Kf4 Rxa6 59. Rxa6 Bxa6 60. Kg4\nBe2+ 61. Kf4 Bd1 62. Ke3 Kf5 63. Kd2 Bb3 64. Ke3 Bc4 65. Kf3 Bd3 66. Ke3 Bc2 67.\nKf3 Bd1+ 68. Ke3 Kg4 69. Kd2 Bb3 70. Ke3 Bc4 71. f3+ Kg3 72. f4 Kg4 73. f5 exf5\n74. Kf2 f4 75. Kg2 f3+ 76. Kf2 Kf4 77. Ke1 Ke3 78. Kd1 f2 79. Kc2 f1=Q 80. Kb2\nQe2+ 81. Ka3 Qa2+ 82. Kb4 Qb3+ 83. Kc5 Qb5+ 84. Kd6 Qb6+ 85. Ke5 Qc7+ 86. Kf5\nQf7+ 87. Kg5 Qg7+ 88. Kf5 Qf7+ 89. Kg5 Ke4 90. Kg4 Qg6+ 91. Kh3 Kf3 92. Kh4 Qg4#",
          "positional_tokens": {
            "prompt_tokens": 547,
            "completion_tokens": 332,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg7",
            "Re1",
            "Bf3",
            "Ra1",
            "Ra7",
            "Kg3",
            "Be2",
            "Kf4",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "Kg4",
            "Be2+",
            "Kf4",
            "Bd1",
            "Ke3",
            "Kf5",
            "Kd2",
            "Bb3",
            "Ke3",
            "Bc4",
            "Kf3",
            "Bd3",
            "Ke3",
            "Bc2",
            "Kf3",
            "Bd1+",
            "Ke3",
            "Kg4",
            "Kd2",
            "Bb3",
            "Ke3",
            "Bc4",
            "f3+",
            "Kg3",
            "f4",
            "Kg4",
            "f5",
            "exf5",
            "Kf2",
            "f4",
            "Kg2",
            "f3+",
            "Kf2",
            "Kf4",
            "Ke1",
            "Ke3",
            "Kd1",
            "f2",
            "Kc2",
            "f1=Q",
            "Kb2",
            "Qe2+",
            "Ka3",
            "Qa2+",
            "Kb4",
            "Qb3+",
            "Kc5",
            "Qb5+",
            "Kd6",
            "Qb6+",
            "Ke5",
            "Qc7+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qg7+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Ke4",
            "Kg4",
            "Qg6+",
            "Kh3",
            "Kf3",
            "Kh4",
            "Qg4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a5a6",
          "neutral_response": "54. a6 Rg7 55. Re1 Bf3 56. Ra1 Ra7 57. Kg3 Be2 58. Kf4 Rxa6 59. Rxa6 Bxa6 60. Ke3 Kf5 61. Kf3 Bc4 62. Ke3 Kg4 63. f3+ Kg3 64. f4 Kg4 65. f5 exf5 66. Kf2 f4 67. Kg2 f3+ 68. Kf2 Kf4 69. Ke1 Ke3 70. Kd1 f2 71. Kc2 f1=Q 72. Kb2 Qe2+ 73. Ka3 Qa2+ 74. Kb4 Qb3+ 75. Kc5 Qb5+ 76. Kd6 Qb6+ 77. Ke5 Qc7+ 78. Kf5 Qf7+ 79. Kg5 Qg7+ 80. Kf5 Bd3+ 81. Ke6 Qg6+ 82. Kxd5 Qf5+ 83. Kc6 Qe6+ 84. Kc5 Qc4+ 85. Kd6 Qxc3 86. d5 Qd4 87. Kc6 Be4 88. Kd6 Qxd5+ 89. Ke7 Qc6 90. Kf7 Qd6 91. Kg7 Qe6 92. Kf8 Qd7 93. Kg8 Qe7 94. Kh8 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 546,
            "completion_tokens": 354,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg7",
            "Re1",
            "Bf3",
            "Ra1",
            "Ra7",
            "Kg3",
            "Be2",
            "Kf4",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "Ke3",
            "Kf5",
            "Kf3",
            "Bc4",
            "Ke3",
            "Kg4",
            "f3+",
            "Kg3",
            "f4",
            "Kg4",
            "f5",
            "exf5",
            "Kf2",
            "f4",
            "Kg2",
            "f3+",
            "Kf2",
            "Kf4",
            "Ke1",
            "Ke3",
            "Kd1",
            "f2",
            "Kc2",
            "f1=Q",
            "Kb2",
            "Qe2+",
            "Ka3",
            "Qa2+",
            "Kb4",
            "Qb3+",
            "Kc5",
            "Qb5+",
            "Kd6",
            "Qb6+",
            "Ke5",
            "Qc7+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qg7+",
            "Kf5",
            "Bd3+",
            "Ke6",
            "Qg6+",
            "Kxd5",
            "Qf5+",
            "Kc6",
            "Qe6+",
            "Kc5",
            "Qc4+",
            "Kd6",
            "Qxc3",
            "d5",
            "Qd4",
            "Kc6",
            "Be4",
            "Kd6",
            "Qxd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Qd6",
            "Kg7",
            "Qe6",
            "Kf8",
            "Qd7",
            "Kg8",
            "Qe7",
            "Kh8",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "a5a6",
          "neutral_uci": "a5a6",
          "consensus_move": "a5a6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxh6",
              "gxh6",
              "Rxh6",
              "Bg7",
              "Bh6",
              "Bh7",
              "Bxg7",
              "Bh6+",
              "Kg8",
              "b6",
              "d5",
              "b7",
              "d4",
              "b8=Q+",
              "Kg7",
              "Qb7+",
              "Kg8",
              "Qf7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg7",
              "Re1",
              "Bf3",
              "Ra1",
              "Ra7",
              "Kg3",
              "Be2",
              "Kf4",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "Kg4",
              "Be2+",
              "Kf4",
              "Bd1",
              "Ke3",
              "Kf5",
              "Kd2",
              "Bb3",
              "Ke3",
              "Bc4",
              "Kf3",
              "Bd3",
              "Ke3",
              "Bc2",
              "Kf3",
              "Bd1+",
              "Ke3",
              "Kg4",
              "Kd2",
              "Bb3",
              "Ke3",
              "Bc4",
              "f3+",
              "Kg3",
              "f4",
              "Kg4",
              "f5",
              "exf5",
              "Kf2",
              "f4",
              "Kg2",
              "f3+",
              "Kf2",
              "Kf4",
              "Ke1",
              "Ke3",
              "Kd1",
              "f2",
              "Kc2",
              "f1=Q",
              "Kb2",
              "Qe2+",
              "Ka3",
              "Qa2+",
              "Kb4",
              "Qb3+",
              "Kc5",
              "Qb5+",
              "Kd6",
              "Qb6+",
              "Ke5",
              "Qc7+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Qg7+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Ke4",
              "Kg4",
              "Qg6+",
              "Kh3",
              "Kf3",
              "Kh4",
              "Qg4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg7",
              "Re1",
              "Bf3",
              "Ra1",
              "Ra7",
              "Kg3",
              "Be2",
              "Kf4",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "Ke3",
              "Kf5",
              "Kf3",
              "Bc4",
              "Ke3",
              "Kg4",
              "f3+",
              "Kg3",
              "f4",
              "Kg4",
              "f5",
              "exf5",
              "Kf2",
              "f4",
              "Kg2",
              "f3+",
              "Kf2",
              "Kf4",
              "Ke1",
              "Ke3",
              "Kd1",
              "f2",
              "Kc2",
              "f1=Q",
              "Kb2",
              "Qe2+",
              "Ka3",
              "Qa2+",
              "Kb4",
              "Qb3+",
              "Kc5",
              "Qb5+",
              "Kd6",
              "Qb6+",
              "Ke5",
              "Qc7+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Qg7+",
              "Kf5",
              "Bd3+",
              "Ke6",
              "Qg6+",
              "Kxd5",
              "Qf5+",
              "Kc6",
              "Qe6+",
              "Kc5",
              "Qc4+",
              "Kd6",
              "Qxc3",
              "d5",
              "Qd4",
              "Kc6",
              "Be4",
              "Kd6",
              "Qxd5+",
              "Ke7",
              "Qc6",
              "Kf7",
              "Qd6",
              "Kg7",
              "Qe6",
              "Kf8",
              "Qd7",
              "Kg8",
              "Qe7",
              "Kh8",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 547,
            "completion_tokens": 139,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 547,
            "completion_tokens": 332,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 546,
            "completion_tokens": 354,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1640,
          "total_completion_tokens": 825,
          "total_tokens": 2465
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 106,
            "turn_number": 54,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 547,
            "completion_tokens": 139,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 106,
            "turn_number": 54,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 547,
            "completion_tokens": 332,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 106,
            "turn_number": 54,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 546,
            "completion_tokens": 354,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/4pkr1/P2p4/3P4/2P1R3/5P1K/3b4 w - - 1 54"
    },
    {
      "turn": 109,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh1",
          "aggressive_uci": null,
          "aggressive_response": "Re8+ Kg7 Bf1 a6 a7 Rh8 Rg3+ Kf7 Rg8 Rh2+ Kg3\nRh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3",
          "aggressive_tokens": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8",
            "Rh2+",
            "Kg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a7",
          "positional_uci": "a6a7",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Rg1+ 51. Kh2 Rg6 52.\nRe3 Bd1 53. a5 Kf6 54. a6 Bc2 55. a7 Rg8 56. Rf3+ Bf5 57. Rg3 Ra8 58. Rg1\nRxa7 59. Rc1 Ra2 60. Kg3 Rc2 61. Rxc2 Bxc2 62. Kf4 Bb3 63. Kg4 Bc4 64. Kf4 Bb5\n65. Kg4 Be8 66. Kf4 Bh5 67. Kg3 Kf5 68. f3 Bg6 69. Kf2 Kf4 70. Ke2 Bh5 71. Kd3\nBxf3 72. c4 dxc4+ 73. Kxc4 Bd5+ 74. Kd3 Kf3 75. Kd2 Ke4 76. Kc3 Ke3 77. Kc2\nKxd",
          "positional_tokens": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8",
            "Rf3+",
            "Bf5",
            "Rg3",
            "Ra8",
            "Rg1",
            "Rxa7",
            "Rc1",
            "Ra2",
            "Kg3",
            "Rc2",
            "Rxc2",
            "Bxc2",
            "Kf4",
            "Bb3",
            "Kg4",
            "Bc4",
            "Kf4",
            "Bb5",
            "Kg4",
            "Be8",
            "Kf4",
            "Bh5",
            "Kg3",
            "Kf5",
            "f3",
            "Bg6",
            "Kf2",
            "Kf4",
            "Ke2",
            "Bh5",
            "Kd3",
            "Bxf3",
            "c4",
            "dxc4+",
            "Kxc4",
            "Bd5+",
            "Kd3",
            "Kf3",
            "Kd2",
            "Ke4",
            "Kc3",
            "Ke3",
            "Kc2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": null,
          "neutral_response": "Re8+ Kg7 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6",
          "neutral_tokens": {
            "prompt_tokens": 554,
            "completion_tokens": 640,
            "total_tokens": 1194,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "a6a7",
          "neutral_uci": null,
          "consensus_move": "a6a7",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg8",
              "Rh2+",
              "Kg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rf3+",
              "Bf5",
              "Rg3",
              "Ra8",
              "Rg1",
              "Rxa7",
              "Rc1",
              "Ra2",
              "Kg3",
              "Rc2",
              "Rxc2",
              "Bxc2",
              "Kf4",
              "Bb3",
              "Kg4",
              "Bc4",
              "Kf4",
              "Bb5",
              "Kg4",
              "Be8",
              "Kf4",
              "Bh5",
              "Kg3",
              "Kf5",
              "f3",
              "Bg6",
              "Kf2",
              "Kf4",
              "Ke2",
              "Bh5",
              "Kd3",
              "Bxf3",
              "c4",
              "dxc4+",
              "Kxc4",
              "Bd5+",
              "Kd3",
              "Kf3",
              "Kd2",
              "Ke4",
              "Kc3",
              "Ke3",
              "Kc2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg7",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 554,
            "completion_tokens": 640,
            "total_tokens": 1194,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1664,
          "total_completion_tokens": 1920,
          "total_tokens": 3584
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 108,
            "turn_number": 55,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 108,
            "turn_number": 55,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 108,
            "turn_number": 55,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 554,
            "completion_tokens": 640,
            "total_tokens": 1194,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/P3pkr1/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 55"
    },
    {
      "turn": 111,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8",
          "aggressive_uci": null,
          "aggressive_response": "Re8 Rg8 Rf8",
          "aggressive_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rg6",
          "positional_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kd6",
          "neutral_uci": null,
          "neutral_response": "Re8 Rxe8 Kf8 Rxe8 Kxe8 Kd7 Kd6 Kc7 Kc5\nKb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7",
          "neutral_tokens": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg8",
              "Rf8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1688,
          "total_completion_tokens": 656,
          "total_tokens": 2344
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56"
    },
    {
      "turn": 111,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 Nf3 Nc6 Bg5 e6 Nbd2 Be7 Bxf6 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ng5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5 hxg5 Qxg5 Rh1 b6 Qh4 Qxh4 gxh4 Rh8 h6 d5 Rf6 Ke7 Rg3 Rxh6 Rg7+ Kf6 Rxc7 b5 Ra7 d5 Rxa6 Bd3 Kd2 Bf1 Ke3 Rh7 Kf4 Rxh6 a4 bxa4 Rxa4 Rh4+ Kg3 Rh1 Ra8 Rg1+ Kh2 Rg6 Re8 Kf7 Rg8 Rh6+ Kg3 Rg6+ Kf4 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 R",
          "aggressive_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Ng5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5",
            "hxg5",
            "Qxg5",
            "Rh1",
            "b6",
            "Qh4",
            "Qxh4",
            "gxh4",
            "Rh8",
            "h6",
            "d5",
            "Rf6",
            "Ke7",
            "Rg3",
            "Rxh6",
            "Rg7+",
            "Kf6",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Rxa6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6",
            "a4",
            "bxa4",
            "Rxa4",
            "Rh4+",
            "Kg3",
            "Rh1",
            "Ra8",
            "Rg1+",
            "Kh2",
            "Rg6",
            "Re8",
            "Kf7",
            "Rg8",
            "Rh6+",
            "Kg3",
            "Rg6+",
            "Kf4",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg6 Rg8",
          "positional_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg6",
            "Rg8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kb1",
          "neutral_uci": null,
          "neutral_response": "Re8 Rxe8 Kf3 Kf5 Ke2 Ke4 Kd2 Kd3 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc",
          "neutral_tokens": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb2",
            "Kc1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Ng5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5",
              "hxg5",
              "Qxg5",
              "Rh1",
              "b6",
              "Qh4",
              "Qxh4",
              "gxh4",
              "Rh8",
              "h6",
              "d5",
              "Rf6",
              "Ke7",
              "Rg3",
              "Rxh6",
              "Rg7+",
              "Kf6",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Rxa6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6",
              "a4",
              "bxa4",
              "Rxa4",
              "Rh4+",
              "Kg3",
              "Rh1",
              "Ra8",
              "Rg1+",
              "Kh2",
              "Rg6",
              "Re8",
              "Kf7",
              "Rg8",
              "Rh6+",
              "Kg3",
              "Rg6+",
              "Kf4",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg6",
              "Rg8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kb2",
              "Kc1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1688,
          "total_completion_tokens": 1288,
          "total_tokens": 2976
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56"
    },
    {
      "turn": 111,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 g5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 gxf6 e5 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ng5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4+ Kc8 Qh6 Kb7 Qh7 Qxh7 Rxh7 Bb7 Rxc7+ Kb8 Rg7 Bc8 Rh1 Ra7 Rxa7 Kxa7 Rh8 Kb8 Rxe8 Kc7 Rxc8+ Kxc8 g4 Kd8 g5 Ke8 g6 Kf8 Kc2 Kg7 Kd3 Kxg6 Ke4 Kf6 f4 Ke7 f5 Kf6 fxe6 Kxe6 d5+ Kd6 Kd4 Kc7 Ke5 Kd7 d6 Kd8 Ke6 Ke8 d7+ Kd8 Kd6 b5 axb5 a4 bxa4 c5 a3 c6 a2 c7# Kd8 Ke7 Kc8 Ke8 Kd8 Kd7 Kc8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7",
          "aggressive_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "g5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "gxf6",
            "e5",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Ng5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4+",
            "Kc8",
            "Qh6",
            "Kb7",
            "Qh7",
            "Qxh7",
            "Rxh7",
            "Bb7",
            "Rxc7+",
            "Kb8",
            "Rg7",
            "Bc8",
            "Rh1",
            "Ra7",
            "Rxa7",
            "Kxa7",
            "Rh8",
            "Kb8",
            "Rxe8",
            "Kc7",
            "Rxc8+",
            "Kxc8",
            "g4",
            "Kd8",
            "g5",
            "Ke8",
            "g6",
            "Kf8",
            "Kc2",
            "Kg7",
            "Kd3",
            "Kxg6",
            "Ke4",
            "Kf6",
            "f4",
            "Ke7",
            "f5",
            "Kf6",
            "fxe6",
            "Kxe6",
            "d5+",
            "Kd6",
            "Kd4",
            "Kc7",
            "Ke5",
            "Kd7",
            "d6",
            "Kd8",
            "Ke6",
            "Ke8",
            "d7+",
            "Kd8",
            "Kd6",
            "b5",
            "axb5",
            "a4",
            "bxa4",
            "c5",
            "a3",
            "c6",
            "a2",
            "c7#",
            "Kd8",
            "Ke7",
            "Kc8",
            "Ke8",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc8",
            "Kd7",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rf8",
          "positional_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rxe8 Kf8",
          "neutral_tokens": {
            "prompt_tokens": 562,
            "completion_tokens": 8,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe8",
            "Kf8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "g5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "gxf6",
              "e5",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Ng5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4+",
              "Kc8",
              "Qh6",
              "Kb7",
              "Qh7",
              "Qxh7",
              "Rxh7",
              "Bb7",
              "Rxc7+",
              "Kb8",
              "Rg7",
              "Bc8",
              "Rh1",
              "Ra7",
              "Rxa7",
              "Kxa7",
              "Rh8",
              "Kb8",
              "Rxe8",
              "Kc7",
              "Rxc8+",
              "Kxc8",
              "g4",
              "Kd8",
              "g5",
              "Ke8",
              "g6",
              "Kf8",
              "Kc2",
              "Kg7",
              "Kd3",
              "Kxg6",
              "Ke4",
              "Kf6",
              "f4",
              "Ke7",
              "f5",
              "Kf6",
              "fxe6",
              "Kxe6",
              "d5+",
              "Kd6",
              "Kd4",
              "Kc7",
              "Ke5",
              "Kd7",
              "d6",
              "Kd8",
              "Ke6",
              "Ke8",
              "d7+",
              "Kd8",
              "Kd6",
              "b5",
              "axb5",
              "a4",
              "bxa4",
              "c5",
              "a3",
              "c6",
              "a2",
              "c7#",
              "Kd8",
              "Ke7",
              "Kc8",
              "Ke8",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc8",
              "Kd7",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rf8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe8",
              "Kf8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 562,
            "completion_tokens": 8,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1688,
          "total_completion_tokens": 656,
          "total_tokens": 2344
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 562,
            "completion_tokens": 8,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1... Nf6 2. d4 d5 3. c4 e6 4. Nc3 Bb4 5. Bg5 O-O 6. e3 c5 7. cxd5 exd5 8. dxc5 Nbd7 9. Rc1 Qa5 10. a3 Bxc3+ 11. Rxc3 Ne4 12. b4 Nxc3 13. Qb3 Qa4 14. Qxc3 a5 15. b5 Nxc5 16. Qxc5 Bg4 17. Qd4 Qxa3 18. Qxg4 Qc1+ 19. Ke2 Rfc8 20. Nd4 a4 21. Bf6 g6 22. Qg5 a3 23. Qh6 Qb2+ 24. Kf3 1-0\n1... Nf6 2. d4 d5 3. c4 e6 4. Nc3 Bb4 5. Bg5 O-O 6. e3 c5 7. cxd5 exd5 8. dxc5 Nbd7 9. Rc1 Qa5 10. a3 Bxc3+ 11. Rxc3 Ne4 12. b4 Nxc3 13. Qb3 Qa4 14. Qxc3 a5 15. b5 Nxc5 16. Qxc5 Bg4 17. Qd4 Qxa3 18. Qxg4 Qc1+ 19. Ke2 Rfc8 20. Nd4 a4 21. Bf6 g6 22. Qg5 a3 23. Qh6 Qb2+ 24. Kf3 1-0 a3 bxa3 c4",
          "aggressive_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 407,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "d5",
            "c4",
            "e6",
            "Nc3",
            "Bb4",
            "Bg5",
            "O-O",
            "e3",
            "c5",
            "cxd5",
            "exd5",
            "dxc5",
            "Nbd7",
            "Rc1",
            "Qa5",
            "a3",
            "Bxc3+",
            "Rxc3",
            "Ne4",
            "b4",
            "Nxc3",
            "Qb3",
            "Qa4",
            "Qxc3",
            "a5",
            "b5",
            "Nxc5",
            "Qxc5",
            "Bg4",
            "Qd4",
            "Qxa3",
            "Qxg4",
            "Qc1+",
            "Ke2",
            "Rfc8",
            "Nd4",
            "a4",
            "Bf6",
            "g6",
            "Qg5",
            "a3",
            "Qh6",
            "Qb2+",
            "Kf3",
            "a3",
            "bxa3",
            "c4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1... Nf6 2. d4 d5 3. c4 e6 4. Nc3 Be7 5. Bg5 O-O 6. e3 Nbd7 7. Rc1 c6 8. Bd3 dxc4 9. Bxc4 Nd5 10. Bxe7 Qxe7 11. O-O Nxc3 12. Rxc3 e5 13. dxe5 Nxe5 14. Nxe5 Qxe5 15. f4 Qe7 16. f5 Qf6 17. e4 Rd8 18. Qh5 Bd7 19. Rh3 h6 20. e5 Qxe5 21. Qxf7+ Kh8 22. f6 Qd4+ 23. Kh1 Qxf6 24. Rxf6 Bxh3 25. gxh3 Rd1+ 26. Kg2 gxf6 27. Qxf6+ Kh7 28. Qf7+ Kh8 29. Qg6 Rd2+ 30. Kf3 Rf8+ 31. Ke3 Rd7 32. Qxh6+ Rh7 33. Qxf8# Bg8 e4 Qe7",
          "positional_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 278,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "d5",
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bg5",
            "O-O",
            "e3",
            "Nbd7",
            "Rc1",
            "c6",
            "Bd3",
            "dxc4",
            "Bxc4",
            "Nd5",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Nxc3",
            "Rxc3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "f4",
            "Qe7",
            "f5",
            "Qf6",
            "e4",
            "Rd8",
            "Qh5",
            "Bd7",
            "Rh3",
            "h6",
            "e5",
            "Qxe5",
            "Qxf7+",
            "Kh8",
            "f6",
            "Qd4+",
            "Kh1",
            "Qxf6",
            "Rxf6",
            "Bxh3",
            "gxh3",
            "Rd1+",
            "Kg2",
            "gxf6",
            "Qxf6+",
            "Kh7",
            "Qf7+",
            "Kh8",
            "Qg6",
            "Rd2+",
            "Kf3",
            "Rf8+",
            "Ke3",
            "Rd7",
            "Qxh6+",
            "Rh7",
            "Qxf8#",
            "Bg8",
            "e4",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1... Nf6 2. d4 d5 3. c4 e6 4. Nc3 Be7 5. Bg5 O-O 6. e3 h6 7. Bh4 b6 8. cxd5 Nxd5 9. Bxe7 Qxe7 10. Nxd5 exd5 11. Rc1 Be6 12. Qa4 c5 13. Qa3 Rc8 14. Bb5 a6 15. dxc5 bxc5 16. O-O Ra7 17. Be2 Nd7 18. Nd4 Qd8 19. Nxe6 fxe6 20. e4 d4 21. Bc4 Qb6 22. Qh3 Nf8 23. f4 Kh8 24. f5 exf5 25. Rxf5 Re8 26. Rcf1 Ng6 27. Qh5 Rae7 28. Bf7 Rxf7 29. Rxf7 Rxe4 30. Qd5 Re8 31. Qd7 Rg8 32. Qf5 c4 33. Kh1 d3 34. Rd7 Qc6 35. Qd5 Qxd5 36. Rxd5 Rb8 37. b3 cxb3 38. axb3 Rxb3 39. g3 Kh7 40. Rd1 Ne7 41. R5xd3 Rb6 42. Rd6 Nc6 43. Rc1 1-0 Nc6 44. Rcxc6 Rxc6 45. Rxc6 a5",
          "neutral_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 366,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "d5",
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bg5",
            "O-O",
            "e3",
            "h6",
            "Bh4",
            "b6",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "exd5",
            "Rc1",
            "Be6",
            "Qa4",
            "c5",
            "Qa3",
            "Rc8",
            "Bb5",
            "a6",
            "dxc5",
            "bxc5",
            "O-O",
            "Ra7",
            "Be2",
            "Nd7",
            "Nd4",
            "Qd8",
            "Nxe6",
            "fxe6",
            "e4",
            "d4",
            "Bc4",
            "Qb6",
            "Qh3",
            "Nf8",
            "f4",
            "Kh8",
            "f5",
            "exf5",
            "Rxf5",
            "Re8",
            "Rcf1",
            "Ng6",
            "Qh5",
            "Rae7",
            "Bf7",
            "Rxf7",
            "Rxf7",
            "Rxe4",
            "Qd5",
            "Re8",
            "Qd7",
            "Rg8",
            "Qf5",
            "c4",
            "Kh1",
            "d3",
            "Rd7",
            "Qc6",
            "Qd5",
            "Qxd5",
            "Rxd5",
            "Rb8",
            "b3",
            "cxb3",
            "axb3",
            "Rxb3",
            "g3",
            "Kh7",
            "Rd1",
            "Ne7",
            "R5xd3",
            "Rb6",
            "Rd6",
            "Nc6",
            "Rc1",
            "Nc6",
            "Rcxc6",
            "Rxc6",
            "Rxc6",
            "a5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d4",
              "d5",
              "c4",
              "e6",
              "Nc3",
              "Bb4",
              "Bg5",
              "O-O",
              "e3",
              "c5",
              "cxd5",
              "exd5",
              "dxc5",
              "Nbd7",
              "Rc1",
              "Qa5",
              "a3",
              "Bxc3+",
              "Rxc3",
              "Ne4",
              "b4",
              "Nxc3",
              "Qb3",
              "Qa4",
              "Qxc3",
              "a5",
              "b5",
              "Nxc5",
              "Qxc5",
              "Bg4",
              "Qd4",
              "Qxa3",
              "Qxg4",
              "Qc1+",
              "Ke2",
              "Rfc8",
              "Nd4",
              "a4",
              "Bf6",
              "g6",
              "Qg5",
              "a3",
              "Qh6",
              "Qb2+",
              "Kf3",
              "a3",
              "bxa3",
              "c4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d4",
              "d5",
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bg5",
              "O-O",
              "e3",
              "Nbd7",
              "Rc1",
              "c6",
              "Bd3",
              "dxc4",
              "Bxc4",
              "Nd5",
              "Bxe7",
              "Qxe7",
              "O-O",
              "Nxc3",
              "Rxc3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "f4",
              "Qe7",
              "f5",
              "Qf6",
              "e4",
              "Rd8",
              "Qh5",
              "Bd7",
              "Rh3",
              "h6",
              "e5",
              "Qxe5",
              "Qxf7+",
              "Kh8",
              "f6",
              "Qd4+",
              "Kh1",
              "Qxf6",
              "Rxf6",
              "Bxh3",
              "gxh3",
              "Rd1+",
              "Kg2",
              "gxf6",
              "Qxf6+",
              "Kh7",
              "Qf7+",
              "Kh8",
              "Qg6",
              "Rd2+",
              "Kf3",
              "Rf8+",
              "Ke3",
              "Rd7",
              "Qxh6+",
              "Rh7",
              "Qxf8#",
              "Bg8",
              "e4",
              "Qe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "d5",
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bg5",
              "O-O",
              "e3",
              "h6",
              "Bh4",
              "b6",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "exd5",
              "Rc1",
              "Be6",
              "Qa4",
              "c5",
              "Qa3",
              "Rc8",
              "Bb5",
              "a6",
              "dxc5",
              "bxc5",
              "O-O",
              "Ra7",
              "Be2",
              "Nd7",
              "Nd4",
              "Qd8",
              "Nxe6",
              "fxe6",
              "e4",
              "d4",
              "Bc4",
              "Qb6",
              "Qh3",
              "Nf8",
              "f4",
              "Kh8",
              "f5",
              "exf5",
              "Rxf5",
              "Re8",
              "Rcf1",
              "Ng6",
              "Qh5",
              "Rae7",
              "Bf7",
              "Rxf7",
              "Rxf7",
              "Rxe4",
              "Qd5",
              "Re8",
              "Qd7",
              "Rg8",
              "Qf5",
              "c4",
              "Kh1",
              "d3",
              "Rd7",
              "Qc6",
              "Qd5",
              "Qxd5",
              "Rxd5",
              "Rb8",
              "b3",
              "cxb3",
              "axb3",
              "Rxb3",
              "g3",
              "Kh7",
              "Rd1",
              "Ne7",
              "R5xd3",
              "Rb6",
              "Rd6",
              "Nc6",
              "Rc1",
              "Nc6",
              "Rcxc6",
              "Rxc6",
              "Rxc6",
              "a5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 115,
            "completion_tokens": 407,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 115,
            "completion_tokens": 278,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 114,
            "completion_tokens": 366,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 344,
          "total_completion_tokens": 1051,
          "total_tokens": 1395
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 115,
            "completion_tokens": 407,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 115,
            "completion_tokens": 278,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 114,
            "completion_tokens": 366,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/5N2/PPPPPPPP/RNBQKB1R b KQkq - 1 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "2... d5 3. d4 Bg4 4. Be2 e6 5. O-O Bd6 6. Nbd2 O-O 7. c4 c6 8. b3 Nbd7 9. Bb2 Qe7 10. Ne5 Bxe2 11. Qxe2 Ba3 12. Bxa3 Qxa3 13. Nxd7 Nxd7 14. cxd5 exd5 15. e4 dxe4 16. Nxe4 Rfe8 17. Qg4 Qe7 18. Rfe1 Nf6 19. Nxf6+ Qxf6 20. Qd7 Rxe1+ 21. Rxe1 h6 22. Qxb7 Rd8 23. Qxa7 Rxd4 24. h3 Rd2 25. Qa8+ Kh7 26. Qa7 Qb2 27. Qxf7 Qxa2 28. Qf5+ g6 29. Qf7+ Kh8 30. Re8# d4 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd8+ Kh7 Qd7+ Kh8 Qd",
          "aggressive_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Bg4",
            "Be2",
            "e6",
            "O-O",
            "Bd6",
            "Nbd2",
            "O-O",
            "c4",
            "c6",
            "b3",
            "Nbd7",
            "Bb2",
            "Qe7",
            "Ne5",
            "Bxe2",
            "Qxe2",
            "Ba3",
            "Bxa3",
            "Qxa3",
            "Nxd7",
            "Nxd7",
            "cxd5",
            "exd5",
            "e4",
            "dxe4",
            "Nxe4",
            "Rfe8",
            "Qg4",
            "Qe7",
            "Rfe1",
            "Nf6",
            "Nxf6+",
            "Qxf6",
            "Qd7",
            "Rxe1+",
            "Rxe1",
            "h6",
            "Qxb7",
            "Rd8",
            "Qxa7",
            "Rxd4",
            "h3",
            "Rd2",
            "Qa8+",
            "Kh7",
            "Qa7",
            "Qb2",
            "Qxf7",
            "Qxa2",
            "Qf5+",
            "g6",
            "Qf7+",
            "Kh8",
            "Re8#",
            "d4",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qd7+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d7d5",
          "positional_response": "2... d5 3. d4 Bg4 4. Be2 e6 5. O-O Bd6 6. Nbd2 O-O 7. c4 c6 8. b3 Nbd7 9. Bb2 Qe7 10. Ne5 Bxe2 11. Qxe2 Ba3 12. Bxa3 Qxa3 13. Nxd7 Nxd7 14. e4 dxe4 15. Nxe4 Qe7 16. Rad1 Rad8 17. Rfe1 Nf6 18. Nxf6+ Qxf6 19. Qe5 Qxe5 20. dxe5 Rfe8 21. f4 Kf8 22. Kf2 Ke7 23. Ke3 Rxd1 24. Rxd1 Rd8 25. Rxd8 Kxd8 26. Kd4 Kd7 27. Kc5 Kc7 28. a4 b6+ 29. Kd4 c5+ 30. Ke4 Kd7 31. g4 Ke7 32. f5 f6 33. h4 h6 34. Kf4 Kf7 35. g5 hxg5+ 36. hxg5 fxg5+ 37. Kxg5 exf5 38. Kxf5 g6+ 39. Kg5 Ke6 40. Kxg6 Kxe5 41. Kf7 Kd4 42. Ke6 Kc3 43. Kd6 Kxb3 44. Kc6 Kxc4 45. Kb7 Kb4 46. Kxa7 Kxa4 47. Kxb6 c4 48. Kc5 c3 49. Kd4 c2 50. Kd3 c1=Q 51. Ke2 Kb3 52. Kd3 Qc4+ 53. Ke3 Kc3 54. Kf3 Qd4 55. Ke2 Qd3+ 56. Kf2 Kd2 57. Kg2 Qe3 58. Kf1 Qe2+ 59. Kg1 Ke3 60. Kh1 Kf3 61. Kg1 Qg2# 0-1 1. Nf3 Nf6 2. e3 d5 3. d4 Bg4 4. Be2 e6 5. O-O Bd6 6. Nbd2 O-O 7. c4 c6 8. b3 Nbd7 9. Bb2 Qe7 10. Ne5 Bxe2 11. Qxe2 Ba3 12. Bxa3 Qxa3 13. Nxd7 Nxd7 14. e4 dxe4 15. Nxe4 Qe7 16. Rad1 Rad8 17. Rfe1",
          "positional_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Bg4",
            "Be2",
            "e6",
            "O-O",
            "Bd6",
            "Nbd2",
            "O-O",
            "c4",
            "c6",
            "b3",
            "Nbd7",
            "Bb2",
            "Qe7",
            "Ne5",
            "Bxe2",
            "Qxe2",
            "Ba3",
            "Bxa3",
            "Qxa3",
            "Nxd7",
            "Nxd7",
            "e4",
            "dxe4",
            "Nxe4",
            "Qe7",
            "Rad1",
            "Rad8",
            "Rfe1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d5",
          "neutral_uci": "d7d5",
          "neutral_response": "2... d5 3. d4 Bg4 4. Be2 e6 5. O-O Bd6 6. Nbd2 O-O 7. c4 c6 8. b3 Nbd7 9. Bb2 Qe7 10. Ne5 Bxe2 11. Qxe2 Ba3 12. Bxa3 Qxa3 13. Nxd7 Nxd7 14. e4 dxe4 15. Nxe4 Qe7 16. Rad1 Rad8 17. Rfe1 Rfe8 18. h3 Nf6 19. Nxf6+ Qxf6 20. Qe5 Qxe5 21. dxe5 Kf8 22. f4 Ke7 23. Kf2 Rxd1 24. Rxd1 Rd8 25. Rxd8 Kxd8 26. Ke3 Kc7 27. Kd4 Kb6 28. b4 a5 29. a3 axb4 30. axb4 Kc7 31. Kc5 b6+ 32. Kd4 Kd7 33. g4 Ke7 34. c5 b5 35. Ke4 f6 36. h4 Kf7 37. f5 exf5+ 38. gxf5 fxe5 39. Kxe5 Ke7 40. h5 Kd7 41. h6 gxh6 42. Kf6 h5 43. Kg7 h4 44. f6 h3 45. f7 h2 46. f8=Q h1=Q 47. Qd6+ Kc8 48. Qe6+ Kb7 49. Qd7+ Kb8 50. Qd8+ Kb7 51. Qb6+ Kc8 52. Qa6+ Kd7 53. Qb7+ Ke6 54. Qc8+ Kd5 55. Qd7+ Kc4 56. Qg4+ Kb3 57. Kf6 Qd5 58. Qg3+ Kxb4 59. Qe1+ Kxc5 60. Qc3+ Qc4 61. Qe5+ Kb4 62. Qb2+ Ka5 63. Qa3+ Kb6 64. Qe3+ Qc5 65. Qe8 Qd6+ 66. Kg5 Qg6+ 67. Qxg6 hxg6 68. Kxg6 b4 69. Kf5 b3 70. Ke4 b2 71. Kd3 b1=Q+ 72. Kc3 Qe4 73. Kb3 Qd4 74. Ka3 Qc4 75. Kb2 Qd3 76. Ka2 Qc3",
          "neutral_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Bg4",
            "Be2",
            "e6",
            "O-O",
            "Bd6",
            "Nbd2",
            "O-O",
            "c4",
            "c6",
            "b3",
            "Nbd7",
            "Bb2",
            "Qe7",
            "Ne5",
            "Bxe2",
            "Qxe2",
            "Ba3",
            "Bxa3",
            "Qxa3",
            "Nxd7",
            "Nxd7",
            "e4",
            "dxe4",
            "Nxe4",
            "Qe7",
            "Rad1",
            "Rad8",
            "Rfe1",
            "Rfe8",
            "h3",
            "Nf6",
            "Nxf6+",
            "Qxf6",
            "Qe5",
            "Qxe5",
            "dxe5",
            "Kf8",
            "f4",
            "Ke7",
            "Kf2",
            "Rxd1",
            "Rxd1",
            "Rd8",
            "Rxd8",
            "Kxd8",
            "Ke3",
            "Kc7",
            "Kd4",
            "Kb6",
            "b4",
            "a5",
            "a3",
            "axb4",
            "axb4",
            "Kc7",
            "Kc5",
            "b6+",
            "Kd4",
            "Kd7",
            "g4",
            "Ke7",
            "c5",
            "b5",
            "Ke4",
            "f6",
            "h4",
            "Kf7",
            "f5",
            "exf5+",
            "gxf5",
            "fxe5",
            "Kxe5",
            "Ke7",
            "h5",
            "Kd7",
            "h6",
            "gxh6",
            "Kf6",
            "h5",
            "Kg7",
            "h4",
            "f6",
            "h3",
            "f7",
            "h2",
            "f8=Q",
            "h1=Q",
            "Qd6+",
            "Kc8",
            "Qe6+",
            "Kb7",
            "Qd7+",
            "Kb8",
            "Qd8+",
            "Kb7",
            "Qb6+",
            "Kc8",
            "Qa6+",
            "Kd7",
            "Qb7+",
            "Ke6",
            "Qc8+",
            "Kd5",
            "Qd7+",
            "Kc4",
            "Qg4+",
            "Kb3",
            "Kf6",
            "Qd5",
            "Qg3+",
            "Kxb4",
            "Qe1+",
            "Kxc5",
            "Qc3+",
            "Qc4",
            "Qe5+",
            "Kb4",
            "Qb2+",
            "Ka5",
            "Qa3+",
            "Kb6",
            "Qe3+",
            "Qc5",
            "Qe8",
            "Qd6+",
            "Kg5",
            "Qg6+",
            "Qxg6",
            "hxg6",
            "Kxg6",
            "b4",
            "Kf5",
            "b3",
            "Ke4",
            "b2",
            "Kd3",
            "b1=Q+",
            "Kc3",
            "Qe4",
            "Kb3",
            "Qd4",
            "Ka3",
            "Qc4",
            "Kb2",
            "Qd3",
            "Ka2",
            "Qc3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": "d7d5",
          "neutral_uci": "d7d5",
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d4",
              "Bg4",
              "Be2",
              "e6",
              "O-O",
              "Bd6",
              "Nbd2",
              "O-O",
              "c4",
              "c6",
              "b3",
              "Nbd7",
              "Bb2",
              "Qe7",
              "Ne5",
              "Bxe2",
              "Qxe2",
              "Ba3",
              "Bxa3",
              "Qxa3",
              "Nxd7",
              "Nxd7",
              "cxd5",
              "exd5",
              "e4",
              "dxe4",
              "Nxe4",
              "Rfe8",
              "Qg4",
              "Qe7",
              "Rfe1",
              "Nf6",
              "Nxf6+",
              "Qxf6",
              "Qd7",
              "Rxe1+",
              "Rxe1",
              "h6",
              "Qxb7",
              "Rd8",
              "Qxa7",
              "Rxd4",
              "h3",
              "Rd2",
              "Qa8+",
              "Kh7",
              "Qa7",
              "Qb2",
              "Qxf7",
              "Qxa2",
              "Qf5+",
              "g6",
              "Qf7+",
              "Kh8",
              "Re8#",
              "d4",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qd7+",
              "Kh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d4",
              "Bg4",
              "Be2",
              "e6",
              "O-O",
              "Bd6",
              "Nbd2",
              "O-O",
              "c4",
              "c6",
              "b3",
              "Nbd7",
              "Bb2",
              "Qe7",
              "Ne5",
              "Bxe2",
              "Qxe2",
              "Ba3",
              "Bxa3",
              "Qxa3",
              "Nxd7",
              "Nxd7",
              "e4",
              "dxe4",
              "Nxe4",
              "Qe7",
              "Rad1",
              "Rad8",
              "Rfe1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "Bg4",
              "Be2",
              "e6",
              "O-O",
              "Bd6",
              "Nbd2",
              "O-O",
              "c4",
              "c6",
              "b3",
              "Nbd7",
              "Bb2",
              "Qe7",
              "Ne5",
              "Bxe2",
              "Qxe2",
              "Ba3",
              "Bxa3",
              "Qxa3",
              "Nxd7",
              "Nxd7",
              "e4",
              "dxe4",
              "Nxe4",
              "Qe7",
              "Rad1",
              "Rad8",
              "Rfe1",
              "Rfe8",
              "h3",
              "Nf6",
              "Nxf6+",
              "Qxf6",
              "Qe5",
              "Qxe5",
              "dxe5",
              "Kf8",
              "f4",
              "Ke7",
              "Kf2",
              "Rxd1",
              "Rxd1",
              "Rd8",
              "Rxd8",
              "Kxd8",
              "Ke3",
              "Kc7",
              "Kd4",
              "Kb6",
              "b4",
              "a5",
              "a3",
              "axb4",
              "axb4",
              "Kc7",
              "Kc5",
              "b6+",
              "Kd4",
              "Kd7",
              "g4",
              "Ke7",
              "c5",
              "b5",
              "Ke4",
              "f6",
              "h4",
              "Kf7",
              "f5",
              "exf5+",
              "gxf5",
              "fxe5",
              "Kxe5",
              "Ke7",
              "h5",
              "Kd7",
              "h6",
              "gxh6",
              "Kf6",
              "h5",
              "Kg7",
              "h4",
              "f6",
              "h3",
              "f7",
              "h2",
              "f8=Q",
              "h1=Q",
              "Qd6+",
              "Kc8",
              "Qe6+",
              "Kb7",
              "Qd7+",
              "Kb8",
              "Qd8+",
              "Kb7",
              "Qb6+",
              "Kc8",
              "Qa6+",
              "Kd7",
              "Qb7+",
              "Ke6",
              "Qc8+",
              "Kd5",
              "Qd7+",
              "Kc4",
              "Qg4+",
              "Kb3",
              "Kf6",
              "Qd5",
              "Qg3+",
              "Kxb4",
              "Qe1+",
              "Kxc5",
              "Qc3+",
              "Qc4",
              "Qe5+",
              "Kb4",
              "Qb2+",
              "Ka5",
              "Qa3+",
              "Kb6",
              "Qe3+",
              "Qc5",
              "Qe8",
              "Qd6+",
              "Kg5",
              "Qg6+",
              "Qxg6",
              "hxg6",
              "Kxg6",
              "b4",
              "Kf5",
              "b3",
              "Ke4",
              "b2",
              "Kd3",
              "b1=Q+",
              "Kc3",
              "Qe4",
              "Kb3",
              "Qd4",
              "Ka3",
              "Qc4",
              "Kb2",
              "Qd3",
              "Ka2",
              "Qc3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 368,
          "total_completion_tokens": 1920,
          "total_tokens": 2288
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pppppppp/5n2/8/8/4PN2/PPPP1PPP/RNBQKB1R b KQkq - 0 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e6",
          "aggressive_uci": "e7e6",
          "aggressive_response": "3... e6 4. Nc3 Be7 5. b3 O-O 6. Bb2 c5 7. cxd5 exd5 8. d4 Nc6 9. Be2 Bg4 10. O-O Rc8 11. Rc1 cxd4 12. Nxd4 Bxe2 13. Ncxe2 Ne4 14. Nf5 Bf6 15. Bxf6 Nxf6 16. Ned4 Qd7 17. Qf3 Ne5 18. Qg3 Ng6 19. h4 Ne4 20. Qg4 Nf6 21. Qg5 h6 22. Nxh6+ gxh6 23. Qxf6 Qe7 24. Qxe7 Nxe7 25. Rfd1 Rfd8 26. Kf1 Kg7 27. Ke2 Kf6 28. g4 Ke5 29. f4+ Kf6 30. Kf3 a6 31. g5+ hxg5 32. hxg5+ Kg6 33. Kg4 f5+ 34. gxf6 Kxf6 35. Kf3 Rh8 36. Rxc8 Rxc8 37. Rh1 Kg6 38. Rg1+ Kf6 39. Rg5 Rc1 40. Rh5 Ra1 41. Rh6+ Kf7 42. Rb6 Rxa2 43. Rxb7 Kf6 44. Rb6+ Kf7 45. f5 Ra1 46. Kf4 Rf1+ 47. Ke5 Re1 48. Rf6+ Ke8 49. Re6 Kd7 50. Kf6 Ng8+ 51. Kf7 Rg1 52. Rxa6 Ne7 53. Ra7+ Kd6 54. Rxe7 Rh1 55. Re6+ Kd7 56. Rg6 Rh7+ 57. Rg7 Rh3 58. Kg8+ Ke8 59. f6 Rxe3 60. f7+ Kd7 61. f8=Q+ Re7 62. Qxe7+ Kc8 63. Qc7# e4 d4 e5",
          "aggressive_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 518,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Be7",
            "b3",
            "O-O",
            "Bb2",
            "c5",
            "cxd5",
            "exd5",
            "d4",
            "Nc6",
            "Be2",
            "Bg4",
            "O-O",
            "Rc8",
            "Rc1",
            "cxd4",
            "Nxd4",
            "Bxe2",
            "Ncxe2",
            "Ne4",
            "Nf5",
            "Bf6",
            "Bxf6",
            "Nxf6",
            "Ned4",
            "Qd7",
            "Qf3",
            "Ne5",
            "Qg3",
            "Ng6",
            "h4",
            "Ne4",
            "Qg4",
            "Nf6",
            "Qg5",
            "h6",
            "Nxh6+",
            "gxh6",
            "Qxf6",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rfd1",
            "Rfd8",
            "Kf1",
            "Kg7",
            "Ke2",
            "Kf6",
            "g4",
            "Ke5",
            "f4+",
            "Kf6",
            "Kf3",
            "a6",
            "g5+",
            "hxg5",
            "hxg5+",
            "Kg6",
            "Kg4",
            "f5+",
            "gxf6",
            "Kxf6",
            "Kf3",
            "Rh8",
            "Rxc8",
            "Rxc8",
            "Rh1",
            "Kg6",
            "Rg1+",
            "Kf6",
            "Rg5",
            "Rc1",
            "Rh5",
            "Ra1",
            "Rh6+",
            "Kf7",
            "Rb6",
            "Rxa2",
            "Rxb7",
            "Kf6",
            "Rb6+",
            "Kf7",
            "f5",
            "Ra1",
            "Kf4",
            "Rf1+",
            "Ke5",
            "Re1",
            "Rf6+",
            "Ke8",
            "Re6",
            "Kd7",
            "Kf6",
            "Ng8+",
            "Kf7",
            "Rg1",
            "Rxa6",
            "Ne7",
            "Ra7+",
            "Kd6",
            "Rxe7",
            "Rh1",
            "Re6+",
            "Kd7",
            "Rg6",
            "Rh7+",
            "Rg7",
            "Rh3",
            "Kg8+",
            "Ke8",
            "f6",
            "Rxe3",
            "f7+",
            "Kd7",
            "f8=Q+",
            "Re7",
            "Qxe7+",
            "Kc8",
            "Qc7#",
            "e4",
            "d4",
            "e5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e6",
          "positional_uci": "e7e6",
          "positional_response": "3... e6 4. Nc3 Be7 5. b3 O-O 6. Bb2 c5 7. cxd5 exd5 8. d4 Nc6 9. Be2 Bg4 10. O-O Rc8 11. Rc1 cxd4 12. Nxd4 Bxe2 13. Ncxe2 Ne4 14. Nf5 Bf6 15. Bxf6 Nxf6 16. Ned4 Qd7 17. Qf3 Ne5 18. Qg3 Ng6 19. h4 h5 20. Qg5 Rxc1 21. Rxc1 Rc8 22. Rxc8+ Qxc8 23. Qxg6 Qc1+ 24. Kh2 fxg6 25. Ne7+ Kf7 26. Nxd5 Nxd5 27. Kg3 Nxe3 28. fxe3 Qxe3+ 29. Nf3 Kf6 30. Kh2 Kf5 31. Kg3 g5 32. hxg5 h4+ 33. Kxh4 Qf4+ 34. Kh3 Qg4+ 35. Kh2 Kf4 36. Kg1 Kg3 37. Kf1 Qe4 38. Ne1 Qe3 39. Nd3 Qxd3+ 40. Ke1 Kxg2 41. b4 Kf3 42. b5 Qe2# e4 d5 Nc3 d4 Nxd4 Nxd4 Nf6 Nc6 Nc3 Nxe4 Nxe4 Qxe4+ Kf2 Qc2+ Ke3 Qxa2 Kd4 Qxb3 Kc5 Qxh3 Kd6 Qxg4 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6 Qf5 Kc5 Qe4 Kd6",
          "positional_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Be7",
            "b3",
            "O-O",
            "Bb2",
            "c5",
            "cxd5",
            "exd5",
            "d4",
            "Nc6",
            "Be2",
            "Bg4",
            "O-O",
            "Rc8",
            "Rc1",
            "cxd4",
            "Nxd4",
            "Bxe2",
            "Ncxe2",
            "Ne4",
            "Nf5",
            "Bf6",
            "Bxf6",
            "Nxf6",
            "Ned4",
            "Qd7",
            "Qf3",
            "Ne5",
            "Qg3",
            "Ng6",
            "h4",
            "h5",
            "Qg5",
            "Rxc1",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Qxc8",
            "Qxg6",
            "Qc1+",
            "Kh2",
            "fxg6",
            "Ne7+",
            "Kf7",
            "Nxd5",
            "Nxd5",
            "Kg3",
            "Nxe3",
            "fxe3",
            "Qxe3+",
            "Nf3",
            "Kf6",
            "Kh2",
            "Kf5",
            "Kg3",
            "g5",
            "hxg5",
            "h4+",
            "Kxh4",
            "Qf4+",
            "Kh3",
            "Qg4+",
            "Kh2",
            "Kf4",
            "Kg1",
            "Kg3",
            "Kf1",
            "Qe4",
            "Ne1",
            "Qe3",
            "Nd3",
            "Qxd3+",
            "Ke1",
            "Kxg2",
            "b4",
            "Kf3",
            "b5",
            "Qe2#",
            "e4",
            "d5",
            "Nc3",
            "d4",
            "Nxd4",
            "Nxd4",
            "Nf6",
            "Nc6",
            "Nc3",
            "Nxe4",
            "Nxe4",
            "Qxe4+",
            "Kf2",
            "Qc2+",
            "Ke3",
            "Qxa2",
            "Kd4",
            "Qxb3",
            "Kc5",
            "Qxh3",
            "Kd6",
            "Qxg4",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc5",
            "Qe4",
            "Kd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c6",
          "neutral_uci": "c7c6",
          "neutral_response": "1. Nf3 Nf6 2. e3 d5 3. c4 c6 4. Nc3 Bg4 5. Qb3 Qb6 6. Ne5 Be6 7. d4 Nbd7 8. Nxd7 Kxd7 9. c5 Qxb3 10. axb3 Kc7 11. b4 a6 12. b5 cxb5 13. Nxb5+ Kc6 14. Nc3 Bf5 15. b4 e6 16. b5+ Kc7 17. bxa6 bxa6 18. Rxa6 Rxa6 19. Bxa6 Be7 20. O-O Ra8 21. Be2 Ne4 22. Nxe4 Bxe4 23. f3 Bg6 24. Bd2 Ra2 25. Rd1 Bc2 26. Rc1 Ba4 27. Ba5+ Kc8 28. Ba6+ Kd7 29. Bb7 Bc6 30. Bxc6+ Kxc6 31. Bb6 Bg5 32. f4 Bh4 33. g3 Bf6 34. Rf1 Re2 35. Rf3 h5 36. h3 g6 37. g4 hxg4 38. hxg4 Bh4 39. Rh3 Bf2+ 40. Kf1 Rxe3 41. Rh7 Bg3 42. Rxf7 Rf3+ 43. Kg2 Rxf4 44. Rc7+ Kb5 45. Kxg3 Rxd4 46. Re7 Re4 47. Kf3 g5 48. Rg7 Rf4+ 49. Kg3 d4 50. Rxg5 Re4 51. Kf3 Re3+ 52. Kf2 e5 53. Rg8 Rc3 54. Re8 Re3 55. g5 Re4 56. g6 Rg4 57. Rxe5 Rxg6 58. Ke2 Kc4 59. Re4 Rg2+ 60. Kf3 Rg6 61. Ba7 Rf6+ 62. Ke2 Kd5 63. Re8 Kc4 64. Rd8 Re6+ 65. Kd2 Re4 66. c6 Re7 67. Rxd4+ Kb5 68. Rd7 Re6 69. c7 Rc6 70. Bb8 Kb6 71. Rd6 * e4 d4 c3",
          "neutral_tokens": {
            "prompt_tokens": 129,
            "completion_tokens": 586,
            "total_tokens": 715,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re7",
            "Rxd4+",
            "Kb5",
            "Rd7",
            "Re6",
            "c7",
            "Rc6",
            "Bb8",
            "Kb6",
            "Rd6",
            "e4",
            "d4",
            "c3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e6",
          "positional_uci": "e7e6",
          "neutral_uci": "c7c6",
          "consensus_move": "e7e6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Be7",
              "b3",
              "O-O",
              "Bb2",
              "c5",
              "cxd5",
              "exd5",
              "d4",
              "Nc6",
              "Be2",
              "Bg4",
              "O-O",
              "Rc8",
              "Rc1",
              "cxd4",
              "Nxd4",
              "Bxe2",
              "Ncxe2",
              "Ne4",
              "Nf5",
              "Bf6",
              "Bxf6",
              "Nxf6",
              "Ned4",
              "Qd7",
              "Qf3",
              "Ne5",
              "Qg3",
              "Ng6",
              "h4",
              "Ne4",
              "Qg4",
              "Nf6",
              "Qg5",
              "h6",
              "Nxh6+",
              "gxh6",
              "Qxf6",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rfd1",
              "Rfd8",
              "Kf1",
              "Kg7",
              "Ke2",
              "Kf6",
              "g4",
              "Ke5",
              "f4+",
              "Kf6",
              "Kf3",
              "a6",
              "g5+",
              "hxg5",
              "hxg5+",
              "Kg6",
              "Kg4",
              "f5+",
              "gxf6",
              "Kxf6",
              "Kf3",
              "Rh8",
              "Rxc8",
              "Rxc8",
              "Rh1",
              "Kg6",
              "Rg1+",
              "Kf6",
              "Rg5",
              "Rc1",
              "Rh5",
              "Ra1",
              "Rh6+",
              "Kf7",
              "Rb6",
              "Rxa2",
              "Rxb7",
              "Kf6",
              "Rb6+",
              "Kf7",
              "f5",
              "Ra1",
              "Kf4",
              "Rf1+",
              "Ke5",
              "Re1",
              "Rf6+",
              "Ke8",
              "Re6",
              "Kd7",
              "Kf6",
              "Ng8+",
              "Kf7",
              "Rg1",
              "Rxa6",
              "Ne7",
              "Ra7+",
              "Kd6",
              "Rxe7",
              "Rh1",
              "Re6+",
              "Kd7",
              "Rg6",
              "Rh7+",
              "Rg7",
              "Rh3",
              "Kg8+",
              "Ke8",
              "f6",
              "Rxe3",
              "f7+",
              "Kd7",
              "f8=Q+",
              "Re7",
              "Qxe7+",
              "Kc8",
              "Qc7#",
              "e4",
              "d4",
              "e5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Be7",
              "b3",
              "O-O",
              "Bb2",
              "c5",
              "cxd5",
              "exd5",
              "d4",
              "Nc6",
              "Be2",
              "Bg4",
              "O-O",
              "Rc8",
              "Rc1",
              "cxd4",
              "Nxd4",
              "Bxe2",
              "Ncxe2",
              "Ne4",
              "Nf5",
              "Bf6",
              "Bxf6",
              "Nxf6",
              "Ned4",
              "Qd7",
              "Qf3",
              "Ne5",
              "Qg3",
              "Ng6",
              "h4",
              "h5",
              "Qg5",
              "Rxc1",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Qxc8",
              "Qxg6",
              "Qc1+",
              "Kh2",
              "fxg6",
              "Ne7+",
              "Kf7",
              "Nxd5",
              "Nxd5",
              "Kg3",
              "Nxe3",
              "fxe3",
              "Qxe3+",
              "Nf3",
              "Kf6",
              "Kh2",
              "Kf5",
              "Kg3",
              "g5",
              "hxg5",
              "h4+",
              "Kxh4",
              "Qf4+",
              "Kh3",
              "Qg4+",
              "Kh2",
              "Kf4",
              "Kg1",
              "Kg3",
              "Kf1",
              "Qe4",
              "Ne1",
              "Qe3",
              "Nd3",
              "Qxd3+",
              "Ke1",
              "Kxg2",
              "b4",
              "Kf3",
              "b5",
              "Qe2#",
              "e4",
              "d5",
              "Nc3",
              "d4",
              "Nxd4",
              "Nxd4",
              "Nf6",
              "Nc6",
              "Nc3",
              "Nxe4",
              "Nxe4",
              "Qxe4+",
              "Kf2",
              "Qc2+",
              "Ke3",
              "Qxa2",
              "Kd4",
              "Qxb3",
              "Kc5",
              "Qxh3",
              "Kd6",
              "Qxg4",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc5",
              "Qe4",
              "Kd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re7",
              "Rxd4+",
              "Kb5",
              "Rd7",
              "Re6",
              "c7",
              "Rc6",
              "Bb8",
              "Kb6",
              "Rd6",
              "e4",
              "d4",
              "c3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 130,
            "completion_tokens": 518,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 129,
            "completion_tokens": 586,
            "total_tokens": 715,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 389,
          "total_completion_tokens": 1744,
          "total_tokens": 2133
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 130,
            "completion_tokens": 518,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 129,
            "completion_tokens": 586,
            "total_tokens": 715,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p4/2P5/4PN2/PP1P1PPP/RNBQKB1R b KQkq - 0 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "4... Be7 5. Bb2 O-O 6. Be2 c5 7. O-O Nc6 8. cxd5 exd5 9. d4 Bf5 10. Nc3 Rc8 11. Rc1 cxd4 12. Nxd4 Nxd4 13. Qxd4 Bc5 14. Qf4 Bg6 15. Rfd1 Bd6 16. Qd4 Bc5 17. Qh4 Be7 18. Qd4 Bc5 19. Qh4 Be7 20. Qd4 Bc5 21. Qh4 Be7 22. Qd4 Bc5 23. Qh4 Be7 24. Qd4 Bc5 25. Qh4 Be7 26. Qd4 Bc5 27. Qh4 Be7 28. Qd4 Bc5 29. Qh4 Be7 30. Qd4 Bc5 31. Qh4 Be7 32. Qd4 Bc5 33. Qh4 Be7 34. Qd4 Bc5 35. Qh4 Be7 36. Qd4 Bc5 37. Qh4 Be7 38. Qd4 Bc5 39. Qh4 Be7 40. Qd4 Bc5 41. Qh4 Be7 42. Qd4 Bc5 43. Qh4 Be7 44. Qd4 Bc5 45. Qh4 Be7 46. Qd4 Bc5 47. Qh4 Be7 48. Qd4 Bc5 49. Qh4 Be7 50. Qd4 Bc5 51. Qh4 Be7 52. Qd4 Bc5 53. Qh4 Be7 54. Qd4 Bc5 55. Qh4 Be7 56. Qd4 Bc5 57. Qh4 Be7 58. Qd4 Bc5 59. Qh4 Be7 60. Qd4 Bc5 61. Qh4 Be7 62. Qd4 Bc5 63. Qh4 Be7 64. Qd4 Bc5 65. Qh4 Be7 66. Qd4 Bc5 67. Qh4 Be7 68. Qd4 Bc5 69. Qh4 Be7 70. Qd4 Bc5 71. Qh4 Be7 72. Qd4 Bc5 73. Qh4 Be7 74. Qd4 Bc5 75. Qh4 Be7 76. Qd4 Bc5 77. Qh4 Be7 78. Qd4 Bc5 79. Qh4 Be7",
          "aggressive_tokens": {
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "4... Be7 5. Bb2 O-O 6. Be2 c5 7. O-O Nc6 8. d4 cxd4 9. Nxd4 Bd7 10. Nc3 Rc8 11. cxd5 exd5 12. Rc1 Re8 13. Bf3 Be6 14. Nce2 Qd7 15. Nf4 Nxd4 16. Qxd4 b6 17. Rfd1 Rxc1 18. Rxc1 Rc8 19. Rxc8+ Qxc8 20. Nxd5 Bxd5 21. Bxd5 Qc2 22. g3 Bc5 23. Qe5 h6 24. Bc4 Qb1+ 25. Kg2 Qxa2 26. Qb8+ Kh7 27. Bd3+ g6 28. Bxf6 Bxe3 29. Qh8# Bb7 30. Qg7# Kg8 31. Qh8# 1-0\n\n1. Nf3 Nf6 2. e3 d5 3. c4 e6 4. b3 * Be7 5. Bb2 O-O 6. Be2 c5 7. O-O Nc6 8. d4 cxd4 9. Nxd4 Bd7 10. Nc3 Rc8 11. cxd5 exd5 12. Rc1 Re8 13. Bf3 Be6 14. Nce2 Qd7 15. Nf4 Nxd4 16. Qxd4 b6 17. Rfd1 Rxc1 18. Rxc1 Rc8 19. Rxc8+ Qxc8 20. Nxd5 Bxd5 21. Bxd5 Qc2 22. g3 Bc5 23. Qe5 h6 24. Bc4 Qb1+ 25. Kg2 Qxa2 26. Qb8+ Kh7 27. Bd3+ g6 28. Bxf6 Bxe3 29. Qh8# Bb7 30. Qg7# Kg8 31. Qh8# 1-0",
          "positional_tokens": {
            "prompt_tokens": 137,
            "completion_tokens": 500,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb2",
            "O-O",
            "Be2",
            "c5",
            "O-O",
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Bd7",
            "Nc3",
            "Rc8",
            "cxd5",
            "exd5",
            "Rc1",
            "Re8",
            "Bf3",
            "Be6",
            "Nce2",
            "Qd7",
            "Nf4",
            "Nxd4",
            "Qxd4",
            "b6",
            "Rfd1",
            "Rxc1",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Qxc8",
            "Nxd5",
            "Bxd5",
            "Bxd5",
            "Qc2",
            "g3",
            "Bc5",
            "Qe5",
            "h6",
            "Bc4",
            "Qb1+",
            "Kg2",
            "Qxa2",
            "Qb8+",
            "Kh7",
            "Bd3+",
            "g6",
            "Bxf6",
            "Bxe3",
            "Qh8#",
            "Bb7",
            "Qg7#",
            "Kg8",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "4... Be7 5. Bb2 O-O 6. Be2 c5 7. O-O Nc6 8. d4 b6 9. Nc3 Bb7 10. Rc1 Rc8 11. cxd5 exd5 12. dxc5 bxc5 13. Na4 Ne4 14. Nd2 Nxd2 15. Qxd2 Nb4 16. a3 Na6 17. Rfd1 Qd6 18. Bf3 Rfd8 19. Nc3 Nc7 20. Ne2 Ne6 21. Ng3 g6 22. Qc3 d4 23. exd4 cxd4 24. Qd3 Ba6 25. Qd2 Bg5 26. Rxc8 Bxd2 27. Rxd8+ Qxd8 28. Rxd2 Qb6 29. Bd5 Qa5 30. Ne4 Kf8 31. Bxe6 fxe6 32. b4 Qb5 33. h3 e5 34. Nc5 Bc8 35. f4 exf4 36. Bxd4 Qc4 37. Kh2 g5 38. Ne4 Qc6 39. Nxg5 Qg6 40. Nf3 Qg3+ 41. Kh1 Bxh3 42. Bc5+ Ke8 43. Re2+ Kd8 44. Rd2+ Kc8 45. Bxa7 Bg4 46. Rc2+ Kb7 47. Bf2 Bxf3 48. Bxg3 Be4 49. Rc4 Bxg2+ 50. Kxg2 fxg3 51. Kxg3 Kb6 52. Rh4 Kb5 53. Rxh7 Ka4 54. Ra7+ Kb5 55. Ra5+ Kb6 56. Kf4 Kc6 57. Ke4 Kb6 58. Kd4 Kc6 59. Kc4 Kb6 60. a4 Kc6 61. Ra6+ Kb7 62. Kb5 Kc7 63. Rh6 Kb7 64. Rh7+ Kc8 65. Kc6 Kd8 66. Ra7 Ke8 67. Kd6 Kf8 68. Ke6 Kg8 69. Kf6 Kh8 70. Kg6 Kg8 71. Ra8# Qe8+ Qxe8",
          "neutral_tokens": {
            "prompt_tokens": 136,
            "completion_tokens": 566,
            "total_tokens": 702,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb2",
            "O-O",
            "Be2",
            "c5",
            "O-O",
            "Nc6",
            "d4",
            "b6",
            "Nc3",
            "Bb7",
            "Rc1",
            "Rc8",
            "cxd5",
            "exd5",
            "dxc5",
            "bxc5",
            "Na4",
            "Ne4",
            "Nd2",
            "Nxd2",
            "Qxd2",
            "Nb4",
            "a3",
            "Na6",
            "Rfd1",
            "Qd6",
            "Bf3",
            "Rfd8",
            "Nc3",
            "Nc7",
            "Ne2",
            "Ne6",
            "Ng3",
            "g6",
            "Qc3",
            "d4",
            "exd4",
            "cxd4",
            "Qd3",
            "Ba6",
            "Qd2",
            "Bg5",
            "Rxc8",
            "Bxd2",
            "Rxd8+",
            "Qxd8",
            "Rxd2",
            "Qb6",
            "Bd5",
            "Qa5",
            "Ne4",
            "Kf8",
            "Bxe6",
            "fxe6",
            "b4",
            "Qb5",
            "h3",
            "e5",
            "Nc5",
            "Bc8",
            "f4",
            "exf4",
            "Bxd4",
            "Qc4",
            "Kh2",
            "g5",
            "Ne4",
            "Qc6",
            "Nxg5",
            "Qg6",
            "Nf3",
            "Qg3+",
            "Kh1",
            "Bxh3",
            "Bc5+",
            "Ke8",
            "Re2+",
            "Kd8",
            "Rd2+",
            "Kc8",
            "Bxa7",
            "Bg4",
            "Rc2+",
            "Kb7",
            "Bf2",
            "Bxf3",
            "Bxg3",
            "Be4",
            "Rc4",
            "Bxg2+",
            "Kxg2",
            "fxg3",
            "Kxg3",
            "Kb6",
            "Rh4",
            "Kb5",
            "Rxh7",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Ra5+",
            "Kb6",
            "Kf4",
            "Kc6",
            "Ke4",
            "Kb6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kb6",
            "a4",
            "Kc6",
            "Ra6+",
            "Kb7",
            "Kb5",
            "Kc7",
            "Rh6",
            "Kb7",
            "Rh7+",
            "Kc8",
            "Kc6",
            "Kd8",
            "Ra7",
            "Ke8",
            "Kd6",
            "Kf8",
            "Ke6",
            "Kg8",
            "Kf6",
            "Kh8",
            "Kg6",
            "Kg8",
            "Ra8#",
            "Qe8+",
            "Qxe8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb2",
              "O-O",
              "Be2",
              "c5",
              "O-O",
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Bd7",
              "Nc3",
              "Rc8",
              "cxd5",
              "exd5",
              "Rc1",
              "Re8",
              "Bf3",
              "Be6",
              "Nce2",
              "Qd7",
              "Nf4",
              "Nxd4",
              "Qxd4",
              "b6",
              "Rfd1",
              "Rxc1",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Qxc8",
              "Nxd5",
              "Bxd5",
              "Bxd5",
              "Qc2",
              "g3",
              "Bc5",
              "Qe5",
              "h6",
              "Bc4",
              "Qb1+",
              "Kg2",
              "Qxa2",
              "Qb8+",
              "Kh7",
              "Bd3+",
              "g6",
              "Bxf6",
              "Bxe3",
              "Qh8#",
              "Bb7",
              "Qg7#",
              "Kg8",
              "Qh8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb2",
              "O-O",
              "Be2",
              "c5",
              "O-O",
              "Nc6",
              "d4",
              "b6",
              "Nc3",
              "Bb7",
              "Rc1",
              "Rc8",
              "cxd5",
              "exd5",
              "dxc5",
              "bxc5",
              "Na4",
              "Ne4",
              "Nd2",
              "Nxd2",
              "Qxd2",
              "Nb4",
              "a3",
              "Na6",
              "Rfd1",
              "Qd6",
              "Bf3",
              "Rfd8",
              "Nc3",
              "Nc7",
              "Ne2",
              "Ne6",
              "Ng3",
              "g6",
              "Qc3",
              "d4",
              "exd4",
              "cxd4",
              "Qd3",
              "Ba6",
              "Qd2",
              "Bg5",
              "Rxc8",
              "Bxd2",
              "Rxd8+",
              "Qxd8",
              "Rxd2",
              "Qb6",
              "Bd5",
              "Qa5",
              "Ne4",
              "Kf8",
              "Bxe6",
              "fxe6",
              "b4",
              "Qb5",
              "h3",
              "e5",
              "Nc5",
              "Bc8",
              "f4",
              "exf4",
              "Bxd4",
              "Qc4",
              "Kh2",
              "g5",
              "Ne4",
              "Qc6",
              "Nxg5",
              "Qg6",
              "Nf3",
              "Qg3+",
              "Kh1",
              "Bxh3",
              "Bc5+",
              "Ke8",
              "Re2+",
              "Kd8",
              "Rd2+",
              "Kc8",
              "Bxa7",
              "Bg4",
              "Rc2+",
              "Kb7",
              "Bf2",
              "Bxf3",
              "Bxg3",
              "Be4",
              "Rc4",
              "Bxg2+",
              "Kxg2",
              "fxg3",
              "Kxg3",
              "Kb6",
              "Rh4",
              "Kb5",
              "Rxh7",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Ra5+",
              "Kb6",
              "Kf4",
              "Kc6",
              "Ke4",
              "Kb6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kb6",
              "a4",
              "Kc6",
              "Ra6+",
              "Kb7",
              "Kb5",
              "Kc7",
              "Rh6",
              "Kb7",
              "Rh7+",
              "Kc8",
              "Kc6",
              "Kd8",
              "Ra7",
              "Ke8",
              "Kd6",
              "Kf8",
              "Ke6",
              "Kg8",
              "Kf6",
              "Kh8",
              "Kg6",
              "Kg8",
              "Ra8#",
              "Qe8+",
              "Qxe8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 137,
            "completion_tokens": 500,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 136,
            "completion_tokens": 566,
            "total_tokens": 702,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 410,
          "total_completion_tokens": 1706,
          "total_tokens": 2116
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 137,
            "completion_tokens": 500,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 136,
            "completion_tokens": 566,
            "total_tokens": 702,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p4/2P5/1P2PN2/P2P1PPP/RNBQKB1R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e8g8",
          "aggressive_response": "5... O-O 6. Be2 c5 7. O-O Nc6 8. cxd5 exd5 9. d4 Bf5 10. Nc3 Rc8 11. Rc1 Ne4 12. dxc5 Nxc3 13. Bxc3 Bxc5 14. Bxg7 Kxg7 15. Rxc5 Be4 16. Nd4 Qg5 17. Bf3 Nxd4 18. Qxd4+ Qf6 19. Qxf6+ Kxf6 20. Rfc1 Rxc5 21. Rxc5 Bxf3 22. gxf3 Ke6 23. Rc7 Rb8 24. Kf1 a5 25. Ke2 b5 26. Kd3 a4 27. b4 Rg8 28. Rc5 Rg2 29. Ke2 Rxh2 30. Rxb5 Rh1 31. Ra5 h5 32. Rxa4 h4 33. b5 h3 34. Rh4 h2 35. a4 Kd6 36. Rh6+ Kc5 37. b6 Rb1 38. Rxh2 Rxb6 39. Rh4 Rb2+ 40. Kf1 Ra2 41. Rd4 f5 42. Kg2 Ra1 43. Kg3 Ra2 44. Rf4 Ra1 45. Rxf5 Rxa4 46. e4 Kd6 47. Rxd5+ Ke6 48. Kf4 Ra2 49. Ke3 Ra3+ 50. Rd3 Ra1 51. f4 Re1+ 52. Kf3 Rh1 53. f5+ Ke5 54. Rd5+ Kf6 55. Rd6+ Ke5 56. Re6+ Kd4 57. f6 Rh6 58. e5 Kd5 59. Re7 Rh5 60. f7 Rf5+ 61. Kg4 Rxf2 62. e6 Kd6 63. Re8 Rg2+ 64. Kf3 Rg1 65. f8=Q+ Ke5 66. Qf4+ Kd5 67. Rd8+ Kxe6 68. Rd6+ Ke7 69. Qf6+ Ke8 70. Rd8# O-O-O O-O-O O-O-O",
          "aggressive_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 549,
            "total_tokens": 694,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "cxd5",
            "exd5",
            "d4",
            "Bf5",
            "Nc3",
            "Rc8",
            "Rc1",
            "Ne4",
            "dxc5",
            "Nxc3",
            "Bxc3",
            "Bxc5",
            "Bxg7",
            "Kxg7",
            "Rxc5",
            "Be4",
            "Nd4",
            "Qg5",
            "Bf3",
            "Nxd4",
            "Qxd4+",
            "Qf6",
            "Qxf6+",
            "Kxf6",
            "Rfc1",
            "Rxc5",
            "Rxc5",
            "Bxf3",
            "gxf3",
            "Ke6",
            "Rc7",
            "Rb8",
            "Kf1",
            "a5",
            "Ke2",
            "b5",
            "Kd3",
            "a4",
            "b4",
            "Rg8",
            "Rc5",
            "Rg2",
            "Ke2",
            "Rxh2",
            "Rxb5",
            "Rh1",
            "Ra5",
            "h5",
            "Rxa4",
            "h4",
            "b5",
            "h3",
            "Rh4",
            "h2",
            "a4",
            "Kd6",
            "Rh6+",
            "Kc5",
            "b6",
            "Rb1",
            "Rxh2",
            "Rxb6",
            "Rh4",
            "Rb2+",
            "Kf1",
            "Ra2",
            "Rd4",
            "f5",
            "Kg2",
            "Ra1",
            "Kg3",
            "Ra2",
            "Rf4",
            "Ra1",
            "Rxf5",
            "Rxa4",
            "e4",
            "Kd6",
            "Rxd5+",
            "Ke6",
            "Kf4",
            "Ra2",
            "Ke3",
            "Ra3+",
            "Rd3",
            "Ra1",
            "f4",
            "Re1+",
            "Kf3",
            "Rh1",
            "f5+",
            "Ke5",
            "Rd5+",
            "Kf6",
            "Rd6+",
            "Ke5",
            "Re6+",
            "Kd4",
            "f6",
            "Rh6",
            "e5",
            "Kd5",
            "Re7",
            "Rh5",
            "f7",
            "Rf5+",
            "Kg4",
            "Rxf2",
            "e6",
            "Kd6",
            "Re8",
            "Rg2+",
            "Kf3",
            "Rg1",
            "f8=Q+",
            "Ke5",
            "Qf4+",
            "Kd5",
            "Rd8+",
            "Kxe6",
            "Rd6+",
            "Ke7",
            "Qf6+",
            "Ke8",
            "Rd8#",
            "O-O-O",
            "O-O-O",
            "O-O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "5... O-O 6. Be2 c5 7. O-O Nc6 8. cxd5 exd5 9. d4 Bf5 10. Nc3 Rc8 11. Rc1 b6 12. Ba6 Rc7 13. Nb5 Rd7 14. dxc5 bxc5 15. Bxf6 Bxf6 16. Rxc5 Qb6 17. Rxd5 Rxd5 18. Qxd5 Be6 19. Qe4 Qxa6 20. Nc7 Qc8 21. Qxc6 Bd8 22. Rc1 Bxc7 23. Qxc7 Qa6 24. Nd4 Rc8 25. Qxc8+ Bxc8 26. Nc6 Kf8 27. Nb4 Qb7 28. Nc6 Bd7 29. Nd4 Qa6 30. a4 Qb6 31. h3 Ke7 32. Rc4 Be6 33. Rc6 Qb7 34. Rc3 Bd5 35. f3 g6 36. Kf2 f5 37. Nb5 Bc6 38. Nd4 Bd7 39. Rc5 Kd6 40. Rc3 Qb4 41. Rc4 Qd2+ 42. Ne2 Be6 43. Rd4+ Qxd4 44. Nxd4 Bd5 45. Ke2 Kc5 46. Kd3 Kb4 47. Kc2 a5 48. Kb2 h6 49. Kc2 h5 50. Kb2 h4 51. Kc2 Bb7 52. Kb2 Bd5 53. Kc2 Bb7 54. Kb2 Bd5 55. Kc2 Bb7 56. Kb2 Bd5 57. Kc2 Bb7 58. Kb2 Bd5 59. Kc2 Bb7 60. Kb2 Bd5 61. Kc2 Bb7 62. Kb2 Bd5 63. Kc2 Bb7 64. Kb2 Bd5 65. Kc2 Bb7 66. Kb2 Bd5 67. Kc2 Bb7 68. Kb2 Bd5 69. Kc2 Bb7 70. Kb2 Bd5 71. Kc2 Bb7 72. Kb2 Bd5 73. Kc2 Bb7 74. Kb2 Bd5 75. Kc2 Bb7 76. Kb2 Bd5 77. Kc2 Bb7 78. Kb2 Bd5 79. Kc2 Bb7 80. Kb2 Bd5 81. Kc2 Bb7 82. Kb2 Bd5 83. Kc2 Bb7 84. Kb2 Bd5 85.",
          "positional_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "cxd5",
            "exd5",
            "d4",
            "Bf5",
            "Nc3",
            "Rc8",
            "Rc1",
            "b6",
            "Ba6",
            "Rc7",
            "Nb5",
            "Rd7",
            "dxc5",
            "bxc5",
            "Bxf6",
            "Bxf6",
            "Rxc5",
            "Qb6",
            "Rxd5",
            "Rxd5",
            "Qxd5",
            "Be6",
            "Qe4",
            "Qxa6",
            "Nc7",
            "Qc8",
            "Qxc6",
            "Bd8",
            "Rc1",
            "Bxc7",
            "Qxc7",
            "Qa6",
            "Nd4",
            "Rc8",
            "Qxc8+",
            "Bxc8",
            "Nc6",
            "Kf8",
            "Nb4",
            "Qb7",
            "Nc6",
            "Bd7",
            "Nd4",
            "Qa6",
            "a4",
            "Qb6",
            "h3",
            "Ke7",
            "Rc4",
            "Be6",
            "Rc6",
            "Qb7",
            "Rc3",
            "Bd5",
            "f3",
            "g6",
            "Kf2",
            "f5",
            "Nb5",
            "Bc6",
            "Nd4",
            "Bd7",
            "Rc5",
            "Kd6",
            "Rc3",
            "Qb4",
            "Rc4",
            "Qd2+",
            "Ne2",
            "Be6",
            "Rd4+",
            "Qxd4",
            "Nxd4",
            "Bd5",
            "Ke2",
            "Kc5",
            "Kd3",
            "Kb4",
            "Kc2",
            "a5",
            "Kb2",
            "h6",
            "Kc2",
            "h5",
            "Kb2",
            "h4",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5",
            "Kc2",
            "Bb7",
            "Kb2",
            "Bd5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "5... O-O 6. Be2 c5 7. O-O Nc6 8. d4 b6 9. Nc3 Bb7 10. Rc1 Rc8 11. cxd5 exd5 12. dxc5 bxc5 13. Na4 Ne4 14. Nd2 Nxd2 15. Qxd2 Nb4 16. a3 Na6 17. Rfd1 Qd6 18. Bf3 Rfd8 19. Nc3 Nc7 20. Ne2 Ne6 21. Ng3 g6 22. Qc3 d4 23. exd4 cxd4 24. Qd2 Bxf3 25. gxf3 Rxc1 26. Rxc1 Bg5 27. Ne4 Bxd2 28. Nxd2 Qf4 29. Rd1 Ng5 30. Kg2 Qh4 31. Nf1 Qh3+ 32. Kh1 Qxf3+ 33. Kg1 Nh3# Nf3+ Nxf3+",
          "neutral_tokens": {
            "prompt_tokens": 144,
            "completion_tokens": 243,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "d4",
            "b6",
            "Nc3",
            "Bb7",
            "Rc1",
            "Rc8",
            "cxd5",
            "exd5",
            "dxc5",
            "bxc5",
            "Na4",
            "Ne4",
            "Nd2",
            "Nxd2",
            "Qxd2",
            "Nb4",
            "a3",
            "Na6",
            "Rfd1",
            "Qd6",
            "Bf3",
            "Rfd8",
            "Nc3",
            "Nc7",
            "Ne2",
            "Ne6",
            "Ng3",
            "g6",
            "Qc3",
            "d4",
            "exd4",
            "cxd4",
            "Qd2",
            "Bxf3",
            "gxf3",
            "Rxc1",
            "Rxc1",
            "Bg5",
            "Ne4",
            "Bxd2",
            "Nxd2",
            "Qf4",
            "Rd1",
            "Ng5",
            "Kg2",
            "Qh4",
            "Nf1",
            "Qh3+",
            "Kh1",
            "Qxf3+",
            "Kg1",
            "Nh3#",
            "Nf3+",
            "Nxf3+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8g8",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc6",
              "cxd5",
              "exd5",
              "d4",
              "Bf5",
              "Nc3",
              "Rc8",
              "Rc1",
              "Ne4",
              "dxc5",
              "Nxc3",
              "Bxc3",
              "Bxc5",
              "Bxg7",
              "Kxg7",
              "Rxc5",
              "Be4",
              "Nd4",
              "Qg5",
              "Bf3",
              "Nxd4",
              "Qxd4+",
              "Qf6",
              "Qxf6+",
              "Kxf6",
              "Rfc1",
              "Rxc5",
              "Rxc5",
              "Bxf3",
              "gxf3",
              "Ke6",
              "Rc7",
              "Rb8",
              "Kf1",
              "a5",
              "Ke2",
              "b5",
              "Kd3",
              "a4",
              "b4",
              "Rg8",
              "Rc5",
              "Rg2",
              "Ke2",
              "Rxh2",
              "Rxb5",
              "Rh1",
              "Ra5",
              "h5",
              "Rxa4",
              "h4",
              "b5",
              "h3",
              "Rh4",
              "h2",
              "a4",
              "Kd6",
              "Rh6+",
              "Kc5",
              "b6",
              "Rb1",
              "Rxh2",
              "Rxb6",
              "Rh4",
              "Rb2+",
              "Kf1",
              "Ra2",
              "Rd4",
              "f5",
              "Kg2",
              "Ra1",
              "Kg3",
              "Ra2",
              "Rf4",
              "Ra1",
              "Rxf5",
              "Rxa4",
              "e4",
              "Kd6",
              "Rxd5+",
              "Ke6",
              "Kf4",
              "Ra2",
              "Ke3",
              "Ra3+",
              "Rd3",
              "Ra1",
              "f4",
              "Re1+",
              "Kf3",
              "Rh1",
              "f5+",
              "Ke5",
              "Rd5+",
              "Kf6",
              "Rd6+",
              "Ke5",
              "Re6+",
              "Kd4",
              "f6",
              "Rh6",
              "e5",
              "Kd5",
              "Re7",
              "Rh5",
              "f7",
              "Rf5+",
              "Kg4",
              "Rxf2",
              "e6",
              "Kd6",
              "Re8",
              "Rg2+",
              "Kf3",
              "Rg1",
              "f8=Q+",
              "Ke5",
              "Qf4+",
              "Kd5",
              "Rd8+",
              "Kxe6",
              "Rd6+",
              "Ke7",
              "Qf6+",
              "Ke8",
              "Rd8#",
              "O-O-O",
              "O-O-O",
              "O-O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc6",
              "cxd5",
              "exd5",
              "d4",
              "Bf5",
              "Nc3",
              "Rc8",
              "Rc1",
              "b6",
              "Ba6",
              "Rc7",
              "Nb5",
              "Rd7",
              "dxc5",
              "bxc5",
              "Bxf6",
              "Bxf6",
              "Rxc5",
              "Qb6",
              "Rxd5",
              "Rxd5",
              "Qxd5",
              "Be6",
              "Qe4",
              "Qxa6",
              "Nc7",
              "Qc8",
              "Qxc6",
              "Bd8",
              "Rc1",
              "Bxc7",
              "Qxc7",
              "Qa6",
              "Nd4",
              "Rc8",
              "Qxc8+",
              "Bxc8",
              "Nc6",
              "Kf8",
              "Nb4",
              "Qb7",
              "Nc6",
              "Bd7",
              "Nd4",
              "Qa6",
              "a4",
              "Qb6",
              "h3",
              "Ke7",
              "Rc4",
              "Be6",
              "Rc6",
              "Qb7",
              "Rc3",
              "Bd5",
              "f3",
              "g6",
              "Kf2",
              "f5",
              "Nb5",
              "Bc6",
              "Nd4",
              "Bd7",
              "Rc5",
              "Kd6",
              "Rc3",
              "Qb4",
              "Rc4",
              "Qd2+",
              "Ne2",
              "Be6",
              "Rd4+",
              "Qxd4",
              "Nxd4",
              "Bd5",
              "Ke2",
              "Kc5",
              "Kd3",
              "Kb4",
              "Kc2",
              "a5",
              "Kb2",
              "h6",
              "Kc2",
              "h5",
              "Kb2",
              "h4",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5",
              "Kc2",
              "Bb7",
              "Kb2",
              "Bd5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc6",
              "d4",
              "b6",
              "Nc3",
              "Bb7",
              "Rc1",
              "Rc8",
              "cxd5",
              "exd5",
              "dxc5",
              "bxc5",
              "Na4",
              "Ne4",
              "Nd2",
              "Nxd2",
              "Qxd2",
              "Nb4",
              "a3",
              "Na6",
              "Rfd1",
              "Qd6",
              "Bf3",
              "Rfd8",
              "Nc3",
              "Nc7",
              "Ne2",
              "Ne6",
              "Ng3",
              "g6",
              "Qc3",
              "d4",
              "exd4",
              "cxd4",
              "Qd2",
              "Bxf3",
              "gxf3",
              "Rxc1",
              "Rxc1",
              "Bg5",
              "Ne4",
              "Bxd2",
              "Nxd2",
              "Qf4",
              "Rd1",
              "Ng5",
              "Kg2",
              "Qh4",
              "Nf1",
              "Qh3+",
              "Kh1",
              "Qxf3+",
              "Kg1",
              "Nh3#",
              "Nf3+",
              "Nxf3+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 145,
            "completion_tokens": 549,
            "total_tokens": 694,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 144,
            "completion_tokens": 243,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 434,
          "total_completion_tokens": 1432,
          "total_tokens": 1866
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 145,
            "completion_tokens": 549,
            "total_tokens": 694,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 144,
            "completion_tokens": 243,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p4/2P5/1P2PN2/PB1P1PPP/RN1QKB1R b KQkq - 2 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c5",
          "aggressive_uci": "c7c5",
          "aggressive_response": "6... c5 7. Nbd2 Nc6 8. Bd3 b6 9. O-O Bb7 10. Rc1 Rc8 11. Qe2 Re8 12. Rfd1 Bf8 13. Ne5 Nxe5 14. dxe5 Nd7 15. f4 g6 16. cxd5 exd5 17. e4 d4 18. Nf3 Bg7 19. Bc4 Nf8 20. Ng5 Rc7 21. b4 h6 22. Nf3 Ne6 23. g3 Qa8 24. Re1 Rd8 25. f5 gxf5 26. exf5 Bxf3 27. Qf2 Ng5 28. Qf1 Bg4 29. Be2 Nh3+ 30. Qxh3 Bxh3 31. Bf1 Bxf1 32. Rxf1 Bxe5 33. Rce1 f6 34. Bc1 Kh7 35. Bf4 Bxf4 36. Rxf4 Re8 37. Ref1 Re2 38. R4f2 Rce7 39. bxc5 bxc5 40. a4 Qe4 41. a5 Qe3 42. Kg2 Rxf2+ 43. Rxf2 d3 44. a6 d2 45. Rf1 Qe2+ 46. Kg1 Qxf1+ 47. Kxf1 d1=Q+ 48. Kg2 Qg4 49. h3 Re2+ 50. Kf1 Qf3+ 51. Kg1 Qg2# 0-1\nNf3 Nf6 e3 d5 c4 e6 b3 Be7 Bb2 O-O d4 c5 Nbd2 Nc6 Bd3 b6 O-O Bb7 Rc1 Rc8 Qe2 Re8 Rfd1 Bf8 Ne5 Nxe5 dxe5 Nd7 f4 g6 cxd5 exd5 e4 d4 Nf3 Bg7 Bc4 Nf8 Ng5 Rc7 b4 h6 Nf3 Ne6 f5 gxf5 exf5 Bxf3 Qxf3 Ng5 Qf1 Bxe5 Re1 Qd6 h4 Nh7 Qf3 Nf6 bxc5 bxc5 Rcd1 Rce7 Bc1 Bh2+ Kf1 Rxe1+ Rxe1 Rxe1+ Kxe1 Qg3+ Qxg3+ Bxg3 Ke2 Bg3 Kf3 Bxh4 Bf4 Bg5 Bb8 a6 Ba7 Kf8 Bc4 a5 Bc7 a4 Bb5 a3 Bc4 Ke7 Bb6 Kd6 Ba5 Nd7 Bb3 Ne",
          "aggressive_tokens": {
            "prompt_tokens": 152,
            "completion_tokens": 640,
            "total_tokens": 792,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd2",
            "Nc6",
            "Bd3",
            "b6",
            "O-O",
            "Bb7",
            "Rc1",
            "Rc8",
            "Qe2",
            "Re8",
            "Rfd1",
            "Bf8",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "f4",
            "g6",
            "cxd5",
            "exd5",
            "e4",
            "d4",
            "Nf3",
            "Bg7",
            "Bc4",
            "Nf8",
            "Ng5",
            "Rc7",
            "b4",
            "h6",
            "Nf3",
            "Ne6",
            "f5",
            "gxf5",
            "exf5",
            "Bxf3",
            "Qxf3",
            "Ng5",
            "Qf1",
            "Bxe5",
            "Re1",
            "Qd6",
            "h4",
            "Nh7",
            "Qf3",
            "Nf6",
            "bxc5",
            "bxc5",
            "Rcd1",
            "Rce7",
            "Bc1",
            "Bh2+",
            "Kf1",
            "Rxe1+",
            "Rxe1",
            "Rxe1+",
            "Kxe1",
            "Qg3+",
            "Qxg3+",
            "Bxg3",
            "Ke2",
            "Bg3",
            "Kf3",
            "Bxh4",
            "Bf4",
            "Bg5",
            "Bb8",
            "a6",
            "Ba7",
            "Kf8",
            "Bc4",
            "a5",
            "Bc7",
            "a4",
            "Bb5",
            "a3",
            "Bc4",
            "Ke7",
            "Bb6",
            "Kd6",
            "Ba5",
            "Nd7",
            "Bb3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c5",
          "positional_uci": "c7c5",
          "positional_response": "6... c5 7. Nbd2 Nc6 8. Bd3 b6 9. O-O Bb7 10. Rc1 Rc8 11. Qe2 Re8 12. Rfd1 Bf8 13. Ne5 Nxe5 14. dxe5 Nd7 15. f4 g6 16. cxd5 exd5 17. e4 d4 18. Nc4 b5 19. Nd2 a6 20. a4 bxa4 21. bxa4 Qa5 22. Nc4 Qxa4 23. Ra1 Qc6 24. Na5 Qc7 25. Nxb7 Qxb7 26. Bxa6 Qb6 27. Bxc8 Rxc8 28. Ra6 Qb7 29. Rda1 Nb6 30. Ra7 Qc6 31. R1a6 Rb8 32. Qc4 Nxc4 33. Rxc6 Nxb2 34. Rcc7 d3 35. Rd7 c4 36. Rac7 Bb4 37. Rxf7 d2 38. Rg7+ Kf8 39. Rgf7+ Ke8 40. Rxh7 d1=Q+ 41. Kf2 Be1+ 42. Ke3 Qd3# d4 Nxd4",
          "positional_tokens": {
            "prompt_tokens": 152,
            "completion_tokens": 312,
            "total_tokens": 464,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Nc6",
            "Bd3",
            "b6",
            "O-O",
            "Bb7",
            "Rc1",
            "Rc8",
            "Qe2",
            "Re8",
            "Rfd1",
            "Bf8",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "f4",
            "g6",
            "cxd5",
            "exd5",
            "e4",
            "d4",
            "Nc4",
            "b5",
            "Nd2",
            "a6",
            "a4",
            "bxa4",
            "bxa4",
            "Qa5",
            "Nc4",
            "Qxa4",
            "Ra1",
            "Qc6",
            "Na5",
            "Qc7",
            "Nxb7",
            "Qxb7",
            "Bxa6",
            "Qb6",
            "Bxc8",
            "Rxc8",
            "Ra6",
            "Qb7",
            "Rda1",
            "Nb6",
            "Ra7",
            "Qc6",
            "R1a6",
            "Rb8",
            "Qc4",
            "Nxc4",
            "Rxc6",
            "Nxb2",
            "Rcc7",
            "d3",
            "Rd7",
            "c4",
            "Rac7",
            "Bb4",
            "Rxf7",
            "d2",
            "Rg7+",
            "Kf8",
            "Rgf7+",
            "Ke8",
            "Rxh7",
            "d1=Q+",
            "Kf2",
            "Be1+",
            "Ke3",
            "Qd3#",
            "d4",
            "Nxd4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nbd7",
          "neutral_uci": "b8d7",
          "neutral_response": "6... Nbd7 7. Nbd2 c5 8. Bd3 b6 9. O-O Bb7 10. Qe2 Ne4 11. Rfd1 f5 12. Rac1 Rc8 13. cxd5 exd5 14. Ba6 Bxa6 15. Qxa6 Rc7 16. dxc5 Ndxc5 17. Qe2 Bf6 18. Bxf6 Qxf6 19. Nd4 f4 20. Nxe4 dxe4 21. b4 f3 22. Qc4+ Kh8 23. bxc5 fxg2 24. Rd2 Rxc5 25. Qxc5 bxc5 26. Rxc5 Qb6 27. Rdc2 h6 28. Kxg2 Qg6+ 29. Kf1 Qg4 30. Rc7 Qh3+ 31. Ke1 Qxh2 32. Ne6 Qg1+ 33. Kd2 Rxf2+ 34. Kc3 Qe1+ 35. Kb3 Qxe3+ 36. R2c3 Qb6+ 37. Ka3 Qxe6 38. Rxa7 Qxa2+ 39. Kb4 Qxa7 40. Rc8+ Kh7 41. Rc4 Rb2+ 42. Kc3 Qa3+ 43. Kd4 Qd3+ 44. Kc5 Qxc4+ 45. Kxc4 Rd2 46. Kc3 Rd8 47. Kc4 e3 48. Kc5 e2 49. Kc6 e1=Q 50. Kc7 Rd2 51. Kc6 Qc1+ 52. Kb5 Rb2+ 53. Ka4 Qa1# Nf3 Nf6 Nbd7 c5 Bd3 O-O Rfd1 f5 Rc1 Rc8 dxc5 Ndxc5 Qe2 Bf6 Bxf6 Qxf6 Nd4 f4 Nxe4 dxe4 b4 f3 Qc4+ Kh8 bxc5 fxg2 Rd2 Rxc5 Qxc5 bxc5 Rxc5 Qb6 Rc7 h6 Kxg2 Qg4+ Kf1 Qh3+ Ke1 Qxh2 Ne6 Qg1+ Kd2 Rxf2+ Kc3 Qe1+ Kb3 Qxe3+ Rc3 Qb6+ Ka3 Qxe6 Rc8+ Kh7 Rc3 Qa6+ Kb3 Qb5+ Ka3 Qa5+ Kb3 Qb5+ Ka3 Qa5+ Kb3 Qb5+ Ka3 Qa5+ Kb3 Qb5+ Ka3 Qa5+ Kb3 Qb5+ Ka3 Qa5+ Kb3 Qb5",
          "neutral_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 640,
            "total_tokens": 791,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "Bd3",
            "O-O",
            "Rfd1",
            "f5",
            "Rc1",
            "Rc8",
            "dxc5",
            "Ndxc5",
            "Qe2",
            "Bf6",
            "Bxf6",
            "Qxf6",
            "Nd4",
            "f4",
            "Nxe4",
            "dxe4",
            "b4",
            "f3",
            "Qc4+",
            "Kh8",
            "bxc5",
            "fxg2",
            "Rd2",
            "Rxc5",
            "Qxc5",
            "bxc5",
            "Rxc5",
            "Qb6",
            "Rc7",
            "h6",
            "Kxg2",
            "Qg4+",
            "Kf1",
            "Qh3+",
            "Ke1",
            "Qxh2",
            "Ne6",
            "Qg1+",
            "Kd2",
            "Rxf2+",
            "Kc3",
            "Qe1+",
            "Kb3",
            "Qxe3+",
            "Rc3",
            "Qb6+",
            "Ka3",
            "Qxe6",
            "Rc8+",
            "Kh7",
            "Rc3",
            "Qa6+",
            "Kb3",
            "Qb5+",
            "Ka3",
            "Qa5+",
            "Kb3",
            "Qb5+",
            "Ka3",
            "Qa5+",
            "Kb3",
            "Qb5+",
            "Ka3",
            "Qa5+",
            "Kb3",
            "Qb5+",
            "Ka3",
            "Qa5+",
            "Kb3",
            "Qb5+",
            "Ka3",
            "Qa5+",
            "Kb3",
            "Qb5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7c5",
          "positional_uci": "c7c5",
          "neutral_uci": "b8d7",
          "consensus_move": "c7c5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "Nc6",
              "Bd3",
              "b6",
              "O-O",
              "Bb7",
              "Rc1",
              "Rc8",
              "Qe2",
              "Re8",
              "Rfd1",
              "Bf8",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "f4",
              "g6",
              "cxd5",
              "exd5",
              "e4",
              "d4",
              "Nf3",
              "Bg7",
              "Bc4",
              "Nf8",
              "Ng5",
              "Rc7",
              "b4",
              "h6",
              "Nf3",
              "Ne6",
              "f5",
              "gxf5",
              "exf5",
              "Bxf3",
              "Qxf3",
              "Ng5",
              "Qf1",
              "Bxe5",
              "Re1",
              "Qd6",
              "h4",
              "Nh7",
              "Qf3",
              "Nf6",
              "bxc5",
              "bxc5",
              "Rcd1",
              "Rce7",
              "Bc1",
              "Bh2+",
              "Kf1",
              "Rxe1+",
              "Rxe1",
              "Rxe1+",
              "Kxe1",
              "Qg3+",
              "Qxg3+",
              "Bxg3",
              "Ke2",
              "Bg3",
              "Kf3",
              "Bxh4",
              "Bf4",
              "Bg5",
              "Bb8",
              "a6",
              "Ba7",
              "Kf8",
              "Bc4",
              "a5",
              "Bc7",
              "a4",
              "Bb5",
              "a3",
              "Bc4",
              "Ke7",
              "Bb6",
              "Kd6",
              "Ba5",
              "Nd7",
              "Bb3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd2",
              "Nc6",
              "Bd3",
              "b6",
              "O-O",
              "Bb7",
              "Rc1",
              "Rc8",
              "Qe2",
              "Re8",
              "Rfd1",
              "Bf8",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "f4",
              "g6",
              "cxd5",
              "exd5",
              "e4",
              "d4",
              "Nc4",
              "b5",
              "Nd2",
              "a6",
              "a4",
              "bxa4",
              "bxa4",
              "Qa5",
              "Nc4",
              "Qxa4",
              "Ra1",
              "Qc6",
              "Na5",
              "Qc7",
              "Nxb7",
              "Qxb7",
              "Bxa6",
              "Qb6",
              "Bxc8",
              "Rxc8",
              "Ra6",
              "Qb7",
              "Rda1",
              "Nb6",
              "Ra7",
              "Qc6",
              "R1a6",
              "Rb8",
              "Qc4",
              "Nxc4",
              "Rxc6",
              "Nxb2",
              "Rcc7",
              "d3",
              "Rd7",
              "c4",
              "Rac7",
              "Bb4",
              "Rxf7",
              "d2",
              "Rg7+",
              "Kf8",
              "Rgf7+",
              "Ke8",
              "Rxh7",
              "d1=Q+",
              "Kf2",
              "Be1+",
              "Ke3",
              "Qd3#",
              "d4",
              "Nxd4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c5",
              "Bd3",
              "O-O",
              "Rfd1",
              "f5",
              "Rc1",
              "Rc8",
              "dxc5",
              "Ndxc5",
              "Qe2",
              "Bf6",
              "Bxf6",
              "Qxf6",
              "Nd4",
              "f4",
              "Nxe4",
              "dxe4",
              "b4",
              "f3",
              "Qc4+",
              "Kh8",
              "bxc5",
              "fxg2",
              "Rd2",
              "Rxc5",
              "Qxc5",
              "bxc5",
              "Rxc5",
              "Qb6",
              "Rc7",
              "h6",
              "Kxg2",
              "Qg4+",
              "Kf1",
              "Qh3+",
              "Ke1",
              "Qxh2",
              "Ne6",
              "Qg1+",
              "Kd2",
              "Rxf2+",
              "Kc3",
              "Qe1+",
              "Kb3",
              "Qxe3+",
              "Rc3",
              "Qb6+",
              "Ka3",
              "Qxe6",
              "Rc8+",
              "Kh7",
              "Rc3",
              "Qa6+",
              "Kb3",
              "Qb5+",
              "Ka3",
              "Qa5+",
              "Kb3",
              "Qb5+",
              "Ka3",
              "Qa5+",
              "Kb3",
              "Qb5+",
              "Ka3",
              "Qa5+",
              "Kb3",
              "Qb5+",
              "Ka3",
              "Qa5+",
              "Kb3",
              "Qb5+",
              "Ka3",
              "Qa5+",
              "Kb3",
              "Qb5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 152,
            "completion_tokens": 640,
            "total_tokens": 792,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 152,
            "completion_tokens": 312,
            "total_tokens": 464,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 151,
            "completion_tokens": 640,
            "total_tokens": 791,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 455,
          "total_completion_tokens": 1592,
          "total_tokens": 2047
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 152,
            "completion_tokens": 640,
            "total_tokens": 792,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 152,
            "completion_tokens": 312,
            "total_tokens": 464,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 151,
            "completion_tokens": 640,
            "total_tokens": 791,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p4/2PP4/1P2PN2/PB3PPP/RN1QKB1R b KQ - 0 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxd5",
          "aggressive_uci": "f6d5",
          "aggressive_response": "1. Nf3 Nf6 2. e3 d5 3. c4 e6 4. b3 Be7 5. Bb2 O-O 6. d4 c5 7. cxd5 Nxd5 8. Nc3 Nc6 9. Bc4 cxd4 10. Nxd4 Nxd4 11. Qxd4 Bf6 12. Qd2 Nxc3 13. Bxc3 Qxd2+ 14. Kxd2 Rd8+ 15. Kc2 Bxc3 16. Kxc3 Bd7 17. Rhd1 Bc6 18. f3 Kf8 19. e4 Ke7 20. a4 a5 21. Rd4 Rxd4 22. Kxd4 Rd8+ 23. Kc3 e5 24. Rc1 Rd4 25. Rc2 f6 26. Rd2 Rxd2 27. Kxd2 Kd6 28. Kc3 Kc5 29. Bg8 h6 30. Bc4 b6 31. Bg8 Bd7 32. Bc4 g5 33. Bg8 h5 34. Bc4 h4 35. Bg8 Bc8 36. Bc4 Bb7 37. Bg8 Bc6 38. Bc4 Bd7 39. Bg8 Bc8 40. Bc4 Bd7 41. Bg8 Bc6 42. Bc4 Bd7 43. Bg8 Bc8 44. Bc4 Bd7 45. Bg8 Bc8 46. Bc4 Bd7 47. Bg8 Bc8 48. Bc4 Bd7 49. Bg8 Bc8 50. Bc4 Bd7 51. Bg8 Bc8 52. Bc4 Bd7 53. Bg8 Bc8 54. Bc4 Bd7 55. Bg8 Bc8 56. Bc4 Bd7 57. Bg8 Bc8 58. Bc4 Bd7 59. Bg8 Bc8 60. Bc4 Bd7 61. Bg8 Bc8 62. Bc4 Bd7 63. Bg8 Bc8 64. Bc4 Bd7 65. Bg8 Bc8 66. Bc4 Bd7 67. Bg8 Bc8 68. Bc4 Bd7 69. Bg8 Bc8 70. Bc4 Bd7 71. Bg8 Bc8 72. Bc4 Bd7 73. Bg8 Bc8 74. Bc4 Bd7 75. Bg8 Bc8 76. Bc4 Bd7 77.",
          "aggressive_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Nc6",
            "Bc4",
            "cxd4",
            "Nxd4",
            "Nxd4",
            "Qxd4",
            "Bf6",
            "Qd2",
            "Nxc3",
            "Bxc3",
            "Qxd2+",
            "Kxd2",
            "Rd8+",
            "Kc2",
            "Bxc3",
            "Kxc3",
            "Bd7",
            "Rhd1",
            "Bc6",
            "f3",
            "Kf8",
            "e4",
            "Ke7",
            "a4",
            "a5",
            "Rd4",
            "Rxd4",
            "Kxd4",
            "Rd8+",
            "Kc3",
            "e5",
            "Rc1",
            "Rd4",
            "Rc2",
            "f6",
            "Rd2",
            "Rxd2",
            "Kxd2",
            "Kd6",
            "Kc3",
            "Kc5",
            "Bg8",
            "h6",
            "Bc4",
            "b6",
            "Bg8",
            "Bd7",
            "Bc4",
            "g5",
            "Bg8",
            "h5",
            "Bc4",
            "h4",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bb7",
            "Bg8",
            "Bc6",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc6",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7",
            "Bg8",
            "Bc8",
            "Bc4",
            "Bd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxd5",
          "positional_uci": "f6d5",
          "positional_response": "7... Nxd5 8. Nc3 Nxc3 9. Bxc3 Nc6 10. Bd3 cxd4 11. Nxd4 Nxd4 12. Bxd4 Bb4+ 13. Ke2 Qg5 14. Qc2 e5 15. Bxh7+ Kh8 16. Bc5 Bxc5 17. Qxc5 Bg4+ 18. f3 Rac8 19. Qb4 Bxf3+ 20. Kxf3 Kxh7 21. Rac1 f5 22. Rxc8 Rxc8 23. Rd1 e4+ 24. Kf2 Rc2+ 25. Rd2 Qh4+ 26. Ke2 Qg4+ 27. Kf2 Qh4+ 28. Ke2 Qg4+ 29. Kf2 Qh4+ 30. Ke2 Qg4+ 31. Kf2 Qh4+ 32. Ke2 Qg4+ 33. Kf2 Qh4+ 34. Ke2 Qg4+ 35. Kf2 Qh4+ 36. Ke2 Qg4+ 37. Kf2 Qh4+ 38. Ke2 Qg4+ 39. Kf2 Qh4+ 40. Ke2 Qg4+ 41. Kf2 Qh4+ 42. Ke2 Qg4+ 43. Kf2 Qh4+ 44. Ke2 Qg4+ 45. Kf2 Qh4+ 46. Ke2 Qg4+ 47. Kf2 Qh4+ 48. Ke2 Qg4+ 49. Kf2 Qh4+ 50. Ke2 Qg4+ 51. Kf2 Qh4+ 52. Ke2 Qg4+ 53. Kf2 Qh4+ 54. Ke2 Qg4+ 55. Kf2 Qh4+ 56. Ke2 Qg4+ 57. Kf2 Qh4+ 58. Ke2 Qg4+ 59. Kf2 Qh4+ 60. Ke2 Qg4+ 61. Kf2 Qh4+ 62. Ke2 Qg4+ 63. Kf2 Qh4+ 64. Ke2 Qg4+ 65. Kf2 Qh4+ 66. Ke2 Qg4+ 67. Kf2 Qh4+ 68. Ke2 Qg4+ 69. Kf2 Qh4+ 70. Ke2 Qg4+ 71. Kf2 Qh4+ 72. Ke2 Qg4+ 73. Kf2 Qh4+ 74. Ke2 Qg4+ 75. Kf2 Qh4+",
          "positional_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Nxc3",
            "Bxc3",
            "Nc6",
            "Bd3",
            "cxd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Bb4+",
            "Ke2",
            "Qg5",
            "Qc2",
            "e5",
            "Bxh7+",
            "Kh8",
            "Bc5",
            "Bxc5",
            "Qxc5",
            "Bg4+",
            "f3",
            "Rac8",
            "Qb4",
            "Bxf3+",
            "Kxf3",
            "Kxh7",
            "Rac1",
            "f5",
            "Rxc8",
            "Rxc8",
            "Rd1",
            "e4+",
            "Kf2",
            "Rc2+",
            "Rd2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+",
            "Ke2",
            "Qg4+",
            "Kf2",
            "Qh4+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxd5",
          "neutral_uci": "f6d5",
          "neutral_response": "7... Nxd5 8. Nc3 Nc6 9. Nxd5 exd5 10. dxc5 Bxc5 11. a3 Bg4 12. Be2 Re8 13. O-O Qd6 14. b4 Bb6 15. Nd4 Bxe2 16. Nxe2 Rad8 17. Nd4 Nxd4 18. Bxd4 Bxd4 19. Qxd4 Re4 20. Qxa7 Rh4 21. g3 Rh6 22. Qxb7 Qe6 23. Qc7 Rc8 24. Qf4 Qh3 25. g4 Rg6 26. f3 h5 27. Qg3 hxg4 28. Qxh3 gxh3+ 29. Kh1 Rc2 30. Rg1 Rgg2 31. Rxg2 hxg2+ 32. Kg1 Re2 33. b5 Rxe3 34. Kxg2 Rb3 35. a4 d4 36. Kf2 d3 37. Ke3 d2+ 38. Kxd2 Rxf3 39. b6 Rb3 40. a5 Kf8 41. Kc2 Rb5 42. Kc3 Ke7 43. Kc4 Rb2 44. Kc5 Kd7 45. a6 Rc2+ 46. Kb5 Rb2+ 47. Ka5 Kc6 48. Rc1+ Kd7 49. a7 Ra2+ 50. Kb5 Rb2+ 51. Ka6 Ra2+ 52. Kb7 1-0\n52... Rxa7+ 53. Kxa7 Ke6 54. b7 Kf5 55. b8=Q Kg5 56. Qg3+ Kh6 57. Rc6+ g6 58. Qh4+ Kg7 59. Qf6+ Kh6 60. Rc4 Kh5 61. Rh4#",
          "neutral_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 463,
            "total_tokens": 622,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exd5",
            "dxc5",
            "Bxc5",
            "a3",
            "Bg4",
            "Be2",
            "Re8",
            "O-O",
            "Qd6",
            "b4",
            "Bb6",
            "Nd4",
            "Bxe2",
            "Nxe2",
            "Rad8",
            "Nd4",
            "Nxd4",
            "Bxd4",
            "Bxd4",
            "Qxd4",
            "Re4",
            "Qxa7",
            "Rh4",
            "g3",
            "Rh6",
            "Qxb7",
            "Qe6",
            "Qc7",
            "Rc8",
            "Qf4",
            "Qh3",
            "g4",
            "Rg6",
            "f3",
            "h5",
            "Qg3",
            "hxg4",
            "Qxh3",
            "gxh3+",
            "Kh1",
            "Rc2",
            "Rg1",
            "Rgg2",
            "Rxg2",
            "hxg2+",
            "Kg1",
            "Re2",
            "b5",
            "Rxe3",
            "Kxg2",
            "Rb3",
            "a4",
            "d4",
            "Kf2",
            "d3",
            "Ke3",
            "d2+",
            "Kxd2",
            "Rxf3",
            "b6",
            "Rb3",
            "a5",
            "Kf8",
            "Kc2",
            "Rb5",
            "Kc3",
            "Ke7",
            "Kc4",
            "Rb2",
            "Kc5",
            "Kd7",
            "a6",
            "Rc2+",
            "Kb5",
            "Rb2+",
            "Ka5",
            "Kc6",
            "Rc1+",
            "Kd7",
            "a7",
            "Ra2+",
            "Kb5",
            "Rb2+",
            "Ka6",
            "Ra2+",
            "Kb7",
            "Rxa7+",
            "Kxa7",
            "Ke6",
            "b7",
            "Kf5",
            "b8=Q",
            "Kg5",
            "Qg3+",
            "Kh6",
            "Rc6+",
            "g6",
            "Qh4+",
            "Kg7",
            "Qf6+",
            "Kh6",
            "Rc4",
            "Kh5",
            "Rh4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6d5",
          "positional_uci": "f6d5",
          "neutral_uci": "f6d5",
          "consensus_move": "f6d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Nc6",
              "Bc4",
              "cxd4",
              "Nxd4",
              "Nxd4",
              "Qxd4",
              "Bf6",
              "Qd2",
              "Nxc3",
              "Bxc3",
              "Qxd2+",
              "Kxd2",
              "Rd8+",
              "Kc2",
              "Bxc3",
              "Kxc3",
              "Bd7",
              "Rhd1",
              "Bc6",
              "f3",
              "Kf8",
              "e4",
              "Ke7",
              "a4",
              "a5",
              "Rd4",
              "Rxd4",
              "Kxd4",
              "Rd8+",
              "Kc3",
              "e5",
              "Rc1",
              "Rd4",
              "Rc2",
              "f6",
              "Rd2",
              "Rxd2",
              "Kxd2",
              "Kd6",
              "Kc3",
              "Kc5",
              "Bg8",
              "h6",
              "Bc4",
              "b6",
              "Bg8",
              "Bd7",
              "Bc4",
              "g5",
              "Bg8",
              "h5",
              "Bc4",
              "h4",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bb7",
              "Bg8",
              "Bc6",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc6",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7",
              "Bg8",
              "Bc8",
              "Bc4",
              "Bd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Nxc3",
              "Bxc3",
              "Nc6",
              "Bd3",
              "cxd4",
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Bb4+",
              "Ke2",
              "Qg5",
              "Qc2",
              "e5",
              "Bxh7+",
              "Kh8",
              "Bc5",
              "Bxc5",
              "Qxc5",
              "Bg4+",
              "f3",
              "Rac8",
              "Qb4",
              "Bxf3+",
              "Kxf3",
              "Kxh7",
              "Rac1",
              "f5",
              "Rxc8",
              "Rxc8",
              "Rd1",
              "e4+",
              "Kf2",
              "Rc2+",
              "Rd2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+",
              "Ke2",
              "Qg4+",
              "Kf2",
              "Qh4+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "exd5",
              "dxc5",
              "Bxc5",
              "a3",
              "Bg4",
              "Be2",
              "Re8",
              "O-O",
              "Qd6",
              "b4",
              "Bb6",
              "Nd4",
              "Bxe2",
              "Nxe2",
              "Rad8",
              "Nd4",
              "Nxd4",
              "Bxd4",
              "Bxd4",
              "Qxd4",
              "Re4",
              "Qxa7",
              "Rh4",
              "g3",
              "Rh6",
              "Qxb7",
              "Qe6",
              "Qc7",
              "Rc8",
              "Qf4",
              "Qh3",
              "g4",
              "Rg6",
              "f3",
              "h5",
              "Qg3",
              "hxg4",
              "Qxh3",
              "gxh3+",
              "Kh1",
              "Rc2",
              "Rg1",
              "Rgg2",
              "Rxg2",
              "hxg2+",
              "Kg1",
              "Re2",
              "b5",
              "Rxe3",
              "Kxg2",
              "Rb3",
              "a4",
              "d4",
              "Kf2",
              "d3",
              "Ke3",
              "d2+",
              "Kxd2",
              "Rxf3",
              "b6",
              "Rb3",
              "a5",
              "Kf8",
              "Kc2",
              "Rb5",
              "Kc3",
              "Ke7",
              "Kc4",
              "Rb2",
              "Kc5",
              "Kd7",
              "a6",
              "Rc2+",
              "Kb5",
              "Rb2+",
              "Ka5",
              "Kc6",
              "Rc1+",
              "Kd7",
              "a7",
              "Ra2+",
              "Kb5",
              "Rb2+",
              "Ka6",
              "Ra2+",
              "Kb7",
              "Rxa7+",
              "Kxa7",
              "Ke6",
              "b7",
              "Kf5",
              "b8=Q",
              "Kg5",
              "Qg3+",
              "Kh6",
              "Rc6+",
              "g6",
              "Qh4+",
              "Kg7",
              "Qf6+",
              "Kh6",
              "Rc4",
              "Kh5",
              "Rh4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 159,
            "completion_tokens": 463,
            "total_tokens": 622,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 479,
          "total_completion_tokens": 1743,
          "total_tokens": 2222
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 159,
            "completion_tokens": 463,
            "total_tokens": 622,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/pp2bppp/4pn2/2pP4/3P4/1P2PN2/PB3PPP/RN1QKB1R b KQ - 0 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "8... Nc6 9. dxc5 Bxc5 10. b4 Be7 11. Nbd2 Bf6 12. Qb3 Bxb2 13. Qxb2 Qf6 14. Qxf6 Nxf6 15. Rc1 Bd7 16. Bd3 Rfc8 17. Ke2 Kf8 18. Rc2 Ke7 19. Rhc1 h6 20. Nb3 b6 21. Ba6 Rd8 22. Bb7 Rab8 23. Bxc6 Bxc6 24. Rxc6 Nd5 25. Nbd4 Kd7 26. Ne5+ Ke7 27. Rc7+ Nxc7 28. Rxc7+ Kd6 29. Nxf7+ Kxc7 30. Nxd8 Kxd8 31. Nc6+ Kc7 32. Nxb8 Kxb8 33. Kd3 Kc7 34. Ke4 Kd6 35. f4 g6 36. g4 a6 37. h4 a5 38. bxa5 bxa5 39. a4 Kc5 40. Ke5 Kb4 41. Kxe6 Kxa4 42. f5 gxf5 43. gxf5 Kb3 44. f6 a4 45. f7 a3 46. f8=Q a2 47. Qa8 Kb2 48. Kf6 a1=Q 49. Qxa1+ Kxa1 50. e4 Kb2 51. e5 Kc3 52. e6 Kd4 53. e7 Ke4 54. e8=Q+ Kf4 55. Qh5 Kg3 56. Qxh6 Kh3 57. Qg5 Kh2 58. h5 Kh3 59. h6 Kh2 60. h7 Kh3 61. h8=Q# Nf3 Nf6 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 451,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "8... Nc6 9. dxc5 Bxc5 10. b4 Be7 11. Nbd2 Bf6 12. Qb3 Bxb2 13. Qxb2 Qf6 14. Qxf6 Nxf6 15. Rc1 Bd7 16. Bd3 Rfc8 17. Ke2 Kf8 18. Rc2 Ke7 19. Rhc1 h6 20. Nb3 b6 21. Ba6 Rd8 22. Bb7 Rab8 23. Bxc6 Bxc6 24. Rxc6 Nd5 25. Nbd4 Kd7 26. Ne5+ Ke7 27. Rc7+ Nxc7 28. Rxc7+ Kd6 29. Nxf7+ Kxc7 30. Nxd8 Kxd8 31. Nc6+ Kc7 32. Nxb8 Kxb8 33. Kd3 Kc7 34. Ke4 Kd6 35. f4 g6 36. g4 a6 37. h4 a5 38. bxa5 bxa5 39. a4 Kc5 40. Ke5 Kb4 41. Kxe6 Kxa4 42. f5 gxf5 43. gxf5 Kb3 44. f6 a4 45. f7 a3 46. f8=Q a2 47. Qa8 Kb2 48. Kf6 a1=Q 49. Qxa1+ Kxa1 50. e4 Kb2 51. e5 Kc3 52. e6 Kd4 53. e7 Ke4 54. e8=Q+ Kf4 55. Qh5 Kg3 56. Qxh6 Kh3 57. Qg5 Kh2 58. h5 Kh3 59. h6 Kh2 60. h7 Kh3 61. h8=Q# Nf3 Nf6 Nc6",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 451,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "8... Nc6 9. dxc5 Bxc5 10. b4 Be7 11. Nbd2 Bf6 12. Qb3 Bxb2 13. Qxb2 Qf6 14. Qxf6 Nxf6 15. Rc1 Bd7 16. Bd3 Rfc8 17. Ke2 Kf8 18. Rc2 Ke7 19. Rhc1 h6 20. Nb3 b6 21. Ba6 Rd8 22. Bb7 Rab8 23. Bxc6 Bxc6 24. Rxc6 Nd5 25. Nbd4 Kd7 26. Ne5+ Ke7 27. Rc7+ Nxc7 28. Rxc7+ Kd6 29. Nxf7+ Kxc7 30. Nxe6+ Kd7 31. Nexd8 Ke7 32. Nc6+ Kxf7 33. Nxb8 Ke6 34. Nc6 Kd5 35. Nxa7 Kc4 36. Nc8 Kb3 37. Nxb6 Kxa3 38. Nd5 Ka4 39. Kd3 Kb5 40. Kd4 Kc6 41. Kc4 Kd6 42. b5 Ke5 43. b6 Kd6 44. Kb5 Kxd5 45. b7 Ke4 46. b8=Q Kd3 47. Qg3 Ke2 48. Qxg7 Kxf2 49. Qxh6 Kxg2 50. Qf4 Kh3 51. Qg3# N1xg3 N1xg3",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 379,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd5",
            "Nxa7",
            "Kc4",
            "Nc8",
            "Kb3",
            "Nxb6",
            "Kxa3",
            "Nd5",
            "Ka4",
            "Kd3",
            "Kb5",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "b5",
            "Ke5",
            "b6",
            "Kd6",
            "Kb5",
            "Kxd5",
            "b7",
            "Ke4",
            "b8=Q",
            "Kd3",
            "Qg3",
            "Ke2",
            "Qxg7",
            "Kxf2",
            "Qxh6",
            "Kxg2",
            "Qf4",
            "Kh3",
            "Qg3#",
            "N1xg3",
            "N1xg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd5",
              "Nxa7",
              "Kc4",
              "Nc8",
              "Kb3",
              "Nxb6",
              "Kxa3",
              "Nd5",
              "Ka4",
              "Kd3",
              "Kb5",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "b5",
              "Ke5",
              "b6",
              "Kd6",
              "Kb5",
              "Kxd5",
              "b7",
              "Ke4",
              "b8=Q",
              "Kd3",
              "Qg3",
              "Ke2",
              "Qxg7",
              "Kxf2",
              "Qxh6",
              "Kxg2",
              "Qf4",
              "Kh3",
              "Qg3#",
              "N1xg3",
              "N1xg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 451,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 451,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 379,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 1281,
          "total_tokens": 1784
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 451,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 451,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 379,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/pp2bppp/4p3/2pn4/3P4/PP2PN2/1B3PPP/RN1QKB1R b KQ - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc5",
          "aggressive_uci": "e7c5",
          "aggressive_response": "9... Bxc5 10. b4 Be7 11. Nbd2 Bf6 12. Qb3 a5 13. b5 a4 14. Qc2 Na5 15. Bd3\nBxb2 16. Qxb2 Nxe3 17. Bxh7+ Kxh7 18. fxe3 Qd3 19. Kf2 Bd7 20. Ne5 Qf5+ 21.\nNdf3 Rfd8 22. g4 Qf6 23. Rad1 Be8 24. Rd4 Nb3 25. Rf4 Qe7 26. g5 Kg8 27. Rg1\nRac8 28. g6 f6 29. Nf7 Bxf7 30. gxf7+ Qxf7 31. Rxf6 Qe7 32. Rxe6 Qf7 33.\nReg6 Rd2+ 34. Qxd2 Nxd2 35. Rxg7+ Qxg7 36. Rxg7+ Kxg7 37. Nxd2 Rc3 38. Nb1\nRb3 39. Nd2 Rxa3 40. Nc4 Rb3 41. b6 a3 42. Nxa3 Rxa3 43. Kf3 Rb3 44. Kf4\nRxb6 45. e4 Rc6 46. e5 b5 47. Kf5 b4 48. e6 b3 49. e7 Kf7 50. h4 Kxe7 51.\nh5 b2 52. h6 b1=Q+ 53. Kg5 Qg6+ 54. Kf4 Rc4+ 55. Ke5 Qe6# 56. h7 Qe4# 57. h8=Q Rc5# 58. Kd6 Qd5# 59. Ke7 Qe6#",
          "aggressive_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 437,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "Be7",
            "Nbd2",
            "Bf6",
            "Qb3",
            "a5",
            "b5",
            "a4",
            "Qc2",
            "Na5",
            "Bd3",
            "Bxb2",
            "Qxb2",
            "Nxe3",
            "Bxh7+",
            "Kxh7",
            "fxe3",
            "Qd3",
            "Kf2",
            "Bd7",
            "Ne5",
            "Qf5+",
            "Ndf3",
            "Rfd8",
            "g4",
            "Qf6",
            "Rad1",
            "Be8",
            "Rd4",
            "Nb3",
            "Rf4",
            "Qe7",
            "g5",
            "Kg8",
            "Rg1",
            "Rac8",
            "g6",
            "f6",
            "Nf7",
            "Bxf7",
            "gxf7+",
            "Qxf7",
            "Rxf6",
            "Qe7",
            "Rxe6",
            "Qf7",
            "Reg6",
            "Rd2+",
            "Qxd2",
            "Nxd2",
            "Rxg7+",
            "Qxg7",
            "Rxg7+",
            "Kxg7",
            "Nxd2",
            "Rc3",
            "Nb1",
            "Rb3",
            "Nd2",
            "Rxa3",
            "Nc4",
            "Rb3",
            "b6",
            "a3",
            "Nxa3",
            "Rxa3",
            "Kf3",
            "Rb3",
            "Kf4",
            "Rxb6",
            "e4",
            "Rc6",
            "e5",
            "b5",
            "Kf5",
            "b4",
            "e6",
            "b3",
            "e7",
            "Kf7",
            "h4",
            "Kxe7",
            "h5",
            "b2",
            "h6",
            "b1=Q+",
            "Kg5",
            "Qg6+",
            "Kf4",
            "Rc4+",
            "Ke5",
            "Qe6#",
            "h7",
            "Qe4#",
            "h8=Q",
            "Rc5#",
            "Kd6",
            "Qd5#",
            "Ke7",
            "Qe6#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxc5",
          "positional_uci": "e7c5",
          "positional_response": "9... Bxc5 10. b4 Be7 11. Nbd2 Bf6 12. Qb3 Bxb2 13. Qxb2 Qf6 14. Qxf6 Nxf6 15.\nBb5 Bd7 16. O-O a6 17. Ba4 b5 18. Bb3 Rfd8 19. Rac1 Rac8 20. Rc5 Ne7 21. Rfc1 Rxc5\n22. Rxc5 Rc8 23. Rxc8+ Nxc8 24. Ne5 Be8 25. f3 Nd7 26. Nc6 Ndb6 27. Nd4 Nd6 28.\nKf2 Kf8 29. Ke2 Ke7 30. Kd3 e5 31. Ne2 f6 32. Nc3 Bf7 33. Bxf7 Kxf7 34. Nce4\nNxe4 35. Nxe4 Nc4 36. Nc5 Nxa3 37. Nxa6 Ke7 38. Nc5 Kd6 39. e4 Nc4 40. Nb3 Nb6\n41. Nc5 Nd7 42. Nb3 Kc6 43. Kc3 Nb6 44. Nc5 Na4+ 45. Nxa4 bxa4 46. Kb2 Kb6 47.\nKa2 Ka6 48. Kb2 Kb6 49. Ka2 Ka6 50. Kb2 Kb6 51. Ka2 Ka6 52. Kb2 Kb6 53. Ka2 Ka6\n54. Kb2 Kb6 55. Ka2 Ka6 56. Kb2 Kb6 57. Ka2 Ka6 58. Kb2 Kb6 59. Ka2 Ka6 60. Kb2\nKb6 61. Ka2 Ka6 62. Kb2 Kb6 63. Ka2 Ka6 64. Kb2 Kb6 65. Ka2 Ka6 66. Kb2 Kb6 67.\nKa2 Ka6 68. Kb2 Kb6 69. Ka2 Ka6 70. Kb2 Kb6 71. Ka2 Ka6 72. Kb2 Kb6 73. Ka2\nKa6 74. Kb2 Kb6 75. Ka2 Ka6 76. Kb2 Kb6 77. Ka2 Ka6 78. Kb2 Kb6 79. Ka2 Ka6 80.\nKb2 Kb6 81. Ka2 Ka6 82. Kb2 Kb6 83. Ka2 Ka6 84. Kb2 Kb6 85. Ka2 Ka6 86. Kb2\nKb6 87. Ka2 Ka6 88. Kb2 Kb6 89. Ka2 Ka6 90. Kb2 Kb6 91. Ka2 Ka6 92. Kb2 Kb6 93.",
          "positional_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "b4",
            "Be7",
            "Nbd2",
            "Bf6",
            "Qb3",
            "Bxb2",
            "Qxb2",
            "Qf6",
            "Qxf6",
            "Nxf6",
            "Bb5",
            "Bd7",
            "O-O",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Rfd8",
            "Rac1",
            "Rac8",
            "Rc5",
            "Ne7",
            "Rfc1",
            "Rxc5",
            "Rxc5",
            "Rc8",
            "Rxc8+",
            "Nxc8",
            "Ne5",
            "Be8",
            "f3",
            "Nd7",
            "Nc6",
            "Ndb6",
            "Nd4",
            "Nd6",
            "Kf2",
            "Kf8",
            "Ke2",
            "Ke7",
            "Kd3",
            "e5",
            "Ne2",
            "f6",
            "Nc3",
            "Bf7",
            "Bxf7",
            "Kxf7",
            "Nce4",
            "Nxe4",
            "Nxe4",
            "Nc4",
            "Nc5",
            "Nxa3",
            "Nxa6",
            "Ke7",
            "Nc5",
            "Kd6",
            "e4",
            "Nc4",
            "Nb3",
            "Nb6",
            "Nc5",
            "Nd7",
            "Nb3",
            "Kc6",
            "Kc3",
            "Nb6",
            "Nc5",
            "Na4+",
            "Nxa4",
            "bxa4",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6",
            "Ka2",
            "Ka6",
            "Kb2",
            "Kb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxc5",
          "neutral_uci": "e7c5",
          "neutral_response": "9... Bxc5 10. b4 Bb6 11. Nbd2 Qe7 12. Bd3 Rd8 13. Qb1 h6 14. O-O e5 15. Nc4 Bc7\n16. b5 Na5 17. Ncxe5 Be6 18. Bh7+ Kh8 19. Bf5 Nb3 20. Bxe6 Qxe6 21. Ra2 Kg8 22.\nQc2 Nxe3 23. fxe3 Bxe5 24. Bxe5 Rac8 25. Qe2 Nc1 26. Rxc1 Rxc1+ 27. Kf2 Rdd1 28.\nRd2 Rf1+ 29. Kg3 Qg6+ 30. Kh3 Qf5+ 31. Kg3 Qg6+ 32. Kh3 Qf5+ 33. Kg3 Qg6+ 34. Kh3\nQf5+ 35. Kg3 Qg6+ 36. Kh3 Qf5+ 37. Kg3 Qg6+ 38. Kh3 Qf5+ 39. Kg3 Qg6+ 40. Kh3\nQf5+ 41. Kg3 Qg6+ 42. Kh3 Qf5+ 43. Kg3 Qg6+ 44. Kh3 Qf5+ 45. Kg3 Qg6+ 46. Kh3\nQf5+ 47. Kg3 Qg6+ 48. Kh3 Qf5+ 49. Kg3 Qg6+ 50. Kh3 Qf5+ 51. Kg3 Qg6+ 52. Kh3\nQf5+ 53. Kg3 Qg6+ 54. Kh3 Qf5+ 55. Kg3 Qg6+ 56. Kh3 Qf5+ 57. Kg3 Qg6+ 58. Kh3\nQf5+ 59. Kg3 Qg6+ 60. Kh3 Qf5+ 61. Kg3 Qg6+ 62. Kh3 Qf5+ 63. Kg3 Qg6+ 64. Kh3\nQf5+ 65. Kg3 Qg6+ 66. Kh3 Qf5+ 67. Kg3 Qg6+ 68. Kh3 Qf5+ 69. Kg3 Qg6+ 70. Kh3\nQf5+ 71. Kg3 Qg6+ 72. Kh3 Qf5+ 73. Kg3 Qg6+ 74. Kh3 Qf5+ 75. Kg3 Qg6+ 76. Kh3\nQf5+ 77. Kg3 Qg6+ 78. Kh3 Qf5+ 79. Kg3 Qg6+ 80. Kh3 Qf",
          "neutral_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "b4",
            "Bb6",
            "Nbd2",
            "Qe7",
            "Bd3",
            "Rd8",
            "Qb1",
            "h6",
            "O-O",
            "e5",
            "Nc4",
            "Bc7",
            "b5",
            "Na5",
            "Ncxe5",
            "Be6",
            "Bh7+",
            "Kh8",
            "Bf5",
            "Nb3",
            "Bxe6",
            "Qxe6",
            "Ra2",
            "Kg8",
            "Qc2",
            "Nxe3",
            "fxe3",
            "Bxe5",
            "Bxe5",
            "Rac8",
            "Qe2",
            "Nc1",
            "Rxc1",
            "Rxc1+",
            "Kf2",
            "Rdd1",
            "Rd2",
            "Rf1+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3",
            "Qf5+",
            "Kg3",
            "Qg6+",
            "Kh3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7c5",
          "positional_uci": "e7c5",
          "neutral_uci": "e7c5",
          "consensus_move": "e7c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b4",
              "Be7",
              "Nbd2",
              "Bf6",
              "Qb3",
              "a5",
              "b5",
              "a4",
              "Qc2",
              "Na5",
              "Bd3",
              "Bxb2",
              "Qxb2",
              "Nxe3",
              "Bxh7+",
              "Kxh7",
              "fxe3",
              "Qd3",
              "Kf2",
              "Bd7",
              "Ne5",
              "Qf5+",
              "Ndf3",
              "Rfd8",
              "g4",
              "Qf6",
              "Rad1",
              "Be8",
              "Rd4",
              "Nb3",
              "Rf4",
              "Qe7",
              "g5",
              "Kg8",
              "Rg1",
              "Rac8",
              "g6",
              "f6",
              "Nf7",
              "Bxf7",
              "gxf7+",
              "Qxf7",
              "Rxf6",
              "Qe7",
              "Rxe6",
              "Qf7",
              "Reg6",
              "Rd2+",
              "Qxd2",
              "Nxd2",
              "Rxg7+",
              "Qxg7",
              "Rxg7+",
              "Kxg7",
              "Nxd2",
              "Rc3",
              "Nb1",
              "Rb3",
              "Nd2",
              "Rxa3",
              "Nc4",
              "Rb3",
              "b6",
              "a3",
              "Nxa3",
              "Rxa3",
              "Kf3",
              "Rb3",
              "Kf4",
              "Rxb6",
              "e4",
              "Rc6",
              "e5",
              "b5",
              "Kf5",
              "b4",
              "e6",
              "b3",
              "e7",
              "Kf7",
              "h4",
              "Kxe7",
              "h5",
              "b2",
              "h6",
              "b1=Q+",
              "Kg5",
              "Qg6+",
              "Kf4",
              "Rc4+",
              "Ke5",
              "Qe6#",
              "h7",
              "Qe4#",
              "h8=Q",
              "Rc5#",
              "Kd6",
              "Qd5#",
              "Ke7",
              "Qe6#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "b4",
              "Be7",
              "Nbd2",
              "Bf6",
              "Qb3",
              "Bxb2",
              "Qxb2",
              "Qf6",
              "Qxf6",
              "Nxf6",
              "Bb5",
              "Bd7",
              "O-O",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Rfd8",
              "Rac1",
              "Rac8",
              "Rc5",
              "Ne7",
              "Rfc1",
              "Rxc5",
              "Rxc5",
              "Rc8",
              "Rxc8+",
              "Nxc8",
              "Ne5",
              "Be8",
              "f3",
              "Nd7",
              "Nc6",
              "Ndb6",
              "Nd4",
              "Nd6",
              "Kf2",
              "Kf8",
              "Ke2",
              "Ke7",
              "Kd3",
              "e5",
              "Ne2",
              "f6",
              "Nc3",
              "Bf7",
              "Bxf7",
              "Kxf7",
              "Nce4",
              "Nxe4",
              "Nxe4",
              "Nc4",
              "Nc5",
              "Nxa3",
              "Nxa6",
              "Ke7",
              "Nc5",
              "Kd6",
              "e4",
              "Nc4",
              "Nb3",
              "Nb6",
              "Nc5",
              "Nd7",
              "Nb3",
              "Kc6",
              "Kc3",
              "Nb6",
              "Nc5",
              "Na4+",
              "Nxa4",
              "bxa4",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6",
              "Ka2",
              "Ka6",
              "Kb2",
              "Kb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "b4",
              "Bb6",
              "Nbd2",
              "Qe7",
              "Bd3",
              "Rd8",
              "Qb1",
              "h6",
              "O-O",
              "e5",
              "Nc4",
              "Bc7",
              "b5",
              "Na5",
              "Ncxe5",
              "Be6",
              "Bh7+",
              "Kh8",
              "Bf5",
              "Nb3",
              "Bxe6",
              "Qxe6",
              "Ra2",
              "Kg8",
              "Qc2",
              "Nxe3",
              "fxe3",
              "Bxe5",
              "Bxe5",
              "Rac8",
              "Qe2",
              "Nc1",
              "Rxc1",
              "Rxc1+",
              "Kf2",
              "Rdd1",
              "Rd2",
              "Rf1+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3",
              "Qf5+",
              "Kg3",
              "Qg6+",
              "Kh3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 178,
            "completion_tokens": 437,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 533,
          "total_completion_tokens": 1717,
          "total_tokens": 2250
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 178,
            "completion_tokens": 437,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bq1rk1/pp2bppp/2n1p3/2Pn4/8/PP2PN2/1B3PPP/RN1QKB1R b KQ - 0 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qb6",
          "aggressive_uci": "d8b6",
          "aggressive_response": "10... Qb6 11. b4 Bxe3 12. fxe3 Nxe3 13. Qc3 e5 14. Nbd2 Bf5 15. Rc1 Rac8 16. Qc5\nNd4 17. Qxb6 Rxc1+ 18. Bxc1 Nec2+ 19. Kf2 axb6 20. Nxe5 Re8 21. Ndf3 f6 22. Bc4+\nKf8 23. Nxd4 Nxd4 24. Nf3 Nxf3 25. gxf3 Rc8 26. Be2 Rc2 27. Be3 Bd3 28. Re1 Ra2\n29. Bxb6 Kf7 30. Ke3 Bxe2 31. Rxe2 Rxa3+ 32. Kf2 Rb3 33. Bc5 b6 34. Re7+ Kg6 35.\nBxb6 Rxb4 36. Be3 Rb2+ 37. Kg3 Rb3 38. h4 h5 39. Bc5 Rb8 40. Rc7 Rg8 41. Kf4\nKh6 42. Kf5 g5 43. Be3 Rg7 44. hxg5+ fxg5 45. Rc6+ Kh7 46. Bxg5 Rf7+ 47. Bf6\nh4 48. Rc8 Rxf6+ 49. Kxf6 h3 50. Rc4 h2 51. Rh4+ Kg8 52. Rxh2 Kf8 53. Rh8# Qb6\nBxe3+ Kg7 Qb7",
          "aggressive_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 382,
            "total_tokens": 569,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe3+",
            "Kg7",
            "Qb7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qb6",
          "positional_uci": "d8b6",
          "positional_response": "10... Qb6 11. b4 Bxe3 12. fxe3 Nxe3 13. Qc3 e5 14. Nbd2 Bf5 15. Rc1 Rac8 16. Qc5\nNd4 17. Qxb6 Rxc1+ 18. Bxc1 Nec2+ 19. Kf2 axb6 20. Nxe5 Re8 21. Ndf3 Nxf3 22.\nNxf3 Be4 23. Bb5 Re7 24. Rd1 h6 25. Rd8+ Kh7 26. Re8 Rxe8 27. Bxe8 f5 28. Bb2\ng5 29. Nd2 Bd3 30. Bd7 Kg6 31. Bc8 Ba6 32. Nf3 f4 33. Ne5+ Kh5 34. Bg4+ Kh4 35.\ng3+ fxg3+ 36. hxg3# Qb6+ 37. Kg2 Ne3+ 38. Kf3 Nxg4 39. Nxg4 Qc6+ 40. Kf2 Kxg4\n41. Be5 Qf3+ 42. Kg1 Kh3 43. g4 Qg2# Qxg4+ 44. Kf2 Qe2+ 45. Kg1 Qf1# 0-1",
          "positional_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 315,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg2",
            "Ne3+",
            "Kf3",
            "Nxg4",
            "Nxg4",
            "Qc6+",
            "Kf2",
            "Kxg4",
            "Be5",
            "Qf3+",
            "Kg1",
            "Kh3",
            "g4",
            "Qg2#",
            "Qxg4+",
            "Kf2",
            "Qe2+",
            "Kg1",
            "Qf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qb6",
          "neutral_uci": "d8b6",
          "neutral_response": "10... Qb6 11. Nbd2 Bxe3 12. fxe3 Qxe3+ 13. Be2 Nf4 14. Qc4 Nxg2+ 15. Kf1 Nf4 16.\nRg1 e5 17. Rg3 Be6 18. Qe4 Qxe4 19. Nxe4 Nxe2 20. Kxe2 Bxb3 21. Nxe5 Nxe5 22.\nBxe5 Rfe8 23. Nf6+ Kf8 24. Nxh7+ Ke7 25. Rxb3 Ke6 26. Re3 Kf5 27. Rf1+ Kg6 28.\nRg1+ Kxh7 29. Rxg7+ Kh6 30. Rh3# Qb6 31. Rg4# Qb5+ 32. Kf2# Qxe5",
          "neutral_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 207,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg4#",
            "Qb5+",
            "Kf2#",
            "Qxe5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8b6",
          "positional_uci": "d8b6",
          "neutral_uci": "d8b6",
          "consensus_move": "d8b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe3+",
              "Kg7",
              "Qb7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg2",
              "Ne3+",
              "Kf3",
              "Nxg4",
              "Nxg4",
              "Qc6+",
              "Kf2",
              "Kxg4",
              "Be5",
              "Qf3+",
              "Kg1",
              "Kh3",
              "g4",
              "Qg2#",
              "Qxg4+",
              "Kf2",
              "Qe2+",
              "Kg1",
              "Qf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg4#",
              "Qb5+",
              "Kf2#",
              "Qxe5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 187,
            "completion_tokens": 382,
            "total_tokens": 569,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 187,
            "completion_tokens": 315,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 186,
            "completion_tokens": 207,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 560,
          "total_completion_tokens": 904,
          "total_tokens": 1464
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 187,
            "completion_tokens": 382,
            "total_tokens": 569,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 187,
            "completion_tokens": 315,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 186,
            "completion_tokens": 207,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/pp3ppp/2n1p3/2bn4/8/PP2PN2/1B3PPP/RNQ1KB1R b KQ - 1 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxe3",
          "aggressive_uci": "c5e3",
          "aggressive_response": "11... Bxe3 12. fxe3 Qxe3+ 13. Be2 Nf4 14. Qc4 Nxg2+ 15. Kd1 Rd8 16. Qc3 Qh6 17. Rg1 Ne3+ 18. Kc1 e5 19. Nxe5 Nd4 20. Bc4 Be6 21. Kb1 Rac8 22. Ka2 b5 23. Rae1 bxc4 24. Rxe3 cxb3+ 25. Nxb3 Rxc3 26. Rxc3 Nxb3 27. Rxb3 Rb8 28. Rg3 Bxb3+ 29. Rxb3 Rxb3 30. Kxb3 Qe6+ 31. Nc4 f5 32. Bd4 f4 33. Kc3 f3 34. Ne5 Qf5 35. Nd3 Qe4 36. Bxa7 Qe2 37. Bf2 g5 38. a4 h5 39. a5 g4 40. a6 Qe6 41. a7 Qc6+ 42. Kd2 Qb7 43. Ke3 Qxa7+ 44. Kf4 Qa3 45. Ne5 Qb2 46. Bg3 f2 47. Bxf2 Qxf2+ 48. Kg5 Qxh2 49. Ng6 g3 50. Nf4 g2 51. Nxg2 Qxg2+ 52. Kxh5 Kf7 53. Kh4 Kf6 54. Kh5 Qg5# Bb3 Bc2 Bb3",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 383,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxe3",
            "Qxe3+",
            "Be2",
            "Nf4",
            "Qc4",
            "Nxg2+",
            "Kd1",
            "Rd8",
            "Qc3",
            "Qh6",
            "Rg1",
            "Ne3+",
            "Kc1",
            "e5",
            "Nxe5",
            "Nd4",
            "Bc4",
            "Be6",
            "Kb1",
            "Rac8",
            "Ka2",
            "b5",
            "Rae1",
            "bxc4",
            "Rxe3",
            "cxb3+",
            "Nxb3",
            "Rxc3",
            "Rxc3",
            "Nxb3",
            "Rxb3",
            "Rb8",
            "Rg3",
            "Bxb3+",
            "Rxb3",
            "Rxb3",
            "Kxb3",
            "Qe6+",
            "Nc4",
            "f5",
            "Bd4",
            "f4",
            "Kc3",
            "f3",
            "Ne5",
            "Qf5",
            "Nd3",
            "Qe4",
            "Bxa7",
            "Qe2",
            "Bf2",
            "g5",
            "a4",
            "h5",
            "a5",
            "g4",
            "a6",
            "Qe6",
            "a7",
            "Qc6+",
            "Kd2",
            "Qb7",
            "Ke3",
            "Qxa7+",
            "Kf4",
            "Qa3",
            "Ne5",
            "Qb2",
            "Bg3",
            "f2",
            "Bxf2",
            "Qxf2+",
            "Kg5",
            "Qxh2",
            "Ng6",
            "g3",
            "Nf4",
            "g2",
            "Nxg2",
            "Qxg2+",
            "Kxh5",
            "Kf7",
            "Kh4",
            "Kf6",
            "Kh5",
            "Qg5#",
            "Bb3",
            "Bc2",
            "Bb3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxe3",
          "positional_uci": "c5e3",
          "positional_response": "11... Bxe3 12. fxe3 Qxe3+ 13. Be2 Nf4 14. Qc4 Nxg2+ 15. Kf1 Nf4 16. Rg1 e5 17. Rg3 Be6 18. Qe4 Qxe4 19. Nxe4 Nxe2 20. Kxe2 Bxb3 21. Nxe5 Nxe5 22. Bxe5 Bc4+ 23. Kf2 f6 24. Nxf6+ Kh8 25. Rf3 gxf6 26. Bxf6+ Kg8 27. Rg1+ Kf7 28. Bg7+ Ke7 29. Bxf8+ Rxf8 30. Rg7+ Rf7 31. Rgxf7+ Bxf7 32. Ke3 Bd5 33. Rf5 Bf7 34. Kd4 Bg6 35. Rc5 Kd6 36. Rc8 Bf5 37. Ra8 a6 38. Rf8 Bg6 39. Rf6+ Kc7 40. Kc5 Be4 41. Rf7+ Kb8 42. Kb6 Kc8 43. Rc7+ Kb8 44. Re7 Bc6 45. Rxh7 Kc8 46. Rc7+ Kd8 47. Rxc6 bxc6 48. Kxc6 Ke7 49. Kb6 Kf6 50. Kxa6 Kg5 51. Kb7 Kh4 52. a4 Kh3 53. a5 Kxh2 54. a6 Kg3 55. a7 Kf4 56. a8=Q Ke5 57. Qd8 Ke6 58. Kc6 Ke5 59. Qd5+ Kf4 60. Qe6 Kf3 61. Kd5 Kf4 62. Qe4+ Kg5 63. Qf3 Kg6 64. Ke6 Kg5 65. Qf5+ Kh4 66. Qg6 Kh3 67. Kf5 Kh2 68. Kf4 Kh1 69. Kf3 Kh2 70. Qg2# Bxg2+ Kxg2 Kf2 Kf3 Ke3 Ke4 Kd4 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 Kd6 Kc5 Kc6 Kd5 K",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe3",
            "Qxe3+",
            "Be2",
            "Nf4",
            "Qc4",
            "Nxg2+",
            "Kf1",
            "Nf4",
            "Rg1",
            "e5",
            "Rg3",
            "Be6",
            "Qe4",
            "Qxe4",
            "Nxe4",
            "Nxe2",
            "Kxe2",
            "Bxb3",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "Bc4+",
            "Kf2",
            "f6",
            "Nxf6+",
            "Kh8",
            "Rf3",
            "gxf6",
            "Bxf6+",
            "Kg8",
            "Rg1+",
            "Kf7",
            "Bg7+",
            "Ke7",
            "Bxf8+",
            "Rxf8",
            "Rg7+",
            "Rf7",
            "Rgxf7+",
            "Bxf7",
            "Ke3",
            "Bd5",
            "Rf5",
            "Bf7",
            "Kd4",
            "Bg6",
            "Rc5",
            "Kd6",
            "Rc8",
            "Bf5",
            "Ra8",
            "a6",
            "Rf8",
            "Bg6",
            "Rf6+",
            "Kc7",
            "Kc5",
            "Be4",
            "Rf7+",
            "Kb8",
            "Kb6",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Re7",
            "Bc6",
            "Rxh7",
            "Kc8",
            "Rc7+",
            "Kd8",
            "Rxc6",
            "bxc6",
            "Kxc6",
            "Ke7",
            "Kb6",
            "Kf6",
            "Kxa6",
            "Kg5",
            "Kb7",
            "Kh4",
            "a4",
            "Kh3",
            "a5",
            "Kxh2",
            "a6",
            "Kg3",
            "a7",
            "Kf4",
            "a8=Q",
            "Ke5",
            "Qd8",
            "Ke6",
            "Kc6",
            "Ke5",
            "Qd5+",
            "Kf4",
            "Qe6",
            "Kf3",
            "Kd5",
            "Kf4",
            "Qe4+",
            "Kg5",
            "Qf3",
            "Kg6",
            "Ke6",
            "Kg5",
            "Qf5+",
            "Kh4",
            "Qg6",
            "Kh3",
            "Kf5",
            "Kh2",
            "Kf4",
            "Kh1",
            "Kf3",
            "Kh2",
            "Qg2#",
            "Bxg2+",
            "Kxg2",
            "Kf2",
            "Kf3",
            "Ke3",
            "Ke4",
            "Kd4",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5",
            "Kd6",
            "Kc5",
            "Kc6",
            "Kd5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxe3",
          "neutral_uci": "c5e3",
          "neutral_response": "11... Bxe3 12. fxe3 Qxe3+ 13. Be2 Nf4 14. Qc4 Nxg2+ 15. Kd1 Rd8 16. Rg1 Qf2 17. Kc1 Ne3 18. Rxg7+ Kf8 19. Qc5+ Ke8 20. Rg8+ Kd7 21. Ne5+ Kc7 22. Rxd8 Qe1+ 23. Bd1 Qxd1# Bb6 Qe1+ Bc1 Qxd1# Bb6 Qe1+ Bc1 Qxd1#",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 144,
            "total_tokens": 339,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxe3",
            "Qxe3+",
            "Be2",
            "Nf4",
            "Qc4",
            "Nxg2+",
            "Kd1",
            "Rd8",
            "Rg1",
            "Qf2",
            "Kc1",
            "Ne3",
            "Rxg7+",
            "Kf8",
            "Qc5+",
            "Ke8",
            "Rg8+",
            "Kd7",
            "Ne5+",
            "Kc7",
            "Rxd8",
            "Qe1+",
            "Bd1",
            "Qxd1#",
            "Bb6",
            "Qe1+",
            "Bc1",
            "Qxd1#",
            "Bb6",
            "Qe1+",
            "Bc1",
            "Qxd1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5e3",
          "positional_uci": "c5e3",
          "neutral_uci": "c5e3",
          "consensus_move": "c5e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxe3",
              "Qxe3+",
              "Be2",
              "Nf4",
              "Qc4",
              "Nxg2+",
              "Kd1",
              "Rd8",
              "Qc3",
              "Qh6",
              "Rg1",
              "Ne3+",
              "Kc1",
              "e5",
              "Nxe5",
              "Nd4",
              "Bc4",
              "Be6",
              "Kb1",
              "Rac8",
              "Ka2",
              "b5",
              "Rae1",
              "bxc4",
              "Rxe3",
              "cxb3+",
              "Nxb3",
              "Rxc3",
              "Rxc3",
              "Nxb3",
              "Rxb3",
              "Rb8",
              "Rg3",
              "Bxb3+",
              "Rxb3",
              "Rxb3",
              "Kxb3",
              "Qe6+",
              "Nc4",
              "f5",
              "Bd4",
              "f4",
              "Kc3",
              "f3",
              "Ne5",
              "Qf5",
              "Nd3",
              "Qe4",
              "Bxa7",
              "Qe2",
              "Bf2",
              "g5",
              "a4",
              "h5",
              "a5",
              "g4",
              "a6",
              "Qe6",
              "a7",
              "Qc6+",
              "Kd2",
              "Qb7",
              "Ke3",
              "Qxa7+",
              "Kf4",
              "Qa3",
              "Ne5",
              "Qb2",
              "Bg3",
              "f2",
              "Bxf2",
              "Qxf2+",
              "Kg5",
              "Qxh2",
              "Ng6",
              "g3",
              "Nf4",
              "g2",
              "Nxg2",
              "Qxg2+",
              "Kxh5",
              "Kf7",
              "Kh4",
              "Kf6",
              "Kh5",
              "Qg5#",
              "Bb3",
              "Bc2",
              "Bb3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "fxe3",
              "Qxe3+",
              "Be2",
              "Nf4",
              "Qc4",
              "Nxg2+",
              "Kf1",
              "Nf4",
              "Rg1",
              "e5",
              "Rg3",
              "Be6",
              "Qe4",
              "Qxe4",
              "Nxe4",
              "Nxe2",
              "Kxe2",
              "Bxb3",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "Bc4+",
              "Kf2",
              "f6",
              "Nxf6+",
              "Kh8",
              "Rf3",
              "gxf6",
              "Bxf6+",
              "Kg8",
              "Rg1+",
              "Kf7",
              "Bg7+",
              "Ke7",
              "Bxf8+",
              "Rxf8",
              "Rg7+",
              "Rf7",
              "Rgxf7+",
              "Bxf7",
              "Ke3",
              "Bd5",
              "Rf5",
              "Bf7",
              "Kd4",
              "Bg6",
              "Rc5",
              "Kd6",
              "Rc8",
              "Bf5",
              "Ra8",
              "a6",
              "Rf8",
              "Bg6",
              "Rf6+",
              "Kc7",
              "Kc5",
              "Be4",
              "Rf7+",
              "Kb8",
              "Kb6",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Re7",
              "Bc6",
              "Rxh7",
              "Kc8",
              "Rc7+",
              "Kd8",
              "Rxc6",
              "bxc6",
              "Kxc6",
              "Ke7",
              "Kb6",
              "Kf6",
              "Kxa6",
              "Kg5",
              "Kb7",
              "Kh4",
              "a4",
              "Kh3",
              "a5",
              "Kxh2",
              "a6",
              "Kg3",
              "a7",
              "Kf4",
              "a8=Q",
              "Ke5",
              "Qd8",
              "Ke6",
              "Kc6",
              "Ke5",
              "Qd5+",
              "Kf4",
              "Qe6",
              "Kf3",
              "Kd5",
              "Kf4",
              "Qe4+",
              "Kg5",
              "Qf3",
              "Kg6",
              "Ke6",
              "Kg5",
              "Qf5+",
              "Kh4",
              "Qg6",
              "Kh3",
              "Kf5",
              "Kh2",
              "Kf4",
              "Kh1",
              "Kf3",
              "Kh2",
              "Qg2#",
              "Bxg2+",
              "Kxg2",
              "Kf2",
              "Kf3",
              "Ke3",
              "Ke4",
              "Kd4",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5",
              "Kd6",
              "Kc5",
              "Kc6",
              "Kd5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "fxe3",
              "Qxe3+",
              "Be2",
              "Nf4",
              "Qc4",
              "Nxg2+",
              "Kd1",
              "Rd8",
              "Rg1",
              "Qf2",
              "Kc1",
              "Ne3",
              "Rxg7+",
              "Kf8",
              "Qc5+",
              "Ke8",
              "Rg8+",
              "Kd7",
              "Ne5+",
              "Kc7",
              "Rxd8",
              "Qe1+",
              "Bd1",
              "Qxd1#",
              "Bb6",
              "Qe1+",
              "Bc1",
              "Qxd1#",
              "Bb6",
              "Qe1+",
              "Bc1",
              "Qxd1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 383,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 144,
            "total_tokens": 339,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 1167,
          "total_tokens": 1754
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 383,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 144,
            "total_tokens": 339,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b2rk1/pp3ppp/1qn1p3/2bn4/8/PP2PN2/1B1N1PPP/R1Q1KB1R b KQ - 3 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe3+",
          "aggressive_uci": "b6e3",
          "aggressive_response": "1. Nf3 Nf6 2. e3 d5 3. c4 e6 4. b3 Be7 5. Bb2 O-O 6. d4 c5 7. cxd5 Nxd5 8. a3\nNc6 9. dxc5 Bxc5 10. Qc1 Qb6 11. Nbd2 Bxe3 12. fxe3 Qxe3+ 13. Be2 Nf4 14. Qc4 Nxg2+ 15. Kd1 Rd8",
          "aggressive_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 126,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Nf4",
            "Qc4",
            "Nxg2+",
            "Kd1",
            "Rd8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe3+",
          "positional_uci": "b6e3",
          "positional_response": "12... Qxe3+ 13. Be2 Nf4 14. Qc4 Nxg2+ 15. Kd1 Rd8 16. Qg4 Qxb3+ 17. Kc1 Qxb2+ 18. Kxb2 Ne3 19. Qe4 Nf5 20. Rad1 Bd7 21. Nc4 Be8 22. Rxd8 Rxd8 23. Rd1 Rxd1 24. Bxd1 b5 25. Nce5 Nxe5 26. Nxe5 f6 27. Qa8 Kf8 28. Nc6 Nd6 29. Bb3 Kf7 30. Qxa7+ Kg6 31. Ne7+ Kh6 32. Qe3+ g5 33. Qxe6 Nc4+ 34. Bxc4 bxc4 35. Qxf6+ Bg6 36. Nf5+ Kh5 37. h3 g4 38. Qh4# Nf3 gxf3 Qg4#",
          "positional_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 241,
            "total_tokens": 446,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Nf4",
            "Qc4",
            "Nxg2+",
            "Kd1",
            "Rd8",
            "Qg4",
            "Qxb3+",
            "Kc1",
            "Qxb2+",
            "Kxb2",
            "Ne3",
            "Qe4",
            "Nf5",
            "Rad1",
            "Bd7",
            "Nc4",
            "Be8",
            "Rxd8",
            "Rxd8",
            "Rd1",
            "Rxd1",
            "Bxd1",
            "b5",
            "Nce5",
            "Nxe5",
            "Nxe5",
            "f6",
            "Qa8",
            "Kf8",
            "Nc6",
            "Nd6",
            "Bb3",
            "Kf7",
            "Qxa7+",
            "Kg6",
            "Ne7+",
            "Kh6",
            "Qe3+",
            "g5",
            "Qxe6",
            "Nc4+",
            "Bxc4",
            "bxc4",
            "Qxf6+",
            "Bg6",
            "Nf5+",
            "Kh5",
            "h3",
            "g4",
            "Qh4#",
            "Nf3",
            "gxf3",
            "Qg4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe3+",
          "neutral_uci": "b6e3",
          "neutral_response": "1. Nf3 Nf6 2. e3 d5 3. c4 e6 4. b3 Be7 5. Bb2 O-O 6. d4 c5 7. cxd5 Nxd5 8. a3\nNc6 9. dxc5 Bxc5 10. Qc1 Qb6 11. Nbd2 Bxe3 12. fxe3 Qxe3+ 13. Be2 Nf4 14. Qc4 Nxg2+ 15. Kd1 Rd8 16. Rg1 Qf2 17. Kc1 e5 18. Kb1 Be6 19. Qe4 f5 20. Bc4 fxe4 21. Bxe6+ Kh8 22. Nxe4 Qxf3 23. Ng5 Qd3+ 24. Ka2 Nf4 25. Nf7+ Kg8 26. Nxe5+ Nxe6 27. Nxd3 Rxd3 28. Rae1 Ncd4 29. Re4 Rc8 30. Rg2 Rc2 31. Rxc2 Nxc2 32. Rxe6 Kf7 33. Re4 Rd2 34. h4 Rh2 35. Rg4 g6 36. Rf4+ Ke6 37. Re4+ Kd5 38. Re5+ Kd6 39. Re4 b5 40. Kb1 Kd5 41. Re5+ Kd6 42. Re4 a5 43. Be5+ Kd5 44. Bxh2 Kxe4 45. Kxc2 Kf3 46. Bc7 a4 47. bxa4 bxa4 48. Kc3 Kg4 49. Bd8 h6 50. Kb4 g5 51. hxg5 hxg5 52. Kxa4 Kf5 53. Kb5 g4 54. a4 g3 55. a5 g2 56. Bb6 Ke6 57. Kc6 Ke7 58. a6 Ke6 59. a7 Ke5 60. a8=Q Ke4 61. Qe8+ Kd3 62. Qe3+ Kc4 63. Qd4+ Kb3 64. Qd3+ Kb4 65. Bc5+ Ka4 66. Qa3# Nf3 Nf4 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 559,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Nf4",
            "Qc4",
            "Nxg2+",
            "Kd1",
            "Rd8",
            "Rg1",
            "Qf2",
            "Kc1",
            "e5",
            "Kb1",
            "Be6",
            "Qe4",
            "f5",
            "Bc4",
            "fxe4",
            "Bxe6+",
            "Kh8",
            "Nxe4",
            "Qxf3",
            "Ng5",
            "Qd3+",
            "Ka2",
            "Nf4",
            "Nf7+",
            "Kg8",
            "Nxe5+",
            "Nxe6",
            "Nxd3",
            "Rxd3",
            "Rae1",
            "Ncd4",
            "Re4",
            "Rc8",
            "Rg2",
            "Rc2",
            "Rxc2",
            "Nxc2",
            "Rxe6",
            "Kf7",
            "Re4",
            "Rd2",
            "h4",
            "Rh2",
            "Rg4",
            "g6",
            "Rf4+",
            "Ke6",
            "Re4+",
            "Kd5",
            "Re5+",
            "Kd6",
            "Re4",
            "b5",
            "Kb1",
            "Kd5",
            "Re5+",
            "Kd6",
            "Re4",
            "a5",
            "Be5+",
            "Kd5",
            "Bxh2",
            "Kxe4",
            "Kxc2",
            "Kf3",
            "Bc7",
            "a4",
            "bxa4",
            "bxa4",
            "Kc3",
            "Kg4",
            "Bd8",
            "h6",
            "Kb4",
            "g5",
            "hxg5",
            "hxg5",
            "Kxa4",
            "Kf5",
            "Kb5",
            "g4",
            "a4",
            "g3",
            "a5",
            "g2",
            "Bb6",
            "Ke6",
            "Kc6",
            "Ke7",
            "a6",
            "Ke6",
            "a7",
            "Ke5",
            "a8=Q",
            "Ke4",
            "Qe8+",
            "Kd3",
            "Qe3+",
            "Kc4",
            "Qd4+",
            "Kb3",
            "Qd3+",
            "Kb4",
            "Bc5+",
            "Ka4",
            "Qa3#",
            "Nf3",
            "Nf4",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b6e3",
          "positional_uci": "b6e3",
          "neutral_uci": "b6e3",
          "consensus_move": "b6e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be2",
              "Nf4",
              "Qc4",
              "Nxg2+",
              "Kd1",
              "Rd8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be2",
              "Nf4",
              "Qc4",
              "Nxg2+",
              "Kd1",
              "Rd8",
              "Qg4",
              "Qxb3+",
              "Kc1",
              "Qxb2+",
              "Kxb2",
              "Ne3",
              "Qe4",
              "Nf5",
              "Rad1",
              "Bd7",
              "Nc4",
              "Be8",
              "Rxd8",
              "Rxd8",
              "Rd1",
              "Rxd1",
              "Bxd1",
              "b5",
              "Nce5",
              "Nxe5",
              "Nxe5",
              "f6",
              "Qa8",
              "Kf8",
              "Nc6",
              "Nd6",
              "Bb3",
              "Kf7",
              "Qxa7+",
              "Kg6",
              "Ne7+",
              "Kh6",
              "Qe3+",
              "g5",
              "Qxe6",
              "Nc4+",
              "Bxc4",
              "bxc4",
              "Qxf6+",
              "Bg6",
              "Nf5+",
              "Kh5",
              "h3",
              "g4",
              "Qh4#",
              "Nf3",
              "gxf3",
              "Qg4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be2",
              "Nf4",
              "Qc4",
              "Nxg2+",
              "Kd1",
              "Rd8",
              "Rg1",
              "Qf2",
              "Kc1",
              "e5",
              "Kb1",
              "Be6",
              "Qe4",
              "f5",
              "Bc4",
              "fxe4",
              "Bxe6+",
              "Kh8",
              "Nxe4",
              "Qxf3",
              "Ng5",
              "Qd3+",
              "Ka2",
              "Nf4",
              "Nf7+",
              "Kg8",
              "Nxe5+",
              "Nxe6",
              "Nxd3",
              "Rxd3",
              "Rae1",
              "Ncd4",
              "Re4",
              "Rc8",
              "Rg2",
              "Rc2",
              "Rxc2",
              "Nxc2",
              "Rxe6",
              "Kf7",
              "Re4",
              "Rd2",
              "h4",
              "Rh2",
              "Rg4",
              "g6",
              "Rf4+",
              "Ke6",
              "Re4+",
              "Kd5",
              "Re5+",
              "Kd6",
              "Re4",
              "b5",
              "Kb1",
              "Kd5",
              "Re5+",
              "Kd6",
              "Re4",
              "a5",
              "Be5+",
              "Kd5",
              "Bxh2",
              "Kxe4",
              "Kxc2",
              "Kf3",
              "Bc7",
              "a4",
              "bxa4",
              "bxa4",
              "Kc3",
              "Kg4",
              "Bd8",
              "h6",
              "Kb4",
              "g5",
              "hxg5",
              "hxg5",
              "Kxa4",
              "Kf5",
              "Kb5",
              "g4",
              "a4",
              "g3",
              "a5",
              "g2",
              "Bb6",
              "Ke6",
              "Kc6",
              "Ke7",
              "a6",
              "Ke6",
              "a7",
              "Ke5",
              "a8=Q",
              "Ke4",
              "Qe8+",
              "Kd3",
              "Qe3+",
              "Kc4",
              "Qd4+",
              "Kb3",
              "Qd3+",
              "Kb4",
              "Bc5+",
              "Ka4",
              "Qa3#",
              "Nf3",
              "Nf4",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 205,
            "completion_tokens": 126,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 205,
            "completion_tokens": 241,
            "total_tokens": 446,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 204,
            "completion_tokens": 559,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 614,
          "total_completion_tokens": 926,
          "total_tokens": 1540
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 205,
            "completion_tokens": 126,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 205,
            "completion_tokens": 241,
            "total_tokens": 446,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 204,
            "completion_tokens": 559,
            "total_tokens": 763,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b2rk1/pp3ppp/1qn1p3/3n4/8/PP2PN2/1B1N2PP/R1Q1KB1R b KQ - 0 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf2",
          "aggressive_uci": "e3f2",
          "aggressive_response": "Repeating\nthe game so far. 13...Qf2 14. Nc4 b5 15. Qd2 Qxd2+ 16. Ncxd2 Ne3+ 17. Ke2 Nxf1\n18. Rhxf1 b4 19. Rfc1 Ba6+ 20. Kf2 Rfc8 21. axb4 Nxb4 22. Rxc8+ Rxc8 23. Kg3\nRc2 24. Ba3 Nd5 25. Bd6 Rc6 26. Bb8 Rb6 27. Bxa7 Rc6 28. Bd4 f6 29. Ra5 Kf7\n30. Rc5 Rxc5 31. Bxc5 e5 32. b4 Ke6 33. Ne4 Bb5 34. Nd6 Bd3 35. b5 Nc7 36. b6\nNa6 37. Ba3 Kd7 38. Ne1 Bg6 39. b7 Kc7 40. Kf3 Nb8 41. Ke3 Nc6 42. Nd3 Bxd3\n43. Kxd3 g6 44. Kc4 f5 45. Kc5 Nb8 46. Kd5 e4 47. Bc5 Nd7 48. Ba7 e3 49. Bxe3\nNf6+ 50. Ke6 Ng4 51. Ba7 * Bg6 e2 Nf3",
          "aggressive_tokens": {
            "prompt_tokens": 215,
            "completion_tokens": 331,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "b5",
            "Qd2",
            "Qxd2+",
            "Ncxd2",
            "Ne3+",
            "Ke2",
            "Nxf1",
            "Rhxf1",
            "b4",
            "Rfc1",
            "Ba6+",
            "Kf2",
            "Rfc8",
            "axb4",
            "Nxb4",
            "Rxc8+",
            "Rxc8",
            "Kg3",
            "Rc2",
            "Ba3",
            "Nd5",
            "Bd6",
            "Rc6",
            "Bb8",
            "Rb6",
            "Bxa7",
            "Rc6",
            "Bd4",
            "f6",
            "Ra5",
            "Kf7",
            "Rc5",
            "Rxc5",
            "Bxc5",
            "e5",
            "b4",
            "Ke6",
            "Ne4",
            "Bb5",
            "Nd6",
            "Bd3",
            "b5",
            "Nc7",
            "b6",
            "Na6",
            "Ba3",
            "Kd7",
            "Ne1",
            "Bg6",
            "b7",
            "Kc7",
            "Kf3",
            "Nb8",
            "Ke3",
            "Nc6",
            "Nd3",
            "Bxd3",
            "Kxd3",
            "g6",
            "Kc4",
            "f5",
            "Kc5",
            "Nb8",
            "Kd5",
            "e4",
            "Bc5",
            "Nd7",
            "Ba7",
            "e3",
            "Bxe3",
            "Nf6+",
            "Ke6",
            "Ng4",
            "Ba7",
            "Bg6",
            "e2",
            "Nf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf4",
          "positional_uci": "d5f4",
          "positional_response": "1. Nf3 Nf6 2. e3 d5 3. c4 e6 4. b3 Be7 5. Bb2 O-O 6. d4 c5 7. cxd5 Nxd5 8. a3\nNc6 9. dxc5 Bxc5 10. Qc1 Qb6 11. Nbd2 Bxe3 12. fxe3 Qxe3+ 13. Kd1 Nf4 14. Qc3 Qxc3 15. Bxc3 Rd8 16. Kc2 b6 17. g3 Nd5 18. Re1 Bb7 19. Bc4 Rac8 20. Kb2 Nxc3 21. Kxc3 Na5 22. Kb2 Nxc4+ 23. bxc4 Bxf3 24. Nxf3 Rxc4 25. Rd1 Rdc8 26. Rd2 f6 27. Rhd1 e5 28. Rd8+ Rxd8 29. Rxd8+ Kf7 30. Rd7+ Kg6 31. Rxa7 e4 32. Nh4+ Kh6 33. Nf5+ Kg6 34. Nxg7 e3 35. Ne6 e2 36. Nf4+ Rxf4 37. Re7 Rf2 38. Kc3 Rxh2 39. Kd2 Rg2 40. Re6 Rxg3 41. Rxb6 Rxa3 42. Kxe2 h5 43. Kf2 Kg5 44. Kg2 f5 45. Rb8 h4 46. Rg8+ Kf4 47. Rh8 h3+ 48. Kh2 Rg3 49. Rh4+ Rg4 50. Rxh3 Ke4 51. Ra3 f4 52. Ra4+ Ke3 53. Ra3+ Ke4 54. Ra4+ Kf5 55. Ra5+ Kg6 56. Ra6+ Kh5 57. Ra5+ Kh4 58. Ra8 Rg5 59. Rh8+ Kg4 60. Kg2 f3+ 61. Kf2 Kf4 62. Rf8+ Rf5 63. Rxf5+ Kxf5 64. Kxf3 *",
          "positional_tokens": {
            "prompt_tokens": 215,
            "completion_tokens": 533,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf4",
            "Re7",
            "Rf2",
            "Kc3",
            "Rxh2",
            "Kd2",
            "Rg2",
            "Re6",
            "Rxg3",
            "Rxb6",
            "Rxa3",
            "Kxe2",
            "h5",
            "Kf2",
            "Kg5",
            "Kg2",
            "f5",
            "Rb8",
            "h4",
            "Rg8+",
            "Kf4",
            "Rh8",
            "h3+",
            "Kh2",
            "Rg3",
            "Rh4+",
            "Rg4",
            "Rxh3",
            "Ke4",
            "Ra3",
            "f4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Kf5",
            "Ra5+",
            "Kg6",
            "Ra6+",
            "Kh5",
            "Ra5+",
            "Kh4",
            "Ra8",
            "Rg5",
            "Rh8+",
            "Kg4",
            "Kg2",
            "f3+",
            "Kf2",
            "Kf4",
            "Rf8+",
            "Rf5",
            "Rxf5+",
            "Kxf5",
            "Kxf3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf4",
          "neutral_uci": "d5f4",
          "neutral_response": "1. Nf3 Nf6 2. e3 d5 3. c4 e6 4. b3 Be7 5. Bb2 O-O 6. d4 c5 7. cxd5 Nxd5 8. a3\nNc6 9. dxc5 Bxc5 10. Qc1 Qb6 11. Nbd2 Bxe3 12. fxe3 Qxe3+ 13. Kd1 Nf4 14. Qc3 Qxc3 15. Bxc3 Rd8 16. Kc2 e5 17. Nxe5 Bf5+ 18. Kb2 Nxe5 19. Bxe5 Rxd2+ 20. Kc3 Rc2+ 21. Kb4 Nd5+ 22. Ka4 Bd7+ 23. Bb5 Nb6+ 24. Kb4 a5# Nf3 Nxf3 Bxf3",
          "neutral_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 213,
            "total_tokens": 427,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc3",
            "Qxc3",
            "Bxc3",
            "Rd8",
            "Kc2",
            "e5",
            "Nxe5",
            "Bf5+",
            "Kb2",
            "Nxe5",
            "Bxe5",
            "Rxd2+",
            "Kc3",
            "Rc2+",
            "Kb4",
            "Nd5+",
            "Ka4",
            "Bd7+",
            "Bb5",
            "Nb6+",
            "Kb4",
            "a5#",
            "Nf3",
            "Nxf3",
            "Bxf3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e3f2",
          "positional_uci": "d5f4",
          "neutral_uci": "d5f4",
          "consensus_move": "d5f4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "b5",
              "Qd2",
              "Qxd2+",
              "Ncxd2",
              "Ne3+",
              "Ke2",
              "Nxf1",
              "Rhxf1",
              "b4",
              "Rfc1",
              "Ba6+",
              "Kf2",
              "Rfc8",
              "axb4",
              "Nxb4",
              "Rxc8+",
              "Rxc8",
              "Kg3",
              "Rc2",
              "Ba3",
              "Nd5",
              "Bd6",
              "Rc6",
              "Bb8",
              "Rb6",
              "Bxa7",
              "Rc6",
              "Bd4",
              "f6",
              "Ra5",
              "Kf7",
              "Rc5",
              "Rxc5",
              "Bxc5",
              "e5",
              "b4",
              "Ke6",
              "Ne4",
              "Bb5",
              "Nd6",
              "Bd3",
              "b5",
              "Nc7",
              "b6",
              "Na6",
              "Ba3",
              "Kd7",
              "Ne1",
              "Bg6",
              "b7",
              "Kc7",
              "Kf3",
              "Nb8",
              "Ke3",
              "Nc6",
              "Nd3",
              "Bxd3",
              "Kxd3",
              "g6",
              "Kc4",
              "f5",
              "Kc5",
              "Nb8",
              "Kd5",
              "e4",
              "Bc5",
              "Nd7",
              "Ba7",
              "e3",
              "Bxe3",
              "Nf6+",
              "Ke6",
              "Ng4",
              "Ba7",
              "Bg6",
              "e2",
              "Nf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf4",
              "Re7",
              "Rf2",
              "Kc3",
              "Rxh2",
              "Kd2",
              "Rg2",
              "Re6",
              "Rxg3",
              "Rxb6",
              "Rxa3",
              "Kxe2",
              "h5",
              "Kf2",
              "Kg5",
              "Kg2",
              "f5",
              "Rb8",
              "h4",
              "Rg8+",
              "Kf4",
              "Rh8",
              "h3+",
              "Kh2",
              "Rg3",
              "Rh4+",
              "Rg4",
              "Rxh3",
              "Ke4",
              "Ra3",
              "f4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Kf5",
              "Ra5+",
              "Kg6",
              "Ra6+",
              "Kh5",
              "Ra5+",
              "Kh4",
              "Ra8",
              "Rg5",
              "Rh8+",
              "Kg4",
              "Kg2",
              "f3+",
              "Kf2",
              "Kf4",
              "Rf8+",
              "Rf5",
              "Rxf5+",
              "Kxf5",
              "Kxf3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qc3",
              "Qxc3",
              "Bxc3",
              "Rd8",
              "Kc2",
              "e5",
              "Nxe5",
              "Bf5+",
              "Kb2",
              "Nxe5",
              "Bxe5",
              "Rxd2+",
              "Kc3",
              "Rc2+",
              "Kb4",
              "Nd5+",
              "Ka4",
              "Bd7+",
              "Bb5",
              "Nb6+",
              "Kb4",
              "a5#",
              "Nf3",
              "Nxf3",
              "Bxf3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 215,
            "completion_tokens": 331,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 215,
            "completion_tokens": 533,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 214,
            "completion_tokens": 213,
            "total_tokens": 427,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 644,
          "total_completion_tokens": 1077,
          "total_tokens": 1721
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 215,
            "completion_tokens": 331,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 215,
            "completion_tokens": 533,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 214,
            "completion_tokens": 213,
            "total_tokens": 427,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b2rk1/pp3ppp/2n1p3/3n4/8/PP2qN2/1B1N2PP/R1QK1B1R b - - 1 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxb4",
          "aggressive_uci": "c6b4",
          "aggressive_response": "1. Nf3 Nf6 2. e3 d5 3. c4 e6 4. b3 Be7 5. Bb2 O-O 6. d4 c5 7. cxd5 Nxd5 8. a3\nNc6 9. dxc5 Bxc5 10. Qc1 Qb6 11. Nbd2 Bxe3 12. fxe3 Qxe3+ 13. Kd1 Nf4 14. b4\nNxb4 15. axb4 Bd7 16. Ra3 Qb6 17. Qc3 f6 18. Qd4 Qc7 19. Rc3 Bc6 20. b5 e5 21.\nQc4+ Kh8 22. bxc6 bxc6 23. Qxc6 Qa5 24. Qc5 Qa4+ 25. Ke1 Rad8 26. Qc4 Qd7 27.\ng3 Nd5 28. Rd3 Qb7 29. Ba3 Rfe8 30. Bg2 e4 31. Nxe4 Qb1+ 32. Kf2 Qb6+ 33. Bc5\nQb2+ 34. Rd2 Qb7 35. Nd6 Rxd6 36. Bxd6 Ne3 37. Qc7 Ng4+ 38. Kg1 Qb1+ 39. Bf1\nQe4 40. Qc3 Ne3 41. Re2 Qxf3 42. Rxe3 Rxe3 43. Qc8+ Re8 44. Qxe8# Nf8 Qe3+\n45. Kg2 Qd2+ 46. Kh3 Qh6+ 47. Kg2 Qd2+ 48. Kh3 Qh6+ 49. Kg2 Qd2+ 50. Kh3 Qh6+ 51. Kg2 Qd2+ 52. Kh3 Qh6+ 53. Kg2 Qd2+ 54. Kh3 Qh6+ 55. Kg2 Qd2+ 56. Kh3 Qh6+ 57. Kg2 Qd2+ 58. Kh3 Qh6+ 59. Kg2 Qd2+ 60. Kh3 Qh6+ 61. Kg2 Qd2+ 62. Kh3 Qh6+ 63. Kg2 Qd2+ 64. Kh3 Qh6+ 65. Kg2 Qd2+ 66. Kh3 Qh6+ 67. Kg2 Qd2+ 68. Kh3 Qh6+ 69. Kg2 Qd2+ 70. Kh3 Qh6+ 71. Kg2 Qd2+ 72. Kh3 Qh6+ 73. Kg2 Qd",
          "aggressive_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 640,
            "total_tokens": 863,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "axb4",
            "Bd7",
            "Ra3",
            "Qb6",
            "Qc3",
            "f6",
            "Qd4",
            "Qc7",
            "Rc3",
            "Bc6",
            "b5",
            "e5",
            "Qc4+",
            "Kh8",
            "bxc6",
            "bxc6",
            "Qxc6",
            "Qa5",
            "Qc5",
            "Qa4+",
            "Ke1",
            "Rad8",
            "Qc4",
            "Qd7",
            "g3",
            "Nd5",
            "Rd3",
            "Qb7",
            "Ba3",
            "Rfe8",
            "Bg2",
            "e4",
            "Nxe4",
            "Qb1+",
            "Kf2",
            "Qb6+",
            "Bc5",
            "Qb2+",
            "Rd2",
            "Qb7",
            "Nd6",
            "Rxd6",
            "Bxd6",
            "Ne3",
            "Qc7",
            "Ng4+",
            "Kg1",
            "Qb1+",
            "Bf1",
            "Qe4",
            "Qc3",
            "Ne3",
            "Re2",
            "Qxf3",
            "Rxe3",
            "Rxe3",
            "Qc8+",
            "Re8",
            "Qxe8#",
            "Nf8",
            "Qe3+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qh6+",
            "Kg2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd8",
          "positional_uci": "f8d8",
          "positional_response": "14... Rd8 15. Qc3 Qxc3 16. Bxc3 Nd5 17. Bb2 Ne3+ 18. Ke2 Nxf1 19. Rhxf1 b6 20. Rac1 Ba6+ 21. Nc4 Rac8 22. Ke3 Ne7 23. Nfd2 Nf5+ 24. Ke4 Bb7+ 25. Kf4 Bxg2 26. Rg1 Bd5 27. Ne3 Rxc1 28. Bxc1 Nd4 29. Re1 f6 30. Nxd5 Rxd5 31. Nf3 Rf5+ 32. Ke4 Nxf3 33. Rd1 Ng5+ 34. Ke3 Rd5 35. Rxd5 exd5 36. Kd4 Nf3+ 37. Kxd5 Nxh2 38. Kc6 g5 39. Kb7 g4 40. Kxa7 g3 41. Kxb6 g2 42. Be3 Nf3 43. a4 h5 44. a5 h4 45. a6 h3 46. a7 h2 47. a8=Q+ Kg7 48. Qxf3 g1=Q 49. Bxg1 hxg1=Q+ 50. Kc6 Qc1+ 51. Kb6 Qg1+ 52. Kc6 Qc1+ 53. Kb6 Qg1+ 54. Kc6 Qc1+ 55. Kb6 Qg1+ 56. Kc6 Qc1+ 57. Kb6 Qg1+ 58. Kc6 Qc1+ 59. Kb6 Qg1+ 60. Kc6 Qc1+ 61. Kb6 Qg1+ 62. Kc6 Qc1+ 63. Kb6 Qg1+ 64. Kc6 Qc1+ 65. Kb6 Qg1+ 66. Kc6 Qc1+ 67. Kb6 Qg1+ 68. Kc6 Qc1+ 69. Kb6 Qg1+ 70. Kc6 Qc1+ 71. Kb6 Qg1+ 72. Kc6 Qc1+ 73. Kb6 Qg1+ 74. Kc6 Qc1+ 75. Kb6 Qg1+ 76. Kc6 Qc1+ 77. Kb6 Qg1+ 78. Kc6 Qc1+ 79. Kb6 Qg1+ 80. Kc6 Qc1+ 81. Kb6 Qg1+ 82. Kc6 Qc1+ 83. Kb6 Qg1+ 84. Kc6 Qc1+ 85. Kb6 Q",
          "positional_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 640,
            "total_tokens": 863,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qc3",
            "Qxc3",
            "Bxc3",
            "Nd5",
            "Bb2",
            "Ne3+",
            "Ke2",
            "Nxf1",
            "Rhxf1",
            "b6",
            "Rac1",
            "Ba6+",
            "Nc4",
            "Rac8",
            "Ke3",
            "Ne7",
            "Nfd2",
            "Nf5+",
            "Ke4",
            "Bb7+",
            "Kf4",
            "Bxg2",
            "Rg1",
            "Bd5",
            "Ne3",
            "Rxc1",
            "Bxc1",
            "Nd4",
            "Re1",
            "f6",
            "Nxd5",
            "Rxd5",
            "Nf3",
            "Rf5+",
            "Ke4",
            "Nxf3",
            "Rd1",
            "Ng5+",
            "Ke3",
            "Rd5",
            "Rxd5",
            "exd5",
            "Kd4",
            "Nf3+",
            "Kxd5",
            "Nxh2",
            "Kc6",
            "g5",
            "Kb7",
            "g4",
            "Kxa7",
            "g3",
            "Kxb6",
            "g2",
            "Be3",
            "Nf3",
            "a4",
            "h5",
            "a5",
            "h4",
            "a6",
            "h3",
            "a7",
            "h2",
            "a8=Q+",
            "Kg7",
            "Qxf3",
            "g1=Q",
            "Bxg1",
            "hxg1=Q+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6",
            "Qg1+",
            "Kc6",
            "Qc1+",
            "Kb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd8",
          "neutral_uci": "f8d8",
          "neutral_response": "14... Rd8 15. Qc3 Qxc3 16. Bxc3 Nd5 17. Bb2 Ne3+ 18. Ke2 Nxf1 19. Rhxf1 b6 20. Rfc1 Ba6+ 21. Kf2 Ne7 22. Rc7 Nd5 23. Rc2 Nf4 24. Kg1 Bd3 25. Rc7 Nd5 26. Rcc1 Nf4 27. Kf2 Ba6 28. Rc2 Nd3+ 29. Kg1 Nxb2 30. Rxb2 Rac8 31. b5 Bb7 32. a4 f6 33. a5 e5 34. axb6 axb6 35. Ra7 Bd5 36. Kf2 e4 37. Nd4 Re8 38. Ke3 Rc3+ 39. Ke2 e3 40. N2f3 Bc4+ 41. Kd1 Rd8 42. Rc2 Bb3 43. Kc1 Bxc2 44. Nxc2 Rdc8 45. Ne1 f5 46. g3 g5 47. Re7 f4 48. gxf4 gxf4 49. Re4 R8c4 50. Re6 Kf7 51. Rxb6 f3 52. Rb7+ Kg6 53. Rb6+ Kg5 54. Rb7 f2 55. Rg7+ Kh6 56. Rf7 fxe1=Q+ 57. Kb2 Qd2 58. Rf6+ Kg7 59. Rf2 Rxc2+ 60. Kb3 Qb4# 0-1\n\n14... Rd8 15. Qc3 Qxc3 16. Bxc3 Nd5 17. Bb2 Ne3 18. Kf2 Nxf1 19. Rhxf1 b6 20. Rfc1 Ba6 21. Kg1 Ne7 22. Rc7 Nd5 23. Rc2 Nf4 24. Kh1 Bd3 25. Rc7 Nd5 26. Rcc1 Nf4 27. Kf2 Ba6 28. Rc2 Nd3+ 29. Kg1 Nxb2 30. Rxb2 Rac8 31. b4 Bb7 32. a4 f6 33. a5 e5 34. axb6 axb6 35. Ra7 Bd5 36. Kf2 e4 37. Nd4 Re8 38. Ke3 Rc3+ 39. Ke2 e3 40. N2f3 Bc4+ 41. Kd1 Rd8 42. Rc2 Bb3 43. Kc1 Bxc2 44. Nxc2 Rdc8 45. Ne1",
          "neutral_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rc2",
            "Bb3",
            "Kc1",
            "Bxc2",
            "Nxc2",
            "Rdc8",
            "Ne1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6b4",
          "positional_uci": "f8d8",
          "neutral_uci": "f8d8",
          "consensus_move": "f8d8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "axb4",
              "Bd7",
              "Ra3",
              "Qb6",
              "Qc3",
              "f6",
              "Qd4",
              "Qc7",
              "Rc3",
              "Bc6",
              "b5",
              "e5",
              "Qc4+",
              "Kh8",
              "bxc6",
              "bxc6",
              "Qxc6",
              "Qa5",
              "Qc5",
              "Qa4+",
              "Ke1",
              "Rad8",
              "Qc4",
              "Qd7",
              "g3",
              "Nd5",
              "Rd3",
              "Qb7",
              "Ba3",
              "Rfe8",
              "Bg2",
              "e4",
              "Nxe4",
              "Qb1+",
              "Kf2",
              "Qb6+",
              "Bc5",
              "Qb2+",
              "Rd2",
              "Qb7",
              "Nd6",
              "Rxd6",
              "Bxd6",
              "Ne3",
              "Qc7",
              "Ng4+",
              "Kg1",
              "Qb1+",
              "Bf1",
              "Qe4",
              "Qc3",
              "Ne3",
              "Re2",
              "Qxf3",
              "Rxe3",
              "Rxe3",
              "Qc8+",
              "Re8",
              "Qxe8#",
              "Nf8",
              "Qe3+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qh6+",
              "Kg2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qc3",
              "Qxc3",
              "Bxc3",
              "Nd5",
              "Bb2",
              "Ne3+",
              "Ke2",
              "Nxf1",
              "Rhxf1",
              "b6",
              "Rac1",
              "Ba6+",
              "Nc4",
              "Rac8",
              "Ke3",
              "Ne7",
              "Nfd2",
              "Nf5+",
              "Ke4",
              "Bb7+",
              "Kf4",
              "Bxg2",
              "Rg1",
              "Bd5",
              "Ne3",
              "Rxc1",
              "Bxc1",
              "Nd4",
              "Re1",
              "f6",
              "Nxd5",
              "Rxd5",
              "Nf3",
              "Rf5+",
              "Ke4",
              "Nxf3",
              "Rd1",
              "Ng5+",
              "Ke3",
              "Rd5",
              "Rxd5",
              "exd5",
              "Kd4",
              "Nf3+",
              "Kxd5",
              "Nxh2",
              "Kc6",
              "g5",
              "Kb7",
              "g4",
              "Kxa7",
              "g3",
              "Kxb6",
              "g2",
              "Be3",
              "Nf3",
              "a4",
              "h5",
              "a5",
              "h4",
              "a6",
              "h3",
              "a7",
              "h2",
              "a8=Q+",
              "Kg7",
              "Qxf3",
              "g1=Q",
              "Bxg1",
              "hxg1=Q+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6",
              "Qg1+",
              "Kc6",
              "Qc1+",
              "Kb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rc2",
              "Bb3",
              "Kc1",
              "Bxc2",
              "Nxc2",
              "Rdc8",
              "Ne1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 223,
            "completion_tokens": 640,
            "total_tokens": 863,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 223,
            "completion_tokens": 640,
            "total_tokens": 863,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 668,
          "total_completion_tokens": 1920,
          "total_tokens": 2588
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 223,
            "completion_tokens": 640,
            "total_tokens": 863,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 223,
            "completion_tokens": 640,
            "total_tokens": 863,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b2rk1/pp3ppp/2n1p3/8/1P3n2/P3qN2/1B1N2PP/R1QK1B1R b - - 0 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf2",
          "aggressive_uci": "e3f2",
          "aggressive_response": "15... Qf2 16. Qxg7#",
          "aggressive_tokens": {
            "prompt_tokens": 233,
            "completion_tokens": 14,
            "total_tokens": 247,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf2",
          "positional_uci": "e3f2",
          "positional_response": "15... Qf2 16. Qxg7#",
          "positional_tokens": {
            "prompt_tokens": 233,
            "completion_tokens": 14,
            "total_tokens": 247,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qf2",
          "neutral_uci": "e3f2",
          "neutral_response": "15... Qf2 16. Qxg7#",
          "neutral_tokens": {
            "prompt_tokens": 232,
            "completion_tokens": 14,
            "total_tokens": 246,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e3f2",
          "positional_uci": "e3f2",
          "neutral_uci": "e3f2",
          "consensus_move": "e3f2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 233,
            "completion_tokens": 14,
            "total_tokens": 247,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 233,
            "completion_tokens": 14,
            "total_tokens": 247,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 232,
            "completion_tokens": 14,
            "total_tokens": 246,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 698,
          "total_completion_tokens": 42,
          "total_tokens": 740
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 233,
            "completion_tokens": 14,
            "total_tokens": 247,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 233,
            "completion_tokens": 14,
            "total_tokens": 247,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 232,
            "completion_tokens": 14,
            "total_tokens": 246,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1br2k1/pp3ppp/2n1p3/8/1P3n2/P1Q1qN2/1B1N2PP/R2K1B1R b - - 2 15"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Bg5+ Qxg5 16. Qf8+ Kd7 17. Nf6+ Ke6 18. f4 Qxf6 19. f5+ Ke5 20. Qe8+ Kd4 21. Rad1+ Kc5 22. Rd5+ Kb6 23. a4 a5 24. Qh5 Bd7 25. Qe2 Ka7 26. Qb5 Kb8 27. Qb3 Ra6 28. Rb5 Rb6 29. Rxb6 cxb6 30. Qxb6 Qd4+ 31. Qxd4 Nxd4 32. f6 Be6 33. f7 Bxf7 34. Rxf7 Nxc2 35. Rxh7 Ne3 36. h4 Nc4 37. h5 Nxb2 38. h6 Nxa4 39. Rg7 Nc5 40. h7 a4 41. h8=Q+ Ka7 42. Qh7 a3 43. Rxb7+ Nxb7 44. Qxb7+ Kxb7 45. g4 a2 46. g5 a1=Q+ 47. Kg2 Qg7 48. Kf3 Qxg5 49. Ke2 Qe5 50. Kd3 Kc6 51. Ke3 Kc5 52. Kd3 Qd4+ 53. Ke2 Qxe4+ 54. Kd2 Kc4 55. Kd1 Qg2 56. Kc1 Kc3 57. Kd1 Qd2# 0-1 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Bg5+ Qxg5 Qf8+ Kd7 Nf6+ Ke6 f4 Qxf6 Qf8+ Kd7 Nf6+ Ke6 f5+ Ke5 Qe8+ Kd4 Rd1+ Kc5",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Bg5+",
            "Qxg5",
            "Qf8+",
            "Kd7",
            "Nf6+",
            "Ke6",
            "f4",
            "Qxf6",
            "Qf8+",
            "Kd7",
            "Nf6+",
            "Ke6",
            "f5+",
            "Ke5",
            "Qe8+",
            "Kd4",
            "Rd1+",
            "Kc5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nc3 O-O 6. d3 d6 7. Bg5 f6 8. Bh4 Bg4 9. h3 Bh5 10. g4 Bf7 11. g5 Ng6 12. gxf6 Nxh4 13. Nxh4 Qxf6 14. Nf5 Qg5+ 15. Kh2 Qf4+ 16. Kh1 Bxf2 17. Qe2 Nd4 18. Qxf2 Qxf2 19. Rxf2 Nxb5 20. Nxb5 c6 21. Nbxd6 Be6 22. Rg1 g6 23. Nh6+ Kg7 24. Rxf8 Rxf8 25. Ng4 Bxg4 26. Rxg4 Rf2 27. Rg2 Rf1+ 28. Kh2 b5 29. Nc8 a5 30. Ne7 c5 31. Nc6 a4 32. Nxe5 Rb1 33. b3 axb3 34. axb3 Rb2 35. Nd7 c4 36. bxc4 bxc4 37. dxc4 Rb4 38. c5 Rxe4 39. c6 Rc4 40. Ne5 Rc5 41. Re2 Kf6 42. Nd7+ Kf7 43. Nxc5 Kf6 44. c7 Kf5 45. c8=Q+ Kf4 46. Qg4# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nc3 O-O d3 d6 Bg5 f6 Bh4 Bg4 h3 Bh5 g4 Bf7 g5 Ng6 gxf6 Nxh4 Nxh4 Qxf6 Nf5 Qg5+ Kh2 Qf4+ Kh1 Bxf2 Qe2 Nd4 Qxf2 Qxf2 Rxf2 Nxb5 Nxb5 c6 Nbxd6 Be6 Rg1 g6 Nh6+ Kg7 Nxf7 Bxf7 Nxf7 Rxf7 Rg4 Rf2 Rg2 Rf1+ Kh2 b5 Nc8 a5 Ne7 c5 Nc6 a4 Nxe5 Rxe4 c6 Rxe5 c7 Rc5 Ne6 Rxc2+ Kg3 b4 Kf4 b3 Ke5 b2 Kd6 b1=Q c8=Q Qd1+ Ke6 Qe2+ Kf5 Qf3+ Ke6 Qe4+ Kd7 Qc7+ Ke6 Qc6+ Kf5 Qf3+ Ke6 Qe4",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nc3",
            "O-O",
            "d3",
            "d6",
            "Bg5",
            "f6",
            "Bh4",
            "Bg4",
            "h3",
            "Bh5",
            "g4",
            "Bf7",
            "g5",
            "Ng6",
            "gxf6",
            "Nxh4",
            "Nxh4",
            "Qxf6",
            "Nf5",
            "Qg5+",
            "Kh2",
            "Qf4+",
            "Kh1",
            "Bxf2",
            "Qe2",
            "Nd4",
            "Qxf2",
            "Qxf2",
            "Rxf2",
            "Nxb5",
            "Nxb5",
            "c6",
            "Nbxd6",
            "Be6",
            "Rg1",
            "g6",
            "Nh6+",
            "Kg7",
            "Nxf7",
            "Bxf7",
            "Nxf7",
            "Rxf7",
            "Rg4",
            "Rf2",
            "Rg2",
            "Rf1+",
            "Kh2",
            "b5",
            "Nc8",
            "a5",
            "Ne7",
            "c5",
            "Nc6",
            "a4",
            "Nxe5",
            "Rxe4",
            "c6",
            "Rxe5",
            "c7",
            "Rc5",
            "Ne6",
            "Rxc2+",
            "Kg3",
            "b4",
            "Kf4",
            "b3",
            "Ke5",
            "b2",
            "Kd6",
            "b1=Q",
            "c8=Q",
            "Qd1+",
            "Ke6",
            "Qe2+",
            "Kf5",
            "Qf3+",
            "Ke6",
            "Qe4+",
            "Kd7",
            "Qc7+",
            "Ke6",
            "Qc6+",
            "Kf5",
            "Qf3+",
            "Ke6",
            "Qe4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 Nf6\n1. d4 Nf6 2. Nf3 d5\n2. Nf3 d5 3. Bf4 e6\n3. Bf4 e6 4. e3 Bd6\n4. e3 Bd6 5. Bg3 O-O\n5. Bg3 O-O 6. Bd3 c5\n6. Bd3 c5 7. c3 Nc6\n7. c3 Nc6 8. Nbd2 b6\n8. Nbd2 b6 9. Ne5 Bb7\n9. Ne5 Bb7 10. f4 Ne7\n10. f4 Ne7 11. O-O Nf5\n11. O-O Nf5 12. Bf2 Be7\n12. Bf2 Be7 13. g4 Nd6\n13. g4 Nd6 14. g5 Nfe4\n14. g5 Nfe4 15. Nxe4 dxe4\n15. Nxe4 dxe4 16. Bc2 f6\n16. Bc2 f6 17. gxf6 gxf6\n17. gxf6 gxf6 18. Ng4 Kh8\n18. Kh1 Rg8 19. Rg1 Qd7\n19. Rg1 Qd7 20. Rg1 Qd7 21. Rg1 Qd7 22. Rg1 Qd7 23. Rg1 Qd7 24. Rg1 Qd7 25. Rg1 Qd7 26. Rg1 Qd7 27. Rg1 Qd7 28. Rg1 Qd7 29. Rg1 Qd7 30. Rg1 Qd7 31. Rg1 Qd7 32. Rg1 Qd7 33. Rg1 Qd7 34. Rg1 Qd7 35. Rg1 Qd7 36. Rg1 Qd7 37. Rg1 Qd7 38. Rg1 Qd7 39. Rg1 Qd7 40. Rg1 Qd7 41. Rg1 Qd7 42. Rg1 Qd7 43. Rg1 Qd7 44. Rg1 Qd7 45. Rg1 Qd7 46. Rg1 Qd7 47. Rg1 Qd7 48. Rg1 Qd7 49. Rg1 Qd7 50. Rg1 Qd7 51. Rg1 Qd7 52. Rg1 Qd7 53. Rg1 Qd7 54. Rg1 Qd7 55. Rg1 Qd7 56. Rg1 Qd7 57. Rg1 Qd7",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nf3",
            "d5",
            "Nf3",
            "d5",
            "Bf4",
            "e6",
            "Bf4",
            "e6",
            "e3",
            "Bd6",
            "e3",
            "Bd6",
            "Bg3",
            "O-O",
            "Bg3",
            "O-O",
            "Bd3",
            "c5",
            "Bd3",
            "c5",
            "c3",
            "Nc6",
            "c3",
            "Nc6",
            "Nbd2",
            "b6",
            "Nbd2",
            "b6",
            "Ne5",
            "Bb7",
            "Ne5",
            "Bb7",
            "f4",
            "Ne7",
            "f4",
            "Ne7",
            "O-O",
            "Nf5",
            "O-O",
            "Nf5",
            "Bf2",
            "Be7",
            "Bf2",
            "Be7",
            "g4",
            "Nd6",
            "g4",
            "Nd6",
            "g5",
            "Nfe4",
            "g5",
            "Nfe4",
            "Nxe4",
            "dxe4",
            "Nxe4",
            "dxe4",
            "Bc2",
            "f6",
            "Bc2",
            "f6",
            "gxf6",
            "gxf6",
            "gxf6",
            "gxf6",
            "Ng4",
            "Kh8",
            "Kh1",
            "Rg8",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7",
            "Rg1",
            "Qd7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Bg5+",
              "Qxg5",
              "Qf8+",
              "Kd7",
              "Nf6+",
              "Ke6",
              "f4",
              "Qxf6",
              "Qf8+",
              "Kd7",
              "Nf6+",
              "Ke6",
              "f5+",
              "Ke5",
              "Qe8+",
              "Kd4",
              "Rd1+",
              "Kc5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nc3",
              "O-O",
              "d3",
              "d6",
              "Bg5",
              "f6",
              "Bh4",
              "Bg4",
              "h3",
              "Bh5",
              "g4",
              "Bf7",
              "g5",
              "Ng6",
              "gxf6",
              "Nxh4",
              "Nxh4",
              "Qxf6",
              "Nf5",
              "Qg5+",
              "Kh2",
              "Qf4+",
              "Kh1",
              "Bxf2",
              "Qe2",
              "Nd4",
              "Qxf2",
              "Qxf2",
              "Rxf2",
              "Nxb5",
              "Nxb5",
              "c6",
              "Nbxd6",
              "Be6",
              "Rg1",
              "g6",
              "Nh6+",
              "Kg7",
              "Nxf7",
              "Bxf7",
              "Nxf7",
              "Rxf7",
              "Rg4",
              "Rf2",
              "Rg2",
              "Rf1+",
              "Kh2",
              "b5",
              "Nc8",
              "a5",
              "Ne7",
              "c5",
              "Nc6",
              "a4",
              "Nxe5",
              "Rxe4",
              "c6",
              "Rxe5",
              "c7",
              "Rc5",
              "Ne6",
              "Rxc2+",
              "Kg3",
              "b4",
              "Kf4",
              "b3",
              "Ke5",
              "b2",
              "Kd6",
              "b1=Q",
              "c8=Q",
              "Qd1+",
              "Ke6",
              "Qe2+",
              "Kf5",
              "Qf3+",
              "Ke6",
              "Qe4+",
              "Kd7",
              "Qc7+",
              "Ke6",
              "Qc6+",
              "Kf5",
              "Qf3+",
              "Ke6",
              "Qe4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Nf3",
              "d5",
              "Nf3",
              "d5",
              "Bf4",
              "e6",
              "Bf4",
              "e6",
              "e3",
              "Bd6",
              "e3",
              "Bd6",
              "Bg3",
              "O-O",
              "Bg3",
              "O-O",
              "Bd3",
              "c5",
              "Bd3",
              "c5",
              "c3",
              "Nc6",
              "c3",
              "Nc6",
              "Nbd2",
              "b6",
              "Nbd2",
              "b6",
              "Ne5",
              "Bb7",
              "Ne5",
              "Bb7",
              "f4",
              "Ne7",
              "f4",
              "Ne7",
              "O-O",
              "Nf5",
              "O-O",
              "Nf5",
              "Bf2",
              "Be7",
              "Bf2",
              "Be7",
              "g4",
              "Nd6",
              "g4",
              "Nd6",
              "g5",
              "Nfe4",
              "g5",
              "Nfe4",
              "Nxe4",
              "dxe4",
              "Nxe4",
              "dxe4",
              "Bc2",
              "f6",
              "Bc2",
              "f6",
              "gxf6",
              "gxf6",
              "gxf6",
              "gxf6",
              "Ng4",
              "Kh8",
              "Kh1",
              "Rg8",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7",
              "Rg1",
              "Qd7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1920,
          "total_tokens": 2249
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nc6 *\n3. d4 cxd4 *\n4. Nxd4 Nf6 *\n5. Nc3 d6 *\n6. Bg5 e6 *\n7. Qd2 a6 *\n8. O-O-O Bd7 *\n9. f4 b5 *\n10. Bxf6 gxf6 *\n11. f5 Qb6 *\n12. Nxc6 Bxc6 *\n13. fxe6 fxe6 *\n14. Kb1 O-O-O *\n15. Bd3 h5 *\n16. Rhf1 Bh6 *\n17. Qe1 Bg7 *\n18. Ne2 d5 *\n19. Nf4 dxe4 *\n20. Nxe6 exd3 *\n21. Nxg7 dxc2+ *\n22. Kxc2 Rxd1 *\n23. Qxd1 Be4+ *\n24. Kc1 Qe3+ *\n25. Qd2 Qc5+ *\n26. Qc3 Qxc3+ *\n27. bxc3 Rg8 *\n28. Nxh5 Rxg2 *\n29. Nxf6 Bd3 *\n30. Rf3 Bc4 *\n31. a3 Rxh2 *\n32. Ne4 Kc7 *\n33. Nd2 Bd5 *\n34. Rf5 Kd6 *\n35. Rf6+ Kc5 *\n36. Rxa6 Rh1+ *\n37. Kb2 Rh2 *\n38. Kc1 Rh1+ *\n39. Kb2 Rh2 *\n40. Kc1 Rh1+ *\n41. Kb2 Rh2 *\n42. Kc1 Rh1+ *\n43. Kb2 Rh2 *\n44. Kc1 Rh1+ *\n45. Kb2 Rh2 *\n46. Kc1 Rh1+ *\n47. Kb2 Rh2 *\n48. Kc1 Rh1+ *\n49. Kb2 Rh2 *\n50. Kc1 Rh1+ *\n51. Kb2 Rh2 *\n52. Kc1 Rh1+ *\n53. Kb2 Rh2 *\n54. Kc1 Rh1+ *\n55. Kb2 Rh2 *\n56. Kc1 Rh1+ *\n57. Kb2 Rh2 *\n58. Kc1 Rh1+ *\n59. Kb2 Rh2 *\n60. Kc1 Rh1+ *\n61. Kb2 Rh2 *\n62. Kc1 Rh1+ *\n63. Kb2 Rh2 *\n64. Kc1 Rh1+ *\n65. Kb2 Rh2 *\n66. Kc1 Rh1+ *\n67. Kb2 Rh2 *\n68. Kc1 Rh1+ *\n69. Kb2 Rh2 *\n70. Kc1 Rh1",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Nc3",
            "d6",
            "Bg5",
            "e6",
            "Qd2",
            "a6",
            "O-O-O",
            "Bd7",
            "f4",
            "b5",
            "Bxf6",
            "gxf6",
            "f5",
            "Qb6",
            "Nxc6",
            "Bxc6",
            "fxe6",
            "fxe6",
            "Kb1",
            "O-O-O",
            "Bd3",
            "h5",
            "Rhf1",
            "Bh6",
            "Qe1",
            "Bg7",
            "Ne2",
            "d5",
            "Nf4",
            "dxe4",
            "Nxe6",
            "exd3",
            "Nxg7",
            "dxc2+",
            "Kxc2",
            "Rxd1",
            "Qxd1",
            "Be4+",
            "Kc1",
            "Qe3+",
            "Qd2",
            "Qc5+",
            "Qc3",
            "Qxc3+",
            "bxc3",
            "Rg8",
            "Nxh5",
            "Rxg2",
            "Nxf6",
            "Bd3",
            "Rf3",
            "Bc4",
            "a3",
            "Rxh2",
            "Ne4",
            "Kc7",
            "Nd2",
            "Bd5",
            "Rf5",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rxa6",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1+",
            "Kb2",
            "Rh2",
            "Kc1",
            "Rh1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nc6 *\n3. d4 cxd4 *\n4. Nxd4 Nf6 *\n5. Nc3 d6 *\n6. Bg5 e6 *\n7. Qd2 a6 *\n8. O-O-O Bd7 *\n9. f4 b5 *\n10. Bxf6 gxf6 *\n11. Kb1 Qb6 *\n12. Nxc6 Bxc6 *\n13. f5 b4 *\n14. Ne2 e5 *\n15. Ng3 h5 *\n16. h4 Bh6 *\n17. Qe1 Bf4 *\n18. Rh3 Ke7 *\n19. Bc4 Rag8 *\n20. Bd5 Bxd5 *\n21. Rxd5 Rg4 *\n22. Ne2 Rxg2 *\n23. Nxf4 exf4 *\n24. Rhd3 Rg1 *\n25. Rd1 Rxe1 *\n26. Rxe1 Rg8 *\n27. Red1 Rg1 *\n28. b3 Rxd1+ *\n29. Rxd1 Qe3 *\n30. Kb2 f3 *\n31. Rd3 Qxd3 *\n32. cxd3 f2 *\n33. a3 f1=Q *\n34. axb4 Qxd3 *\n35. Ka3 Qxe4 *\n36. Ka4 Qxf5 *\n37. b5 Qxb5+ *\n38. Ka3 a5 *\n39. Kb2 Qb4 *\n40. Kc2 d5 *\n41. Kd3 Qxb3+ *\n42. Kd4 Qc4+ *\n43. Ke3 Qe4+ *\n44. Kd2 d4 *\n45. Kc1 Qe2 *\n46. Kb1 d3 *\n47. Ka1 d2 *\n48. Kb2 d1=Q+ *\n49. Ka3 Qdd3+ *\n50. Ka4 Qb5+ *\n51. Ka3 Qeb2#",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 464,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Nc3",
            "d6",
            "Bg5",
            "e6",
            "Qd2",
            "a6",
            "O-O-O",
            "Bd7",
            "f4",
            "b5",
            "Bxf6",
            "gxf6",
            "Kb1",
            "Qb6",
            "Nxc6",
            "Bxc6",
            "f5",
            "b4",
            "Ne2",
            "e5",
            "Ng3",
            "h5",
            "h4",
            "Bh6",
            "Qe1",
            "Bf4",
            "Rh3",
            "Ke7",
            "Bc4",
            "Rag8",
            "Bd5",
            "Bxd5",
            "Rxd5",
            "Rg4",
            "Ne2",
            "Rxg2",
            "Nxf4",
            "exf4",
            "Rhd3",
            "Rg1",
            "Rd1",
            "Rxe1",
            "Rxe1",
            "Rg8",
            "Red1",
            "Rg1",
            "b3",
            "Rxd1+",
            "Rxd1",
            "Qe3",
            "Kb2",
            "f3",
            "Rd3",
            "Qxd3",
            "cxd3",
            "f2",
            "a3",
            "f1=Q",
            "axb4",
            "Qxd3",
            "Ka3",
            "Qxe4",
            "Ka4",
            "Qxf5",
            "b5",
            "Qxb5+",
            "Ka3",
            "a5",
            "Kb2",
            "Qb4",
            "Kc2",
            "d5",
            "Kd3",
            "Qxb3+",
            "Kd4",
            "Qc4+",
            "Ke3",
            "Qe4+",
            "Kd2",
            "d4",
            "Kc1",
            "Qe2",
            "Kb1",
            "d3",
            "Ka1",
            "d2",
            "Kb2",
            "d1=Q+",
            "Ka3",
            "Qdd3+",
            "Ka4",
            "Qb5+",
            "Ka3",
            "Qeb2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nc6 *\n3. d4 cxd4 *\n4. Nxd4 Nf6 *\n5. Nc3 d6 *\n6. Bg5 e6 *\n7. Qd2 a6 *\n8. O-O-O Bd7 *\n9. f4 b5 *\n10. Bxf6 gxf6 *\n11. Kb1 Qb6 *\n12. Nxc6 Bxc6 *\n13. f5 b4 *\n14. Ne2 e5 *\n15. Ng3 h5 *\n16. h4 Bh6 *\n17. Qe1 Bf4 *\n18. Rh3 Ke7 *\n19. Bc4 Rag8 *\n20. Bd5 Bxd5 *\n21. Rxd5 Rg4 *\n22. Ne2 Rxg2 *\n23. Nxf4 exf4 *\n24. Rhd3 Rg1 *\n25. Rd1 Rxe1 *\n26. Rxe1 Rg8 *\n27. Red1 Rg1 *\n28. b3 Rxd1+ *\n29. Rxd1 Qe3 *\n30. Kb2 f3 *\n31. Rd3 Qxd3 *\n32. cxd3 f2 *\n33. a3 f1=Q *\n34. axb4 Qxd3 *\n35. Ka3 Qxe4 *\n36. Ka4 Qxf5 *\n37. b5 Qxb5+ *\n38. Ka3 a5 *\n39. Kb2 Qb4 *\n40. Kc2 a4 *\n41. bxa4 Qxa4+ *\n42. Kd3 Qxh4 *\n43. Ke3 Qg4 *\n44. Kf2 h4 *\n45. Ke3 h3 *\n46. Kf2 h2 *\n47. Ke3 h1=Q *\n48. Kf2 Qhf3+ *\n49. Ke1 Qe2# 0-1\ne4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Nc3 d6 Bg5 e6 Qd2 a6 O-O-O Bd7 f4 b5 Bxf6 gxf6 Kb1 Qb6 Nxc6 Bxc6 f5 b4 Ne2 e5 Ng3 h5 h4 Bh6 Qe1 Bf4 Bd3 Rg8 Ne2 Bh6 Bc4 Bxd5 Rxd5 Rg4 Ng3 Ke7 Bd5 Rag8 Nxh5 Rxg2 Bb3 Rg1 Rxg1 Rxg1 Qxg1 Qxg1 Bxg1 c3 bxc3 bxc3 Bf2 Kc2 Bxh4 Kd3 Bf2 Kc4 Bc5 Kd5 a5 Kc6 Kd8 Kb5 Kc7 Kxa",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Nc3",
            "d6",
            "Bg5",
            "e6",
            "Qd2",
            "a6",
            "O-O-O",
            "Bd7",
            "f4",
            "b5",
            "Bxf6",
            "gxf6",
            "Kb1",
            "Qb6",
            "Nxc6",
            "Bxc6",
            "f5",
            "b4",
            "Ne2",
            "e5",
            "Ng3",
            "h5",
            "h4",
            "Bh6",
            "Qe1",
            "Bf4",
            "Bd3",
            "Rg8",
            "Ne2",
            "Bh6",
            "Bc4",
            "Bxd5",
            "Rxd5",
            "Rg4",
            "Ng3",
            "Ke7",
            "Bd5",
            "Rag8",
            "Nxh5",
            "Rxg2",
            "Bb3",
            "Rg1",
            "Rxg1",
            "Rxg1",
            "Qxg1",
            "Qxg1",
            "Bxg1",
            "c3",
            "bxc3",
            "bxc3",
            "Bf2",
            "Kc2",
            "Bxh4",
            "Kd3",
            "Bf2",
            "Kc4",
            "Bc5",
            "Kd5",
            "a5",
            "Kc6",
            "Kd8",
            "Kb5",
            "Kc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Nc3",
              "d6",
              "Bg5",
              "e6",
              "Qd2",
              "a6",
              "O-O-O",
              "Bd7",
              "f4",
              "b5",
              "Bxf6",
              "gxf6",
              "f5",
              "Qb6",
              "Nxc6",
              "Bxc6",
              "fxe6",
              "fxe6",
              "Kb1",
              "O-O-O",
              "Bd3",
              "h5",
              "Rhf1",
              "Bh6",
              "Qe1",
              "Bg7",
              "Ne2",
              "d5",
              "Nf4",
              "dxe4",
              "Nxe6",
              "exd3",
              "Nxg7",
              "dxc2+",
              "Kxc2",
              "Rxd1",
              "Qxd1",
              "Be4+",
              "Kc1",
              "Qe3+",
              "Qd2",
              "Qc5+",
              "Qc3",
              "Qxc3+",
              "bxc3",
              "Rg8",
              "Nxh5",
              "Rxg2",
              "Nxf6",
              "Bd3",
              "Rf3",
              "Bc4",
              "a3",
              "Rxh2",
              "Ne4",
              "Kc7",
              "Nd2",
              "Bd5",
              "Rf5",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rxa6",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1+",
              "Kb2",
              "Rh2",
              "Kc1",
              "Rh1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Nc3",
              "d6",
              "Bg5",
              "e6",
              "Qd2",
              "a6",
              "O-O-O",
              "Bd7",
              "f4",
              "b5",
              "Bxf6",
              "gxf6",
              "Kb1",
              "Qb6",
              "Nxc6",
              "Bxc6",
              "f5",
              "b4",
              "Ne2",
              "e5",
              "Ng3",
              "h5",
              "h4",
              "Bh6",
              "Qe1",
              "Bf4",
              "Rh3",
              "Ke7",
              "Bc4",
              "Rag8",
              "Bd5",
              "Bxd5",
              "Rxd5",
              "Rg4",
              "Ne2",
              "Rxg2",
              "Nxf4",
              "exf4",
              "Rhd3",
              "Rg1",
              "Rd1",
              "Rxe1",
              "Rxe1",
              "Rg8",
              "Red1",
              "Rg1",
              "b3",
              "Rxd1+",
              "Rxd1",
              "Qe3",
              "Kb2",
              "f3",
              "Rd3",
              "Qxd3",
              "cxd3",
              "f2",
              "a3",
              "f1=Q",
              "axb4",
              "Qxd3",
              "Ka3",
              "Qxe4",
              "Ka4",
              "Qxf5",
              "b5",
              "Qxb5+",
              "Ka3",
              "a5",
              "Kb2",
              "Qb4",
              "Kc2",
              "d5",
              "Kd3",
              "Qxb3+",
              "Kd4",
              "Qc4+",
              "Ke3",
              "Qe4+",
              "Kd2",
              "d4",
              "Kc1",
              "Qe2",
              "Kb1",
              "d3",
              "Ka1",
              "d2",
              "Kb2",
              "d1=Q+",
              "Ka3",
              "Qdd3+",
              "Ka4",
              "Qb5+",
              "Ka3",
              "Qeb2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Nc3",
              "d6",
              "Bg5",
              "e6",
              "Qd2",
              "a6",
              "O-O-O",
              "Bd7",
              "f4",
              "b5",
              "Bxf6",
              "gxf6",
              "Kb1",
              "Qb6",
              "Nxc6",
              "Bxc6",
              "f5",
              "b4",
              "Ne2",
              "e5",
              "Ng3",
              "h5",
              "h4",
              "Bh6",
              "Qe1",
              "Bf4",
              "Bd3",
              "Rg8",
              "Ne2",
              "Bh6",
              "Bc4",
              "Bxd5",
              "Rxd5",
              "Rg4",
              "Ng3",
              "Ke7",
              "Bd5",
              "Rag8",
              "Nxh5",
              "Rxg2",
              "Bb3",
              "Rg1",
              "Rxg1",
              "Rxg1",
              "Qxg1",
              "Qxg1",
              "Bxg1",
              "c3",
              "bxc3",
              "bxc3",
              "Bf2",
              "Kc2",
              "Bxh4",
              "Kd3",
              "Bf2",
              "Kc4",
              "Bc5",
              "Kd5",
              "a5",
              "Kc6",
              "Kd8",
              "Kb5",
              "Kc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 464,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1744,
          "total_tokens": 2091
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 464,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pp1ppppp/8/2p5/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6 11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5 15. Bc4 Rb8 16. b3 Kh8 17. O-O f5 18. exf5 Bxf5 19. Nce3 Bxe3 20. Nxe3 Be4 21. Bd5 Bxd5 22. Nxd5 Ne7 23. Nxe7 Qxe7 24. Rxa5 Qc7 25. Rd5 Qxc3 26. Rxd6 Rxb3 27. Rd8 Rb8 28. Rxb8 Rxb8 29. Qd6 Re8 30. Qd7 Qc8 31. Qxc8 Rxc8 32. Re1 Kg8 33. g3 Re8 34. Kg2 Kf7 35. Kf3 Kf6 36. Ke4 Ra8 37. Rd1 Ra4+ 38. Ke3 Ra3+ 39. Ke4 Ra4+ 40. Ke3 Ra3+ 41. Ke4 Ra4+ 42. Ke3 Ra3+ 43. Ke4 Ra4+ 44. Ke3 Ra3+ 45. Ke4 Ra4+ 46. Ke3 Ra3+ 47. Ke4 Ra4+ 48. Ke3 Ra3+ 49. Ke4 Ra4+ 50. Ke3 Ra3+ 51. Ke4 Ra4+ 52. Ke3 Ra3+ 53. Ke4 Ra4+ 54. Ke3 Ra3+ 55. Ke4 Ra4+ 56. Ke3 Ra3+ 57. Ke4 Ra4+ 58. Ke3 Ra3+ 59. Ke4 Ra4+ 60. Ke3 Ra3+ 61. Ke4 Ra4+ 62. Ke3 Ra3+ 63. Ke4 Ra4+ 64. Ke3 Ra3+ 65. Ke4 Ra4+ 66. Ke3 Ra3+ 67. Ke4 Ra4+ 68. Ke3 Ra3+ 69. Ke4 Ra4+ 70. Ke3 Ra3+ 71. Ke4 Ra4+ 72. Ke3 Ra3+ 73. Ke4 Ra4+ 74. Ke3 Ra3+ 75. Ke4 Ra4+ 76. Ke3 Ra3+ 77. Ke4 Ra4+ 78. Ke3 Ra3+ 79. Ke4 Ra4+ 80. Ke3 Ra3+ 81. Ke4 Ra4+ 82.",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "cxd4",
            "Nxd4",
            "Nf6",
            "Nc3",
            "e5",
            "Ndb5",
            "d6",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Bxe3",
            "Nxe3",
            "Be4",
            "Bd5",
            "Bxd5",
            "Nxd5",
            "Ne7",
            "Nxe7",
            "Qxe7",
            "Rxa5",
            "Qc7",
            "Rd5",
            "Qxc3",
            "Rxd6",
            "Rxb3",
            "Rd8",
            "Rb8",
            "Rxb8",
            "Rxb8",
            "Qd6",
            "Re8",
            "Qd7",
            "Qc8",
            "Qxc8",
            "Rxc8",
            "Re1",
            "Kg8",
            "g3",
            "Re8",
            "Kg2",
            "Kf7",
            "Kf3",
            "Kf6",
            "Ke4",
            "Ra8",
            "Rd1",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Ke4",
            "Ra4+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": "d2d4",
          "positional_response": "3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6 11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5 15. Bc4 Rb8 16. b3 Kh8 17. O-O f5 18. exf5 Bxf5 19. Nce3 Bxe3 20. Nxe3 Be4 21. Bd5 Bxd5 22. Nxd5 Ne7 23. Nxe7 Qxe7 24. Rxa5 Qc7 25. Rd5 Qxc3 26. Rxd6 Rxb3 27. Rd8 Rb8 28. Rxb8 Rxb8 29. Qd6 Re8 30. Qd7 Qc8 31. Qxc8 Rxc8 32. Re1 Kg8 33. g3 Rc5 34. Kg2 Kf7 35. Kf3 Kf6 36. Ra1 Rc3+ 37. Ke4 Rc4+ 38. Kd5 Rd4+ 39. Kc5 Rd2 40. Rf1 Kf5 41. Kc4 Kg4 42. Kc3 Rd7 43. Re1 Kf3 44. Rxe5 Kxf2 45. Rh5 h6 46. g4 Kf3 47. g5 Rd5 48. h4 Kg4 49. Kc4 Rf5 50. gxh6 Rxh5 51. hxg7 Rxh4 52. g8=Q+ Kf3+ 53. Kd3 Rf4 54. Qd5+ Kg4 55. Ke3 Rf5 56. Qg2+ Kh5 57. Ke4 Rg5 58. Qh3+ Kg6 59. Qe6+ Kh5 60. Kf4 Rg6 61. Qh3# e4 d5 g5",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 496,
            "total_tokens": 621,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "cxd4",
            "Nxd4",
            "Nf6",
            "Nc3",
            "e5",
            "Ndb5",
            "d6",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Bxe3",
            "Nxe3",
            "Be4",
            "Bd5",
            "Bxd5",
            "Nxd5",
            "Ne7",
            "Nxe7",
            "Qxe7",
            "Rxa5",
            "Qc7",
            "Rd5",
            "Qxc3",
            "Rxd6",
            "Rxb3",
            "Rd8",
            "Rb8",
            "Rxb8",
            "Rxb8",
            "Qd6",
            "Re8",
            "Qd7",
            "Qc8",
            "Qxc8",
            "Rxc8",
            "Re1",
            "Kg8",
            "g3",
            "Rc5",
            "Kg2",
            "Kf7",
            "Kf3",
            "Kf6",
            "Ra1",
            "Rc3+",
            "Ke4",
            "Rc4+",
            "Kd5",
            "Rd4+",
            "Kc5",
            "Rd2",
            "Rf1",
            "Kf5",
            "Kc4",
            "Kg4",
            "Kc3",
            "Rd7",
            "Re1",
            "Kf3",
            "Rxe5",
            "Kxf2",
            "Rh5",
            "h6",
            "g4",
            "Kf3",
            "g5",
            "Rd5",
            "h4",
            "Kg4",
            "Kc4",
            "Rf5",
            "gxh6",
            "Rxh5",
            "hxg7",
            "Rxh4",
            "g8=Q+",
            "Kf3+",
            "Kd3",
            "Rf4",
            "Qd5+",
            "Kg4",
            "Ke3",
            "Rf5",
            "Qg2+",
            "Kh5",
            "Ke4",
            "Rg5",
            "Qh3+",
            "Kg6",
            "Qe6+",
            "Kh5",
            "Kf4",
            "Rg6",
            "Qh3#",
            "e4",
            "d5",
            "g5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6\n7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6\n11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5\n15. Bc4 Rb8 16. b3 Kh8 17. Nce3 g6 18. h4 Bxh4\n19. g3 Bg5 20. f4 exf4 21. gxf4 Bh4+ 22. Kd2 f5\n23. exf5 Bxf5 24. Nxf5 Rxf5 25. Qg4 Rh5 26. Kc2 Ne7\n27. Nxe7 Qxe7 28. Bd3 Bf6 29. Rxh5 gxh5 30. Qxh5 Qg7\n31. Rc4 d5 32. Rc6 a4 33. bxa4 Qg2+ 34. Kd1 Qg1+\n35. Kd2 Qf2+ 36. Kd1 Qg1+ 37. Kd2 Qf2+ 38. Kd1 Qg1+\n39. Kd2 Qf2+ 40. Kd1 Qg1+ 41. Kd2 Qf2+ 42. Kd1 Qg1+\n43. Kd2 Qf2+ 44. Kd1 Qg1+ 45. Kd2 Qf2+ 46. Kd1 Qg1+\n47. Kd2 Qf2+ 48. Kd1 Qg1+ 49. Kd2 Qf2+ 50. Kd1 Qg1+ 51. Kd2 Qf2+ 52. Kd1 Qg1+ 53. Kd2 Qf2+ 54. Kd1 Qg1+ 55. Kd2 Qf2+ 56. Kd1 Qg1+ 57. Kd2 Qf2+ 58. Kd1 Qg1+ 59. Kd2 Qf2+ 60. Kd1 Qg1+ 61. Kd2 Qf2+ 62. Kd1 Qg1+ 63. Kd2 Qf2+ 64. Kd1 Qg1+ 65. Kd2 Qf2+ 66. Kd1 Qg1+ 67. Kd2 Qf2+ 68. Kd1 Qg1+ 69. Kd2 Qf2+ 70. Kd1 Qg1+ 71. Kd2 Qf2+ 72. K",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "cxd4",
            "Nxd4",
            "Nf6",
            "Nc3",
            "e5",
            "Ndb5",
            "d6",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "Nce3",
            "g6",
            "h4",
            "Bxh4",
            "g3",
            "Bg5",
            "f4",
            "exf4",
            "gxf4",
            "Bh4+",
            "Kd2",
            "f5",
            "exf5",
            "Bxf5",
            "Nxf5",
            "Rxf5",
            "Qg4",
            "Rh5",
            "Kc2",
            "Ne7",
            "Nxe7",
            "Qxe7",
            "Bd3",
            "Bf6",
            "Rxh5",
            "gxh5",
            "Qxh5",
            "Qg7",
            "Rc4",
            "d5",
            "Rc6",
            "a4",
            "bxa4",
            "Qg2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Qg1+",
            "Kd2",
            "Qf2+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "d2d4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "cxd4",
              "Nxd4",
              "Nf6",
              "Nc3",
              "e5",
              "Ndb5",
              "d6",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Bxe3",
              "Nxe3",
              "Be4",
              "Bd5",
              "Bxd5",
              "Nxd5",
              "Ne7",
              "Nxe7",
              "Qxe7",
              "Rxa5",
              "Qc7",
              "Rd5",
              "Qxc3",
              "Rxd6",
              "Rxb3",
              "Rd8",
              "Rb8",
              "Rxb8",
              "Rxb8",
              "Qd6",
              "Re8",
              "Qd7",
              "Qc8",
              "Qxc8",
              "Rxc8",
              "Re1",
              "Kg8",
              "g3",
              "Re8",
              "Kg2",
              "Kf7",
              "Kf3",
              "Kf6",
              "Ke4",
              "Ra8",
              "Rd1",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Ke4",
              "Ra4+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "cxd4",
              "Nxd4",
              "Nf6",
              "Nc3",
              "e5",
              "Ndb5",
              "d6",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Bxe3",
              "Nxe3",
              "Be4",
              "Bd5",
              "Bxd5",
              "Nxd5",
              "Ne7",
              "Nxe7",
              "Qxe7",
              "Rxa5",
              "Qc7",
              "Rd5",
              "Qxc3",
              "Rxd6",
              "Rxb3",
              "Rd8",
              "Rb8",
              "Rxb8",
              "Rxb8",
              "Qd6",
              "Re8",
              "Qd7",
              "Qc8",
              "Qxc8",
              "Rxc8",
              "Re1",
              "Kg8",
              "g3",
              "Rc5",
              "Kg2",
              "Kf7",
              "Kf3",
              "Kf6",
              "Ra1",
              "Rc3+",
              "Ke4",
              "Rc4+",
              "Kd5",
              "Rd4+",
              "Kc5",
              "Rd2",
              "Rf1",
              "Kf5",
              "Kc4",
              "Kg4",
              "Kc3",
              "Rd7",
              "Re1",
              "Kf3",
              "Rxe5",
              "Kxf2",
              "Rh5",
              "h6",
              "g4",
              "Kf3",
              "g5",
              "Rd5",
              "h4",
              "Kg4",
              "Kc4",
              "Rf5",
              "gxh6",
              "Rxh5",
              "hxg7",
              "Rxh4",
              "g8=Q+",
              "Kf3+",
              "Kd3",
              "Rf4",
              "Qd5+",
              "Kg4",
              "Ke3",
              "Rf5",
              "Qg2+",
              "Kh5",
              "Ke4",
              "Rg5",
              "Qh3+",
              "Kg6",
              "Qe6+",
              "Kh5",
              "Kf4",
              "Rg6",
              "Qh3#",
              "e4",
              "d5",
              "g5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "cxd4",
              "Nxd4",
              "Nf6",
              "Nc3",
              "e5",
              "Ndb5",
              "d6",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "Nce3",
              "g6",
              "h4",
              "Bxh4",
              "g3",
              "Bg5",
              "f4",
              "exf4",
              "gxf4",
              "Bh4+",
              "Kd2",
              "f5",
              "exf5",
              "Bxf5",
              "Nxf5",
              "Rxf5",
              "Qg4",
              "Rh5",
              "Kc2",
              "Ne7",
              "Nxe7",
              "Qxe7",
              "Bd3",
              "Bf6",
              "Rxh5",
              "gxh5",
              "Qxh5",
              "Qg7",
              "Rc4",
              "d5",
              "Rc6",
              "a4",
              "bxa4",
              "Qg2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Qg1+",
              "Kd2",
              "Qf2+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 496,
            "total_tokens": 621,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1776,
          "total_tokens": 2150
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 496,
            "total_tokens": 621,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pp1ppppp/2n5/2p5/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxd4",
          "aggressive_uci": "f3d4",
          "aggressive_response": "4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6 11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5 15. Bc4 Rb8 16. b3 Kh8 17. O-O f5 18. exf5 Bxf5 19. Nce3 Bxe3 20. Nxe3 Be4 21. Bd5 Bxd5 22. Nxd5 Ne7 23. Nxe7 Qxe7 24. Rxa5 Qc7 25. Rd5 Qxc3 26. Rxd6 Rxb3 27. Rd8 Rb8 28. Rxb8 Rxb8 29. Qd6 Re8 30. Qd7 Qc8 31. Qxc8 Rxc8 32. Re1 Kg8 33. g3 Rc5 34. Kg2 Kf7 35. Kf3 Kf6 36. Ra1 Rc3+ 37. Ke4 Rc4+ 38. Kd5 Rd4+ 39. Kc5 Rd2 40. Rf1 Kf5 41. Kc4 Kg4 42. Kc3 Rd7 43. Re1 Kf3 44. Rxe5 Kxf2 45. Rh5 h6 46. g4 Kf3 47. g5 Rd5 48. h4 Kg4 49. gxh6 Rxh5 50. hxg7 Rc5+ 51. Kd4 Rc8 52. Ke5 Kxh4 53. Kf6 Kh5 54. Kf7 Kh6 55. g8=Q Rxg8 56. Kxg8 Kg6 57. Kf8 Kf6 58. Ke8 Ke6 59. Kd8 Kd6 60. Kc8 Kc6 61. Kb8 Kb6 62. Ka8 Ka6 63. Kb8 Kb6 64. Ka8 Ka6 65. Kb8 Kb6 66. Ka8 Ka6 67. Kb8 Kb6 68. Ka8 Ka6 69. Kb8 Kb6 70. Ka8 Ka6 71. Kb8 Kb6 72. Ka8 Ka6 73. Kb8 Kb6 74. Ka8 Ka6 75. Kb8 Kb6 76. Ka8 Ka6 77. Kb8 Kb6 78. Ka8 Ka6 79. Kb8 Kb6 80. Ka8 Ka6 81. Kb8 Kb6 82. Ka8 Ka6 83. Kb8 Kb6 84. Ka8 Ka6 85",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "e5",
            "Ndb5",
            "d6",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Bxe3",
            "Nxe3",
            "Be4",
            "Bd5",
            "Bxd5",
            "Nxd5",
            "Ne7",
            "Nxe7",
            "Qxe7",
            "Rxa5",
            "Qc7",
            "Rd5",
            "Qxc3",
            "Rxd6",
            "Rxb3",
            "Rd8",
            "Rb8",
            "Rxb8",
            "Rxb8",
            "Qd6",
            "Re8",
            "Qd7",
            "Qc8",
            "Qxc8",
            "Rxc8",
            "Re1",
            "Kg8",
            "g3",
            "Rc5",
            "Kg2",
            "Kf7",
            "Kf3",
            "Kf6",
            "Ra1",
            "Rc3+",
            "Ke4",
            "Rc4+",
            "Kd5",
            "Rd4+",
            "Kc5",
            "Rd2",
            "Rf1",
            "Kf5",
            "Kc4",
            "Kg4",
            "Kc3",
            "Rd7",
            "Re1",
            "Kf3",
            "Rxe5",
            "Kxf2",
            "Rh5",
            "h6",
            "g4",
            "Kf3",
            "g5",
            "Rd5",
            "h4",
            "Kg4",
            "gxh6",
            "Rxh5",
            "hxg7",
            "Rc5+",
            "Kd4",
            "Rc8",
            "Ke5",
            "Kxh4",
            "Kf6",
            "Kh5",
            "Kf7",
            "Kh6",
            "g8=Q",
            "Rxg8",
            "Kxg8",
            "Kg6",
            "Kf8",
            "Kf6",
            "Ke8",
            "Ke6",
            "Kd8",
            "Kd6",
            "Kc8",
            "Kc6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Ka6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxd4",
          "positional_uci": "f3d4",
          "positional_response": "4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6 11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5 15. Bc4 Rb8 16. b3 Kh8 17. O-O f5 18. exf5 Bxf5 19. Nce3 Bxe3 20. Nxe3 Be4 21. Bd5 Bxd5 22. Nxd5 Ne7 23. Nxe7 Qxe7 24. Rxa5 Qc7 25. Rd5 Qxc3 26. Rxd6 Rxb3 27. Rd8 Rb8 28. Rxb8 Rxb8 29. Qd6 Re8 30. Qd7 Qc8 31. Qxc8 Rxc8 32. Re1 Kg8 33. g3 Rc5 34. Kg2 Kf7 35. Kf3 Kf6 36. Ra1 Rc3+ 37. Ke4 Rc4+ 38. Kd5 Rd4+ 39. Kc5 Rd2 40. Rf1 Kf5 41. Kc4 Kg4 42. Kc3 Rd7 43. Re1 Kf3 44. Rxe5 Kxf2 45. Rh5 h6 46. g4 Kf3 47. g5 Rd5 48. h4 Kg4 49. Kc4 Rf5 50. gxh6 Rxh5 51. hxg7 Rxh4 52. g8=Q+ Kh3+ 53. Kd3 Rg4 54. Qh7+ Kg3 55. Ke3 Rh4 56. Qg6+ Rg4 57. Qd6+ Kh4 58. Kf3 Rg5 59. Qh6+ Rh5 60. Qf4+ Kh3 61. Qg3# 1-0 1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6 11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5 15. Bc4 Rb8 16. b3 Kh8 17. O-O f5 18. exf5 Bxf5 19. Nce3 Bxe4",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "e5",
            "Ndb5",
            "d6",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Bxe4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxd4",
          "neutral_uci": "f3d4",
          "neutral_response": "4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6 11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5 15. Bc4 Rb8 16. b3 Kh8 17. Nce3 g6 18. h4 Bxh4 19. g3 Bg5 20. f4 exf4 21. gxf4 Bh4+ 22. Kd2 f5 23. exf5 Bxf5 24. Nxf5 Rxf5 25. Qg4 Rh5 26. Kc2 Ne7 27. Nxe7 Qxe7 28. Raa1 Qe4+ 29. Bd3 Qd5 30. Bc4 Qe4+ 31. Bd3 Qd5 32. Bc4 Qe4+ 33. Bd3 Qd5 34. Bc4 Qe4+ 35. Bd3 Qd5 36. Bc4 Qe4+ 37. Bd3 Qd5 38. Bc4 Qe4+ 39. Bd3 Qd5 40. Bc4 Qe4+ 41. Bd3 Qd5 42. Bc4 Qe4+ 43. Bd3 Qd5 44. Bc4 Qe4+ 45. Bd3 Qd5 46. Bc4 Qe4+ 47. Bd3 Qd5 48. Bc4 Qe4+ 49. Bd3 Qd5 50. Bc4 Qe4+ 51. Bd3 Qd5 52. Bc4 Qe4+ 53. Bd3 Qd5 54. Bc4 Qe4+ 55. Bd3 Qd5 56. Bc4 Qe4+ 57. Bd3 Qd5 58. Bc4 Qe4+ 59. Bd3 Qd5 60. Bc4 Qe4+ 61. Bd3 Qd5 62. Bc4 Qe4+ 63. Bd3 Qd5 64. Bc4 Qe4+ 65. Bd3 Qd5 66. Bc4 Qe4+ 67. Bd3 Qd5 68. Bc4 Qe4+ 69. Bd3 Qd5 70. Bc4 Qe4+ 71. Bd3 Qd5 72. Bc4 Qe4+ 73. Bd3 Qd5 74. Bc4 Qe4+ 75. Bd3 Qd5 76. Bc4 Qe4+",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "e5",
            "Ndb5",
            "d6",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "Nce3",
            "g6",
            "h4",
            "Bxh4",
            "g3",
            "Bg5",
            "f4",
            "exf4",
            "gxf4",
            "Bh4+",
            "Kd2",
            "f5",
            "exf5",
            "Bxf5",
            "Nxf5",
            "Rxf5",
            "Qg4",
            "Rh5",
            "Kc2",
            "Ne7",
            "Nxe7",
            "Qxe7",
            "Raa1",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+",
            "Bd3",
            "Qd5",
            "Bc4",
            "Qe4+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3d4",
          "positional_uci": "f3d4",
          "neutral_uci": "f3d4",
          "consensus_move": "f3d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Nc3",
              "e5",
              "Ndb5",
              "d6",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Bxe3",
              "Nxe3",
              "Be4",
              "Bd5",
              "Bxd5",
              "Nxd5",
              "Ne7",
              "Nxe7",
              "Qxe7",
              "Rxa5",
              "Qc7",
              "Rd5",
              "Qxc3",
              "Rxd6",
              "Rxb3",
              "Rd8",
              "Rb8",
              "Rxb8",
              "Rxb8",
              "Qd6",
              "Re8",
              "Qd7",
              "Qc8",
              "Qxc8",
              "Rxc8",
              "Re1",
              "Kg8",
              "g3",
              "Rc5",
              "Kg2",
              "Kf7",
              "Kf3",
              "Kf6",
              "Ra1",
              "Rc3+",
              "Ke4",
              "Rc4+",
              "Kd5",
              "Rd4+",
              "Kc5",
              "Rd2",
              "Rf1",
              "Kf5",
              "Kc4",
              "Kg4",
              "Kc3",
              "Rd7",
              "Re1",
              "Kf3",
              "Rxe5",
              "Kxf2",
              "Rh5",
              "h6",
              "g4",
              "Kf3",
              "g5",
              "Rd5",
              "h4",
              "Kg4",
              "gxh6",
              "Rxh5",
              "hxg7",
              "Rc5+",
              "Kd4",
              "Rc8",
              "Ke5",
              "Kxh4",
              "Kf6",
              "Kh5",
              "Kf7",
              "Kh6",
              "g8=Q",
              "Rxg8",
              "Kxg8",
              "Kg6",
              "Kf8",
              "Kf6",
              "Ke8",
              "Ke6",
              "Kd8",
              "Kd6",
              "Kc8",
              "Kc6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Ka6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Nc3",
              "e5",
              "Ndb5",
              "d6",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Bxe4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Nc3",
              "e5",
              "Ndb5",
              "d6",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "Nce3",
              "g6",
              "h4",
              "Bxh4",
              "g3",
              "Bg5",
              "f4",
              "exf4",
              "gxf4",
              "Bh4+",
              "Kd2",
              "f5",
              "exf5",
              "Bxf5",
              "Nxf5",
              "Rxf5",
              "Qg4",
              "Rh5",
              "Kc2",
              "Ne7",
              "Nxe7",
              "Qxe7",
              "Raa1",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+",
              "Bd3",
              "Qd5",
              "Bc4",
              "Qe4+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1920,
          "total_tokens": 2318
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pp1ppppp/2n5/8/3pP3/5N2/PPP2PPP/RNBQKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "5. Nc3 d6 6. Bg5 e6 7. Qd2 a6 8. O-O-O Bd7 9. f4 b5 10. Bxf6 gxf6 11. Kb1 Qb6 12. Nxc6 Bxc6 13. f5 b4 14. Ne2 e5 15. Ng3 h5 16. h4 Qc5 17. Be2 Bh6 18. Qxd6 Qxd6 19. Rxd6 Bb7 20. Rxf6 Bf4 21. Nxh5 Bxe4 22. Nxf4 exf4 23. Bf3 Bxf3 24. gxf3 Ke7 25. Rb6 a5 26. h5 Rad8 27. h6 Rd5 28. f6+ Kd7 29. Rb7+ Ke6 30. Rb6+ Kf5 31. Rh5+ Kg6 32. Rxd5 Rxh6 33. b3 Rh3 34. Rd3 Rh5 35. Kb2 Re5 36. a3 bxa3+ 37. Kxa3 Rc5 38. c4 Re5 39. Ka4 Re3 40. Rxe3 fxe3 41. Rd6 Kf5 42. Rd1 Kf4 43. c5 Kxf3 44. c6 e2 45. Ra1 Kf2 46. c7 e1=Q 47. Rxe1 Kxe1 48. c8=Q Kd2 49. Qd7+ Kc3 50. Qxf7 Kd4 51. Qe6 Kc5 52. f7 Kd4 53. f8=Q Kc3 54. Qf3+ Kd4 55. Qee4+ Kc5 56. Qff5+ Kd6 57. Qee6+ Kc7 58. Qff7+ Kd8 59. Qee8# e5 dxe5 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc6 Qc4+ Kd7 Qd5+ Kc",
          "aggressive_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d6",
            "Bg5",
            "e6",
            "Qd2",
            "a6",
            "O-O-O",
            "Bd7",
            "f4",
            "b5",
            "Bxf6",
            "gxf6",
            "Kb1",
            "Qb6",
            "Nxc6",
            "Bxc6",
            "f5",
            "b4",
            "Ne2",
            "e5",
            "Ng3",
            "h5",
            "h4",
            "Qc5",
            "Be2",
            "Bh6",
            "Qxd6",
            "Qxd6",
            "Rxd6",
            "Bb7",
            "Rxf6",
            "Bf4",
            "Nxh5",
            "Bxe4",
            "Nxf4",
            "exf4",
            "Bf3",
            "Bxf3",
            "gxf3",
            "Ke7",
            "Rb6",
            "a5",
            "h5",
            "Rad8",
            "h6",
            "Rd5",
            "f6+",
            "Kd7",
            "Rb7+",
            "Ke6",
            "Rb6+",
            "Kf5",
            "Rh5+",
            "Kg6",
            "Rxd5",
            "Rxh6",
            "b3",
            "Rh3",
            "Rd3",
            "Rh5",
            "Kb2",
            "Re5",
            "a3",
            "bxa3+",
            "Kxa3",
            "Rc5",
            "c4",
            "Re5",
            "Ka4",
            "Re3",
            "Rxe3",
            "fxe3",
            "Rd6",
            "Kf5",
            "Rd1",
            "Kf4",
            "c5",
            "Kxf3",
            "c6",
            "e2",
            "Ra1",
            "Kf2",
            "c7",
            "e1=Q",
            "Rxe1",
            "Kxe1",
            "c8=Q",
            "Kd2",
            "Qd7+",
            "Kc3",
            "Qxf7",
            "Kd4",
            "Qe6",
            "Kc5",
            "f7",
            "Kd4",
            "f8=Q",
            "Kc3",
            "Qf3+",
            "Kd4",
            "Qee4+",
            "Kc5",
            "Qff5+",
            "Kd6",
            "Qee6+",
            "Kc7",
            "Qff7+",
            "Kd8",
            "Qee8#",
            "e5",
            "dxe5",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qd5+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Bxf6 Bxf6 11. c3 O-O 12. Nc2 Bg5 13. a4 bxa4 14. Rxa4 a5 15. Bc4 Rb8 16. b3 Kh8 17. O-O f5 18. exf5 Bxf5 19. Nce3 Be6 20. Qd3 Bxe3 21. Nxe3 Bxc4 22. Qxc4 Ne7 23. Rd1 Qb6 24. Ra3 Rbc8 25. Qd3 d5 26. Nxd5 Qxf2+ 27. Kh1 Nxd5 28. Qxd5 Qf1+ 29. Rxf1 Rxf1# 30. Kh2 Rxc3 31. Qd8+ Rf8 32. Qxf8# 1-0\n33. Qxf8# 1-0",
          "positional_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 247,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Ndb5",
            "d6",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Be6",
            "Qd3",
            "Bxe3",
            "Nxe3",
            "Bxc4",
            "Qxc4",
            "Ne7",
            "Rd1",
            "Qb6",
            "Ra3",
            "Rbc8",
            "Qd3",
            "d5",
            "Nxd5",
            "Qxf2+",
            "Kh1",
            "Nxd5",
            "Qxd5",
            "Qf1+",
            "Rxf1",
            "Rxf1#",
            "Kh2",
            "Rxc3",
            "Qd8+",
            "Rf8",
            "Qxf8#",
            "Qxf8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "5. Nc3 d6 6. Bg5 e6 7. Qd2 a6 8. O-O-O Bd7 9. f4 b5 10. Bxf6 gxf6 11. Kb1 Qb6 12. Nxc6 Bxc6 13. f5 b4 14. Ne2 e5 15. Ng3 h5 16. h4 Qc5 17. Be2 Bh6 18. Qd3 Bf4 19. Nxh5 Rxh5 20. Bxh5 Ke7 21. g3 Be3 22. Rhe1 Bd4 23. Qb3 d5 24. exd5 Bxd5 25. Qd3 Kf8 26. Bf3 Bc4 27. Qe4 Rc8 28. Rd2 a5 29. Red1 a4 30. Rxd4 exd4 31. Qxd4 Qxf5 32. Bg4 Bxa2+ 33. Kxa2 b3+ 34. cxb3 axb3+ 35. Kxb3 Qb5+ 36. Qb4+ Qxb4+ 37. Kxb4 Rb8+ 38. Kc3 Kg7 39. b4 Kg6 40. Rd5 Re8 41. b5 Re3+ 42. Rd3 Re5 43. Kb4 f5 44. Bf3 f4 45. gxf4 Rf5 46. Be4 *\n46... Kh6 47. Bxf5 f6 48. b6 Kh5 49. b7 Kh6 50. b8=Q Kh5 51. Qh8#",
          "neutral_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 387,
            "total_tokens": 528,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d6",
            "Bg5",
            "e6",
            "Qd2",
            "a6",
            "O-O-O",
            "Bd7",
            "f4",
            "b5",
            "Bxf6",
            "gxf6",
            "Kb1",
            "Qb6",
            "Nxc6",
            "Bxc6",
            "f5",
            "b4",
            "Ne2",
            "e5",
            "Ng3",
            "h5",
            "h4",
            "Qc5",
            "Be2",
            "Bh6",
            "Qd3",
            "Bf4",
            "Nxh5",
            "Rxh5",
            "Bxh5",
            "Ke7",
            "g3",
            "Be3",
            "Rhe1",
            "Bd4",
            "Qb3",
            "d5",
            "exd5",
            "Bxd5",
            "Qd3",
            "Kf8",
            "Bf3",
            "Bc4",
            "Qe4",
            "Rc8",
            "Rd2",
            "a5",
            "Red1",
            "a4",
            "Rxd4",
            "exd4",
            "Qxd4",
            "Qxf5",
            "Bg4",
            "Bxa2+",
            "Kxa2",
            "b3+",
            "cxb3",
            "axb3+",
            "Kxb3",
            "Qb5+",
            "Qb4+",
            "Qxb4+",
            "Kxb4",
            "Rb8+",
            "Kc3",
            "Kg7",
            "b4",
            "Kg6",
            "Rd5",
            "Re8",
            "b5",
            "Re3+",
            "Rd3",
            "Re5",
            "Kb4",
            "f5",
            "Bf3",
            "f4",
            "gxf4",
            "Rf5",
            "Be4",
            "Kh6",
            "Bxf5",
            "f6",
            "b6",
            "Kh5",
            "b7",
            "Kh6",
            "b8=Q",
            "Kh5",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "b1c3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d6",
              "Bg5",
              "e6",
              "Qd2",
              "a6",
              "O-O-O",
              "Bd7",
              "f4",
              "b5",
              "Bxf6",
              "gxf6",
              "Kb1",
              "Qb6",
              "Nxc6",
              "Bxc6",
              "f5",
              "b4",
              "Ne2",
              "e5",
              "Ng3",
              "h5",
              "h4",
              "Qc5",
              "Be2",
              "Bh6",
              "Qxd6",
              "Qxd6",
              "Rxd6",
              "Bb7",
              "Rxf6",
              "Bf4",
              "Nxh5",
              "Bxe4",
              "Nxf4",
              "exf4",
              "Bf3",
              "Bxf3",
              "gxf3",
              "Ke7",
              "Rb6",
              "a5",
              "h5",
              "Rad8",
              "h6",
              "Rd5",
              "f6+",
              "Kd7",
              "Rb7+",
              "Ke6",
              "Rb6+",
              "Kf5",
              "Rh5+",
              "Kg6",
              "Rxd5",
              "Rxh6",
              "b3",
              "Rh3",
              "Rd3",
              "Rh5",
              "Kb2",
              "Re5",
              "a3",
              "bxa3+",
              "Kxa3",
              "Rc5",
              "c4",
              "Re5",
              "Ka4",
              "Re3",
              "Rxe3",
              "fxe3",
              "Rd6",
              "Kf5",
              "Rd1",
              "Kf4",
              "c5",
              "Kxf3",
              "c6",
              "e2",
              "Ra1",
              "Kf2",
              "c7",
              "e1=Q",
              "Rxe1",
              "Kxe1",
              "c8=Q",
              "Kd2",
              "Qd7+",
              "Kc3",
              "Qxf7",
              "Kd4",
              "Qe6",
              "Kc5",
              "f7",
              "Kd4",
              "f8=Q",
              "Kc3",
              "Qf3+",
              "Kd4",
              "Qee4+",
              "Kc5",
              "Qff5+",
              "Kd6",
              "Qee6+",
              "Kc7",
              "Qff7+",
              "Kd8",
              "Qee8#",
              "e5",
              "dxe5",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qd5+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Ndb5",
              "d6",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Be6",
              "Qd3",
              "Bxe3",
              "Nxe3",
              "Bxc4",
              "Qxc4",
              "Ne7",
              "Rd1",
              "Qb6",
              "Ra3",
              "Rbc8",
              "Qd3",
              "d5",
              "Nxd5",
              "Qxf2+",
              "Kh1",
              "Nxd5",
              "Qxd5",
              "Qf1+",
              "Rxf1",
              "Rxf1#",
              "Kh2",
              "Rxc3",
              "Qd8+",
              "Rf8",
              "Qxf8#",
              "Qxf8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d6",
              "Bg5",
              "e6",
              "Qd2",
              "a6",
              "O-O-O",
              "Bd7",
              "f4",
              "b5",
              "Bxf6",
              "gxf6",
              "Kb1",
              "Qb6",
              "Nxc6",
              "Bxc6",
              "f5",
              "b4",
              "Ne2",
              "e5",
              "Ng3",
              "h5",
              "h4",
              "Qc5",
              "Be2",
              "Bh6",
              "Qd3",
              "Bf4",
              "Nxh5",
              "Rxh5",
              "Bxh5",
              "Ke7",
              "g3",
              "Be3",
              "Rhe1",
              "Bd4",
              "Qb3",
              "d5",
              "exd5",
              "Bxd5",
              "Qd3",
              "Kf8",
              "Bf3",
              "Bc4",
              "Qe4",
              "Rc8",
              "Rd2",
              "a5",
              "Red1",
              "a4",
              "Rxd4",
              "exd4",
              "Qxd4",
              "Qxf5",
              "Bg4",
              "Bxa2+",
              "Kxa2",
              "b3+",
              "cxb3",
              "axb3+",
              "Kxb3",
              "Qb5+",
              "Qb4+",
              "Qxb4+",
              "Kxb4",
              "Rb8+",
              "Kc3",
              "Kg7",
              "b4",
              "Kg6",
              "Rd5",
              "Re8",
              "b5",
              "Re3+",
              "Rd3",
              "Re5",
              "Kb4",
              "f5",
              "Bf3",
              "f4",
              "gxf4",
              "Rf5",
              "Be4",
              "Kh6",
              "Bxf5",
              "f6",
              "b6",
              "Kh5",
              "b7",
              "Kh6",
              "b8=Q",
              "Kh5",
              "Qh8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 142,
            "completion_tokens": 247,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 141,
            "completion_tokens": 387,
            "total_tokens": 528,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 425,
          "total_completion_tokens": 1274,
          "total_tokens": 1699
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 142,
            "completion_tokens": 247,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 141,
            "completion_tokens": 387,
            "total_tokens": 528,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/pp1ppppp/2n2n2/8/3NP3/8/PPP2PPP/RNBQKB1R w KQkq - 1 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ndb5",
          "aggressive_uci": "d4b5",
          "aggressive_response": "6. Ndb5 d6 7. Bf4 e5 8. Bg5 a6 9. Na3 b5 10. Nd5 Be7 11. Bxf6 Bxf6 12. c3 O-O 13. Nc2 Bg5 14. a4 bxa4 15. Rxa4 a5 16. Bc4 Rb8 17. b3 Kh8 18. O-O f5 19. exf5 Bxf5 20. Nce3 Be6 21. Qd3 Bxe3 22. Nxe3 Bxc4 23. Qxc4 Qb6 24. Nd5 Qb5 25. Qxb5 Rxb5 26. Nc7 Rxb3 27. Ne6 Rfb8 28. Rc4 Ne7 29. Rc7 Nd5 30. Rxg7 Rb1 31. Ra7 Rxf1+ 32. Kxf1 Nxc3 33. g3 a4 34. Ng5 h6 35. Nf7+ Kg8 36. Nxh6+ Kf8 37. Nf5 d5 38. h4 d4 39. h5 d3 40. h6 d2 41. Ne3 Kg8 42. g4 Rb1+ 43. Kg2 d1=Q 44. Nxd1 Rxd1 45. g5 Rd6 46. Kg3 Rg6 47. Kg4 Ne4 48. Kf5 Rxg5+ 49. Kxe4 Rh5 50. Rxa4 Rxh6 51. Kxe5 Kf7 52. Ra7+ Ke8 53. f4 Rh1 54. f5 Re1+ 55. Kf6 Rf1 56. Ra8+ Kd7 57. Kg6 Rg1+ 58. Kf7 Rf1 59. f6 Rf2 60. Ra7+ Kd8 61. Ra6 Kd7 62. Kf8 Kd8 63. f7 Kd7 64. Ra7+ Kd8 65. Ra8+ Kd7 66. Re8 Rf1 67. Re4 Rf2 68. Kg7 Rg2+ 69. Kf6 Rf2+ 70. Kg6 Rg2+ 71. Kf5 Rf2+ 72. Kg6 Rg2+ 73. Kf6 Rf2+ 74. Kg7 Rg2+ 75. Kf8 Rf2 76. Re7+ Kd8 77. Re5 Kd7 78. Kg7 Rg2+ 79. Kf6 Rf2+ 80. Kg6 Rg2+ 81. Rg5 Rf2",
          "aggressive_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d6",
            "Bf4",
            "e5",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Be6",
            "Qd3",
            "Bxe3",
            "Nxe3",
            "Bxc4",
            "Qxc4",
            "Qb6",
            "Nd5",
            "Qb5",
            "Qxb5",
            "Rxb5",
            "Nc7",
            "Rxb3",
            "Ne6",
            "Rfb8",
            "Rc4",
            "Ne7",
            "Rc7",
            "Nd5",
            "Rxg7",
            "Rb1",
            "Ra7",
            "Rxf1+",
            "Kxf1",
            "Nxc3",
            "g3",
            "a4",
            "Ng5",
            "h6",
            "Nf7+",
            "Kg8",
            "Nxh6+",
            "Kf8",
            "Nf5",
            "d5",
            "h4",
            "d4",
            "h5",
            "d3",
            "h6",
            "d2",
            "Ne3",
            "Kg8",
            "g4",
            "Rb1+",
            "Kg2",
            "d1=Q",
            "Nxd1",
            "Rxd1",
            "g5",
            "Rd6",
            "Kg3",
            "Rg6",
            "Kg4",
            "Ne4",
            "Kf5",
            "Rxg5+",
            "Kxe4",
            "Rh5",
            "Rxa4",
            "Rxh6",
            "Kxe5",
            "Kf7",
            "Ra7+",
            "Ke8",
            "f4",
            "Rh1",
            "f5",
            "Re1+",
            "Kf6",
            "Rf1",
            "Ra8+",
            "Kd7",
            "Kg6",
            "Rg1+",
            "Kf7",
            "Rf1",
            "f6",
            "Rf2",
            "Ra7+",
            "Kd8",
            "Ra6",
            "Kd7",
            "Kf8",
            "Kd8",
            "f7",
            "Kd7",
            "Ra7+",
            "Kd8",
            "Ra8+",
            "Kd7",
            "Re8",
            "Rf1",
            "Re4",
            "Rf2",
            "Kg7",
            "Rg2+",
            "Kf6",
            "Rf2+",
            "Kg6",
            "Rg2+",
            "Kf5",
            "Rf2+",
            "Kg6",
            "Rg2+",
            "Kf6",
            "Rf2+",
            "Kg7",
            "Rg2+",
            "Kf8",
            "Rf2",
            "Re7+",
            "Kd8",
            "Re5",
            "Kd7",
            "Kg7",
            "Rg2+",
            "Kf6",
            "Rf2+",
            "Kg6",
            "Rg2+",
            "Rg5",
            "Rf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ndb5",
          "positional_uci": "d4b5",
          "positional_response": "6. Ndb5 d6 7. Bf4 e5 8. Bg5 a6 9. Na3 b5 10. Nd5 Be7 11. Bxf6 Bxf6 12. c3 O-O 13. Nc2 Bg5 14. a4 bxa4 15. Rxa4 a5 16. Bc4 Rb8 17. b3 Kh8 18. O-O f5 19. exf5 Bxf5 20. Nce3 Be6 21. Qd3 Bxe3 22. Nxe3 Bxc4 23. Qxc4 Ne7 24. Rd1 Qb6 25. b4 axb4 26. Rxb4 Qa7 27. Rxb8 Qxb8 28. Qe6 Ng6 29. Qxd6 Qb2 30. Qd2 Qb3 31. g3 e4 32. Qd4 Qb2 33. Rd2 Qb1+ 34. Kg2 h6 35. c4 Qb7 36. c5 Qf7 37. Qxe4 Re8 38. Qd5 Qf6 39. c6 Ne5 40. c7 Rc8 41. Qd8+ Kh7 42. Qxc8 Qf3+ 43. Kg1 1-0\n\n43... Qe4 44. Qf5+ Qxf5 45. Nxf5 Nf3+",
          "positional_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 338,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d6",
            "Bf4",
            "e5",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Be6",
            "Qd3",
            "Bxe3",
            "Nxe3",
            "Bxc4",
            "Qxc4",
            "Ne7",
            "Rd1",
            "Qb6",
            "b4",
            "axb4",
            "Rxb4",
            "Qa7",
            "Rxb8",
            "Qxb8",
            "Qe6",
            "Ng6",
            "Qxd6",
            "Qb2",
            "Qd2",
            "Qb3",
            "g3",
            "e4",
            "Qd4",
            "Qb2",
            "Rd2",
            "Qb1+",
            "Kg2",
            "h6",
            "c4",
            "Qb7",
            "c5",
            "Qf7",
            "Qxe4",
            "Re8",
            "Qd5",
            "Qf6",
            "c6",
            "Ne5",
            "c7",
            "Rc8",
            "Qd8+",
            "Kh7",
            "Qxc8",
            "Qf3+",
            "Kg1",
            "Qe4",
            "Qf5+",
            "Qxf5",
            "Nxf5",
            "Nf3+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ndb5",
          "neutral_uci": "d4b5",
          "neutral_response": "6. Ndb5 d6 7. Bf4 e5 8. Bg5 a6 9. Na3 b5 10. Nd5 Be7 11. Bxf6 Bxf6 12. c3 O-O 13. Nc2 Bg5 14. a4 bxa4 15. Rxa4 a5 16. Bc4 Rb8 17. b3 Kh8 18. O-O f5 19. exf5 Bxf5 20. Nce3 Be6 21. Qd3 Bxe3 22. Nxe3 Bxc4 23. Qxc4 Ne7 24. Rd1 Qb6 25. Ra3 Rbc8 26. Qd3 d5 27. Nxd5 Qxf2+ 28. Kh1 Nxd5 29. Qxd5 Qf1+ 30. Rxf1 Rxf1# 31. Kh2 Rxc3 32. Qd8+ Rf8 33. Qxf8# Rxf8 34. Rxf8# Rxf8 35. Rxa5 Re8 36. Kg3 Kg8 37. Kf3 Kf7 38. Ke4 Kf6 39. Ra6+ Kg5 40. Ra7 Kf6 41. Ra6+ Kg5 42. Ra7 Kf6 43. Ra6+ Kg5 44. Ra7 Kf6 45. Ra6+ Kg5 46. Ra7 Kf6 47. Ra6+ Kg5 48. Ra7 Kf6 49. Ra6+ Kg5 50. Ra7 Kf6 51. Ra6+ Kg5 52. Ra7 Kf6 53. Ra6+ Kg5 54. Ra7 Kf6 55. Ra6+ Kg5 56. Ra7 Kf6 57. Ra6+ Kg5 58. Ra7 Kf6 59. Ra6+ Kg5 60. Ra7 Kf6 61. Ra6+ Kg5 62. Ra7 Kf6 63. Ra6+ Kg5 64. Ra7 Kf6 65. Ra6+ Kg5 66. Ra7 Kf6 67. Ra6+ Kg5 68. Ra7 Kf6 69. Ra6+ Kg5 70. Ra7 Kf6 71. Ra6+ Kg5 72. Ra7 Kf6 73. Ra6+ Kg5 74. Ra7 Kf6 75. Ra6+ Kg5 76. Ra7 Kf6 77. Ra6+ Kg5 78. Ra7 Kf6 79. Ra6+ Kg5 80. Ra7 Kf6 81. Ra6+ Kg5 82. Ra7 Kf6 83. Ra6+ Kg5 84.",
          "neutral_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d6",
            "Bf4",
            "e5",
            "Bg5",
            "a6",
            "Na3",
            "b5",
            "Nd5",
            "Be7",
            "Bxf6",
            "Bxf6",
            "c3",
            "O-O",
            "Nc2",
            "Bg5",
            "a4",
            "bxa4",
            "Rxa4",
            "a5",
            "Bc4",
            "Rb8",
            "b3",
            "Kh8",
            "O-O",
            "f5",
            "exf5",
            "Bxf5",
            "Nce3",
            "Be6",
            "Qd3",
            "Bxe3",
            "Nxe3",
            "Bxc4",
            "Qxc4",
            "Ne7",
            "Rd1",
            "Qb6",
            "Ra3",
            "Rbc8",
            "Qd3",
            "d5",
            "Nxd5",
            "Qxf2+",
            "Kh1",
            "Nxd5",
            "Qxd5",
            "Qf1+",
            "Rxf1",
            "Rxf1#",
            "Kh2",
            "Rxc3",
            "Qd8+",
            "Rf8",
            "Qxf8#",
            "Rxf8",
            "Rxf8#",
            "Rxf8",
            "Rxa5",
            "Re8",
            "Kg3",
            "Kg8",
            "Kf3",
            "Kf7",
            "Ke4",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5",
            "Ra7",
            "Kf6",
            "Ra6+",
            "Kg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4b5",
          "positional_uci": "d4b5",
          "neutral_uci": "d4b5",
          "consensus_move": "d4b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d6",
              "Bf4",
              "e5",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Be6",
              "Qd3",
              "Bxe3",
              "Nxe3",
              "Bxc4",
              "Qxc4",
              "Qb6",
              "Nd5",
              "Qb5",
              "Qxb5",
              "Rxb5",
              "Nc7",
              "Rxb3",
              "Ne6",
              "Rfb8",
              "Rc4",
              "Ne7",
              "Rc7",
              "Nd5",
              "Rxg7",
              "Rb1",
              "Ra7",
              "Rxf1+",
              "Kxf1",
              "Nxc3",
              "g3",
              "a4",
              "Ng5",
              "h6",
              "Nf7+",
              "Kg8",
              "Nxh6+",
              "Kf8",
              "Nf5",
              "d5",
              "h4",
              "d4",
              "h5",
              "d3",
              "h6",
              "d2",
              "Ne3",
              "Kg8",
              "g4",
              "Rb1+",
              "Kg2",
              "d1=Q",
              "Nxd1",
              "Rxd1",
              "g5",
              "Rd6",
              "Kg3",
              "Rg6",
              "Kg4",
              "Ne4",
              "Kf5",
              "Rxg5+",
              "Kxe4",
              "Rh5",
              "Rxa4",
              "Rxh6",
              "Kxe5",
              "Kf7",
              "Ra7+",
              "Ke8",
              "f4",
              "Rh1",
              "f5",
              "Re1+",
              "Kf6",
              "Rf1",
              "Ra8+",
              "Kd7",
              "Kg6",
              "Rg1+",
              "Kf7",
              "Rf1",
              "f6",
              "Rf2",
              "Ra7+",
              "Kd8",
              "Ra6",
              "Kd7",
              "Kf8",
              "Kd8",
              "f7",
              "Kd7",
              "Ra7+",
              "Kd8",
              "Ra8+",
              "Kd7",
              "Re8",
              "Rf1",
              "Re4",
              "Rf2",
              "Kg7",
              "Rg2+",
              "Kf6",
              "Rf2+",
              "Kg6",
              "Rg2+",
              "Kf5",
              "Rf2+",
              "Kg6",
              "Rg2+",
              "Kf6",
              "Rf2+",
              "Kg7",
              "Rg2+",
              "Kf8",
              "Rf2",
              "Re7+",
              "Kd8",
              "Re5",
              "Kd7",
              "Kg7",
              "Rg2+",
              "Kf6",
              "Rf2+",
              "Kg6",
              "Rg2+",
              "Rg5",
              "Rf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d6",
              "Bf4",
              "e5",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Be6",
              "Qd3",
              "Bxe3",
              "Nxe3",
              "Bxc4",
              "Qxc4",
              "Ne7",
              "Rd1",
              "Qb6",
              "b4",
              "axb4",
              "Rxb4",
              "Qa7",
              "Rxb8",
              "Qxb8",
              "Qe6",
              "Ng6",
              "Qxd6",
              "Qb2",
              "Qd2",
              "Qb3",
              "g3",
              "e4",
              "Qd4",
              "Qb2",
              "Rd2",
              "Qb1+",
              "Kg2",
              "h6",
              "c4",
              "Qb7",
              "c5",
              "Qf7",
              "Qxe4",
              "Re8",
              "Qd5",
              "Qf6",
              "c6",
              "Ne5",
              "c7",
              "Rc8",
              "Qd8+",
              "Kh7",
              "Qxc8",
              "Qf3+",
              "Kg1",
              "Qe4",
              "Qf5+",
              "Qxf5",
              "Nxf5",
              "Nf3+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d6",
              "Bf4",
              "e5",
              "Bg5",
              "a6",
              "Na3",
              "b5",
              "Nd5",
              "Be7",
              "Bxf6",
              "Bxf6",
              "c3",
              "O-O",
              "Nc2",
              "Bg5",
              "a4",
              "bxa4",
              "Rxa4",
              "a5",
              "Bc4",
              "Rb8",
              "b3",
              "Kh8",
              "O-O",
              "f5",
              "exf5",
              "Bxf5",
              "Nce3",
              "Be6",
              "Qd3",
              "Bxe3",
              "Nxe3",
              "Bxc4",
              "Qxc4",
              "Ne7",
              "Rd1",
              "Qb6",
              "Ra3",
              "Rbc8",
              "Qd3",
              "d5",
              "Nxd5",
              "Qxf2+",
              "Kh1",
              "Nxd5",
              "Qxd5",
              "Qf1+",
              "Rxf1",
              "Rxf1#",
              "Kh2",
              "Rxc3",
              "Qd8+",
              "Rf8",
              "Qxf8#",
              "Rxf8",
              "Rxf8#",
              "Rxf8",
              "Rxa5",
              "Re8",
              "Kg3",
              "Kg8",
              "Kf3",
              "Kf7",
              "Ke4",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5",
              "Ra7",
              "Kf6",
              "Ra6+",
              "Kg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 150,
            "completion_tokens": 338,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 449,
          "total_completion_tokens": 1618,
          "total_tokens": 2067
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 150,
            "completion_tokens": 338,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/pp1p1ppp/2n1pn2/8/3NP3/2N5/PPP2PPP/R1BQKB1R w KQkq - 0 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nd6+",
          "aggressive_uci": "b5d6",
          "aggressive_response": "7. Nd6+ Bxd6 8. Qxd6 Qe7 9. Qxe7+ Kxe7 10. Bg5 h6 11. Bh4 g5 12. Bg3 d6 13. O-O-O e5 14. f3 Be6 15. Bf2 a6 16. h4 g4 17. h5 Rhg8 18. Bh4 gxf3 19. gxf3 Nd4 20. f4 Rg4 21. f5 Bd7 22. Nd5+ Kf8 23. Nxf6 Rf4 24. Nxd7+ Kg7 25. Rg1+ Kh7 26. Nf6+ Kh8 27. Bg3 Rf3 28. Bh4 Rc8 29. c3 b5 30. Kb1 Nc6 31. Rxd6 b4 32. Nd5 bxc3 33. Rxh6# 1-0 e5 Nf6 d4 d6 Nc3 Nbd7 Bc4 Be7 O-O O-O Re1 a6 a4 b6 Be3 Bb7 Nd2 Rc8 f3 Nc5 Bf1 d5 exd5 Nxd5 Nxd5 Bxd5 Bxd5 Qxd5+ Kh1 Rfd8 Qe2 Ne6 Ne4 Nd4 Qf2 Rxc2 Qg3 Rxb2 Nf6+ Kh8 Nxd5 Qxd5 Rxe5 Qd6 Rae1 h6 Re8+ Rxe8 Rxe8+ Kh7 Qxd6 Rb1 Qd3+ g6 Qxb1 Kg7 Qxb6 h5 Qxa6 Kh6 Qb7 Kg5 Qxf7 Kh6 Re6 Kg5 Qxg6+ Kf4 Qxh5#",
          "aggressive_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 407,
            "total_tokens": 565,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "d6",
            "O-O-O",
            "e5",
            "f3",
            "Be6",
            "Bf2",
            "a6",
            "h4",
            "g4",
            "h5",
            "Rhg8",
            "Bh4",
            "gxf3",
            "gxf3",
            "Nd4",
            "f4",
            "Rg4",
            "f5",
            "Bd7",
            "Nd5+",
            "Kf8",
            "Nxf6",
            "Rf4",
            "Nxd7+",
            "Kg7",
            "Rg1+",
            "Kh7",
            "Nf6+",
            "Kh8",
            "Bg3",
            "Rf3",
            "Bh4",
            "Rc8",
            "c3",
            "b5",
            "Kb1",
            "Nc6",
            "Rxd6",
            "b4",
            "Nd5",
            "bxc3",
            "Rxh6#",
            "e5",
            "Nf6",
            "d4",
            "d6",
            "Nc3",
            "Nbd7",
            "Bc4",
            "Be7",
            "O-O",
            "O-O",
            "Re1",
            "a6",
            "a4",
            "b6",
            "Be3",
            "Bb7",
            "Nd2",
            "Rc8",
            "f3",
            "Nc5",
            "Bf1",
            "d5",
            "exd5",
            "Nxd5",
            "Nxd5",
            "Bxd5",
            "Bxd5",
            "Qxd5+",
            "Kh1",
            "Rfd8",
            "Qe2",
            "Ne6",
            "Ne4",
            "Nd4",
            "Qf2",
            "Rxc2",
            "Qg3",
            "Rxb2",
            "Nf6+",
            "Kh8",
            "Nxd5",
            "Qxd5",
            "Rxe5",
            "Qd6",
            "Rae1",
            "h6",
            "Re8+",
            "Rxe8",
            "Rxe8+",
            "Kh7",
            "Qxd6",
            "Rb1",
            "Qd3+",
            "g6",
            "Qxb1",
            "Kg7",
            "Qxb6",
            "h5",
            "Qxa6",
            "Kh6",
            "Qb7",
            "Kg5",
            "Qxf7",
            "Kh6",
            "Re6",
            "Kg5",
            "Qxg6+",
            "Kf4",
            "Qxh5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nd6+",
          "positional_uci": "b5d6",
          "positional_response": "7. Nd6+ Bxd6 8. Qxd6 Qe7 9. Qxe7+ Kxe7 10. Bg5 h6 11. Bh4 g5 12. Bg3 d6 13. O-O-O e5 14. f3 Be6 15. Bf2 a6 16. h4 g4 17. h5 Rhg8 18. Bh4 Rad8 19. Nd5+ Bxd5 20. exd5 Nd4 21. fxg4 Rxg4 22. c3 Nf5 23. Bf2 Ne4 24. Bb6 Rdg8 25. Bd3 Nfg3 26. Rhe1 f5 27. c4 Nxh5 28. c5 Nf4 29. Bxe4 fxe4 30. Rxe4 Rxg2 31. cxd6+ Kxd6 32. Ba5 Rc8+ 33. Kb1 Rcc2 34. Bc3 Rce2 35. Rb4 b5 36. a4 Nxd5 37. axb5 axb5 38. Rxb5 Ke6 39. Rbxd5 h5 40. Rd6+ Kf5 41. Rf1+ Ke4 42. Re6 Kd3 43. Rxe5 Rxe5 44. Bxe5 h4 45. Rh1 Rg4 46. Bf6 Ke2 47. Rxh4 Rg1+ 48. Ka2 Kd3 49. Rd4+ Ke3 50. Rd8 Rg6 51. Bc3 Ra6+ 52. Kb3 Rb6+ 53. Kc2 Ke4 54. b4 Kf5 55. Kb3 Ke6 56. Kc4 Ke7 57. Rd1 Rc6+ 58. Kb3 Rb6 59. Bd4 Rb7 60. Bc5+ Ke6 61. Kc4 Ke5 62. b5 Ke6 63. b6 Ke5 64. Kb5 Ke6 65. Kc6 Rb8 66. b7 Ke5 67. Bd6+ Ke6 68. Bxb8 Ke7 69. Bc7 Ke6 70. b8=Q Kf5 71. Qe8 Kg4 72. Rf1 Kh3 73. Qg8 Kh4 74. Rh1# e6 d5 Nf6",
          "positional_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 564,
            "total_tokens": 722,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "d6",
            "O-O-O",
            "e5",
            "f3",
            "Be6",
            "Bf2",
            "a6",
            "h4",
            "g4",
            "h5",
            "Rhg8",
            "Bh4",
            "Rad8",
            "Nd5+",
            "Bxd5",
            "exd5",
            "Nd4",
            "fxg4",
            "Rxg4",
            "c3",
            "Nf5",
            "Bf2",
            "Ne4",
            "Bb6",
            "Rdg8",
            "Bd3",
            "Nfg3",
            "Rhe1",
            "f5",
            "c4",
            "Nxh5",
            "c5",
            "Nf4",
            "Bxe4",
            "fxe4",
            "Rxe4",
            "Rxg2",
            "cxd6+",
            "Kxd6",
            "Ba5",
            "Rc8+",
            "Kb1",
            "Rcc2",
            "Bc3",
            "Rce2",
            "Rb4",
            "b5",
            "a4",
            "Nxd5",
            "axb5",
            "axb5",
            "Rxb5",
            "Ke6",
            "Rbxd5",
            "h5",
            "Rd6+",
            "Kf5",
            "Rf1+",
            "Ke4",
            "Re6",
            "Kd3",
            "Rxe5",
            "Rxe5",
            "Bxe5",
            "h4",
            "Rh1",
            "Rg4",
            "Bf6",
            "Ke2",
            "Rxh4",
            "Rg1+",
            "Ka2",
            "Kd3",
            "Rd4+",
            "Ke3",
            "Rd8",
            "Rg6",
            "Bc3",
            "Ra6+",
            "Kb3",
            "Rb6+",
            "Kc2",
            "Ke4",
            "b4",
            "Kf5",
            "Kb3",
            "Ke6",
            "Kc4",
            "Ke7",
            "Rd1",
            "Rc6+",
            "Kb3",
            "Rb6",
            "Bd4",
            "Rb7",
            "Bc5+",
            "Ke6",
            "Kc4",
            "Ke5",
            "b5",
            "Ke6",
            "b6",
            "Ke5",
            "Kb5",
            "Ke6",
            "Kc6",
            "Rb8",
            "b7",
            "Ke5",
            "Bd6+",
            "Ke6",
            "Bxb8",
            "Ke7",
            "Bc7",
            "Ke6",
            "b8=Q",
            "Kf5",
            "Qe8",
            "Kg4",
            "Rf1",
            "Kh3",
            "Qg8",
            "Kh4",
            "Rh1#",
            "e6",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nd6+",
          "neutral_uci": "b5d6",
          "neutral_response": "7. Nd6+ Bxd6 8. Qxd6 Qe7 9. Qxe7+ Kxe7 10. Bg5 h6 11. Bh4 g5 12. Bg3 d6 13. O-O-O e5 14. f3 Be6 15. Bf2 a6 16. h4 g4 17. h5 Rhg8 18. Bh4 Rad8 19. Nd5+ Bxd5 20. exd5 Nb8 21. fxg4 Rxg4 22. g3 Nd7 23. Bh3 Rgg8 24. Rhf1 Rg5 25. Bxg5 hxg5 26. Bxd7 Nxd7 27. g4 Nf6 28. Rf5 Nh7 29. Rdf1 f6 30. Kd2 Rc8 31. b3 b5 32. Kd3 Rc5 33. c4 bxc4+ 34. bxc4 Ra5 35. R1f2 Ra3+ 36. Ke4 Rc3 37. Rb2 Rxc4+ 38. Kd3 Rc7 39. Rb6 Ra7 40. Rf1 Nf8 41. Rfb1 Nd7 42. Rb7 Ra8 43. Rc7 Kd8 44. Rbb7 Nc5+ 45. Rxc5 dxc5 46. h6 Kc8 47. Rg7 Rb8 48. h7 1-0\n49. h6 Rb1 50. h7 Rd1+ 51. Kc4 Rc1+",
          "neutral_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 375,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "d6",
            "O-O-O",
            "e5",
            "f3",
            "Be6",
            "Bf2",
            "a6",
            "h4",
            "g4",
            "h5",
            "Rhg8",
            "Bh4",
            "Rad8",
            "Nd5+",
            "Bxd5",
            "exd5",
            "Nb8",
            "fxg4",
            "Rxg4",
            "g3",
            "Nd7",
            "Bh3",
            "Rgg8",
            "Rhf1",
            "Rg5",
            "Bxg5",
            "hxg5",
            "Bxd7",
            "Nxd7",
            "g4",
            "Nf6",
            "Rf5",
            "Nh7",
            "Rdf1",
            "f6",
            "Kd2",
            "Rc8",
            "b3",
            "b5",
            "Kd3",
            "Rc5",
            "c4",
            "bxc4+",
            "bxc4",
            "Ra5",
            "R1f2",
            "Ra3+",
            "Ke4",
            "Rc3",
            "Rb2",
            "Rxc4+",
            "Kd3",
            "Rc7",
            "Rb6",
            "Ra7",
            "Rf1",
            "Nf8",
            "Rfb1",
            "Nd7",
            "Rb7",
            "Ra8",
            "Rc7",
            "Kd8",
            "Rbb7",
            "Nc5+",
            "Rxc5",
            "dxc5",
            "h6",
            "Kc8",
            "Rg7",
            "Rb8",
            "h7",
            "h6",
            "Rb1",
            "h7",
            "Rd1+",
            "Kc4",
            "Rc1+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b5d6",
          "positional_uci": "b5d6",
          "neutral_uci": "b5d6",
          "consensus_move": "b5d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "d6",
              "O-O-O",
              "e5",
              "f3",
              "Be6",
              "Bf2",
              "a6",
              "h4",
              "g4",
              "h5",
              "Rhg8",
              "Bh4",
              "gxf3",
              "gxf3",
              "Nd4",
              "f4",
              "Rg4",
              "f5",
              "Bd7",
              "Nd5+",
              "Kf8",
              "Nxf6",
              "Rf4",
              "Nxd7+",
              "Kg7",
              "Rg1+",
              "Kh7",
              "Nf6+",
              "Kh8",
              "Bg3",
              "Rf3",
              "Bh4",
              "Rc8",
              "c3",
              "b5",
              "Kb1",
              "Nc6",
              "Rxd6",
              "b4",
              "Nd5",
              "bxc3",
              "Rxh6#",
              "e5",
              "Nf6",
              "d4",
              "d6",
              "Nc3",
              "Nbd7",
              "Bc4",
              "Be7",
              "O-O",
              "O-O",
              "Re1",
              "a6",
              "a4",
              "b6",
              "Be3",
              "Bb7",
              "Nd2",
              "Rc8",
              "f3",
              "Nc5",
              "Bf1",
              "d5",
              "exd5",
              "Nxd5",
              "Nxd5",
              "Bxd5",
              "Bxd5",
              "Qxd5+",
              "Kh1",
              "Rfd8",
              "Qe2",
              "Ne6",
              "Ne4",
              "Nd4",
              "Qf2",
              "Rxc2",
              "Qg3",
              "Rxb2",
              "Nf6+",
              "Kh8",
              "Nxd5",
              "Qxd5",
              "Rxe5",
              "Qd6",
              "Rae1",
              "h6",
              "Re8+",
              "Rxe8",
              "Rxe8+",
              "Kh7",
              "Qxd6",
              "Rb1",
              "Qd3+",
              "g6",
              "Qxb1",
              "Kg7",
              "Qxb6",
              "h5",
              "Qxa6",
              "Kh6",
              "Qb7",
              "Kg5",
              "Qxf7",
              "Kh6",
              "Re6",
              "Kg5",
              "Qxg6+",
              "Kf4",
              "Qxh5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "d6",
              "O-O-O",
              "e5",
              "f3",
              "Be6",
              "Bf2",
              "a6",
              "h4",
              "g4",
              "h5",
              "Rhg8",
              "Bh4",
              "Rad8",
              "Nd5+",
              "Bxd5",
              "exd5",
              "Nd4",
              "fxg4",
              "Rxg4",
              "c3",
              "Nf5",
              "Bf2",
              "Ne4",
              "Bb6",
              "Rdg8",
              "Bd3",
              "Nfg3",
              "Rhe1",
              "f5",
              "c4",
              "Nxh5",
              "c5",
              "Nf4",
              "Bxe4",
              "fxe4",
              "Rxe4",
              "Rxg2",
              "cxd6+",
              "Kxd6",
              "Ba5",
              "Rc8+",
              "Kb1",
              "Rcc2",
              "Bc3",
              "Rce2",
              "Rb4",
              "b5",
              "a4",
              "Nxd5",
              "axb5",
              "axb5",
              "Rxb5",
              "Ke6",
              "Rbxd5",
              "h5",
              "Rd6+",
              "Kf5",
              "Rf1+",
              "Ke4",
              "Re6",
              "Kd3",
              "Rxe5",
              "Rxe5",
              "Bxe5",
              "h4",
              "Rh1",
              "Rg4",
              "Bf6",
              "Ke2",
              "Rxh4",
              "Rg1+",
              "Ka2",
              "Kd3",
              "Rd4+",
              "Ke3",
              "Rd8",
              "Rg6",
              "Bc3",
              "Ra6+",
              "Kb3",
              "Rb6+",
              "Kc2",
              "Ke4",
              "b4",
              "Kf5",
              "Kb3",
              "Ke6",
              "Kc4",
              "Ke7",
              "Rd1",
              "Rc6+",
              "Kb3",
              "Rb6",
              "Bd4",
              "Rb7",
              "Bc5+",
              "Ke6",
              "Kc4",
              "Ke5",
              "b5",
              "Ke6",
              "b6",
              "Ke5",
              "Kb5",
              "Ke6",
              "Kc6",
              "Rb8",
              "b7",
              "Ke5",
              "Bd6+",
              "Ke6",
              "Bxb8",
              "Ke7",
              "Bc7",
              "Ke6",
              "b8=Q",
              "Kf5",
              "Qe8",
              "Kg4",
              "Rf1",
              "Kh3",
              "Qg8",
              "Kh4",
              "Rh1#",
              "e6",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "d6",
              "O-O-O",
              "e5",
              "f3",
              "Be6",
              "Bf2",
              "a6",
              "h4",
              "g4",
              "h5",
              "Rhg8",
              "Bh4",
              "Rad8",
              "Nd5+",
              "Bxd5",
              "exd5",
              "Nb8",
              "fxg4",
              "Rxg4",
              "g3",
              "Nd7",
              "Bh3",
              "Rgg8",
              "Rhf1",
              "Rg5",
              "Bxg5",
              "hxg5",
              "Bxd7",
              "Nxd7",
              "g4",
              "Nf6",
              "Rf5",
              "Nh7",
              "Rdf1",
              "f6",
              "Kd2",
              "Rc8",
              "b3",
              "b5",
              "Kd3",
              "Rc5",
              "c4",
              "bxc4+",
              "bxc4",
              "Ra5",
              "R1f2",
              "Ra3+",
              "Ke4",
              "Rc3",
              "Rb2",
              "Rxc4+",
              "Kd3",
              "Rc7",
              "Rb6",
              "Ra7",
              "Rf1",
              "Nf8",
              "Rfb1",
              "Nd7",
              "Rb7",
              "Ra8",
              "Rc7",
              "Kd8",
              "Rbb7",
              "Nc5+",
              "Rxc5",
              "dxc5",
              "h6",
              "Kc8",
              "Rg7",
              "Rb8",
              "h7",
              "h6",
              "Rb1",
              "h7",
              "Rd1+",
              "Kc4",
              "Rc1+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 158,
            "completion_tokens": 407,
            "total_tokens": 565,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 158,
            "completion_tokens": 564,
            "total_tokens": 722,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 157,
            "completion_tokens": 375,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 473,
          "total_completion_tokens": 1346,
          "total_tokens": 1819
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 158,
            "completion_tokens": 407,
            "total_tokens": 565,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 158,
            "completion_tokens": 564,
            "total_tokens": 722,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 157,
            "completion_tokens": 375,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/pp1pbppp/2n1pn2/1N6/4P3/2N5/PPP2PPP/R1BQKB1R w KQkq - 2 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be2",
          "aggressive_uci": "f1e2",
          "aggressive_response": "8. Be2 Qc7 9. Ndb5 Qb8 10. O-O a6 11. Nd4 b5 12. Nxc6 dxc6 13. Bf3 e5 14. Bg5 Be6 15. Qd2 h6 16. Be3 Qc7 17. Rfd1 Rd8 18. Qe1 g5 19. Rxd8+ Bxd8 20. Rd1 Kg7 21. Bc5 Be7 22. Bxe7 Qxe7 23. Qd2 g4 24. Be2 b4 25. Na4 Nxe4 26. Qe3 f5 27. Bxg4 Rd8 28. Rxd8 Qxd8 29. Be2 Qd4 30. Qxd4 exd4 31. Bxa6 Bxa2 32. b3 Bb1 33. Bd3 Kf6 34. f3 Nd6 35. Nc5 Nb5 36. Kf2 Na3 37. Na6 Bxc2 38. Bxc2 Nxc2 39. Ke2 Ke5 40. Kd3 Ne1+ 41. Kc4 Nxg2 42. Nxb4 Ne1 43. Nxc6+ Kf4 44. Nxd4 Nxf3 45. Nxf3 Kxf3 46. b4 Ke3 47. b5 f4 48. b6 f3 49. b7 f2 50. b8=Q f1=Q+ 51. Kd5 Qf5+ 52. Kc4 Qe4+ 53. Kc5 Qd4+ 54. Kc6 Qc4+ 55. Kd7 Qf7+ 56. Kc6 Qc4+ 57. Kd7 Qf7+ 58. Kc6 Qc4+ 59. Kd7 Qf7+ 60. Kc6 Qc4+ 61. Kd7 Qf7+ 62. Kc6 Qc4+ 63. Kd7 Qf7+ 64. Kc6 Qc4+ 65. Kd7 Qf7+ 66. Kc6 Qc4+ 67. Kd7 Qf7+ 68. Kc6 Qc4+ 69. Kd7 Qf7+ 70. Kc6 Qc4+ 71. Kd7 Qf7+ 72. Kc6 Qc4+ 73. Kd7 Qf7+ 74. Kc6 Qc4+ 75. Kd7 Qf7+ 76. Kc6 Qc4+ 77. Kd7 Qf7+ 78. Kc6 Qc4+ 79. Kd7",
          "aggressive_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 640,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd4",
            "Qxd4",
            "exd4",
            "Bxa6",
            "Bxa2",
            "b3",
            "Bb1",
            "Bd3",
            "Kf6",
            "f3",
            "Nd6",
            "Nc5",
            "Nb5",
            "Kf2",
            "Na3",
            "Na6",
            "Bxc2",
            "Bxc2",
            "Nxc2",
            "Ke2",
            "Ke5",
            "Kd3",
            "Ne1+",
            "Kc4",
            "Nxg2",
            "Nxb4",
            "Ne1",
            "Nxc6+",
            "Kf4",
            "Nxd4",
            "Nxf3",
            "Nxf3",
            "Kxf3",
            "b4",
            "Ke3",
            "b5",
            "f4",
            "b6",
            "f3",
            "b7",
            "f2",
            "b8=Q",
            "f1=Q+",
            "Kd5",
            "Qf5+",
            "Kc4",
            "Qe4+",
            "Kc5",
            "Qd4+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7",
            "Qf7+",
            "Kc6",
            "Qc4+",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be2",
          "positional_uci": "f1e2",
          "positional_response": "8. Be2 Qc7 9. Ndb5 Qb8 10. O-O a6 11. Nd4 b5 12. Nxc6 dxc6 13. Bf3 e5 14. Be3 Be6 15. a3 Qc7 16. Qe2 Bc4 17. Qe1 Bxf1 18. Qxf1 Rd8 19. Rd1 Rxd1 20. Qxd1 Qd6 21. Qe2 h6 22. b4 Qe6 23. Qd3 Kg8 24. h3 Kh7 25. Ne2 Rd8 26. Qc3 Nd7 27. Ng3 g6 28. Bg4 Qd6 29. Bxd7 Rxd7 30. Bc5 Qd1+ 31. Kh2 Bxc5 32. Qxc5 Qd6 33. Qb6 Qd4 34. Qxc6 Rd6 35. Qe8 Kg7 36. f3 Re6 37. Qc8 Qc4 38. Qxc4 bxc4 39. Ne2 Rd6 40. Nc3 Rd2 41. Nd5 Rxc2 42. a4 Rb2 43. Kg3 Rb3 44. Kf2 c3 45. Ke2 c2 46. Kd2 Ra3 47. Kxc2 Rxa4 48. Kb3 Ra1 49. Nc7 Kf8 50. Kb2 Ra4 51. Kb3 Ra1 52. Kb2 Rg1 53. Nxa6 Rxg2+ 54. Kb3 Rg3 55. b5 Rxf3+ 56. Kb4 Rf1 57. b6 Rb1+ 58. Kc5 Ke7 59. Nb4 Kd7 60. Nd5 Rc1+ 61. Kb5 Kc8 62. Ka6 Ra1+ 63. Kb5 Kb7 64. Kc5 Ra5+ 65. Kd6 Rxd5+ 66. Kxd5 f6 67. Ke6 Kxb6 68. Kxf6 Kc5 69. Kxe5 Kc6 70. Kf6 Kd6 71. e5+ Kd7 72. Kf7 g5 73. e6+ Kd6 74. e7 h5 75. e8=Q g4 76. hxg4 hxg4 77. Qe6+ Kc5 78. Qxg4 Kd5 79. Qe6+ Kd4 80. Kf6 Kd3 81. Qe5 Kc4 82. Kf5 Kd3 83. Qe4+ Kc3 84. Kf4",
          "positional_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 640,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qc7",
            "Ndb5",
            "Qb8",
            "O-O",
            "a6",
            "Nd4",
            "b5",
            "Nxc6",
            "dxc6",
            "Bf3",
            "e5",
            "Be3",
            "Be6",
            "a3",
            "Qc7",
            "Qe2",
            "Bc4",
            "Qe1",
            "Bxf1",
            "Qxf1",
            "Rd8",
            "Rd1",
            "Rxd1",
            "Qxd1",
            "Qd6",
            "Qe2",
            "h6",
            "b4",
            "Qe6",
            "Qd3",
            "Kg8",
            "h3",
            "Kh7",
            "Ne2",
            "Rd8",
            "Qc3",
            "Nd7",
            "Ng3",
            "g6",
            "Bg4",
            "Qd6",
            "Bxd7",
            "Rxd7",
            "Bc5",
            "Qd1+",
            "Kh2",
            "Bxc5",
            "Qxc5",
            "Qd6",
            "Qb6",
            "Qd4",
            "Qxc6",
            "Rd6",
            "Qe8",
            "Kg7",
            "f3",
            "Re6",
            "Qc8",
            "Qc4",
            "Qxc4",
            "bxc4",
            "Ne2",
            "Rd6",
            "Nc3",
            "Rd2",
            "Nd5",
            "Rxc2",
            "a4",
            "Rb2",
            "Kg3",
            "Rb3",
            "Kf2",
            "c3",
            "Ke2",
            "c2",
            "Kd2",
            "Ra3",
            "Kxc2",
            "Rxa4",
            "Kb3",
            "Ra1",
            "Nc7",
            "Kf8",
            "Kb2",
            "Ra4",
            "Kb3",
            "Ra1",
            "Kb2",
            "Rg1",
            "Nxa6",
            "Rxg2+",
            "Kb3",
            "Rg3",
            "b5",
            "Rxf3+",
            "Kb4",
            "Rf1",
            "b6",
            "Rb1+",
            "Kc5",
            "Ke7",
            "Nb4",
            "Kd7",
            "Nd5",
            "Rc1+",
            "Kb5",
            "Kc8",
            "Ka6",
            "Ra1+",
            "Kb5",
            "Kb7",
            "Kc5",
            "Ra5+",
            "Kd6",
            "Rxd5+",
            "Kxd5",
            "f6",
            "Ke6",
            "Kxb6",
            "Kxf6",
            "Kc5",
            "Kxe5",
            "Kc6",
            "Kf6",
            "Kd6",
            "e5+",
            "Kd7",
            "Kf7",
            "g5",
            "e6+",
            "Kd6",
            "e7",
            "h5",
            "e8=Q",
            "g4",
            "hxg4",
            "hxg4",
            "Qe6+",
            "Kc5",
            "Qxg4",
            "Kd5",
            "Qe6+",
            "Kd4",
            "Kf6",
            "Kd3",
            "Qe5",
            "Kc4",
            "Kf5",
            "Kd3",
            "Qe4+",
            "Kc3",
            "Kf4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be2",
          "neutral_uci": "f1e2",
          "neutral_response": "8. Be2 Qc7 9. Ndb5 Qb8 10. O-O a6 11. Nd4 b5 12. Nxc6 dxc6 13. Bf3 e5 14. Bg5 Be6 15. Qd2 h6 16. Bh4 g5 17. Bg3 Kg7 18. Rad1 Rd8 19. Qe3 Qc7 20. h4 g4 21. Be2 Nh5 22. Rxd8 Rxd8 23. Rd1 Rxd1+ 24. Bxd1 Nxg3 25. Qxg3 h5 26. f3 Bc5+ 27. Kh1 Qd6 28. fxg4 hxg4 29. Bxg4 Bxg4 30. Qxg4+ Qg6 31. Qxg6+ Kxg6 32. g4 Bd4 33. Kg2 b4 34. Nd1 a5 35. c3 bxc3 36. Nxc3 f6 37. Kf3 Kh6 38. Ke2 Kg6 39. Kd3 Bf2 40. h5+ Kg5 41. Nd1 Bd4 42. Ne3 Bxb2 43. Nc4 Bd4 44. Nxa5 c5 45. Nc6 Bf2 46. a4 Kxg4 47. h6 c4+ 48. Kxc4 Kf4 49. h7 Kxe4 50. h8=Q f5 51. Qxe5+ Kf3 52. Qxf5+ Ke2 53. Qxf2+ Kxf2 54. a5 Ke3 55. a6 Ke4 56. a7 Kf5 57. a8=Q Ke6 58. Qe8+ Kd6 59. Qe5+ Kxc6 60. Qe6+ Kc7 61. Kc5 Kb7 62. Qd7+ Ka6 63. Qb5+ Ka7 64. Kc6 Ka8 65. Qb7# 1-0 1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Qc7 9. Ndb5 Qb8 10. O-O a6 11. Nd4 b5 12. Nxc6 dxc6 13. Bf3 e5 14. Bg5 Be6 15. Qd2 h6 16. Bh4 g5 17. Bg3 Kg7 18. Rad1 Rd8 19. Q",
          "neutral_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qc7",
            "Ndb5",
            "Qb8",
            "O-O",
            "a6",
            "Nd4",
            "b5",
            "Nxc6",
            "dxc6",
            "Bf3",
            "e5",
            "Bg5",
            "Be6",
            "Qd2",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Kg7",
            "Rad1",
            "Rd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1e2",
          "positional_uci": "f1e2",
          "neutral_uci": "f1e2",
          "consensus_move": "f1e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd4",
              "Qxd4",
              "exd4",
              "Bxa6",
              "Bxa2",
              "b3",
              "Bb1",
              "Bd3",
              "Kf6",
              "f3",
              "Nd6",
              "Nc5",
              "Nb5",
              "Kf2",
              "Na3",
              "Na6",
              "Bxc2",
              "Bxc2",
              "Nxc2",
              "Ke2",
              "Ke5",
              "Kd3",
              "Ne1+",
              "Kc4",
              "Nxg2",
              "Nxb4",
              "Ne1",
              "Nxc6+",
              "Kf4",
              "Nxd4",
              "Nxf3",
              "Nxf3",
              "Kxf3",
              "b4",
              "Ke3",
              "b5",
              "f4",
              "b6",
              "f3",
              "b7",
              "f2",
              "b8=Q",
              "f1=Q+",
              "Kd5",
              "Qf5+",
              "Kc4",
              "Qe4+",
              "Kc5",
              "Qd4+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7",
              "Qf7+",
              "Kc6",
              "Qc4+",
              "Kd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qc7",
              "Ndb5",
              "Qb8",
              "O-O",
              "a6",
              "Nd4",
              "b5",
              "Nxc6",
              "dxc6",
              "Bf3",
              "e5",
              "Be3",
              "Be6",
              "a3",
              "Qc7",
              "Qe2",
              "Bc4",
              "Qe1",
              "Bxf1",
              "Qxf1",
              "Rd8",
              "Rd1",
              "Rxd1",
              "Qxd1",
              "Qd6",
              "Qe2",
              "h6",
              "b4",
              "Qe6",
              "Qd3",
              "Kg8",
              "h3",
              "Kh7",
              "Ne2",
              "Rd8",
              "Qc3",
              "Nd7",
              "Ng3",
              "g6",
              "Bg4",
              "Qd6",
              "Bxd7",
              "Rxd7",
              "Bc5",
              "Qd1+",
              "Kh2",
              "Bxc5",
              "Qxc5",
              "Qd6",
              "Qb6",
              "Qd4",
              "Qxc6",
              "Rd6",
              "Qe8",
              "Kg7",
              "f3",
              "Re6",
              "Qc8",
              "Qc4",
              "Qxc4",
              "bxc4",
              "Ne2",
              "Rd6",
              "Nc3",
              "Rd2",
              "Nd5",
              "Rxc2",
              "a4",
              "Rb2",
              "Kg3",
              "Rb3",
              "Kf2",
              "c3",
              "Ke2",
              "c2",
              "Kd2",
              "Ra3",
              "Kxc2",
              "Rxa4",
              "Kb3",
              "Ra1",
              "Nc7",
              "Kf8",
              "Kb2",
              "Ra4",
              "Kb3",
              "Ra1",
              "Kb2",
              "Rg1",
              "Nxa6",
              "Rxg2+",
              "Kb3",
              "Rg3",
              "b5",
              "Rxf3+",
              "Kb4",
              "Rf1",
              "b6",
              "Rb1+",
              "Kc5",
              "Ke7",
              "Nb4",
              "Kd7",
              "Nd5",
              "Rc1+",
              "Kb5",
              "Kc8",
              "Ka6",
              "Ra1+",
              "Kb5",
              "Kb7",
              "Kc5",
              "Ra5+",
              "Kd6",
              "Rxd5+",
              "Kxd5",
              "f6",
              "Ke6",
              "Kxb6",
              "Kxf6",
              "Kc5",
              "Kxe5",
              "Kc6",
              "Kf6",
              "Kd6",
              "e5+",
              "Kd7",
              "Kf7",
              "g5",
              "e6+",
              "Kd6",
              "e7",
              "h5",
              "e8=Q",
              "g4",
              "hxg4",
              "hxg4",
              "Qe6+",
              "Kc5",
              "Qxg4",
              "Kd5",
              "Qe6+",
              "Kd4",
              "Kf6",
              "Kd3",
              "Qe5",
              "Kc4",
              "Kf5",
              "Kd3",
              "Qe4+",
              "Kc3",
              "Kf4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qc7",
              "Ndb5",
              "Qb8",
              "O-O",
              "a6",
              "Nd4",
              "b5",
              "Nxc6",
              "dxc6",
              "Bf3",
              "e5",
              "Bg5",
              "Be6",
              "Qd2",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Kg7",
              "Rad1",
              "Rd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 167,
            "completion_tokens": 640,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 167,
            "completion_tokens": 640,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 500,
          "total_completion_tokens": 1920,
          "total_tokens": 2420
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 167,
            "completion_tokens": 640,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 167,
            "completion_tokens": 640,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bq1k1r/pp1pbppp/2nNpn2/8/4P3/2N5/PPP2PPP/R1BQKB1R w KQ - 4 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "9. O-O h6 10. f4 Kh7 11. e5 Ne8 12. Nxf7 Qb6+ 13. Kh1 Rf8 14. Bd3+ Kg8 15. Nxh6+ gxh6 16. Qg4+ Ng7 17. Qg6 Rf5 18. Bxf5 exf5 19. Nd5 Qd8 20. Nf6+ Bxf6 21. exf6 Qf8 22. fxg7 Qxg7 23. Qxf5 d6 24. Qd5+ Kh8 25. Qxd6 Bf5 26. Be3 Rd8 27. Qc5 Be4 28. Rf2 Rg8 29. Rg1 Qg4 30. Bd4+ Kh7 31. Qc3 Nxd4 32. Qxd4 Bc6 33. Qd3+ Kh8 34. Qg3 Qxg3 35. hxg3 Rxg3 36. Kh2 Rg4 37. g3 h5 38. Re1 h4 39. gxh4 Rxh4+ 40. Kg3 Rh7 41. Rh2 Rxh2 42. Kxh2 Kg7 43. Kg3 Kf6 44. Re5 a6 45. c4 Bh1 46. b4 Bc6 47. b5 axb5 48. cxb5 Bh1 49. a4 Kf7 50. a5 Kf6 51. a6 bxa6 52. bxa6 Kf7 53. a7 Kf6 54. Re8 Kf7 55. a8=Q Bxa8 56. Rxa8 Kf6 57. Ra5 Kf7 58. Kg4 Kf6 59. Ra6+ Kf7 60. Kg5 Ke7 61. f5 Kf7 62. Ra7+ Kf8 63. Kg6 Ke8 64. f6 Kd8 65. f7 Kc8 66. f8=Q# Kd8 67. Qf6+ Ke8 68. Qe7# Kd8 69. Qd7# Kc8 70. Qc7# Kd8 71. Ra8# Kc8 72. Rxb8# Kxb8 73. f5 Kc8 74. f6 Kd8 75. f7 Kc8 76. f8=Q# Kd8 77. Qf6+ Ke8 78. Qe6+ Kd8 79. Qd6+ Ke8 80. Qc6+ Kd8 81. Qcc8# Ke7 82. Qc7+ Ke8 83. Q",
          "aggressive_tokens": {
            "prompt_tokens": 174,
            "completion_tokens": 640,
            "total_tokens": 814,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h6",
            "f4",
            "Kh7",
            "e5",
            "Ne8",
            "Nxf7",
            "Qb6+",
            "Kh1",
            "Rf8",
            "Bd3+",
            "Kg8",
            "Nxh6+",
            "gxh6",
            "Qg4+",
            "Ng7",
            "Qg6",
            "Rf5",
            "Bxf5",
            "exf5",
            "Nd5",
            "Qd8",
            "Nf6+",
            "Bxf6",
            "exf6",
            "Qf8",
            "fxg7",
            "Qxg7",
            "Qxf5",
            "d6",
            "Qd5+",
            "Kh8",
            "Qxd6",
            "Bf5",
            "Be3",
            "Rd8",
            "Qc5",
            "Be4",
            "Rf2",
            "Rg8",
            "Rg1",
            "Qg4",
            "Bd4+",
            "Kh7",
            "Qc3",
            "Nxd4",
            "Qxd4",
            "Bc6",
            "Qd3+",
            "Kh8",
            "Qg3",
            "Qxg3",
            "hxg3",
            "Rxg3",
            "Kh2",
            "Rg4",
            "g3",
            "h5",
            "Re1",
            "h4",
            "gxh4",
            "Rxh4+",
            "Kg3",
            "Rh7",
            "Rh2",
            "Rxh2",
            "Kxh2",
            "Kg7",
            "Kg3",
            "Kf6",
            "Re5",
            "a6",
            "c4",
            "Bh1",
            "b4",
            "Bc6",
            "b5",
            "axb5",
            "cxb5",
            "Bh1",
            "a4",
            "Kf7",
            "a5",
            "Kf6",
            "a6",
            "bxa6",
            "bxa6",
            "Kf7",
            "a7",
            "Kf6",
            "Re8",
            "Kf7",
            "a8=Q",
            "Bxa8",
            "Rxa8",
            "Kf6",
            "Ra5",
            "Kf7",
            "Kg4",
            "Kf6",
            "Ra6+",
            "Kf7",
            "Kg5",
            "Ke7",
            "f5",
            "Kf7",
            "Ra7+",
            "Kf8",
            "Kg6",
            "Ke8",
            "f6",
            "Kd8",
            "f7",
            "Kc8",
            "f8=Q#",
            "Kd8",
            "Qf6+",
            "Ke8",
            "Qe7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Ra8#",
            "Kc8",
            "Rxb8#",
            "Kxb8",
            "f5",
            "Kc8",
            "f6",
            "Kd8",
            "f7",
            "Kc8",
            "f8=Q#",
            "Kd8",
            "Qf6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qc6+",
            "Kd8",
            "Qcc8#",
            "Ke7",
            "Qc7+",
            "Ke8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "9. O-O h6 10. f4 Kh7 11. e5 Ne8 12. Nxf7 Qb6+ 13. Kh1 Rf8 14. Bd3+ Kg8 15. Nxh6+ gxh6 16. Qg4+ Ng7 17. Qg6 Rf5 18. Bxf5 exf5 19. Nd5 Qd8 20. Nf6+ Bxf6 21. exf6 Qf8 22. fxg7 Qxg7 23. Qxg7+ Kxg7 24. Bd2 d5 25. Rae1 Bd7 26. Bc3+ Kf7 27. Be5 Rg8 28. c3 Ne7 29. Bd6 Ng6 30. g3 Bc6 31. Kg1 h5 32. Kf2 h4 33. Rg1 hxg3+ 34. hxg3 Rh8 35. Rh1 Rd8 36. Rh7+ Kg8 37. Rh6 Rxd6 38. g4 Kg7 39. g5 d4 40. cxd4 Rxd4 41. Re6 Rxf4+ 42. Ke3 Re4+ 43. Rxe4 Bxe4 44. Rh2 Ne5 45. Kf4 Ng4 46. Rd2 Kg6 47. Rd6+ Kg7 48. Rd7+ Kg6 49. Rd6+ Kg7 50. Rd7+ Kg6 51. Rd6+ Kg7 52. Rd7+ Kg6 53. Rd6+ Kg7 54. Rd7+ Kg6 55. Rd6+ Kg7 56. Rd7+ Kg6 57. Rd6+ Kg7 58. Rd7+ Kg6 59. Rd6+ Kg7 60. Rd7+ Kg6 61. Rd6+ Kg7 62. Rd7+ Kg6 63. Rd6+ Kg7 64. Rd7+ Kg6 65. Rd6+ Kg7 66. Rd7+ Kg6 67. Rd6+ Kg7 68. Rd7+ Kg6 69. Rd6+ Kg7 70. Rd7+ Kg6 71. Rd6+ Kg7 72. Rd7+ Kg6 73. Rd6+ Kg7 74. Rd7+ Kg6 75. Rd6+ Kg7 76. Rd7+ Kg6 77. Rd6+ Kg7 78. Rd7+ Kg6 79. Rd6+ Kg7 80. Rd7+ Kg6 81. Rd6+ Kg7 82. Rd7+ Kg6 83. Rd6+ Kg7 84. Rd7+ Kg6 85. Rd6+ Kg7 86. Rd7+ Kg6 87. Rd6+",
          "positional_tokens": {
            "prompt_tokens": 174,
            "completion_tokens": 640,
            "total_tokens": 814,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h6",
            "f4",
            "Kh7",
            "e5",
            "Ne8",
            "Nxf7",
            "Qb6+",
            "Kh1",
            "Rf8",
            "Bd3+",
            "Kg8",
            "Nxh6+",
            "gxh6",
            "Qg4+",
            "Ng7",
            "Qg6",
            "Rf5",
            "Bxf5",
            "exf5",
            "Nd5",
            "Qd8",
            "Nf6+",
            "Bxf6",
            "exf6",
            "Qf8",
            "fxg7",
            "Qxg7",
            "Qxg7+",
            "Kxg7",
            "Bd2",
            "d5",
            "Rae1",
            "Bd7",
            "Bc3+",
            "Kf7",
            "Be5",
            "Rg8",
            "c3",
            "Ne7",
            "Bd6",
            "Ng6",
            "g3",
            "Bc6",
            "Kg1",
            "h5",
            "Kf2",
            "h4",
            "Rg1",
            "hxg3+",
            "hxg3",
            "Rh8",
            "Rh1",
            "Rd8",
            "Rh7+",
            "Kg8",
            "Rh6",
            "Rxd6",
            "g4",
            "Kg7",
            "g5",
            "d4",
            "cxd4",
            "Rxd4",
            "Re6",
            "Rxf4+",
            "Ke3",
            "Re4+",
            "Rxe4",
            "Bxe4",
            "Rh2",
            "Ne5",
            "Kf4",
            "Ng4",
            "Rd2",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rd6+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "9. O-O h6 10. f4 Kh7 11. e5 Ne8 12. Nxf7 Qb6+ 13. Kh1 Rf8 14. Bd3+ Kg8 15. Nxh6+ gxh6 16. Qg4+ Ng7 17. Qg6 Rf5 18. Bxf5 exf5 19. Nd5 Qd8 20. Rf3 Qe8 21. Qxh6 Qh5 22. Nxe7+ Nxe7 23. Qd6 Kf7 24. Be3 Ne6 25. Rh3 Qg6 26. Rg3 Qh5 27. Bc5 Nxc5 28. Qf6+ Ke8 29. Rg7 Nc6 30. Rg8# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6 Kf8 Be2 Kg8 O-O h6 f4 Kh7 e5 Ne8 Nxf7 Qb6 Kh1 Rf8 Bd3+ Kg8 Nxh6+ gxh6 Qg6+ Ng7 Qg6 Rf5 Bxf5 exf5 Nd5 Qd8 Rf3 Qe8 Qh5 Ne7 Qd6 Kf7 Be3 Ne6 Rh3 Qg6 Rg3 Qh5 Bc5 Nxc5 Qf6+ Ke8 Rg8# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h6 f4 Kh7 e5 Ne8 Nxf7 Qb6+ Kh1 Rf8 Bd3+ Kg8 Nxh6+ gxh6 Qg6+ Ng7 Qg6 Rf5 Bxf5 exf5 Nd5 Qd8 Rf3 Qe8 Qh5 Ne7 Qd6 Kf7 Be3 Ne6 Rh3 Qg6 Rg3 Qh5 Bc5 Nxc5 Qf6+ Ke8 Rg8# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h6 f4 Kh7 e5 Ne8 Nxf7 Qb6+ Kh1 Rf8 Bd3+ Kg8 Nxh6+ gxh6 Qg6+ Ng7 Qg6 Rf5 Bxf5 exf5 Nd5 Qd8 Rf3 Qe8 Qh5 Ne7 Qd6 Kf7 Be3 Ne6 Rh3 Qg6 Rg3 Qh5 Bc5 Nxc5 Qf6+ Ke8 Rg8# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be",
          "neutral_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 640,
            "total_tokens": 813,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h6",
            "f4",
            "Kh7",
            "e5",
            "Ne8",
            "Nxf7",
            "Qb6+",
            "Kh1",
            "Rf8",
            "Bd3+",
            "Kg8",
            "Nxh6+",
            "gxh6",
            "Qg6+",
            "Ng7",
            "Qg6",
            "Rf5",
            "Bxf5",
            "exf5",
            "Nd5",
            "Qd8",
            "Rf3",
            "Qe8",
            "Qh5",
            "Ne7",
            "Qd6",
            "Kf7",
            "Be3",
            "Ne6",
            "Rh3",
            "Qg6",
            "Rg3",
            "Qh5",
            "Bc5",
            "Nxc5",
            "Qf6+",
            "Ke8",
            "Rg8#",
            "e4",
            "c5",
            "Nf3",
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Ndb5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h6",
              "f4",
              "Kh7",
              "e5",
              "Ne8",
              "Nxf7",
              "Qb6+",
              "Kh1",
              "Rf8",
              "Bd3+",
              "Kg8",
              "Nxh6+",
              "gxh6",
              "Qg4+",
              "Ng7",
              "Qg6",
              "Rf5",
              "Bxf5",
              "exf5",
              "Nd5",
              "Qd8",
              "Nf6+",
              "Bxf6",
              "exf6",
              "Qf8",
              "fxg7",
              "Qxg7",
              "Qxf5",
              "d6",
              "Qd5+",
              "Kh8",
              "Qxd6",
              "Bf5",
              "Be3",
              "Rd8",
              "Qc5",
              "Be4",
              "Rf2",
              "Rg8",
              "Rg1",
              "Qg4",
              "Bd4+",
              "Kh7",
              "Qc3",
              "Nxd4",
              "Qxd4",
              "Bc6",
              "Qd3+",
              "Kh8",
              "Qg3",
              "Qxg3",
              "hxg3",
              "Rxg3",
              "Kh2",
              "Rg4",
              "g3",
              "h5",
              "Re1",
              "h4",
              "gxh4",
              "Rxh4+",
              "Kg3",
              "Rh7",
              "Rh2",
              "Rxh2",
              "Kxh2",
              "Kg7",
              "Kg3",
              "Kf6",
              "Re5",
              "a6",
              "c4",
              "Bh1",
              "b4",
              "Bc6",
              "b5",
              "axb5",
              "cxb5",
              "Bh1",
              "a4",
              "Kf7",
              "a5",
              "Kf6",
              "a6",
              "bxa6",
              "bxa6",
              "Kf7",
              "a7",
              "Kf6",
              "Re8",
              "Kf7",
              "a8=Q",
              "Bxa8",
              "Rxa8",
              "Kf6",
              "Ra5",
              "Kf7",
              "Kg4",
              "Kf6",
              "Ra6+",
              "Kf7",
              "Kg5",
              "Ke7",
              "f5",
              "Kf7",
              "Ra7+",
              "Kf8",
              "Kg6",
              "Ke8",
              "f6",
              "Kd8",
              "f7",
              "Kc8",
              "f8=Q#",
              "Kd8",
              "Qf6+",
              "Ke8",
              "Qe7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Ra8#",
              "Kc8",
              "Rxb8#",
              "Kxb8",
              "f5",
              "Kc8",
              "f6",
              "Kd8",
              "f7",
              "Kc8",
              "f8=Q#",
              "Kd8",
              "Qf6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qc6+",
              "Kd8",
              "Qcc8#",
              "Ke7",
              "Qc7+",
              "Ke8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h6",
              "f4",
              "Kh7",
              "e5",
              "Ne8",
              "Nxf7",
              "Qb6+",
              "Kh1",
              "Rf8",
              "Bd3+",
              "Kg8",
              "Nxh6+",
              "gxh6",
              "Qg4+",
              "Ng7",
              "Qg6",
              "Rf5",
              "Bxf5",
              "exf5",
              "Nd5",
              "Qd8",
              "Nf6+",
              "Bxf6",
              "exf6",
              "Qf8",
              "fxg7",
              "Qxg7",
              "Qxg7+",
              "Kxg7",
              "Bd2",
              "d5",
              "Rae1",
              "Bd7",
              "Bc3+",
              "Kf7",
              "Be5",
              "Rg8",
              "c3",
              "Ne7",
              "Bd6",
              "Ng6",
              "g3",
              "Bc6",
              "Kg1",
              "h5",
              "Kf2",
              "h4",
              "Rg1",
              "hxg3+",
              "hxg3",
              "Rh8",
              "Rh1",
              "Rd8",
              "Rh7+",
              "Kg8",
              "Rh6",
              "Rxd6",
              "g4",
              "Kg7",
              "g5",
              "d4",
              "cxd4",
              "Rxd4",
              "Re6",
              "Rxf4+",
              "Ke3",
              "Re4+",
              "Rxe4",
              "Bxe4",
              "Rh2",
              "Ne5",
              "Kf4",
              "Ng4",
              "Rd2",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rd6+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h6",
              "f4",
              "Kh7",
              "e5",
              "Ne8",
              "Nxf7",
              "Qb6+",
              "Kh1",
              "Rf8",
              "Bd3+",
              "Kg8",
              "Nxh6+",
              "gxh6",
              "Qg6+",
              "Ng7",
              "Qg6",
              "Rf5",
              "Bxf5",
              "exf5",
              "Nd5",
              "Qd8",
              "Rf3",
              "Qe8",
              "Qh5",
              "Ne7",
              "Qd6",
              "Kf7",
              "Be3",
              "Ne6",
              "Rh3",
              "Qg6",
              "Rg3",
              "Qh5",
              "Bc5",
              "Nxc5",
              "Qf6+",
              "Ke8",
              "Rg8#",
              "e4",
              "c5",
              "Nf3",
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Ndb5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 174,
            "completion_tokens": 640,
            "total_tokens": 814,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 174,
            "completion_tokens": 640,
            "total_tokens": 814,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 173,
            "completion_tokens": 640,
            "total_tokens": 813,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 521,
          "total_completion_tokens": 1920,
          "total_tokens": 2441
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 174,
            "completion_tokens": 640,
            "total_tokens": 814,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 174,
            "completion_tokens": 640,
            "total_tokens": 814,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 173,
            "completion_tokens": 640,
            "total_tokens": 813,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bq2kr/pp1pbppp/2nNpn2/8/4P3/2N5/PPP1BPPP/R1BQK2R w KQ - 6 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "f4",
          "aggressive_uci": "f2f4",
          "aggressive_response": "10. f4 Qb6+ 11. Kh1 Nd4 12. Nc4 Qc5 13. Be3 d5 14. Bxd4 Qc7 15. exd5 exd5 16. Ne5\nBe6 17. f5 Bd7 18. Nxd7 Qxd7 19. Bxf6 Bxf6 20. Nxd5 Bxb2 21. Nf6+ Bxf6 22. Qxd7\nBxa1 23. Rxa1 Kh7 24. Qxf7 Rhf8 25. Qxh5+ Kg8 26. Bc4+ Rf7 27. Qxf7+ Kh8 28. Qh5# Qh6\n29. Qxh6+ gxh6 30. f6 Rf8 31. f7 Kg7 32. Re1 a6 33. Re8 b5 34. Rxf8 Kxf8 35. Bd5\na5 36. Kg1 b4 37. Kf2 a4 38. Ke3 b3 39. cxb3 axb3 40. axb3 h5 41. b4 h4 42. b5\nh3 43. gxh3 Ke7 44. b6 Kd6 45. f8=Q+ Kxd5 46. b7 Kc6 47. b8=Q Kd5 48. Qbd6+ Kc4\n49. Qc8+ Kb5 50. Qdb8+ Ka5 51. Qc5+ Ka6 52. Qcb6# Qxb6 53. Qxb6+ Kxb6 54. Kf4\nKc6 55. Kg5 Kd6 56. Kg6 Ke7 57. Kg7 Ke6 58. h4 Kf5 59. h5 Kg5 60. h6 Kh5 61.\nh7 Kg5 62. h8=Q Kf5 63. Qh6 Ke5 64. Qf6+ Kd5 65. h4 Ke4 66. h5 Kd5 67. h6\nKe4 68. h7 Kd5 69. h8=Q Ke4 70. Qe8+ Kd5 71. Qfd8+ Kc5 72. Qee7+ Kc6 73. Qec7+\nKb5 74. Qdb8+ Ka6 75. Qca7# Qxa7 76. Qxa7+ Kxa7 77. Kf7 Kb7 78. h4 Kc7 79. h5\nKd7 80. h6 Kd6 81. h7 Ke5 82. h8=Q+ Kf5 83. Qh5+ Ke4",
          "aggressive_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 640,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qb6+",
            "Kh1",
            "Nd4",
            "Nc4",
            "Qc5",
            "Be3",
            "d5",
            "Bxd4",
            "Qc7",
            "exd5",
            "exd5",
            "Ne5",
            "Be6",
            "f5",
            "Bd7",
            "Nxd7",
            "Qxd7",
            "Bxf6",
            "Bxf6",
            "Nxd5",
            "Bxb2",
            "Nf6+",
            "Bxf6",
            "Qxd7",
            "Bxa1",
            "Rxa1",
            "Kh7",
            "Qxf7",
            "Rhf8",
            "Qxh5+",
            "Kg8",
            "Bc4+",
            "Rf7",
            "Qxf7+",
            "Kh8",
            "Qh5#",
            "Qh6",
            "Qxh6+",
            "gxh6",
            "f6",
            "Rf8",
            "f7",
            "Kg7",
            "Re1",
            "a6",
            "Re8",
            "b5",
            "Rxf8",
            "Kxf8",
            "Bd5",
            "a5",
            "Kg1",
            "b4",
            "Kf2",
            "a4",
            "Ke3",
            "b3",
            "cxb3",
            "axb3",
            "axb3",
            "h5",
            "b4",
            "h4",
            "b5",
            "h3",
            "gxh3",
            "Ke7",
            "b6",
            "Kd6",
            "f8=Q+",
            "Kxd5",
            "b7",
            "Kc6",
            "b8=Q",
            "Kd5",
            "Qbd6+",
            "Kc4",
            "Qc8+",
            "Kb5",
            "Qdb8+",
            "Ka5",
            "Qc5+",
            "Ka6",
            "Qcb6#",
            "Qxb6",
            "Qxb6+",
            "Kxb6",
            "Kf4",
            "Kc6",
            "Kg5",
            "Kd6",
            "Kg6",
            "Ke7",
            "Kg7",
            "Ke6",
            "h4",
            "Kf5",
            "h5",
            "Kg5",
            "h6",
            "Kh5",
            "h7",
            "Kg5",
            "h8=Q",
            "Kf5",
            "Qh6",
            "Ke5",
            "Qf6+",
            "Kd5",
            "h4",
            "Ke4",
            "h5",
            "Kd5",
            "h6",
            "Ke4",
            "h7",
            "Kd5",
            "h8=Q",
            "Ke4",
            "Qe8+",
            "Kd5",
            "Qfd8+",
            "Kc5",
            "Qee7+",
            "Kc6",
            "Qec7+",
            "Kb5",
            "Qdb8+",
            "Ka6",
            "Qca7#",
            "Qxa7",
            "Qxa7+",
            "Kxa7",
            "Kf7",
            "Kb7",
            "h4",
            "Kc7",
            "h5",
            "Kd7",
            "h6",
            "Kd6",
            "h7",
            "Ke5",
            "h8=Q+",
            "Kf5",
            "Qh5+",
            "Ke4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bf4",
          "positional_uci": "c1f4",
          "positional_response": "10. Bf4 e5 11. Be3 Qc7 12. Nf5 d6 13. Nxe7+ Qxe7 14. Bg5 Be6 15. f4 exf4 16.\nRxf4 Ne5 17. Qd4 Ng6 18. Rf2 Ne5 19. Raf1 Ned7 20. Bb5 Qf8 21. Bxd7 Nxd7 22.\nNd5 Bxd5 23. Qxd5 Ne5 24. Bf4 Qe7 25. Bxe5 dxe5 26. Rxf7 Qg5 27. R7f5+ Kh7 28.\nRxg5 Kh6 29. Qxe5 g6 30. Rf6 Rhg8 31. Qf5 Raf8 32. Rgxg6+ Rxg6 33. Qxg6# g5 h4 g4 *",
          "positional_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 211,
            "total_tokens": 392,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe7",
            "Bxe5",
            "dxe5",
            "Rxf7",
            "Qg5",
            "R7f5+",
            "Kh7",
            "Rxg5",
            "Kh6",
            "Qxe5",
            "g6",
            "Rf6",
            "Rhg8",
            "Qf5",
            "Raf8",
            "Rgxg6+",
            "Rxg6",
            "Qxg6#",
            "g5",
            "h4",
            "g4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bf4",
          "neutral_uci": "c1f4",
          "neutral_response": "10. Bf4 e5 11. Be3 Qc7 12. Nf5 d6 13. Nxe7+ Qxe7 14. Bg5 Be6 15. f4 exf4 16. Rxf4\nNe5 17. Qd4 Ng6 18. Rf2 Ne5 19. Raf1 Ned7 20. Bb5 Qf8 21. Bxd7 Nxd7 22. Nd5 Bxd5\n23. Qxd5 Ne5 24. Bf4 Ng4 25. Bxd6 Qe8 26. Rxf7 Ne3 27. Rf8+ Kh7 28. Rxe8 Nxd5\n29. Rxh8+ Kxh8 30. exd5 Rd8 31. Rf8+ Rxf8 32. Bxf8 Kg8 33. Bc5 Kf7 34. Bxa7 Ke7\n35. Bc5+ Kd7 36. Kf2 g5 37. Ke3 b6 38. Bxb6 Kd6 39. Kd4 g4 40. c4 h4 41. c5+ Kd7\n42. c6+ Kd6 43. Bc5+ Kc7 44. Ke5 g3 45. hxg3 hxg3 46. Ke6 Kd8 47. d6 Kc8 48. d7+\nKc7 49. Bd6+ Kxc6 50. d8=Q Kb5 51. Qc7 Ka6 52. Qb8 Ka5 53. Bc5 Ka4 54. Qb4# Kc7\n55. Qb6+ Kc8 56. Qa7 Kd8 57. Qd7# Kc8 58. Qc7# Kxc7 59. Kd5 Kd7 60. Bf2 Kc7\n61. Bxg3+ Kd7 62. Bf4 Ke7 63. g4 Kf6 64. g5+ Kf5 65. a4 Kxf4 66. g6 Kf5 67.\ng7 Kf6 68. g8=Q Kf5 69. Qf7+ Kg4 70. Ke4 Kg5 71. Qg7+ Kh5 72. Kf4 Kh4 73. Qh6#\nh5 g4 g5",
          "neutral_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 557,
            "total_tokens": 737,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g4",
            "Kf6",
            "g5+",
            "Kf5",
            "a4",
            "Kxf4",
            "g6",
            "Kf5",
            "g7",
            "Kf6",
            "g8=Q",
            "Kf5",
            "Qf7+",
            "Kg4",
            "Ke4",
            "Kg5",
            "Qg7+",
            "Kh5",
            "Kf4",
            "Kh4",
            "Qh6#",
            "h5",
            "g4",
            "g5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f2f4",
          "positional_uci": "c1f4",
          "neutral_uci": "c1f4",
          "consensus_move": "c1f4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qb6+",
              "Kh1",
              "Nd4",
              "Nc4",
              "Qc5",
              "Be3",
              "d5",
              "Bxd4",
              "Qc7",
              "exd5",
              "exd5",
              "Ne5",
              "Be6",
              "f5",
              "Bd7",
              "Nxd7",
              "Qxd7",
              "Bxf6",
              "Bxf6",
              "Nxd5",
              "Bxb2",
              "Nf6+",
              "Bxf6",
              "Qxd7",
              "Bxa1",
              "Rxa1",
              "Kh7",
              "Qxf7",
              "Rhf8",
              "Qxh5+",
              "Kg8",
              "Bc4+",
              "Rf7",
              "Qxf7+",
              "Kh8",
              "Qh5#",
              "Qh6",
              "Qxh6+",
              "gxh6",
              "f6",
              "Rf8",
              "f7",
              "Kg7",
              "Re1",
              "a6",
              "Re8",
              "b5",
              "Rxf8",
              "Kxf8",
              "Bd5",
              "a5",
              "Kg1",
              "b4",
              "Kf2",
              "a4",
              "Ke3",
              "b3",
              "cxb3",
              "axb3",
              "axb3",
              "h5",
              "b4",
              "h4",
              "b5",
              "h3",
              "gxh3",
              "Ke7",
              "b6",
              "Kd6",
              "f8=Q+",
              "Kxd5",
              "b7",
              "Kc6",
              "b8=Q",
              "Kd5",
              "Qbd6+",
              "Kc4",
              "Qc8+",
              "Kb5",
              "Qdb8+",
              "Ka5",
              "Qc5+",
              "Ka6",
              "Qcb6#",
              "Qxb6",
              "Qxb6+",
              "Kxb6",
              "Kf4",
              "Kc6",
              "Kg5",
              "Kd6",
              "Kg6",
              "Ke7",
              "Kg7",
              "Ke6",
              "h4",
              "Kf5",
              "h5",
              "Kg5",
              "h6",
              "Kh5",
              "h7",
              "Kg5",
              "h8=Q",
              "Kf5",
              "Qh6",
              "Ke5",
              "Qf6+",
              "Kd5",
              "h4",
              "Ke4",
              "h5",
              "Kd5",
              "h6",
              "Ke4",
              "h7",
              "Kd5",
              "h8=Q",
              "Ke4",
              "Qe8+",
              "Kd5",
              "Qfd8+",
              "Kc5",
              "Qee7+",
              "Kc6",
              "Qec7+",
              "Kb5",
              "Qdb8+",
              "Ka6",
              "Qca7#",
              "Qxa7",
              "Qxa7+",
              "Kxa7",
              "Kf7",
              "Kb7",
              "h4",
              "Kc7",
              "h5",
              "Kd7",
              "h6",
              "Kd6",
              "h7",
              "Ke5",
              "h8=Q+",
              "Kf5",
              "Qh5+",
              "Ke4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe7",
              "Bxe5",
              "dxe5",
              "Rxf7",
              "Qg5",
              "R7f5+",
              "Kh7",
              "Rxg5",
              "Kh6",
              "Qxe5",
              "g6",
              "Rf6",
              "Rhg8",
              "Qf5",
              "Raf8",
              "Rgxg6+",
              "Rxg6",
              "Qxg6#",
              "g5",
              "h4",
              "g4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke7",
              "g4",
              "Kf6",
              "g5+",
              "Kf5",
              "a4",
              "Kxf4",
              "g6",
              "Kf5",
              "g7",
              "Kf6",
              "g8=Q",
              "Kf5",
              "Qf7+",
              "Kg4",
              "Ke4",
              "Kg5",
              "Qg7+",
              "Kh5",
              "Kf4",
              "Kh4",
              "Qh6#",
              "h5",
              "g4",
              "g5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 181,
            "completion_tokens": 640,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 181,
            "completion_tokens": 211,
            "total_tokens": 392,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 180,
            "completion_tokens": 557,
            "total_tokens": 737,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 542,
          "total_completion_tokens": 1408,
          "total_tokens": 1950
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 181,
            "completion_tokens": 640,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 181,
            "completion_tokens": 211,
            "total_tokens": 392,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 180,
            "completion_tokens": 557,
            "total_tokens": 737,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq2kr/pp1pbpp1/2nNpn2/7p/4P3/2N5/PPP1BPPP/R1BQ1RK1 w - - 0 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e4e5",
          "aggressive_response": "11. e5 Ne8 12. Nce4 Nxd6 13. Nxd6 Bxd6 14. Qxd6 Qe7 15. Qd2 f6 16. exf6 gxf6 17.\nBd6 Qg7 18. f4 b6 19. f5 Bb7 20. Bc4 Ne5 21. Bxe5 fxe5 22. fxe6 d5 23. Bxd5 Rd8\n24. e7+ Rxd5 25. e8=Q+ Kh7 26. Qh5+ Kg8 27. Qe8+ Kh7 28. Qh5+ Kg8 29. Qdf2 Rd8\n30. Qf7+ Qxf7 31. Qxf7# e4 32. Qg6# e3 33. Qf7# e2",
          "aggressive_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 199,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ne8",
            "Nce4",
            "Nxd6",
            "Nxd6",
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qd2",
            "f6",
            "exf6",
            "gxf6",
            "Bd6",
            "Qg7",
            "f4",
            "b6",
            "f5",
            "Bb7",
            "Bc4",
            "Ne5",
            "Bxe5",
            "fxe5",
            "fxe6",
            "d5",
            "Bxd5",
            "Rd8",
            "e7+",
            "Rxd5",
            "e8=Q+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qe8+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qdf2",
            "Rd8",
            "Qf7+",
            "Qxf7",
            "Qxf7#",
            "e4",
            "Qg6#",
            "e3",
            "Qf7#",
            "e2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h3",
          "positional_uci": "h2h3",
          "positional_response": "11. h3 Qa5 12. Qd2 Nh5 13. Bh2 Ng3 14. fxg3 Qc5+ 15. Kh1 Qxd6 16. Qxd6 Bxd6 17.\ngxh4 Bxh2 18. Kxh2 Rxh4 19. Rad1 Ne5 20. Kg3 Rh6 21. Nb5 b6 22. Nd6 Rg6+ 23. Kh2\nRb8 24. Bh5 Rf6 25. Rxf6 gxf6 26. Rf1 Kg7 27. Ne8+ Kh6 28. Nxf6 Ba6 29. Rf2 Kg7\n30. Ng4 Nxg4+ 31. Bxg4 Rc8 32. c3 Rc4 33. Be2 Ra4 34. Bxa6 Rxa6 35. a3 Ra4 36.\nRe2 Kf6 37. Kg3 Ke5 38. Kf3 Rc4 39. g4 Rc8 40. h4 Rh8 41. h5 f6 42. Rd2 d6 43.\nRd4 b5 44. a4 a6 45. axb5 axb5 46. Rb4 Rb8 47. c4 Kd4 48. cxb5+ Kc5 49. Rb3\nKc4 50. Rc3+ Kxb5 51. Rb3+ Kc4 52. Rxb8 Kd4 53. h6 Ke5 54. h7 d5 55. exd5\nexd5 56. h8=Q d4 57. Rb5+ Ke6 58. Qe8+ Kd6 59. Qd8+ Ke6 60. Qxd4 Kf7 61. Rb7+\nKg6 62. Qe4+ Kg5 63. Qf5+ Kh4 64. Rh7# e5 dxe5 Qxe5+ Kg6 Qg8#",
          "positional_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 465,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qa5",
            "Qd2",
            "Nh5",
            "Bh2",
            "Ng3",
            "fxg3",
            "Qc5+",
            "Kh1",
            "Qxd6",
            "Qxd6",
            "Bxd6",
            "gxh4",
            "Bxh2",
            "Kxh2",
            "Rxh4",
            "Rad1",
            "Ne5",
            "Kg3",
            "Rh6",
            "Nb5",
            "b6",
            "Nd6",
            "Rg6+",
            "Kh2",
            "Rb8",
            "Bh5",
            "Rf6",
            "Rxf6",
            "gxf6",
            "Rf1",
            "Kg7",
            "Ne8+",
            "Kh6",
            "Nxf6",
            "Ba6",
            "Rf2",
            "Kg7",
            "Ng4",
            "Nxg4+",
            "Bxg4",
            "Rc8",
            "c3",
            "Rc4",
            "Be2",
            "Ra4",
            "Bxa6",
            "Rxa6",
            "a3",
            "Ra4",
            "Re2",
            "Kf6",
            "Kg3",
            "Ke5",
            "Kf3",
            "Rc4",
            "g4",
            "Rc8",
            "h4",
            "Rh8",
            "h5",
            "f6",
            "Rd2",
            "d6",
            "Rd4",
            "b5",
            "a4",
            "a6",
            "axb5",
            "axb5",
            "Rb4",
            "Rb8",
            "c4",
            "Kd4",
            "cxb5+",
            "Kc5",
            "Rb3",
            "Kc4",
            "Rc3+",
            "Kxb5",
            "Rb3+",
            "Kc4",
            "Rxb8",
            "Kd4",
            "h6",
            "Ke5",
            "h7",
            "d5",
            "exd5",
            "exd5",
            "h8=Q",
            "d4",
            "Rb5+",
            "Ke6",
            "Qe8+",
            "Kd6",
            "Qd8+",
            "Ke6",
            "Qxd4",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Qe4+",
            "Kg5",
            "Qf5+",
            "Kh4",
            "Rh7#",
            "e5",
            "dxe5",
            "Qxe5+",
            "Kg6",
            "Qg8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e4e5",
          "neutral_response": "11. e5 Ne8 12. Nce4 Nxd6 13. Nxd6 Bxd6 14. Qxd6 Qe7 15. Qd2 b6 16. Rad1 Bb7 17.\nQxd7 Qxd7 18. Rxd7 Rb8 19. Rfd1 Kh7 20. Rxf7 Kg6 21. Rdd7 Rhg8 22. Bd3+ Kh5 23.\nRxb7 Rxb7 24. Rxb7 Nd4 25. Be3 Nf5 26. Bxf5 exf5 27. Rxa7 g5 28. Bxb6 Rb8 29.\nRa6 g4 30. c4 f4 31. c5 g3 32. hxg3 hxg3 33. fxg3 fxg3 34. Ra3 Kg4 35. Rf3 Ra8\n36. a3 Ra4 37. b4 Ra8 38. c6 Re8 39. c7 Rxe5 40. c8=Q+ Kh4 41. Bd8+ Kh5 42.\nQh3+ Kg6 43. Qxg3+ Kh7 44. Rf7+ Kh6 45. Qg7+ Kh5 46. Qxe5+ Kg4 47. Qg5# g3\n48. Rf4# g2 49. Qg4# g1=Q+ 50. Kxg1# g5 51. Qxg5# g4 52. Qxg4# g3 53. Qxg3# g2\n54. Qxg2# g3 55. Qxg3# g2 56. Qxg2# g3 57. Qxg3# g2 58. Qxg2# g3 59. Qxg3# g2\n60. Qxg2# g3 61. Qxg3# g2 62. Qxg2# g3 63. Qxg3# g2 64. Qxg2# g3 65. Qxg3# g2\n66. Qxg2# g3 67. Qxg3# g2 68. Qxg2# g3 69. Qxg3# g2 70. Qxg2# g3 71. Qxg3# g2\n72. Qxg2# g3 73. Qxg3# g2 74. Qxg2# g3 75. Qxg3# g2 76. Qxg2# g3 77. Qxg3# g2\n78. Qxg2# g3 79. Qxg3# g2 80. Qxg2# g3",
          "neutral_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ne8",
            "Nce4",
            "Nxd6",
            "Nxd6",
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qd2",
            "b6",
            "Rad1",
            "Bb7",
            "Qxd7",
            "Qxd7",
            "Rxd7",
            "Rb8",
            "Rfd1",
            "Kh7",
            "Rxf7",
            "Kg6",
            "Rdd7",
            "Rhg8",
            "Bd3+",
            "Kh5",
            "Rxb7",
            "Rxb7",
            "Rxb7",
            "Nd4",
            "Be3",
            "Nf5",
            "Bxf5",
            "exf5",
            "Rxa7",
            "g5",
            "Bxb6",
            "Rb8",
            "Ra6",
            "g4",
            "c4",
            "f4",
            "c5",
            "g3",
            "hxg3",
            "hxg3",
            "fxg3",
            "fxg3",
            "Ra3",
            "Kg4",
            "Rf3",
            "Ra8",
            "a3",
            "Ra4",
            "b4",
            "Ra8",
            "c6",
            "Re8",
            "c7",
            "Rxe5",
            "c8=Q+",
            "Kh4",
            "Bd8+",
            "Kh5",
            "Qh3+",
            "Kg6",
            "Qxg3+",
            "Kh7",
            "Rf7+",
            "Kh6",
            "Qg7+",
            "Kh5",
            "Qxe5+",
            "Kg4",
            "Qg5#",
            "g3",
            "Rf4#",
            "g2",
            "Qg4#",
            "g1=Q+",
            "Kxg1#",
            "g5",
            "Qxg5#",
            "g4",
            "Qxg4#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3",
            "Qxg3#",
            "g2",
            "Qxg2#",
            "g3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4e5",
          "positional_uci": "h2h3",
          "neutral_uci": "e4e5",
          "consensus_move": "e4e5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ne8",
              "Nce4",
              "Nxd6",
              "Nxd6",
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qd2",
              "f6",
              "exf6",
              "gxf6",
              "Bd6",
              "Qg7",
              "f4",
              "b6",
              "f5",
              "Bb7",
              "Bc4",
              "Ne5",
              "Bxe5",
              "fxe5",
              "fxe6",
              "d5",
              "Bxd5",
              "Rd8",
              "e7+",
              "Rxd5",
              "e8=Q+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qe8+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qdf2",
              "Rd8",
              "Qf7+",
              "Qxf7",
              "Qxf7#",
              "e4",
              "Qg6#",
              "e3",
              "Qf7#",
              "e2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qa5",
              "Qd2",
              "Nh5",
              "Bh2",
              "Ng3",
              "fxg3",
              "Qc5+",
              "Kh1",
              "Qxd6",
              "Qxd6",
              "Bxd6",
              "gxh4",
              "Bxh2",
              "Kxh2",
              "Rxh4",
              "Rad1",
              "Ne5",
              "Kg3",
              "Rh6",
              "Nb5",
              "b6",
              "Nd6",
              "Rg6+",
              "Kh2",
              "Rb8",
              "Bh5",
              "Rf6",
              "Rxf6",
              "gxf6",
              "Rf1",
              "Kg7",
              "Ne8+",
              "Kh6",
              "Nxf6",
              "Ba6",
              "Rf2",
              "Kg7",
              "Ng4",
              "Nxg4+",
              "Bxg4",
              "Rc8",
              "c3",
              "Rc4",
              "Be2",
              "Ra4",
              "Bxa6",
              "Rxa6",
              "a3",
              "Ra4",
              "Re2",
              "Kf6",
              "Kg3",
              "Ke5",
              "Kf3",
              "Rc4",
              "g4",
              "Rc8",
              "h4",
              "Rh8",
              "h5",
              "f6",
              "Rd2",
              "d6",
              "Rd4",
              "b5",
              "a4",
              "a6",
              "axb5",
              "axb5",
              "Rb4",
              "Rb8",
              "c4",
              "Kd4",
              "cxb5+",
              "Kc5",
              "Rb3",
              "Kc4",
              "Rc3+",
              "Kxb5",
              "Rb3+",
              "Kc4",
              "Rxb8",
              "Kd4",
              "h6",
              "Ke5",
              "h7",
              "d5",
              "exd5",
              "exd5",
              "h8=Q",
              "d4",
              "Rb5+",
              "Ke6",
              "Qe8+",
              "Kd6",
              "Qd8+",
              "Ke6",
              "Qxd4",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Qe4+",
              "Kg5",
              "Qf5+",
              "Kh4",
              "Rh7#",
              "e5",
              "dxe5",
              "Qxe5+",
              "Kg6",
              "Qg8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ne8",
              "Nce4",
              "Nxd6",
              "Nxd6",
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qd2",
              "b6",
              "Rad1",
              "Bb7",
              "Qxd7",
              "Qxd7",
              "Rxd7",
              "Rb8",
              "Rfd1",
              "Kh7",
              "Rxf7",
              "Kg6",
              "Rdd7",
              "Rhg8",
              "Bd3+",
              "Kh5",
              "Rxb7",
              "Rxb7",
              "Rxb7",
              "Nd4",
              "Be3",
              "Nf5",
              "Bxf5",
              "exf5",
              "Rxa7",
              "g5",
              "Bxb6",
              "Rb8",
              "Ra6",
              "g4",
              "c4",
              "f4",
              "c5",
              "g3",
              "hxg3",
              "hxg3",
              "fxg3",
              "fxg3",
              "Ra3",
              "Kg4",
              "Rf3",
              "Ra8",
              "a3",
              "Ra4",
              "b4",
              "Ra8",
              "c6",
              "Re8",
              "c7",
              "Rxe5",
              "c8=Q+",
              "Kh4",
              "Bd8+",
              "Kh5",
              "Qh3+",
              "Kg6",
              "Qxg3+",
              "Kh7",
              "Rf7+",
              "Kh6",
              "Qg7+",
              "Kh5",
              "Qxe5+",
              "Kg4",
              "Qg5#",
              "g3",
              "Rf4#",
              "g2",
              "Qg4#",
              "g1=Q+",
              "Kxg1#",
              "g5",
              "Qxg5#",
              "g4",
              "Qxg4#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3",
              "Qxg3#",
              "g2",
              "Qxg2#",
              "g3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 189,
            "completion_tokens": 199,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 189,
            "completion_tokens": 465,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 566,
          "total_completion_tokens": 1304,
          "total_tokens": 1870
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 189,
            "completion_tokens": 199,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 189,
            "completion_tokens": 465,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bq2kr/pp1pbpp1/2nNpn2/8/4PB1p/2N5/PPP1BPPP/R2Q1RK1 w - - 0 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nce4",
          "aggressive_uci": "c3e4",
          "aggressive_response": "12. Nce4 Nxd6 13. Nxd6 Bxd6 14. Qxd6 Qe7 15. Qd2 f6 16. exf6 gxf6 17. Bd6 Qg7 18. f4 f5 19. c3 b6 20. Bf3 Bb7 21. Rae1 Re8 22. b4 a6 23. a4 Nd8 24. Be5 Qg6 25. Bxh8 Bxf3 26. Rxf3 Kxh8 27. Qxd7 Rg8 28. Qd4+ Kh7 29. Qf2 Qg4 30. Rd3 Nf7 31. Rxe6 Nh6 32. Rd7+ Rg7 33. Rxg7+ Kxg7 34. Qd4+ Kh7 35. Re7+ Kg6 36. Qg7+ Kh5 37. Qxg4+ Kxg4 38. g3 hxg3 39. hxg3 Kxg3 40. Re6 Ng4 41. Rxb6 Kxf4 42. Rxa6 Ke3 43. Re6+ Kd3 44. a5 Kxc3 45. a6 Kxb4 46. a7 f4 47. a8=Q f3 48. Qxf3 1-0\n\n1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Nxd6 13. Nxd6 Bxd6 14. Qxd6 Qe7 15. Qd2 f6 16. exf6 gxf6 17. Bd6 Qg7 18. f4 f5 19. c3 b6 20. Bf3 Bb7 21. Rae1 Re8 22. b4 a6 23. a4 Nd8 24. Be5 Qg6 25. Bxh8 Bxf3 26. Rxf3 Kxh8 27. Qxd7 Rg8 28. Qd2 Kh7 29. Qf2 Qg4 30. Rd3 Nf7 31. Rxe6 Nh6 32. Rd7+ Rg7 33. Rxg7+ Kxg7 34. Qd4+ Kh7 35. Re7+ Kg6 36. Qg7+ Kh5 37. Qxg4+ Kxg4 38. g3 hxg3 39.",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd6",
            "Nxd6",
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qd2",
            "f6",
            "exf6",
            "gxf6",
            "Bd6",
            "Qg7",
            "f4",
            "f5",
            "c3",
            "b6",
            "Bf3",
            "Bb7",
            "Rae1",
            "Re8",
            "b4",
            "a6",
            "a4",
            "Nd8",
            "Be5",
            "Qg6",
            "Bxh8",
            "Bxf3",
            "Rxf3",
            "Kxh8",
            "Qxd7",
            "Rg8",
            "Qd2",
            "Kh7",
            "Qf2",
            "Qg4",
            "Rd3",
            "Nf7",
            "Rxe6",
            "Nh6",
            "Rd7+",
            "Rg7",
            "Rxg7+",
            "Kxg7",
            "Qd4+",
            "Kh7",
            "Re7+",
            "Kg6",
            "Qg7+",
            "Kh5",
            "Qxg4+",
            "Kxg4",
            "g3",
            "hxg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nce4",
          "positional_uci": "c3e4",
          "positional_response": "12. Nce4 Nxd6 13. Nxd6 Bxd6 14. Qxd6 Qe7 15. Qd2 f6 16. exf6 gxf6 17. Bd6 Qg7 18. f4 f5 19. c3 b6 20. Bf3 Bb7 21. Rae1 Rh6 22. b4 Rg6 23. b5 Na5 24. Bxb7 Nxb7 25. Be5 Qe7 26. Rd1 d6 27. Bd4 Kh7 28. Rf3 Rag8 29. Rf2 Nc5 30. Bxc5 dxc5 31. Qd7 R8g7 32. Qxe7 Rxe7 33. Rd6 Kg7 34. Rfd2 Kf7 35. Kf2 Rg8 36. Rd7 Re8 37. Rxe7+ Rxe7 38. Rd8 e5 39. fxe5 Rxe5 40. Rd7+ Re7 41. Rxe7+ Kxe7 42. Kf3 Ke6 43. Kf4 Kf6 44. c4 Ke6 45. Kg5 Ke5 46. Kxh4 Kd4 47. Kg5 Kxc4 48. h4 Kxb5 49. h5 c4 50. h6 c3 51. h7 c2 52. h8=Q c1=Q+ 53. Kxf5 Qc2+ 54. Ke6 Qxa2+ 55. Kd7 Qd5+ 56. Kc7 Qc6+ 57. Kb8 Qd6+ 58. Kxa7 Qc7+ 59. Ka8 Ka6 60. Qa1+ Kb5 61. Qb2+ Kc6 62. Qc3+ Kd7 63. Qxc7+ Kxc7 64. g4 b5 65. g5 b4 66. g6 b3 67. g7 b2 68. g8=Q b1=Q 69. Qf7+ Kc6 70. Qe6+ Kc5 71. Qc8+ Kd4 72. Qd7+ Ke3 73. Qe6+ Kd2 74. Qd5+ Ke3 75. Qe5+ Kd2 76. Qd4+ Ke2 77. Qe5+ Kd2 78. Qd4+ Ke2 79. Qe5+ Kd2 80. Qd4+ Ke2 81. Qe5+ Kd2 82. Qd4+ Ke2 83. Qe5+ Kd2 84. Qd4+ Ke2 85. Qe",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd6",
            "Nxd6",
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qd2",
            "f6",
            "exf6",
            "gxf6",
            "Bd6",
            "Qg7",
            "f4",
            "f5",
            "c3",
            "b6",
            "Bf3",
            "Bb7",
            "Rae1",
            "Rh6",
            "b4",
            "Rg6",
            "b5",
            "Na5",
            "Bxb7",
            "Nxb7",
            "Be5",
            "Qe7",
            "Rd1",
            "d6",
            "Bd4",
            "Kh7",
            "Rf3",
            "Rag8",
            "Rf2",
            "Nc5",
            "Bxc5",
            "dxc5",
            "Qd7",
            "R8g7",
            "Qxe7",
            "Rxe7",
            "Rd6",
            "Kg7",
            "Rfd2",
            "Kf7",
            "Kf2",
            "Rg8",
            "Rd7",
            "Re8",
            "Rxe7+",
            "Rxe7",
            "Rd8",
            "e5",
            "fxe5",
            "Rxe5",
            "Rd7+",
            "Re7",
            "Rxe7+",
            "Kxe7",
            "Kf3",
            "Ke6",
            "Kf4",
            "Kf6",
            "c4",
            "Ke6",
            "Kg5",
            "Ke5",
            "Kxh4",
            "Kd4",
            "Kg5",
            "Kxc4",
            "h4",
            "Kxb5",
            "h5",
            "c4",
            "h6",
            "c3",
            "h7",
            "c2",
            "h8=Q",
            "c1=Q+",
            "Kxf5",
            "Qc2+",
            "Ke6",
            "Qxa2+",
            "Kd7",
            "Qd5+",
            "Kc7",
            "Qc6+",
            "Kb8",
            "Qd6+",
            "Kxa7",
            "Qc7+",
            "Ka8",
            "Ka6",
            "Qa1+",
            "Kb5",
            "Qb2+",
            "Kc6",
            "Qc3+",
            "Kd7",
            "Qxc7+",
            "Kxc7",
            "g4",
            "b5",
            "g5",
            "b4",
            "g6",
            "b3",
            "g7",
            "b2",
            "g8=Q",
            "b1=Q",
            "Qf7+",
            "Kc6",
            "Qe6+",
            "Kc5",
            "Qc8+",
            "Kd4",
            "Qd7+",
            "Ke3",
            "Qe6+",
            "Kd2",
            "Qd5+",
            "Ke3",
            "Qe5+",
            "Kd2",
            "Qd4+",
            "Ke2",
            "Qe5+",
            "Kd2",
            "Qd4+",
            "Ke2",
            "Qe5+",
            "Kd2",
            "Qd4+",
            "Ke2",
            "Qe5+",
            "Kd2",
            "Qd4+",
            "Ke2",
            "Qe5+",
            "Kd2",
            "Qd4+",
            "Ke2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nce4",
          "neutral_uci": "c3e4",
          "neutral_response": "12. Nce4 Nxd6 13. Nxd6 Bxd6 14. Qxd6 Qe7 15. Qd2 b6 16. Rad1 Bb7 17. Qxd7 Qxd7 18. Rxd7 Rb8 19. Rfd1 Kh7 20. Rxf7 Kg6 21. Rdd7 Rhg8 22. Bd3+ Kh5 23. Rxg7 Rxg7 24. Rxg7 Nd4 25. h3 Nf5 26. Bxf5 exf5 27. e6 Re8 28. Rxb7 Rxe6 29. Rxa7 Re1+ 30. Kh2 Re2 31. Rc7 Rxf2 32. Be3 Re2 33. Bxb6 f4 34. Rc5+ Kg6 35. Rc3 Kf5 36. a4 Ke4 37. a5 Kd5 38. a6 Re6 39. a7 Rxb6 40. a8=Q+ Kd4 41. Qd8+ Ke4 42. Qxb6 Kf5 43. Rc5+ Ke4 44. Qb4+ Ke3 45. Rc3+ Kd2 46. Qd4+ Kc1 47. b4 Kb2 48. b5 Kc1 49. b6 Kb2 50. b7 Kc1 51. b8=Q f3 52. Qbf4+ Kb2 53. Rb3+ Ka2 54. Qa4# e6 e5 e4 e3 e2 e1=Q e8=Q Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8 Qxe8#",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 452,
            "total_tokens": 647,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd6",
            "Nxd6",
            "Bxd6",
            "Qxd6",
            "Qe7",
            "Qd2",
            "b6",
            "Rad1",
            "Bb7",
            "Qxd7",
            "Qxd7",
            "Rxd7",
            "Rb8",
            "Rfd1",
            "Kh7",
            "Rxf7",
            "Kg6",
            "Rdd7",
            "Rhg8",
            "Bd3+",
            "Kh5",
            "Rxg7",
            "Rxg7",
            "Rxg7",
            "Nd4",
            "h3",
            "Nf5",
            "Bxf5",
            "exf5",
            "e6",
            "Re8",
            "Rxb7",
            "Rxe6",
            "Rxa7",
            "Re1+",
            "Kh2",
            "Re2",
            "Rc7",
            "Rxf2",
            "Be3",
            "Re2",
            "Bxb6",
            "f4",
            "Rc5+",
            "Kg6",
            "Rc3",
            "Kf5",
            "a4",
            "Ke4",
            "a5",
            "Kd5",
            "a6",
            "Re6",
            "a7",
            "Rxb6",
            "a8=Q+",
            "Kd4",
            "Qd8+",
            "Ke4",
            "Qxb6",
            "Kf5",
            "Rc5+",
            "Ke4",
            "Qb4+",
            "Ke3",
            "Rc3+",
            "Kd2",
            "Qd4+",
            "Kc1",
            "b4",
            "Kb2",
            "b5",
            "Kc1",
            "b6",
            "Kb2",
            "b7",
            "Kc1",
            "b8=Q",
            "f3",
            "Qbf4+",
            "Kb2",
            "Rb3+",
            "Ka2",
            "Qa4#",
            "e6",
            "e5",
            "e4",
            "e3",
            "e2",
            "e1=Q",
            "e8=Q",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8",
            "Qxe8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c3e4",
          "positional_uci": "c3e4",
          "neutral_uci": "c3e4",
          "consensus_move": "c3e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd6",
              "Nxd6",
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qd2",
              "f6",
              "exf6",
              "gxf6",
              "Bd6",
              "Qg7",
              "f4",
              "f5",
              "c3",
              "b6",
              "Bf3",
              "Bb7",
              "Rae1",
              "Re8",
              "b4",
              "a6",
              "a4",
              "Nd8",
              "Be5",
              "Qg6",
              "Bxh8",
              "Bxf3",
              "Rxf3",
              "Kxh8",
              "Qxd7",
              "Rg8",
              "Qd2",
              "Kh7",
              "Qf2",
              "Qg4",
              "Rd3",
              "Nf7",
              "Rxe6",
              "Nh6",
              "Rd7+",
              "Rg7",
              "Rxg7+",
              "Kxg7",
              "Qd4+",
              "Kh7",
              "Re7+",
              "Kg6",
              "Qg7+",
              "Kh5",
              "Qxg4+",
              "Kxg4",
              "g3",
              "hxg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxd6",
              "Nxd6",
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qd2",
              "f6",
              "exf6",
              "gxf6",
              "Bd6",
              "Qg7",
              "f4",
              "f5",
              "c3",
              "b6",
              "Bf3",
              "Bb7",
              "Rae1",
              "Rh6",
              "b4",
              "Rg6",
              "b5",
              "Na5",
              "Bxb7",
              "Nxb7",
              "Be5",
              "Qe7",
              "Rd1",
              "d6",
              "Bd4",
              "Kh7",
              "Rf3",
              "Rag8",
              "Rf2",
              "Nc5",
              "Bxc5",
              "dxc5",
              "Qd7",
              "R8g7",
              "Qxe7",
              "Rxe7",
              "Rd6",
              "Kg7",
              "Rfd2",
              "Kf7",
              "Kf2",
              "Rg8",
              "Rd7",
              "Re8",
              "Rxe7+",
              "Rxe7",
              "Rd8",
              "e5",
              "fxe5",
              "Rxe5",
              "Rd7+",
              "Re7",
              "Rxe7+",
              "Kxe7",
              "Kf3",
              "Ke6",
              "Kf4",
              "Kf6",
              "c4",
              "Ke6",
              "Kg5",
              "Ke5",
              "Kxh4",
              "Kd4",
              "Kg5",
              "Kxc4",
              "h4",
              "Kxb5",
              "h5",
              "c4",
              "h6",
              "c3",
              "h7",
              "c2",
              "h8=Q",
              "c1=Q+",
              "Kxf5",
              "Qc2+",
              "Ke6",
              "Qxa2+",
              "Kd7",
              "Qd5+",
              "Kc7",
              "Qc6+",
              "Kb8",
              "Qd6+",
              "Kxa7",
              "Qc7+",
              "Ka8",
              "Ka6",
              "Qa1+",
              "Kb5",
              "Qb2+",
              "Kc6",
              "Qc3+",
              "Kd7",
              "Qxc7+",
              "Kxc7",
              "g4",
              "b5",
              "g5",
              "b4",
              "g6",
              "b3",
              "g7",
              "b2",
              "g8=Q",
              "b1=Q",
              "Qf7+",
              "Kc6",
              "Qe6+",
              "Kc5",
              "Qc8+",
              "Kd4",
              "Qd7+",
              "Ke3",
              "Qe6+",
              "Kd2",
              "Qd5+",
              "Ke3",
              "Qe5+",
              "Kd2",
              "Qd4+",
              "Ke2",
              "Qe5+",
              "Kd2",
              "Qd4+",
              "Ke2",
              "Qe5+",
              "Kd2",
              "Qd4+",
              "Ke2",
              "Qe5+",
              "Kd2",
              "Qd4+",
              "Ke2",
              "Qe5+",
              "Kd2",
              "Qd4+",
              "Ke2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxd6",
              "Nxd6",
              "Bxd6",
              "Qxd6",
              "Qe7",
              "Qd2",
              "b6",
              "Rad1",
              "Bb7",
              "Qxd7",
              "Qxd7",
              "Rxd7",
              "Rb8",
              "Rfd1",
              "Kh7",
              "Rxf7",
              "Kg6",
              "Rdd7",
              "Rhg8",
              "Bd3+",
              "Kh5",
              "Rxg7",
              "Rxg7",
              "Rxg7",
              "Nd4",
              "h3",
              "Nf5",
              "Bxf5",
              "exf5",
              "e6",
              "Re8",
              "Rxb7",
              "Rxe6",
              "Rxa7",
              "Re1+",
              "Kh2",
              "Re2",
              "Rc7",
              "Rxf2",
              "Be3",
              "Re2",
              "Bxb6",
              "f4",
              "Rc5+",
              "Kg6",
              "Rc3",
              "Kf5",
              "a4",
              "Ke4",
              "a5",
              "Kd5",
              "a6",
              "Re6",
              "a7",
              "Rxb6",
              "a8=Q+",
              "Kd4",
              "Qd8+",
              "Ke4",
              "Qxb6",
              "Kf5",
              "Rc5+",
              "Ke4",
              "Qb4+",
              "Ke3",
              "Rc3+",
              "Kd2",
              "Qd4+",
              "Kc1",
              "b4",
              "Kb2",
              "b5",
              "Kc1",
              "b6",
              "Kb2",
              "b7",
              "Kc1",
              "b8=Q",
              "f3",
              "Qbf4+",
              "Kb2",
              "Rb3+",
              "Ka2",
              "Qa4#",
              "e6",
              "e5",
              "e4",
              "e3",
              "e2",
              "e1=Q",
              "e8=Q",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8",
              "Qxe8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 452,
            "total_tokens": 647,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 1732,
          "total_tokens": 2319
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 452,
            "total_tokens": 647,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqn1kr/pp1pbpp1/2nNp3/4P3/5B1p/2N5/PPP1BPPP/R2Q1RK1 w - - 1 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxd6",
          "aggressive_uci": "e4d6",
          "aggressive_response": "13. Nxd6 Nxd6 14. Qxd6 Qe7 15. Qd2 f6 16. exf6 gxf6 17. Bd6 Qg7 18. f4 f5 19. c3\nb6 20. Bf3 Bb7 21. Rae1 Rh6 22. b4 Rg6 23. b5 Na5 24. Bxb7 Nxb7 25. Be5 Qf7 26.\nRf3 d6 27. Bd4 Nc5 28. Rh3 Ne4 29. Qe2 Rg4 30. Qf3 Rc8 31. Rxe4 fxe4 32. Qxg4+\nKf8 33. Rxh4 Ke7 34. Qg5+ Kd7 35. Qg7 Qxg7 36. Bxg7 Rg8 37. Rh7 Ke8 38. Bd4 Rf8\n39. g3 Rf7 40. Rxf7 Kxf7 41. Kf2 Kg6 42. Ke3 Kf5 43. h3 e5 44. g4+ Ke6 45. f5+\nKd5 46. Bxe5 Kxe5 47. h4 d5 48. h5 Kf6 49. h6 Kf7 50. g5 Kg8 51. g6 Kh8 52. f6\nKg8 53. h7+ Kh8 54. f7 Kg7 55. h8=Q+ Kxh8 56. f8=Q# e4 dxe4 Qd4#",
          "aggressive_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 375,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd6",
            "Qe7",
            "Qd2",
            "f6",
            "exf6",
            "gxf6",
            "Bd6",
            "Qg7",
            "f4",
            "f5",
            "c3",
            "b6",
            "Bf3",
            "Bb7",
            "Rae1",
            "Rh6",
            "b4",
            "Rg6",
            "b5",
            "Na5",
            "Bxb7",
            "Nxb7",
            "Be5",
            "Qf7",
            "Rf3",
            "d6",
            "Bd4",
            "Nc5",
            "Rh3",
            "Ne4",
            "Qe2",
            "Rg4",
            "Qf3",
            "Rc8",
            "Rxe4",
            "fxe4",
            "Qxg4+",
            "Kf8",
            "Rxh4",
            "Ke7",
            "Qg5+",
            "Kd7",
            "Qg7",
            "Qxg7",
            "Bxg7",
            "Rg8",
            "Rh7",
            "Ke8",
            "Bd4",
            "Rf8",
            "g3",
            "Rf7",
            "Rxf7",
            "Kxf7",
            "Kf2",
            "Kg6",
            "Ke3",
            "Kf5",
            "h3",
            "e5",
            "g4+",
            "Ke6",
            "f5+",
            "Kd5",
            "Bxe5",
            "Kxe5",
            "h4",
            "d5",
            "h5",
            "Kf6",
            "h6",
            "Kf7",
            "g5",
            "Kg8",
            "g6",
            "Kh8",
            "f6",
            "Kg8",
            "h7+",
            "Kh8",
            "f7",
            "Kg7",
            "h8=Q+",
            "Kxh8",
            "f8=Q#",
            "e4",
            "dxe4",
            "Qd4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxd6",
          "positional_uci": "e4d6",
          "positional_response": "13. Nxd6 Nxd6 14. Qxd6 Qe7 15. Qd2 f6 16. exf6 gxf6 17. Bd6 Qg7 18. f4 f5 19. c3\nb6 20. Bf3 Bb7 21. Rae1 Rh6 22. b4 Rg6 23. b5 Na5 24. Bxb7 Nxb7 25. Be5 Qf7 26.\nRf3 d6 27. Bd4 Nc5 28. Rh3 Qh7 29. Bxc5 dxc5 30. Qf2 Rh6 31. Rhe3 Re8 32. Qf3 Qd7\n33. Qc6 Qxc6 34. bxc6 Kf7 35. Rd1 Re7 36. Rd7 Rxd7 37. cxd7 Ke7 38. Rd3 Kd8 39.\nKf2 Rh7 40. Rd6 Re7 41. g3 hxg3+ 42. hxg3 Rxd7 43. Rxe6 Rd2+ 44. Re2 Rxe2+ 45.\nKxe2 Ke7 46. Kf3 Kf6 47. g4 fxg4+ 48. Kxg4 b5 49. Kf3 Kf5 50. Ke3 a5 51. Kd3 Kxf4\n52. c4 b4 53. Kc2 Ke4 54. Kb3 Kd4 55. Ka4 Kxc4 56. Kxa5 Kd3 57. Kb5 c4 58. Kxb4\nc3 59. Kb3 c2 60. Kb2 Kd2 61. a4 c1=Q+ 62. Kb3 Qc3+ 63. Ka2 Kc2 64. a5 Qb2# c3\n65. a6 Qb3+ 66. Ka1 Qb2#",
          "positional_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 450,
            "total_tokens": 655,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd6",
            "Qe7",
            "Qd2",
            "f6",
            "exf6",
            "gxf6",
            "Bd6",
            "Qg7",
            "f4",
            "f5",
            "c3",
            "b6",
            "Bf3",
            "Bb7",
            "Rae1",
            "Rh6",
            "b4",
            "Rg6",
            "b5",
            "Na5",
            "Bxb7",
            "Nxb7",
            "Be5",
            "Qf7",
            "Rf3",
            "d6",
            "Bd4",
            "Nc5",
            "Rh3",
            "Qh7",
            "Bxc5",
            "dxc5",
            "Qf2",
            "Rh6",
            "Rhe3",
            "Re8",
            "Qf3",
            "Qd7",
            "Qc6",
            "Qxc6",
            "bxc6",
            "Kf7",
            "Rd1",
            "Re7",
            "Rd7",
            "Rxd7",
            "cxd7",
            "Ke7",
            "Rd3",
            "Kd8",
            "Kf2",
            "Rh7",
            "Rd6",
            "Re7",
            "g3",
            "hxg3+",
            "hxg3",
            "Rxd7",
            "Rxe6",
            "Rd2+",
            "Re2",
            "Rxe2+",
            "Kxe2",
            "Ke7",
            "Kf3",
            "Kf6",
            "g4",
            "fxg4+",
            "Kxg4",
            "b5",
            "Kf3",
            "Kf5",
            "Ke3",
            "a5",
            "Kd3",
            "Kxf4",
            "c4",
            "b4",
            "Kc2",
            "Ke4",
            "Kb3",
            "Kd4",
            "Ka4",
            "Kxc4",
            "Kxa5",
            "Kd3",
            "Kb5",
            "c4",
            "Kxb4",
            "c3",
            "Kb3",
            "c2",
            "Kb2",
            "Kd2",
            "a4",
            "c1=Q+",
            "Kb3",
            "Qc3+",
            "Ka2",
            "Kc2",
            "a5",
            "Qb2#",
            "c3",
            "a6",
            "Qb3+",
            "Ka1",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxd6",
          "neutral_uci": "e4d6",
          "neutral_response": "13. Nxd6 Nxd6 14. Qxd6 Qe7 15. Qd2 f6 16. exf6 gxf6 17. Bd6 Qg7 18. f4 f5 19. c3\nb6 20. Bf3 Bb7 21. Rae1 Rh6 22. b4 a6 23. a4 Rg6 24. b5 axb5 25. axb5 Na5 26.\nBxb7 Nxb7 27. Be5 Qe7 28. Ra1 Rxa1 29. Rxa1 d6 30. Ra8+ Kf7 31. Bd4 Nc5 32. Qe2\nQb7 33. Rh8 Qe4 34. Qxe4 Nxe4 35. Rxh4 e5 36. fxe5 dxe5 37. Bxe5 Ke6 38. Bd4 Kd5\n39. Rh8 Kc4 40. Rb8 Kxb5 41. h4 Kc4 42. h5 Rh6 43. Rxb6 Rxh5 44. Rc6+ Kd3 45.\nRc8 Ng3 46. Kf2 Ne4+ 47. Kf3 Rh1 48. Kf4 Rf1+ 49. Ke5 Ng3 50. c4 Re1+ 51. Kd5\nRe4 52. Be5 Ne2 53. c5 Nc3+ 54. Bxc3 Kxc3 55. c6 Rd4+ 56. Ke5 Rc4 57. c7 Kd3\n58. Kxf5 Ke3 59. g4 Kf3 60. g5 Rc5+ 61. Kf6 Kf4 62. g6 Rc6+ 63. Kf7 Kf5 64. g7\nRf6+ 65. Ke7 Re6+ 66. Kd7 Rg6 67. Rf8+ Ke5 68. g8=Q Rxg8 69. Rxg8 Kd5 70. Rg5+\nKe4 71. c8=Q Kf4 72. Qc5 Ke4 73. Qe5+ Kd3 74. Rg3+ Kc4 75. Rc3+ Kb4 76. Qc5+\nKa4 77. Ra3# Qc5 Qb7",
          "neutral_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 553,
            "total_tokens": 757,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd6",
            "Qe7",
            "Qd2",
            "f6",
            "exf6",
            "gxf6",
            "Bd6",
            "Qg7",
            "f4",
            "f5",
            "c3",
            "b6",
            "Bf3",
            "Bb7",
            "Rae1",
            "Rh6",
            "b4",
            "a6",
            "a4",
            "Rg6",
            "b5",
            "axb5",
            "axb5",
            "Na5",
            "Bxb7",
            "Nxb7",
            "Be5",
            "Qe7",
            "Ra1",
            "Rxa1",
            "Rxa1",
            "d6",
            "Ra8+",
            "Kf7",
            "Bd4",
            "Nc5",
            "Qe2",
            "Qb7",
            "Rh8",
            "Qe4",
            "Qxe4",
            "Nxe4",
            "Rxh4",
            "e5",
            "fxe5",
            "dxe5",
            "Bxe5",
            "Ke6",
            "Bd4",
            "Kd5",
            "Rh8",
            "Kc4",
            "Rb8",
            "Kxb5",
            "h4",
            "Kc4",
            "h5",
            "Rh6",
            "Rxb6",
            "Rxh5",
            "Rc6+",
            "Kd3",
            "Rc8",
            "Ng3",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Rh1",
            "Kf4",
            "Rf1+",
            "Ke5",
            "Ng3",
            "c4",
            "Re1+",
            "Kd5",
            "Re4",
            "Be5",
            "Ne2",
            "c5",
            "Nc3+",
            "Bxc3",
            "Kxc3",
            "c6",
            "Rd4+",
            "Ke5",
            "Rc4",
            "c7",
            "Kd3",
            "Kxf5",
            "Ke3",
            "g4",
            "Kf3",
            "g5",
            "Rc5+",
            "Kf6",
            "Kf4",
            "g6",
            "Rc6+",
            "Kf7",
            "Kf5",
            "g7",
            "Rf6+",
            "Ke7",
            "Re6+",
            "Kd7",
            "Rg6",
            "Rf8+",
            "Ke5",
            "g8=Q",
            "Rxg8",
            "Rxg8",
            "Kd5",
            "Rg5+",
            "Ke4",
            "c8=Q",
            "Kf4",
            "Qc5",
            "Ke4",
            "Qe5+",
            "Kd3",
            "Rg3+",
            "Kc4",
            "Rc3+",
            "Kb4",
            "Qc5+",
            "Ka4",
            "Ra3#",
            "Qc5",
            "Qb7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4d6",
          "positional_uci": "e4d6",
          "neutral_uci": "e4d6",
          "consensus_move": "e4d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxd6",
              "Qe7",
              "Qd2",
              "f6",
              "exf6",
              "gxf6",
              "Bd6",
              "Qg7",
              "f4",
              "f5",
              "c3",
              "b6",
              "Bf3",
              "Bb7",
              "Rae1",
              "Rh6",
              "b4",
              "Rg6",
              "b5",
              "Na5",
              "Bxb7",
              "Nxb7",
              "Be5",
              "Qf7",
              "Rf3",
              "d6",
              "Bd4",
              "Nc5",
              "Rh3",
              "Ne4",
              "Qe2",
              "Rg4",
              "Qf3",
              "Rc8",
              "Rxe4",
              "fxe4",
              "Qxg4+",
              "Kf8",
              "Rxh4",
              "Ke7",
              "Qg5+",
              "Kd7",
              "Qg7",
              "Qxg7",
              "Bxg7",
              "Rg8",
              "Rh7",
              "Ke8",
              "Bd4",
              "Rf8",
              "g3",
              "Rf7",
              "Rxf7",
              "Kxf7",
              "Kf2",
              "Kg6",
              "Ke3",
              "Kf5",
              "h3",
              "e5",
              "g4+",
              "Ke6",
              "f5+",
              "Kd5",
              "Bxe5",
              "Kxe5",
              "h4",
              "d5",
              "h5",
              "Kf6",
              "h6",
              "Kf7",
              "g5",
              "Kg8",
              "g6",
              "Kh8",
              "f6",
              "Kg8",
              "h7+",
              "Kh8",
              "f7",
              "Kg7",
              "h8=Q+",
              "Kxh8",
              "f8=Q#",
              "e4",
              "dxe4",
              "Qd4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxd6",
              "Qe7",
              "Qd2",
              "f6",
              "exf6",
              "gxf6",
              "Bd6",
              "Qg7",
              "f4",
              "f5",
              "c3",
              "b6",
              "Bf3",
              "Bb7",
              "Rae1",
              "Rh6",
              "b4",
              "Rg6",
              "b5",
              "Na5",
              "Bxb7",
              "Nxb7",
              "Be5",
              "Qf7",
              "Rf3",
              "d6",
              "Bd4",
              "Nc5",
              "Rh3",
              "Qh7",
              "Bxc5",
              "dxc5",
              "Qf2",
              "Rh6",
              "Rhe3",
              "Re8",
              "Qf3",
              "Qd7",
              "Qc6",
              "Qxc6",
              "bxc6",
              "Kf7",
              "Rd1",
              "Re7",
              "Rd7",
              "Rxd7",
              "cxd7",
              "Ke7",
              "Rd3",
              "Kd8",
              "Kf2",
              "Rh7",
              "Rd6",
              "Re7",
              "g3",
              "hxg3+",
              "hxg3",
              "Rxd7",
              "Rxe6",
              "Rd2+",
              "Re2",
              "Rxe2+",
              "Kxe2",
              "Ke7",
              "Kf3",
              "Kf6",
              "g4",
              "fxg4+",
              "Kxg4",
              "b5",
              "Kf3",
              "Kf5",
              "Ke3",
              "a5",
              "Kd3",
              "Kxf4",
              "c4",
              "b4",
              "Kc2",
              "Ke4",
              "Kb3",
              "Kd4",
              "Ka4",
              "Kxc4",
              "Kxa5",
              "Kd3",
              "Kb5",
              "c4",
              "Kxb4",
              "c3",
              "Kb3",
              "c2",
              "Kb2",
              "Kd2",
              "a4",
              "c1=Q+",
              "Kb3",
              "Qc3+",
              "Ka2",
              "Kc2",
              "a5",
              "Qb2#",
              "c3",
              "a6",
              "Qb3+",
              "Ka1",
              "Qb2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxd6",
              "Qe7",
              "Qd2",
              "f6",
              "exf6",
              "gxf6",
              "Bd6",
              "Qg7",
              "f4",
              "f5",
              "c3",
              "b6",
              "Bf3",
              "Bb7",
              "Rae1",
              "Rh6",
              "b4",
              "a6",
              "a4",
              "Rg6",
              "b5",
              "axb5",
              "axb5",
              "Na5",
              "Bxb7",
              "Nxb7",
              "Be5",
              "Qe7",
              "Ra1",
              "Rxa1",
              "Rxa1",
              "d6",
              "Ra8+",
              "Kf7",
              "Bd4",
              "Nc5",
              "Qe2",
              "Qb7",
              "Rh8",
              "Qe4",
              "Qxe4",
              "Nxe4",
              "Rxh4",
              "e5",
              "fxe5",
              "dxe5",
              "Bxe5",
              "Ke6",
              "Bd4",
              "Kd5",
              "Rh8",
              "Kc4",
              "Rb8",
              "Kxb5",
              "h4",
              "Kc4",
              "h5",
              "Rh6",
              "Rxb6",
              "Rxh5",
              "Rc6+",
              "Kd3",
              "Rc8",
              "Ng3",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Rh1",
              "Kf4",
              "Rf1+",
              "Ke5",
              "Ng3",
              "c4",
              "Re1+",
              "Kd5",
              "Re4",
              "Be5",
              "Ne2",
              "c5",
              "Nc3+",
              "Bxc3",
              "Kxc3",
              "c6",
              "Rd4+",
              "Ke5",
              "Rc4",
              "c7",
              "Kd3",
              "Kxf5",
              "Ke3",
              "g4",
              "Kf3",
              "g5",
              "Rc5+",
              "Kf6",
              "Kf4",
              "g6",
              "Rc6+",
              "Kf7",
              "Kf5",
              "g7",
              "Rf6+",
              "Ke7",
              "Re6+",
              "Kd7",
              "Rg6",
              "Rf8+",
              "Ke5",
              "g8=Q",
              "Rxg8",
              "Rxg8",
              "Kd5",
              "Rg5+",
              "Ke4",
              "c8=Q",
              "Kf4",
              "Qc5",
              "Ke4",
              "Qe5+",
              "Kd3",
              "Rg3+",
              "Kc4",
              "Rc3+",
              "Kb4",
              "Qc5+",
              "Ka4",
              "Ra3#",
              "Qc5",
              "Qb7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 205,
            "completion_tokens": 375,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 205,
            "completion_tokens": 450,
            "total_tokens": 655,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 204,
            "completion_tokens": 553,
            "total_tokens": 757,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 614,
          "total_completion_tokens": 1378,
          "total_tokens": 1992
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 205,
            "completion_tokens": 375,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 205,
            "completion_tokens": 450,
            "total_tokens": 655,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 204,
            "completion_tokens": 553,
            "total_tokens": 757,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqn1kr/pp1p1pp1/2nbp3/4P3/4NB1p/8/PPP1BPPP/R2Q1RK1 w - - 0 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe8",
          "aggressive_uci": "d6e8",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 gxf4 15. Nf6+ Kf8 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 Rh5 19. Rfe1 Nxe5 20. Nxe5 Rxe5 21. Bf3 Rxe1+ 22. Rxe1 d6 23. Re4 e5 24. Rb4 Rb8 25. g3 hxg3 26. hxg3 fxg3 27. fxg3 b6 28. Ra4 a5 29. b4 Bd7 30. Ra3 axb4 31. Rb3 Be6 32. Rxb4 Bxa2 33. c4 Rc8 34. Bd5 Rc5 35. Rxb6 Bxc4 36. Rb7+ Kf6 37. Rxf7+ Kg6 38. Bxc4 Rxc4 39. Rd7 Rd4 40. Kf2 Kf5 41. Ke3 Ke6 42. Rd8 Rg4 43. Kf3 Rg7 44. g4 d5 45. Re8+ Kd6 46. Rd8+ Kc5 47. Rc8+ Kd4 48. Ra8 e4+ 49. Kf4 Rf7+ 50. Kg5 e3 51. Kg6 Rf4 52. g5 e2 53. Ra4+ Ke3 54. Ra3+ Kf2 55. Ra2 Kf1 56. Ra1+ e1=Q 57. Rxe1+ Kxe1 58. Kh7 d4 59. g6 d3 60. g7 Rg4 61. g8=Q Rxg8 62. Kxg8 d2 63. Kf7 d1=Q 64. Ke6 Qd4 65. Kf5 Ke2 66. Ke6 Ke3 67. Kf5 Qe4+ 68. Kf6 Kf4 69. Kf7 Qe5 70. Kg6 Qf5+ 71. Kg7 Kg5 72. Kg8 Kg6 73. Kh8 Qf8#",
          "aggressive_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 610,
            "total_tokens": 823,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf4",
            "Nf6+",
            "Kf8",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Ng4",
            "Rh5",
            "Rfe1",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Bf3",
            "Rxe1+",
            "Rxe1",
            "d6",
            "Re4",
            "e5",
            "Rb4",
            "Rb8",
            "g3",
            "hxg3",
            "hxg3",
            "fxg3",
            "fxg3",
            "b6",
            "Ra4",
            "a5",
            "b4",
            "Bd7",
            "Ra3",
            "axb4",
            "Rb3",
            "Be6",
            "Rxb4",
            "Bxa2",
            "c4",
            "Rc8",
            "Bd5",
            "Rc5",
            "Rxb6",
            "Bxc4",
            "Rb7+",
            "Kf6",
            "Rxf7+",
            "Kg6",
            "Bxc4",
            "Rxc4",
            "Rd7",
            "Rd4",
            "Kf2",
            "Kf5",
            "Ke3",
            "Ke6",
            "Rd8",
            "Rg4",
            "Kf3",
            "Rg7",
            "g4",
            "d5",
            "Re8+",
            "Kd6",
            "Rd8+",
            "Kc5",
            "Rc8+",
            "Kd4",
            "Ra8",
            "e4+",
            "Kf4",
            "Rf7+",
            "Kg5",
            "e3",
            "Kg6",
            "Rf4",
            "g5",
            "e2",
            "Ra4+",
            "Ke3",
            "Ra3+",
            "Kf2",
            "Ra2",
            "Kf1",
            "Ra1+",
            "e1=Q",
            "Rxe1+",
            "Kxe1",
            "Kh7",
            "d4",
            "g6",
            "d3",
            "g7",
            "Rg4",
            "g8=Q",
            "Rxg8",
            "Kxg8",
            "d2",
            "Kf7",
            "d1=Q",
            "Ke6",
            "Qd4",
            "Kf5",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kf5",
            "Qe4+",
            "Kf6",
            "Kf4",
            "Kf7",
            "Qe5",
            "Kg6",
            "Qf5+",
            "Kg7",
            "Kg5",
            "Kg8",
            "Kg6",
            "Kh8",
            "Qf8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe8",
          "positional_uci": "d6e8",
          "positional_response": "14. Nxe8 gxf4 15. Nf6+ Kf8 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 Rh5 19. Rfe1 Nxe5 20. Nxe5 Rxe5 21. Bf3 Rxe1+ 22. Rxe1 d6 23. Re4 e5 24. Rb4 Rb8 25. g3 hxg3 26. hxg3 fxg3 27. fxg3 b6 28. Ra4 a5 29. b4 Bd7 30. Ra3 axb4 31. Rb3 Rc8 32. Rxb4 Rxc2 33. Rxb6 Rxa2 34. Rb7 Ke6 35. Bg4+ f5 36. Bxf5+ Kxf5 37. Rxd7 Rd2 38. Rg7 e4 39. g4+ Kf4 40. g5 Kg3 41. Kf1 d5 42. g6 d4 43. Re7 e3 44. g7 Kf3 45. Rf7+ Ke4 46. g8=Q Rd1+ 47. Kg2 Rd2+ 48. Kg3 Kd3 49. Qg6+ Ke2 50. Qg4+ Kd3 51. Qf5+ Ke2 52. Qf1# d3 e2 Qe3+ Kd2 Qe2+ Kc1 Qxf1+ Rxf1+ Kxf1 d2 54. d1=Q+ Ke1 55. Qh4+ Kd1 56. Qa4+ Ke1 57. Qa1# d1=Q 58. Qc3# d2 Qe2+ Kd1 Qe1+ Kc2 Qc1+ Kb3 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4 Qa3+ Kb5 Qb2+ Ka4",
          "positional_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 640,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "gxf4",
            "Nf6+",
            "Kf8",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Ng4",
            "Rh5",
            "Rfe1",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Bf3",
            "Rxe1+",
            "Rxe1",
            "d6",
            "Re4",
            "e5",
            "Rb4",
            "Rb8",
            "g3",
            "hxg3",
            "hxg3",
            "fxg3",
            "fxg3",
            "b6",
            "Ra4",
            "a5",
            "b4",
            "Bd7",
            "Ra3",
            "axb4",
            "Rb3",
            "Rc8",
            "Rxb4",
            "Rxc2",
            "Rxb6",
            "Rxa2",
            "Rb7",
            "Ke6",
            "Bg4+",
            "f5",
            "Bxf5+",
            "Kxf5",
            "Rxd7",
            "Rd2",
            "Rg7",
            "e4",
            "g4+",
            "Kf4",
            "g5",
            "Kg3",
            "Kf1",
            "d5",
            "g6",
            "d4",
            "Re7",
            "e3",
            "g7",
            "Kf3",
            "Rf7+",
            "Ke4",
            "g8=Q",
            "Rd1+",
            "Kg2",
            "Rd2+",
            "Kg3",
            "Kd3",
            "Qg6+",
            "Ke2",
            "Qg4+",
            "Kd3",
            "Qf5+",
            "Ke2",
            "Qf1#",
            "d3",
            "e2",
            "Qe3+",
            "Kd2",
            "Qe2+",
            "Kc1",
            "Qxf1+",
            "Rxf1+",
            "Kxf1",
            "d2",
            "d1=Q+",
            "Ke1",
            "Qh4+",
            "Kd1",
            "Qa4+",
            "Ke1",
            "Qa1#",
            "d1=Q",
            "Qc3#",
            "d2",
            "Qe2+",
            "Kd1",
            "Qe1+",
            "Kc2",
            "Qc1+",
            "Kb3",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Qa3+",
            "Kb5",
            "Qb2+",
            "Ka4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe8",
          "neutral_uci": "d6e8",
          "neutral_response": "14. Nxe8 gxf4 15. Nf6+ Kf8 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 Rh5 19. Rfe1 Nxe5 20. Nxe5 Rxe5 21. Bf3 Rxe1+ 22. Rxe1 d6 23. Re4 e5 24. Rb4 Rb8 25. g3 hxg3 26. hxg3 fxg3 27. fxg3 b6 28. Ra4 a5 29. b4 Bd7 30. Ra3 axb4 31. Rb3 Be6 32. Rxb4 Bxa2 33. c4 Rc8 34. Bd5 b5 35. Rxb5 Bxc4 36. Rb7+ Kf6 37. Bxc4 Rxc4 38. Kf2 Ke6 39. Ke3 f5 40. Rb8 Rc3+ 41. Kf2 e4 42. Re8+ Kd5 43. Rf8 Rf3+ 44. Kg2 Kd4 45. Ra8 d5 46. Ra4+ Ke5 47. Ra8 d4 48. Re8+ Kd5 49. Rd8+ Kc4 50. Rc8+ Kd3 51. Ra8 Ke3 52. Ra3+ d3 53. Ra1 Rf2+ 54. Kg1 d2 55. Ra3+ Ke2 56. Ra2 e3 57. Rb2 Kf3 58. Rb1 Kxg3 59. Ra1 f4 60. Rb1 f3 61. Ra1 Rg2+ 62. Kh1 Rh2+ 63. Kg1 f2+ 64. Kf1 Kf3 65. Ra3 Rh1#",
          "neutral_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 434,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf4",
            "Nf6+",
            "Kf8",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Ng4",
            "Rh5",
            "Rfe1",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Bf3",
            "Rxe1+",
            "Rxe1",
            "d6",
            "Re4",
            "e5",
            "Rb4",
            "Rb8",
            "g3",
            "hxg3",
            "hxg3",
            "fxg3",
            "fxg3",
            "b6",
            "Ra4",
            "a5",
            "b4",
            "Bd7",
            "Ra3",
            "axb4",
            "Rb3",
            "Be6",
            "Rxb4",
            "Bxa2",
            "c4",
            "Rc8",
            "Bd5",
            "b5",
            "Rxb5",
            "Bxc4",
            "Rb7+",
            "Kf6",
            "Bxc4",
            "Rxc4",
            "Kf2",
            "Ke6",
            "Ke3",
            "f5",
            "Rb8",
            "Rc3+",
            "Kf2",
            "e4",
            "Re8+",
            "Kd5",
            "Rf8",
            "Rf3+",
            "Kg2",
            "Kd4",
            "Ra8",
            "d5",
            "Ra4+",
            "Ke5",
            "Ra8",
            "d4",
            "Re8+",
            "Kd5",
            "Rd8+",
            "Kc4",
            "Rc8+",
            "Kd3",
            "Ra8",
            "Ke3",
            "Ra3+",
            "d3",
            "Ra1",
            "Rf2+",
            "Kg1",
            "d2",
            "Ra3+",
            "Ke2",
            "Ra2",
            "e3",
            "Rb2",
            "Kf3",
            "Rb1",
            "Kxg3",
            "Ra1",
            "f4",
            "Rb1",
            "f3",
            "Ra1",
            "Rg2+",
            "Kh1",
            "Rh2+",
            "Kg1",
            "f2+",
            "Kf1",
            "Kf3",
            "Ra3",
            "Rh1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d6e8",
          "positional_uci": "d6e8",
          "neutral_uci": "d6e8",
          "consensus_move": "d6e8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "gxf4",
              "Nf6+",
              "Kf8",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Ng4",
              "Rh5",
              "Rfe1",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Bf3",
              "Rxe1+",
              "Rxe1",
              "d6",
              "Re4",
              "e5",
              "Rb4",
              "Rb8",
              "g3",
              "hxg3",
              "hxg3",
              "fxg3",
              "fxg3",
              "b6",
              "Ra4",
              "a5",
              "b4",
              "Bd7",
              "Ra3",
              "axb4",
              "Rb3",
              "Be6",
              "Rxb4",
              "Bxa2",
              "c4",
              "Rc8",
              "Bd5",
              "Rc5",
              "Rxb6",
              "Bxc4",
              "Rb7+",
              "Kf6",
              "Rxf7+",
              "Kg6",
              "Bxc4",
              "Rxc4",
              "Rd7",
              "Rd4",
              "Kf2",
              "Kf5",
              "Ke3",
              "Ke6",
              "Rd8",
              "Rg4",
              "Kf3",
              "Rg7",
              "g4",
              "d5",
              "Re8+",
              "Kd6",
              "Rd8+",
              "Kc5",
              "Rc8+",
              "Kd4",
              "Ra8",
              "e4+",
              "Kf4",
              "Rf7+",
              "Kg5",
              "e3",
              "Kg6",
              "Rf4",
              "g5",
              "e2",
              "Ra4+",
              "Ke3",
              "Ra3+",
              "Kf2",
              "Ra2",
              "Kf1",
              "Ra1+",
              "e1=Q",
              "Rxe1+",
              "Kxe1",
              "Kh7",
              "d4",
              "g6",
              "d3",
              "g7",
              "Rg4",
              "g8=Q",
              "Rxg8",
              "Kxg8",
              "d2",
              "Kf7",
              "d1=Q",
              "Ke6",
              "Qd4",
              "Kf5",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kf5",
              "Qe4+",
              "Kf6",
              "Kf4",
              "Kf7",
              "Qe5",
              "Kg6",
              "Qf5+",
              "Kg7",
              "Kg5",
              "Kg8",
              "Kg6",
              "Kh8",
              "Qf8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "gxf4",
              "Nf6+",
              "Kf8",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Ng4",
              "Rh5",
              "Rfe1",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Bf3",
              "Rxe1+",
              "Rxe1",
              "d6",
              "Re4",
              "e5",
              "Rb4",
              "Rb8",
              "g3",
              "hxg3",
              "hxg3",
              "fxg3",
              "fxg3",
              "b6",
              "Ra4",
              "a5",
              "b4",
              "Bd7",
              "Ra3",
              "axb4",
              "Rb3",
              "Rc8",
              "Rxb4",
              "Rxc2",
              "Rxb6",
              "Rxa2",
              "Rb7",
              "Ke6",
              "Bg4+",
              "f5",
              "Bxf5+",
              "Kxf5",
              "Rxd7",
              "Rd2",
              "Rg7",
              "e4",
              "g4+",
              "Kf4",
              "g5",
              "Kg3",
              "Kf1",
              "d5",
              "g6",
              "d4",
              "Re7",
              "e3",
              "g7",
              "Kf3",
              "Rf7+",
              "Ke4",
              "g8=Q",
              "Rd1+",
              "Kg2",
              "Rd2+",
              "Kg3",
              "Kd3",
              "Qg6+",
              "Ke2",
              "Qg4+",
              "Kd3",
              "Qf5+",
              "Ke2",
              "Qf1#",
              "d3",
              "e2",
              "Qe3+",
              "Kd2",
              "Qe2+",
              "Kc1",
              "Qxf1+",
              "Rxf1+",
              "Kxf1",
              "d2",
              "d1=Q+",
              "Ke1",
              "Qh4+",
              "Kd1",
              "Qa4+",
              "Ke1",
              "Qa1#",
              "d1=Q",
              "Qc3#",
              "d2",
              "Qe2+",
              "Kd1",
              "Qe1+",
              "Kc2",
              "Qc1+",
              "Kb3",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Qa3+",
              "Kb5",
              "Qb2+",
              "Ka4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf4",
              "Nf6+",
              "Kf8",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Ng4",
              "Rh5",
              "Rfe1",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Bf3",
              "Rxe1+",
              "Rxe1",
              "d6",
              "Re4",
              "e5",
              "Rb4",
              "Rb8",
              "g3",
              "hxg3",
              "hxg3",
              "fxg3",
              "fxg3",
              "b6",
              "Ra4",
              "a5",
              "b4",
              "Bd7",
              "Ra3",
              "axb4",
              "Rb3",
              "Be6",
              "Rxb4",
              "Bxa2",
              "c4",
              "Rc8",
              "Bd5",
              "b5",
              "Rxb5",
              "Bxc4",
              "Rb7+",
              "Kf6",
              "Bxc4",
              "Rxc4",
              "Kf2",
              "Ke6",
              "Ke3",
              "f5",
              "Rb8",
              "Rc3+",
              "Kf2",
              "e4",
              "Re8+",
              "Kd5",
              "Rf8",
              "Rf3+",
              "Kg2",
              "Kd4",
              "Ra8",
              "d5",
              "Ra4+",
              "Ke5",
              "Ra8",
              "d4",
              "Re8+",
              "Kd5",
              "Rd8+",
              "Kc4",
              "Rc8+",
              "Kd3",
              "Ra8",
              "Ke3",
              "Ra3+",
              "d3",
              "Ra1",
              "Rf2+",
              "Kg1",
              "d2",
              "Ra3+",
              "Ke2",
              "Ra2",
              "e3",
              "Rb2",
              "Kf3",
              "Rb1",
              "Kxg3",
              "Ra1",
              "f4",
              "Rb1",
              "f3",
              "Ra1",
              "Rg2+",
              "Kh1",
              "Rh2+",
              "Kg1",
              "f2+",
              "Kf1",
              "Kf3",
              "Ra3",
              "Rh1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 213,
            "completion_tokens": 610,
            "total_tokens": 823,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 213,
            "completion_tokens": 640,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 212,
            "completion_tokens": 434,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 638,
          "total_completion_tokens": 1684,
          "total_tokens": 2322
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 213,
            "completion_tokens": 610,
            "total_tokens": 823,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 213,
            "completion_tokens": 640,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 212,
            "completion_tokens": 434,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqn1kr/pp1p1p2/2nNp3/4P1p1/5B1p/8/PPP1BPPP/R2Q1RK1 w - - 0 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "e8f6",
          "aggressive_response": "15. Nf6 gxf4 16. Qd6+ Kg7 17. Rad1 Qe7 18. Qxe7 Nxe7 19. Nxd7 Bxd7 20. Rxd7\nNc6 21. Rxb7 Nxe5 22. Rd1 Rhb8 23. Rxb8 Rxb8 24. b3 Rc8 25. c4 Rc7 26. Rd4 Ng6\n27. Bd3 e5 28. Rd6 Ne7 29. Kf1 f5 30. f3 Rc6 31. Rd7 Kf6 32. Rxa7 Rd6 33. Ke2\nNc6 34. Ra6 Nd4+ 35. Kd2 Rxa6 36. a4 Nxb3+ 37. Kc3 Nc5 38. Bc2 Nxa4+ 39. Kb4\nNb6 40. Kb5 Ra2 41. Bb3 Rb2 42. Kb4 Nxc4 43. Kxc4 Rxg2 44. Kd3 Rxh2 45. Bd5\nRf2 46. Bc6 h3 47. Bb5 h2 48. Kc3 h1=Q 49. Kb4 Qb1+ 50. Kc5 Rc2+ 51. Kb6 Rb2\n52. Kc7 Rxb5 53. Kd6 Qd3+ 54. Kc6 Qd5+ 55. Kc7 Rb7+ 56. Kc8 Qd7# 57. Kb8 Qc7+ 58. Ka8 Ra7# 59. Kb8 Qb7# 60. Kc8 Qc7#",
          "aggressive_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 396,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf4",
            "Qd6+",
            "Kg7",
            "Rad1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Nxd7",
            "Bxd7",
            "Rxd7",
            "Nc6",
            "Rxb7",
            "Nxe5",
            "Rd1",
            "Rhb8",
            "Rxb8",
            "Rxb8",
            "b3",
            "Rc8",
            "c4",
            "Rc7",
            "Rd4",
            "Ng6",
            "Bd3",
            "e5",
            "Rd6",
            "Ne7",
            "Kf1",
            "f5",
            "f3",
            "Rc6",
            "Rd7",
            "Kf6",
            "Rxa7",
            "Rd6",
            "Ke2",
            "Nc6",
            "Ra6",
            "Nd4+",
            "Kd2",
            "Rxa6",
            "a4",
            "Nxb3+",
            "Kc3",
            "Nc5",
            "Bc2",
            "Nxa4+",
            "Kb4",
            "Nb6",
            "Kb5",
            "Ra2",
            "Bb3",
            "Rb2",
            "Kb4",
            "Nxc4",
            "Kxc4",
            "Rxg2",
            "Kd3",
            "Rxh2",
            "Bd5",
            "Rf2",
            "Bc6",
            "h3",
            "Bb5",
            "h2",
            "Kc3",
            "h1=Q",
            "Kb4",
            "Qb1+",
            "Kc5",
            "Rc2+",
            "Kb6",
            "Rb2",
            "Kc7",
            "Rxb5",
            "Kd6",
            "Qd3+",
            "Kc6",
            "Qd5+",
            "Kc7",
            "Rb7+",
            "Kc8",
            "Qd7#",
            "Kb8",
            "Qc7+",
            "Ka8",
            "Ra7#",
            "Kb8",
            "Qb7#",
            "Kc8",
            "Qc7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "e8f6",
          "positional_response": "15. Nf6 gxf4 16. Qd6+ Kg7 17. Rad1 Qe7 18. Qxe7 Nxe7 19. Nxd7 Bxd7 20. Rxd7 Ng6\n21. Rxb7 Nxe5 22. Rd1 Rhc8 23. c3 a5 24. Rd4 f3 25. Bxf3 Nxf3+ 26. gxf3 h3 27.\nRg4+ Kf6 28. Rf4+ Ke5 29. Rfxf7 Rd8 30. Rfd7 Rg8+ 31. Kf1 Rg2 32. Rb5+ Kf6 33.\nRh5 Rxh2 34. Rdh7 Rh1+ 35. Ke2 Rb8 36. b3 a4 37. b4 Ra1 38. Rxh3 Rxa2+ 39. Ke3\nRc2 40. R3h6+ Ke5 41. Rh5+ Kd6 42. Rc5 a3 43. Ra7 a2 44. Ra6+ Ke7 45. f4 Rd8\n46. Rc7+ Kf6 47. Rcc6 Re8 48. f3 Kf5 49. Ra5+ Kf6 50. f5 Rxc3+ 51. Rxc3 exf5+\n52. Kf4 Re2 53. Rc6+ Ke7 54. Ra7+ Kd8 55. Rh6 Re8 56. Rxa2 Kc7 57. Ra7+ Kb8\n58. Rf7 Rc8 59. Rhh7 Rc4+ 60. Kg5 Rxb4 61. Rh8# e4 d5 e6 d4 e7 d3 e8=Q#",
          "positional_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 413,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf4",
            "Qd6+",
            "Kg7",
            "Rad1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Nxd7",
            "Bxd7",
            "Rxd7",
            "Ng6",
            "Rxb7",
            "Nxe5",
            "Rd1",
            "Rhc8",
            "c3",
            "a5",
            "Rd4",
            "f3",
            "Bxf3",
            "Nxf3+",
            "gxf3",
            "h3",
            "Rg4+",
            "Kf6",
            "Rf4+",
            "Ke5",
            "Rfxf7",
            "Rd8",
            "Rfd7",
            "Rg8+",
            "Kf1",
            "Rg2",
            "Rb5+",
            "Kf6",
            "Rh5",
            "Rxh2",
            "Rdh7",
            "Rh1+",
            "Ke2",
            "Rb8",
            "b3",
            "a4",
            "b4",
            "Ra1",
            "Rxh3",
            "Rxa2+",
            "Ke3",
            "Rc2",
            "R3h6+",
            "Ke5",
            "Rh5+",
            "Kd6",
            "Rc5",
            "a3",
            "Ra7",
            "a2",
            "Ra6+",
            "Ke7",
            "f4",
            "Rd8",
            "Rc7+",
            "Kf6",
            "Rcc6",
            "Re8",
            "f3",
            "Kf5",
            "Ra5+",
            "Kf6",
            "f5",
            "Rxc3+",
            "Rxc3",
            "exf5+",
            "Kf4",
            "Re2",
            "Rc6+",
            "Ke7",
            "Ra7+",
            "Kd8",
            "Rh6",
            "Re8",
            "Rxa2",
            "Kc7",
            "Ra7+",
            "Kb8",
            "Rf7",
            "Rc8",
            "Rhh7",
            "Rc4+",
            "Kg5",
            "Rxb4",
            "Rh8#",
            "e4",
            "d5",
            "e6",
            "d4",
            "e7",
            "d3",
            "e8=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "e8f6",
          "neutral_response": "15. Nf6 gxf4 16. Qd6+ Kg7 17. Rad1 Qe7 18. Qxe7 Nxe7 19. Nxd7 Bxd7 20. Rxd7\nNc6 21. Rxb7 Nxe5 22. Rd1 Rhb8 23. Rxb8 Rxb8 24. b3 Rc8 25. c4 Kf6 26. Rd4\nKf5 27. Bd3+ Nxd3 28. Rxd3 e5 29. f3 Ke6 30. Kf2 f5 31. Rd5 e4 32. fxe4 fxe4\n33. Rh5 Rd8 34. Ke2 Rg8 35. Kf2 Rd8 36. Ke2 Rg8 37. Kf2 Rd8 38. Ke2 Rg8\n39. Kf2 Rd8 40. Ke2 Rg8 41. Kf2 Rd8 42. Ke2 Rg8 43. Kf2 Rd8 44. Ke2 Rg8\n45. Kf2 Rd8 46. Ke2 Rg8 47. Kf2 Rd8 48. Ke2 Rg8 49. Kf2 Rd8 50. Ke2 Rg8\n51. Kf2 Rd8 52. Ke2 Rg8 53. Kf2 Rd8 54. Ke2 Rg8 55. Kf2 Rd8 56. Ke2 Rg8\n57. Kf2 Rd8 58. Ke2 Rg8 59. Kf2 Rd8 60. Ke2 Rg8 61. Kf2 Rd8 62. Ke2 Rg8\n63. Kf2 Rd8 64. Ke2 Rg8 65. Kf2 Rd8 66. Ke2 Rg8 67. Kf2 Rd8 68. Ke2 Rg8\n69. Kf2 Rd8 70. Ke2 Rg8 71. Kf2 Rd8 72. Ke2 Rg8 73. Kf2 Rd8 74. Ke2 Rg8\n75. Kf2 Rd8 76. Ke2 Rg8 77. Kf2 Rd8 78. Ke2 Rg8 79. Kf2 Rd8 80. Ke2 Rg8\n81. Kf2 Rd8 82. Ke2 Rg8 83. Kf2 Rd8 84. Ke2 Rg8 85. Kf2 Rd8 86. Ke2 Rg8\n87. Kf2 Rd8 88. Ke2 Rg8 89. Kf2 Rd8 90. Ke2 Rg8 91. Kf2 Rd8 92. Ke2 Rg8\n93. Kf2 Rd8",
          "neutral_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "gxf4",
            "Qd6+",
            "Kg7",
            "Rad1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Nxd7",
            "Bxd7",
            "Rxd7",
            "Nc6",
            "Rxb7",
            "Nxe5",
            "Rd1",
            "Rhb8",
            "Rxb8",
            "Rxb8",
            "b3",
            "Rc8",
            "c4",
            "Kf6",
            "Rd4",
            "Kf5",
            "Bd3+",
            "Nxd3",
            "Rxd3",
            "e5",
            "f3",
            "Ke6",
            "Kf2",
            "f5",
            "Rd5",
            "e4",
            "fxe4",
            "fxe4",
            "Rh5",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8f6",
          "positional_uci": "e8f6",
          "neutral_uci": "e8f6",
          "consensus_move": "e8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "gxf4",
              "Qd6+",
              "Kg7",
              "Rad1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Nxd7",
              "Bxd7",
              "Rxd7",
              "Nc6",
              "Rxb7",
              "Nxe5",
              "Rd1",
              "Rhb8",
              "Rxb8",
              "Rxb8",
              "b3",
              "Rc8",
              "c4",
              "Rc7",
              "Rd4",
              "Ng6",
              "Bd3",
              "e5",
              "Rd6",
              "Ne7",
              "Kf1",
              "f5",
              "f3",
              "Rc6",
              "Rd7",
              "Kf6",
              "Rxa7",
              "Rd6",
              "Ke2",
              "Nc6",
              "Ra6",
              "Nd4+",
              "Kd2",
              "Rxa6",
              "a4",
              "Nxb3+",
              "Kc3",
              "Nc5",
              "Bc2",
              "Nxa4+",
              "Kb4",
              "Nb6",
              "Kb5",
              "Ra2",
              "Bb3",
              "Rb2",
              "Kb4",
              "Nxc4",
              "Kxc4",
              "Rxg2",
              "Kd3",
              "Rxh2",
              "Bd5",
              "Rf2",
              "Bc6",
              "h3",
              "Bb5",
              "h2",
              "Kc3",
              "h1=Q",
              "Kb4",
              "Qb1+",
              "Kc5",
              "Rc2+",
              "Kb6",
              "Rb2",
              "Kc7",
              "Rxb5",
              "Kd6",
              "Qd3+",
              "Kc6",
              "Qd5+",
              "Kc7",
              "Rb7+",
              "Kc8",
              "Qd7#",
              "Kb8",
              "Qc7+",
              "Ka8",
              "Ra7#",
              "Kb8",
              "Qb7#",
              "Kc8",
              "Qc7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "gxf4",
              "Qd6+",
              "Kg7",
              "Rad1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Nxd7",
              "Bxd7",
              "Rxd7",
              "Ng6",
              "Rxb7",
              "Nxe5",
              "Rd1",
              "Rhc8",
              "c3",
              "a5",
              "Rd4",
              "f3",
              "Bxf3",
              "Nxf3+",
              "gxf3",
              "h3",
              "Rg4+",
              "Kf6",
              "Rf4+",
              "Ke5",
              "Rfxf7",
              "Rd8",
              "Rfd7",
              "Rg8+",
              "Kf1",
              "Rg2",
              "Rb5+",
              "Kf6",
              "Rh5",
              "Rxh2",
              "Rdh7",
              "Rh1+",
              "Ke2",
              "Rb8",
              "b3",
              "a4",
              "b4",
              "Ra1",
              "Rxh3",
              "Rxa2+",
              "Ke3",
              "Rc2",
              "R3h6+",
              "Ke5",
              "Rh5+",
              "Kd6",
              "Rc5",
              "a3",
              "Ra7",
              "a2",
              "Ra6+",
              "Ke7",
              "f4",
              "Rd8",
              "Rc7+",
              "Kf6",
              "Rcc6",
              "Re8",
              "f3",
              "Kf5",
              "Ra5+",
              "Kf6",
              "f5",
              "Rxc3+",
              "Rxc3",
              "exf5+",
              "Kf4",
              "Re2",
              "Rc6+",
              "Ke7",
              "Ra7+",
              "Kd8",
              "Rh6",
              "Re8",
              "Rxa2",
              "Kc7",
              "Ra7+",
              "Kb8",
              "Rf7",
              "Rc8",
              "Rhh7",
              "Rc4+",
              "Kg5",
              "Rxb4",
              "Rh8#",
              "e4",
              "d5",
              "e6",
              "d4",
              "e7",
              "d3",
              "e8=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf4",
              "Qd6+",
              "Kg7",
              "Rad1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Nxd7",
              "Bxd7",
              "Rxd7",
              "Nc6",
              "Rxb7",
              "Nxe5",
              "Rd1",
              "Rhb8",
              "Rxb8",
              "Rxb8",
              "b3",
              "Rc8",
              "c4",
              "Kf6",
              "Rd4",
              "Kf5",
              "Bd3+",
              "Nxd3",
              "Rxd3",
              "e5",
              "f3",
              "Ke6",
              "Kf2",
              "f5",
              "Rd5",
              "e4",
              "fxe4",
              "fxe4",
              "Rh5",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 223,
            "completion_tokens": 396,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 223,
            "completion_tokens": 413,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 668,
          "total_completion_tokens": 1449,
          "total_tokens": 2117
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 223,
            "completion_tokens": 396,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 223,
            "completion_tokens": 413,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqNk1r/pp1p1p2/2n1p3/4P1p1/5B1p/8/PPP1BPPP/R2Q1RK1 w - - 1 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd6+",
          "aggressive_uci": "d1d6",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Kg7 17. Rad1 Qe7 18. Qxe7 Nxe7 19. Nxd7 Bxd7 20. Rxd7 Nc6\n21. Rxb7 Nxe5 22. Rd1 Rhc8 23. c3 a5 24. Rd4 f3 25. Bxf3 Nxf3+ 26. gxf3 h3 27.\nRg4+ Kf6 28. Rf4+ Ke5 29. Rfxf7 Rg8+ 30. Kf1 Rg2 31. Rb5+ Kd6 32. Rh5 Rxh2 33.\nRfh7 Rb8 34. b3 a4 35. b4 Rc8 36. Rc5 Rxc5 37. bxc5+ Kxc5 38. Rh4 a3 39. Kg1\nRg2+ 40. Kf1 Rh2 41. Ra4 Rh1+ 42. Ke2 h2 43. Rh4 Ra1 44. Rxh2 Rxa2+ 45. Kd3\nRb2 46. Rh5+ Kb6 47. Rh8 a2 48. Ra8 Rxf2 49. Ke3 Rc2 50. Kd3 Rf2 51. Ke3 Rc2\n52. Kd3 Rf2 53. Ke3 Rc2 54. Kd3 Rf2 55. Ke3 Rc2 56. Kd3 Rf2 57. Ke3 Rc2 58.\nKd3 Rf2 59. Ke3 Rc2 60. Kd3 Rf2 61. Ke3 Rc2 62. Kd3 Rf2 63. Ke3 Rc2 64. Kd3\nRf2 65. Ke3 Rc2 66. Kd3 Rf2 67. Ke3 Rc2 68. Kd3 Rf2 69. Ke3 Rc2 70. Kd3 Rf2\n71. Ke3 Rc2 72. Kd3 Rf2 73. Ke3 Rc2 74. Kd3 Rf2 75. Ke3 Rc2 76. Kd3 Rf2 77.\nKe3 Rc2 78. Kd",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Rad1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Nxd7",
            "Bxd7",
            "Rxd7",
            "Nc6",
            "Rxb7",
            "Nxe5",
            "Rd1",
            "Rhc8",
            "c3",
            "a5",
            "Rd4",
            "f3",
            "Bxf3",
            "Nxf3+",
            "gxf3",
            "h3",
            "Rg4+",
            "Kf6",
            "Rf4+",
            "Ke5",
            "Rfxf7",
            "Rg8+",
            "Kf1",
            "Rg2",
            "Rb5+",
            "Kd6",
            "Rh5",
            "Rxh2",
            "Rfh7",
            "Rb8",
            "b3",
            "a4",
            "b4",
            "Rc8",
            "Rc5",
            "Rxc5",
            "bxc5+",
            "Kxc5",
            "Rh4",
            "a3",
            "Kg1",
            "Rg2+",
            "Kf1",
            "Rh2",
            "Ra4",
            "Rh1+",
            "Ke2",
            "h2",
            "Rh4",
            "Ra1",
            "Rxh2",
            "Rxa2+",
            "Kd3",
            "Rb2",
            "Rh5+",
            "Kb6",
            "Rh8",
            "a2",
            "Ra8",
            "Rxf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2",
            "Kd3",
            "Rf2",
            "Ke3",
            "Rc2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd6+",
          "positional_uci": "d1d6",
          "positional_response": "16. Qd6+ Kg7 17. Rad1 Qe7 18. Qxe7 Nxe7 19. Nxd7 Bxd7 20. Rxd7 Nc6 21. Rxb7\nNxe5 22. Rd1 Rhb8 23. Rxb8 Rxb8 24. b3 Rc8 25. c4 Kf6 26. Rd4 Kf5 27. Bd3+ Nxd3\n28. Rxd3 Ke4 29. Rd7 f5 30. Kf1 f3 31. gxf3+ Kxf3 32. Rd3+ Ke4 33. Ke2 e5 34.\nf3+ Kf4 35. Rd7 Rg8 36. Kf2 h3 37. Rh7 Rg2+ 38. Kf1 Rxh2 39. Kg1 Rg2+ 40. Kh1\nKg3 41. Rg7+ Kxf3 42. Rh7 h2 43. Rxh2 Rxh2+ 44. Kxh2 e4 45. c5 e3 46. c6 e2\n47. c7 e1=Q 48. c8=Q Qg3+ 49. Kh1 Qg2# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Kg7 Rad1 Qe7 Qxe7 Nxe7 Nxd7 Bxd7 Rxd7 Nc6 Rxb7 Nxe5 Rd1 Rhb8 Rxb8 Rxb8 b3 Rc8 c4 Kf6 Rd4 Kf5 Bd3+ Nxd3 Rxd3 Ke4 Rd7 f5 Kf1 f3 gxf3+ Kxf3 Rd7 Ke4 Rd3+ Ke5 Rd2+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd6+ Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5 Rd5+ Ke6 Rd3 Ke5",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Rad1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Nxd7",
            "Bxd7",
            "Rxd7",
            "Nc6",
            "Rxb7",
            "Nxe5",
            "Rd1",
            "Rhb8",
            "Rxb8",
            "Rxb8",
            "b3",
            "Rc8",
            "c4",
            "Kf6",
            "Rd4",
            "Kf5",
            "Bd3+",
            "Nxd3",
            "Rxd3",
            "Ke4",
            "Rd7",
            "f5",
            "Kf1",
            "f3",
            "gxf3+",
            "Kxf3",
            "Rd7",
            "Ke4",
            "Rd3+",
            "Ke5",
            "Rd2+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd6+",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5",
            "Rd5+",
            "Ke6",
            "Rd3",
            "Ke5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd6+",
          "neutral_uci": "d1d6",
          "neutral_response": "16. Qd6+ Kg7 17. Rad1 Qe7 18. Qxe7 Nxe7 19. Nxd7 Bxd7 20. Rxd7 Nc6 21. Rxb7 Nxe5\n22. Rd1 Rhb8 23. Rxb8 Rxb8 24. b3 Rc8 25. c4 Kf6 26. Rd4 Kf5 27. Bd3+ Nxd3 28.\nRxd3 e5 29. f3 Ke6 30. Kf2 f5 31. Rd5 e4 32. fxe4 fxe4 33. Rh5 Rd8 34. Ke2 Rg8\n35. Kf2 Rd8 36. Ke2 Rg8 37. Kf2 Rd8 38. Ke2 Rg8 39. Kf2 Rd8 40. Ke2 Rg8 41. Kf2 Rd8 42. Ke2 Rg8 43. Kf2 Rd8 44. Ke2 Rg8 45. Kf2 Rd8 46. Ke2 Rg8 47. Kf2 Rd8 48. Ke2 Rg8 49. Kf2 Rd8 50. Ke2 Rg8 51. Kf2 Rd8 52. Ke2 Rg8 53. Kf2 Rd8 54. Ke2 Rg8 55. Kf2 Rd8 56. Ke2 Rg8 57. Kf2 Rd8 58. Ke2 Rg8 59. Kf2 Rd8 60. Ke2 Rg8 61. Kf2 Rd8 62. Ke2 Rg8 63. Kf2 Rd8 64. Ke2 Rg8 65. Kf2 Rd8 66. Ke2 Rg8 67. Kf2 Rd8 68. Ke2 Rg8 69. Kf2 Rd8 70. Ke2 Rg8 71. Kf2 Rd8 72. Ke2 Rg8 73. Kf2 Rd8 74. Ke2 Rg8 75. Kf2 Rd8 76. Ke2 Rg8 77. Kf2 Rd8 78. Ke2 Rg8 79. Kf2 Rd8 80. Ke2 Rg8 81. Kf2 Rd8 82. Ke2 Rg8 83. Kf2 Rd8 84. Ke2 Rg8 85. Kf2 Rd8 86. Ke2 Rg8 87. Kf2 Rd8 88. Ke2 Rg8 89. Kf2 Rd8 90. Ke2 Rg8 91. Kf2 Rd8 92. Ke2 Rg8 93. Kf2 Rd8 94. Ke2 Rg8 95. K",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 640,
            "total_tokens": 870,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Rad1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Nxd7",
            "Bxd7",
            "Rxd7",
            "Nc6",
            "Rxb7",
            "Nxe5",
            "Rd1",
            "Rhb8",
            "Rxb8",
            "Rxb8",
            "b3",
            "Rc8",
            "c4",
            "Kf6",
            "Rd4",
            "Kf5",
            "Bd3+",
            "Nxd3",
            "Rxd3",
            "e5",
            "f3",
            "Ke6",
            "Kf2",
            "f5",
            "Rd5",
            "e4",
            "fxe4",
            "fxe4",
            "Rh5",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8",
            "Kf2",
            "Rd8",
            "Ke2",
            "Rg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1d6",
          "positional_uci": "d1d6",
          "neutral_uci": "d1d6",
          "consensus_move": "d1d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg7",
              "Rad1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Nxd7",
              "Bxd7",
              "Rxd7",
              "Nc6",
              "Rxb7",
              "Nxe5",
              "Rd1",
              "Rhc8",
              "c3",
              "a5",
              "Rd4",
              "f3",
              "Bxf3",
              "Nxf3+",
              "gxf3",
              "h3",
              "Rg4+",
              "Kf6",
              "Rf4+",
              "Ke5",
              "Rfxf7",
              "Rg8+",
              "Kf1",
              "Rg2",
              "Rb5+",
              "Kd6",
              "Rh5",
              "Rxh2",
              "Rfh7",
              "Rb8",
              "b3",
              "a4",
              "b4",
              "Rc8",
              "Rc5",
              "Rxc5",
              "bxc5+",
              "Kxc5",
              "Rh4",
              "a3",
              "Kg1",
              "Rg2+",
              "Kf1",
              "Rh2",
              "Ra4",
              "Rh1+",
              "Ke2",
              "h2",
              "Rh4",
              "Ra1",
              "Rxh2",
              "Rxa2+",
              "Kd3",
              "Rb2",
              "Rh5+",
              "Kb6",
              "Rh8",
              "a2",
              "Ra8",
              "Rxf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2",
              "Kd3",
              "Rf2",
              "Ke3",
              "Rc2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg7",
              "Rad1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Nxd7",
              "Bxd7",
              "Rxd7",
              "Nc6",
              "Rxb7",
              "Nxe5",
              "Rd1",
              "Rhb8",
              "Rxb8",
              "Rxb8",
              "b3",
              "Rc8",
              "c4",
              "Kf6",
              "Rd4",
              "Kf5",
              "Bd3+",
              "Nxd3",
              "Rxd3",
              "Ke4",
              "Rd7",
              "f5",
              "Kf1",
              "f3",
              "gxf3+",
              "Kxf3",
              "Rd7",
              "Ke4",
              "Rd3+",
              "Ke5",
              "Rd2+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd6+",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5",
              "Rd5+",
              "Ke6",
              "Rd3",
              "Ke5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg7",
              "Rad1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Nxd7",
              "Bxd7",
              "Rxd7",
              "Nc6",
              "Rxb7",
              "Nxe5",
              "Rd1",
              "Rhb8",
              "Rxb8",
              "Rxb8",
              "b3",
              "Rc8",
              "c4",
              "Kf6",
              "Rd4",
              "Kf5",
              "Bd3+",
              "Nxd3",
              "Rxd3",
              "e5",
              "f3",
              "Ke6",
              "Kf2",
              "f5",
              "Rd5",
              "e4",
              "fxe4",
              "fxe4",
              "Rh5",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8",
              "Kf2",
              "Rd8",
              "Ke2",
              "Rg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 640,
            "total_tokens": 870,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 1920,
          "total_tokens": 2612
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 640,
            "total_tokens": 870,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bq1k1r/pp1p1p2/2n1pN2/4P3/5p1p/8/PPP1BPPP/R2Q1RK1 w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe7+",
          "aggressive_uci": "d6e7",
          "aggressive_response": "17. Qxe7+ Kxe7 18. Ng4 Rh5 19. Rfe1 Nxe5 20. Nxe5 Rxe5 21. Bf3 Rxe1+ 22. Rxe1 d6 23. Re4 e5 24. Rb4 Rb8 25. g3 hxg3 26. hxg3 fxg3 27. fxg3 b6 28. Ra4 a5 29. b4 Bd7 30. Ra3 axb4 31. Rb3 Be6 32. Rxb4 Bxa2 33. c4 Rc8 34. Bd5 Rc5 35. Rxb6 Bxc4 36. Rb7+ Kf6 37. Bxc4 Rxc4 38. Kf2 Ke6 39. Ke3 f5 40. Rb8 Rc3+ 41. Kf2 Kd5 42. Rf8 Ke4 43. Rd8 d5 44. Ra8 d4 45. Ra4 Rc2+ 46. Ke1 Ke3 47. Ra3+ d3 48. Kd1 e4 49. Ra5 Rg2 50. Kc1 d2+ 51. Kc2 Rg1 52. Ra3+ Ke2 53. Ra1 Rxa1 54. g4 d1=Q+ 55. Kc3 Rc1+ 56. Kb4 Qd4+ 57. Kb5 Qb2+ 58. Ka4 Ra1# e4 d5 c4",
          "aggressive_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 354,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxe7",
            "Ng4",
            "Rh5",
            "Rfe1",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Bf3",
            "Rxe1+",
            "Rxe1",
            "d6",
            "Re4",
            "e5",
            "Rb4",
            "Rb8",
            "g3",
            "hxg3",
            "hxg3",
            "fxg3",
            "fxg3",
            "b6",
            "Ra4",
            "a5",
            "b4",
            "Bd7",
            "Ra3",
            "axb4",
            "Rb3",
            "Be6",
            "Rxb4",
            "Bxa2",
            "c4",
            "Rc8",
            "Bd5",
            "Rc5",
            "Rxb6",
            "Bxc4",
            "Rb7+",
            "Kf6",
            "Bxc4",
            "Rxc4",
            "Kf2",
            "Ke6",
            "Ke3",
            "f5",
            "Rb8",
            "Rc3+",
            "Kf2",
            "Kd5",
            "Rf8",
            "Ke4",
            "Rd8",
            "d5",
            "Ra8",
            "d4",
            "Ra4",
            "Rc2+",
            "Ke1",
            "Ke3",
            "Ra3+",
            "d3",
            "Kd1",
            "e4",
            "Ra5",
            "Rg2",
            "Kc1",
            "d2+",
            "Kc2",
            "Rg1",
            "Ra3+",
            "Ke2",
            "Ra1",
            "Rxa1",
            "g4",
            "d1=Q+",
            "Kc3",
            "Rc1+",
            "Kb4",
            "Qd4+",
            "Kb5",
            "Qb2+",
            "Ka4",
            "Ra1#",
            "e4",
            "d5",
            "c4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe7+",
          "positional_uci": "d6e7",
          "positional_response": "17. Qxe7+ Kxe7 18. Ng4 Rh5 19. Rfe1 Nxe5 20. Nxe5 Rxe5 21. Bf3 Rxe1+ 22. Rxe1 d6 23. Re4 e5 24. Rb4 Rb8 25. g3 hxg3 26. hxg3 fxg3 27. fxg3 b6 28. Ra4 a5 29. b4 Bd7 30. Ra3 axb4 31. Rb3 Rc8 32. Rxb4 Rxc2 33. Rxb6 Rxa2 34. Rb7 Ke6 35. Bg4+ f5 36. Bxf5+ Kxf5 37. Rxd7 Rd2 38. Kf1 Kg4 39. Rg7+ Kf3 40. Ke1 Rg2 41. Rd7 Ke3 42. Kf1 Rd2 43. g4 d5 44. g5 d4 45. g6 Rf2+ 46. Kg1 Rf6 47. g7 Rg6+ 48. Kf1 d3 49. Re7 e4 50. Rd7 d2 51. Rd8 Rxg7 52. Rd6 Rf7+ 53. Kg2 Ke2 54. Rd4 e3 55. Rd5 d1=Q 56. Rxd1 Kxd1 57. Kg3 e2 58. Kg4 e1=Q 59. Kg5 Qg1+ 60. Kh6 Rf2 61. Kh5 Rh2# 0-1",
          "positional_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 374,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxe7",
            "Ng4",
            "Rh5",
            "Rfe1",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Bf3",
            "Rxe1+",
            "Rxe1",
            "d6",
            "Re4",
            "e5",
            "Rb4",
            "Rb8",
            "g3",
            "hxg3",
            "hxg3",
            "fxg3",
            "fxg3",
            "b6",
            "Ra4",
            "a5",
            "b4",
            "Bd7",
            "Ra3",
            "axb4",
            "Rb3",
            "Rc8",
            "Rxb4",
            "Rxc2",
            "Rxb6",
            "Rxa2",
            "Rb7",
            "Ke6",
            "Bg4+",
            "f5",
            "Bxf5+",
            "Kxf5",
            "Rxd7",
            "Rd2",
            "Kf1",
            "Kg4",
            "Rg7+",
            "Kf3",
            "Ke1",
            "Rg2",
            "Rd7",
            "Ke3",
            "Kf1",
            "Rd2",
            "g4",
            "d5",
            "g5",
            "d4",
            "g6",
            "Rf2+",
            "Kg1",
            "Rf6",
            "g7",
            "Rg6+",
            "Kf1",
            "d3",
            "Re7",
            "e4",
            "Rd7",
            "d2",
            "Rd8",
            "Rxg7",
            "Rd6",
            "Rf7+",
            "Kg2",
            "Ke2",
            "Rd4",
            "e3",
            "Rd5",
            "d1=Q",
            "Rxd1",
            "Kxd1",
            "Kg3",
            "e2",
            "Kg4",
            "e1=Q",
            "Kg5",
            "Qg1+",
            "Kh6",
            "Rf2",
            "Kh5",
            "Rh2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe7+",
          "neutral_uci": "d6e7",
          "neutral_response": "17. Qxe7+ Kxe7 18. Ng4 Rh5 19. Rfe1 Nxe5 20. Nxe5 Rxe5 21. Bf3 Rxe1+ 22. Rxe1 d6 23. Re4 e5 24. Rb4 Rb8 25. g3 hxg3 26. hxg3 fxg3 27. fxg3 b6 28. Ra4 a5 29. Rh4 Be6 30. a3 Rc8 31. c3 Rc4 32. Rh8 Rc8 33. Rh4 Rc4 34. Rh8 Rc8 35. Rh4 Rc4 36. Rh8 Rc8 37. Rh4 Rc4 38. Rh8 Rc8 39. Rh4 Rc4 40. Rh8 Rc8 41. Rh4 Rc4 42. Rh8 Rc8 43. Rh4 Rc4 44. Rh8 Rc8 45. Rh4 Rc4 46. Rh8 Rc8 47. Rh4 Rc4 48. Rh8 Rc8 49. Rh4 Rc4 50. Rh8 Rc8 51. Rh4 Rc4 52. Rh8 Rc8 53. Rh4 Rc4 54. Rh8 Rc8 55. Rh4 Rc4 56. Rh8 Rc8 57. Rh4 Rc4 58. Rh8 Rc8 59. Rh4 Rc4 60. Rh8 Rc8 61. Rh4 Rc4 62. Rh8 Rc8 63. Rh4 Rc4 64. Rh8 Rc8 65. Rh4 Rc4 66. Rh8 Rc8 67. Rh4 Rc4 68. Rh8 Rc8 69. Rh4 Rc4 70. Rh8 Rc8 71. Rh4 Rc4 72. Rh8 Rc8 73. Rh4 Rc4 74. Rh8 Rc8 75. Rh4 Rc4 76. Rh8 Rc8 77. Rh4 Rc4 78. Rh8 Rc8 79. Rh4 Rc4 80. Rh8 Rc8 81. Rh4 Rc4 82. Rh8 Rc8 83. Rh4 Rc4 84. Rh8 Rc8 85. Rh4 Rc4 86. Rh8 Rc8 87. Rh4 Rc4 88. Rh8 Rc8 89. Rh4 Rc4 90. Rh8 Rc8 91. Rh4 Rc4 92. Rh8 Rc8 93. Rh4 Rc4 94. Rh8 Rc8 95. Rh4 Rc4 96. Rh8 Rc8 97. Rh4 Rc4 98. Rh8 Rc8 99. Rh4 Rc4 100. Rh8 Rc8 101. Rh4 Rc4 102. Rh8 Rc8 103. Rh4 Rc4 104. Rh8 Rc8 105. Rh4 Rc4",
          "neutral_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxe7",
            "Ng4",
            "Rh5",
            "Rfe1",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Bf3",
            "Rxe1+",
            "Rxe1",
            "d6",
            "Re4",
            "e5",
            "Rb4",
            "Rb8",
            "g3",
            "hxg3",
            "hxg3",
            "fxg3",
            "fxg3",
            "b6",
            "Ra4",
            "a5",
            "Rh4",
            "Be6",
            "a3",
            "Rc8",
            "c3",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4",
            "Rh8",
            "Rc8",
            "Rh4",
            "Rc4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d6e7",
          "positional_uci": "d6e7",
          "neutral_uci": "d6e7",
          "consensus_move": "d6e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxe7",
              "Ng4",
              "Rh5",
              "Rfe1",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Bf3",
              "Rxe1+",
              "Rxe1",
              "d6",
              "Re4",
              "e5",
              "Rb4",
              "Rb8",
              "g3",
              "hxg3",
              "hxg3",
              "fxg3",
              "fxg3",
              "b6",
              "Ra4",
              "a5",
              "b4",
              "Bd7",
              "Ra3",
              "axb4",
              "Rb3",
              "Be6",
              "Rxb4",
              "Bxa2",
              "c4",
              "Rc8",
              "Bd5",
              "Rc5",
              "Rxb6",
              "Bxc4",
              "Rb7+",
              "Kf6",
              "Bxc4",
              "Rxc4",
              "Kf2",
              "Ke6",
              "Ke3",
              "f5",
              "Rb8",
              "Rc3+",
              "Kf2",
              "Kd5",
              "Rf8",
              "Ke4",
              "Rd8",
              "d5",
              "Ra8",
              "d4",
              "Ra4",
              "Rc2+",
              "Ke1",
              "Ke3",
              "Ra3+",
              "d3",
              "Kd1",
              "e4",
              "Ra5",
              "Rg2",
              "Kc1",
              "d2+",
              "Kc2",
              "Rg1",
              "Ra3+",
              "Ke2",
              "Ra1",
              "Rxa1",
              "g4",
              "d1=Q+",
              "Kc3",
              "Rc1+",
              "Kb4",
              "Qd4+",
              "Kb5",
              "Qb2+",
              "Ka4",
              "Ra1#",
              "e4",
              "d5",
              "c4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxe7",
              "Ng4",
              "Rh5",
              "Rfe1",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Bf3",
              "Rxe1+",
              "Rxe1",
              "d6",
              "Re4",
              "e5",
              "Rb4",
              "Rb8",
              "g3",
              "hxg3",
              "hxg3",
              "fxg3",
              "fxg3",
              "b6",
              "Ra4",
              "a5",
              "b4",
              "Bd7",
              "Ra3",
              "axb4",
              "Rb3",
              "Rc8",
              "Rxb4",
              "Rxc2",
              "Rxb6",
              "Rxa2",
              "Rb7",
              "Ke6",
              "Bg4+",
              "f5",
              "Bxf5+",
              "Kxf5",
              "Rxd7",
              "Rd2",
              "Kf1",
              "Kg4",
              "Rg7+",
              "Kf3",
              "Ke1",
              "Rg2",
              "Rd7",
              "Ke3",
              "Kf1",
              "Rd2",
              "g4",
              "d5",
              "g5",
              "d4",
              "g6",
              "Rf2+",
              "Kg1",
              "Rf6",
              "g7",
              "Rg6+",
              "Kf1",
              "d3",
              "Re7",
              "e4",
              "Rd7",
              "d2",
              "Rd8",
              "Rxg7",
              "Rd6",
              "Rf7+",
              "Kg2",
              "Ke2",
              "Rd4",
              "e3",
              "Rd5",
              "d1=Q",
              "Rxd1",
              "Kxd1",
              "Kg3",
              "e2",
              "Kg4",
              "e1=Q",
              "Kg5",
              "Qg1+",
              "Kh6",
              "Rf2",
              "Kh5",
              "Rh2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxe7",
              "Ng4",
              "Rh5",
              "Rfe1",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Bf3",
              "Rxe1+",
              "Rxe1",
              "d6",
              "Re4",
              "e5",
              "Rb4",
              "Rb8",
              "g3",
              "hxg3",
              "hxg3",
              "fxg3",
              "fxg3",
              "b6",
              "Ra4",
              "a5",
              "Rh4",
              "Be6",
              "a3",
              "Rc8",
              "c3",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4",
              "Rh8",
              "Rc8",
              "Rh4",
              "Rc4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 241,
            "completion_tokens": 354,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 241,
            "completion_tokens": 374,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 722,
          "total_completion_tokens": 1368,
          "total_tokens": 2090
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 241,
            "completion_tokens": 354,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 241,
            "completion_tokens": 374,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b2k1r/pp1pqp2/2nQpN2/4P3/5p1p/8/PPP1BPPP/R4RK1 w - - 2 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ng4",
          "aggressive_uci": "f6g4",
          "aggressive_response": "18. Ng4 Nd4 19. Bd3 b6 20. c3 Nc6 21. Be4 Bb7 22. Rad1 Rag8 23. Nf6 Rd8 24. Bxc6 Bxc6\n25. Rd4 f3 26. g3 hxg3 27. fxg3 d6 28. Ng4 dxe5 29. Rxd8 Rxd8 30. Nxe5 Bb7 31.\nNxf3 Rd3 32. Ne5 Rd2 33. Rxf7+ Kd6 34. Nc4+ Kc5 35. Nxd2 Bd5 36. Rxa7 b5 37. b4+\nKb6 38. Rd7 Kc6 39. Rxd5 exd5 40. h4 Kd6 41. h5 Ke6 42. g4 Kf6 43. Nf3 Kg7 44.\ng5 Kh7 45. Nd4 Kg7 46. Nxb5 Kh7 47. Nc7 Kg7 48. Nxd5 Kh7 49. b5 Kg7 50. b6 Kh7\n51. b7 Kg7 52. b8=Q Kh7 53. Qc7+ Kh8 54. Qd8+ Kh7 55. Qe7+ Kh8 56. Qf8+ Kh7 57.\nNf6# c5 Nc6 d5",
          "aggressive_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Rxd8",
            "Rxd8",
            "Nxe5",
            "Bb7",
            "Nxf3",
            "Rd3",
            "Ne5",
            "Rd2",
            "Rxf7+",
            "Kd6",
            "Nc4+",
            "Kc5",
            "Nxd2",
            "Bd5",
            "Rxa7",
            "b5",
            "b4+",
            "Kb6",
            "Rd7",
            "Kc6",
            "Rxd5",
            "exd5",
            "h4",
            "Kd6",
            "h5",
            "Ke6",
            "g4",
            "Kf6",
            "Nf3",
            "Kg7",
            "g5",
            "Kh7",
            "Nd4",
            "Kg7",
            "Nxb5",
            "Kh7",
            "Nc7",
            "Kg7",
            "Nxd5",
            "Kh7",
            "b5",
            "Kg7",
            "b6",
            "Kh7",
            "b7",
            "Kg7",
            "b8=Q",
            "Kh7",
            "Qc7+",
            "Kh8",
            "Qd8+",
            "Kh7",
            "Qe7+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Nf6#",
            "c5",
            "Nc6",
            "d5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ng4",
          "positional_uci": "f6g4",
          "positional_response": "18. Ng4 Nd4 19. Bd3 Rg8 20. h3 b6 21. Be4 Rb8 22. Rad1 Nf5 23. Bxf5 exf5 24. Nf6 Rg6 25. Nd5+ Kf8 26. Nxf4 Rg5 27. Rd6 Bb7 28. Rxd7 Bc6 29. Rc7 Be4 30. Rd1 Re8 31. Rdd7 Rg7 32. e6 Kg8 33. exf7+ Rxf7 34. Rxf7 Rd8 35. Rg7+ Kf8 36. Ng6+ Ke8 37. Rce7# Bb7 38. Rg8# 1-0\nNf6 gxf6 Qd6+ Qe7 Qxe7+ Kxe7 Nd5+ Kf8 Nf6+ Kg7 Nxd7 Bxd7 Rad1 Bc6 Rd6 Rac8 Rfd1 Rhe8 f4 Kg6 Kf2 Kf5 Ke3 Rg8 R1d2 Rg3+ Kf2 Rcg8 Kf1 Bb5+ Kg1 Rxh3 R6d3 Rxd3 Rxd3 Rg3 Rxg3 fxg3 Kf1 Ke4 Ke2 Bc4+ Kd2 Kd4 b3 Bd5 g4 Ke4 f5 Kxe5 fxe6 fxe6 Kc3 Kf4 Kb4 Kxg4 Kb5 Kf4 a4 Ke4 a5 Kd4 a6 Kc5 a7 Kxb6 a8=Q Kc5 Qa5+ Kd6 Qb6+ Ke5 Qc5+ Kf6 Qd6 Kg5 Qe5+ Kh6 Qf6+ Kh7 Kg5 Kg8 Qe7 Kh8 Kg6 Kg8 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 424,
            "total_tokens": 675,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Bd3",
            "Rg8",
            "h3",
            "b6",
            "Be4",
            "Rb8",
            "Rad1",
            "Nf5",
            "Bxf5",
            "exf5",
            "Nf6",
            "Rg6",
            "Nd5+",
            "Kf8",
            "Nxf4",
            "Rg5",
            "Rd6",
            "Bb7",
            "Rxd7",
            "Bc6",
            "Rc7",
            "Be4",
            "Rd1",
            "Re8",
            "Rdd7",
            "Rg7",
            "e6",
            "Kg8",
            "exf7+",
            "Rxf7",
            "Rxf7",
            "Rd8",
            "Rg7+",
            "Kf8",
            "Ng6+",
            "Ke8",
            "Rce7#",
            "Bb7",
            "Rg8#",
            "Nf6",
            "gxf6",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Nd5+",
            "Kf8",
            "Nf6+",
            "Kg7",
            "Nxd7",
            "Bxd7",
            "Rad1",
            "Bc6",
            "Rd6",
            "Rac8",
            "Rfd1",
            "Rhe8",
            "f4",
            "Kg6",
            "Kf2",
            "Kf5",
            "Ke3",
            "Rg8",
            "R1d2",
            "Rg3+",
            "Kf2",
            "Rcg8",
            "Kf1",
            "Bb5+",
            "Kg1",
            "Rxh3",
            "R6d3",
            "Rxd3",
            "Rxd3",
            "Rg3",
            "Rxg3",
            "fxg3",
            "Kf1",
            "Ke4",
            "Ke2",
            "Bc4+",
            "Kd2",
            "Kd4",
            "b3",
            "Bd5",
            "g4",
            "Ke4",
            "f5",
            "Kxe5",
            "fxe6",
            "fxe6",
            "Kc3",
            "Kf4",
            "Kb4",
            "Kxg4",
            "Kb5",
            "Kf4",
            "a4",
            "Ke4",
            "a5",
            "Kd4",
            "a6",
            "Kc5",
            "a7",
            "Kxb6",
            "a8=Q",
            "Kc5",
            "Qa5+",
            "Kd6",
            "Qb6+",
            "Ke5",
            "Qc5+",
            "Kf6",
            "Qd6",
            "Kg5",
            "Qe5+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Kg5",
            "Kg8",
            "Qe7",
            "Kh8",
            "Kg6",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ng4",
          "neutral_uci": "f6g4",
          "neutral_response": "18. Ng4 Nd4 19. Bd3 b6 20. c3 Nc6 21. Be4 Bb7 22. Rad1 Rag8 23. h3 Rg5 24. Rfe1 Rhh5\n25. Nf6 Rxe5 26. Nxh5 Rxh5 27. Bf3 Rg5 28. Re4 Ne5 29. Rxf4 Nxf3+ 30. Kh1 Ne5\n31. f3 Ng6 32. Rfd4 Bc6 33. b4 a6 34. c4 b5 35. c5 f5 36. Kh2 e5 37. Rd6 Nf4\n38. R1d2 e4 39. fxe4 fxe4 40. Rh6 e3 41. Rh7+ Kd8 42. Rd6 Rxg2+ 43. Kh1 Rg7+ 44. Kh2 Rxh7 45. Rxc6 dxc6 46. a4 Rg7 47. axb5 Rg2+ 48. Kh1 e2 49. bxc6 e1=Q#",
          "neutral_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 262,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Bd3",
            "b6",
            "c3",
            "Nc6",
            "Be4",
            "Bb7",
            "Rad1",
            "Rag8",
            "h3",
            "Rg5",
            "Rfe1",
            "Rhh5",
            "Nf6",
            "Rxe5",
            "Nxh5",
            "Rxh5",
            "Bf3",
            "Rg5",
            "Re4",
            "Ne5",
            "Rxf4",
            "Nxf3+",
            "Kh1",
            "Ne5",
            "f3",
            "Ng6",
            "Rfd4",
            "Bc6",
            "b4",
            "a6",
            "c4",
            "b5",
            "c5",
            "f5",
            "Kh2",
            "e5",
            "Rd6",
            "Nf4",
            "R1d2",
            "e4",
            "fxe4",
            "fxe4",
            "Rh6",
            "e3",
            "Rh7+",
            "Kd8",
            "Rd6",
            "Rxg2+",
            "Kh1",
            "Rg7+",
            "Kh2",
            "Rxh7",
            "Rxc6",
            "dxc6",
            "a4",
            "Rg7",
            "axb5",
            "Rg2+",
            "Kh1",
            "e2",
            "bxc6",
            "e1=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6g4",
          "positional_uci": "f6g4",
          "neutral_uci": "f6g4",
          "consensus_move": "f6g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxe5",
              "Rxd8",
              "Rxd8",
              "Nxe5",
              "Bb7",
              "Nxf3",
              "Rd3",
              "Ne5",
              "Rd2",
              "Rxf7+",
              "Kd6",
              "Nc4+",
              "Kc5",
              "Nxd2",
              "Bd5",
              "Rxa7",
              "b5",
              "b4+",
              "Kb6",
              "Rd7",
              "Kc6",
              "Rxd5",
              "exd5",
              "h4",
              "Kd6",
              "h5",
              "Ke6",
              "g4",
              "Kf6",
              "Nf3",
              "Kg7",
              "g5",
              "Kh7",
              "Nd4",
              "Kg7",
              "Nxb5",
              "Kh7",
              "Nc7",
              "Kg7",
              "Nxd5",
              "Kh7",
              "b5",
              "Kg7",
              "b6",
              "Kh7",
              "b7",
              "Kg7",
              "b8=Q",
              "Kh7",
              "Qc7+",
              "Kh8",
              "Qd8+",
              "Kh7",
              "Qe7+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Nf6#",
              "c5",
              "Nc6",
              "d5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nd4",
              "Bd3",
              "Rg8",
              "h3",
              "b6",
              "Be4",
              "Rb8",
              "Rad1",
              "Nf5",
              "Bxf5",
              "exf5",
              "Nf6",
              "Rg6",
              "Nd5+",
              "Kf8",
              "Nxf4",
              "Rg5",
              "Rd6",
              "Bb7",
              "Rxd7",
              "Bc6",
              "Rc7",
              "Be4",
              "Rd1",
              "Re8",
              "Rdd7",
              "Rg7",
              "e6",
              "Kg8",
              "exf7+",
              "Rxf7",
              "Rxf7",
              "Rd8",
              "Rg7+",
              "Kf8",
              "Ng6+",
              "Ke8",
              "Rce7#",
              "Bb7",
              "Rg8#",
              "Nf6",
              "gxf6",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Nd5+",
              "Kf8",
              "Nf6+",
              "Kg7",
              "Nxd7",
              "Bxd7",
              "Rad1",
              "Bc6",
              "Rd6",
              "Rac8",
              "Rfd1",
              "Rhe8",
              "f4",
              "Kg6",
              "Kf2",
              "Kf5",
              "Ke3",
              "Rg8",
              "R1d2",
              "Rg3+",
              "Kf2",
              "Rcg8",
              "Kf1",
              "Bb5+",
              "Kg1",
              "Rxh3",
              "R6d3",
              "Rxd3",
              "Rxd3",
              "Rg3",
              "Rxg3",
              "fxg3",
              "Kf1",
              "Ke4",
              "Ke2",
              "Bc4+",
              "Kd2",
              "Kd4",
              "b3",
              "Bd5",
              "g4",
              "Ke4",
              "f5",
              "Kxe5",
              "fxe6",
              "fxe6",
              "Kc3",
              "Kf4",
              "Kb4",
              "Kxg4",
              "Kb5",
              "Kf4",
              "a4",
              "Ke4",
              "a5",
              "Kd4",
              "a6",
              "Kc5",
              "a7",
              "Kxb6",
              "a8=Q",
              "Kc5",
              "Qa5+",
              "Kd6",
              "Qb6+",
              "Ke5",
              "Qc5+",
              "Kf6",
              "Qd6",
              "Kg5",
              "Qe5+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Kg5",
              "Kg8",
              "Qe7",
              "Kh8",
              "Kg6",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nd4",
              "Bd3",
              "b6",
              "c3",
              "Nc6",
              "Be4",
              "Bb7",
              "Rad1",
              "Rag8",
              "h3",
              "Rg5",
              "Rfe1",
              "Rhh5",
              "Nf6",
              "Rxe5",
              "Nxh5",
              "Rxh5",
              "Bf3",
              "Rg5",
              "Re4",
              "Ne5",
              "Rxf4",
              "Nxf3+",
              "Kh1",
              "Ne5",
              "f3",
              "Ng6",
              "Rfd4",
              "Bc6",
              "b4",
              "a6",
              "c4",
              "b5",
              "c5",
              "f5",
              "Kh2",
              "e5",
              "Rd6",
              "Nf4",
              "R1d2",
              "e4",
              "fxe4",
              "fxe4",
              "Rh6",
              "e3",
              "Rh7+",
              "Kd8",
              "Rd6",
              "Rxg2+",
              "Kh1",
              "Rg7+",
              "Kh2",
              "Rxh7",
              "Rxc6",
              "dxc6",
              "a4",
              "Rg7",
              "axb5",
              "Rg2+",
              "Kh1",
              "e2",
              "bxc6",
              "e1=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 251,
            "completion_tokens": 424,
            "total_tokens": 675,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 250,
            "completion_tokens": 262,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 752,
          "total_completion_tokens": 1015,
          "total_tokens": 1767
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 251,
            "completion_tokens": 424,
            "total_tokens": 675,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 250,
            "completion_tokens": 262,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b4r/pp1pkp2/2n1pN2/4P3/5p1p/8/PPP1BPPP/R4RK1 w - - 0 18"
    },
    {
      "turn": 37,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g3",
          "aggressive_uci": "g2g3",
          "aggressive_response": "19. g3 Nd4 20. Bd3 Nf3+ 21. Kh1 b6 22. Be4 Nd2 23. Bxa8 Nxf1 24. Rxf1 Ba6 25.\nRd1 Rxa8 26. Nf6 Bb7+ 27. Kg1 Bc6 28. gxf4 Rh8 29. Rd3 Rh4 30. Rd4 Rh6 31. Kf1\nRg6 32. Ke2 Rg2 33. Rd3 Rxh2 34. Rg3 Rh1 35. Rg8 d6 36. Rc8 Bb5+ 37. c4 Ba4 38.\nb3 h2 39. Rh8 Bc6 40. f3 dxe5 41. fxe5 Ra1 42. Rxh2 Rxa2+ 43. Ke3 Rxh2 44. b4\nRh3 45. b5 Bxf3 46. Kd4 Be2 47. c5 bxc5+ 48. Kxc5 Rc3+ 49. Kb4 Rc4+ 50. Ka5 Rc5\n51. Ka6 Bxb5+ 52. Kxa7 Rxe5 53. Ng8+ Kd6 54. Kb6 f5 55. Nf6 f4 56. Ng4 f3 57.\nNf2 Re2 58. Ng4 f2 59. Nxf2 Rxf2 60. Kxb5 Rc2 61. Kb4 e5 62. Kb3 Rc8 63. Kb4\ne4 64. Kb5 e3 65. Kb6 e2 66. Kb7 Rc1 67. Kb6 e1=Q 68. Kb5 Qc3 69. Kb6 Qb2+ 70.\nKa5 Ra1# 1-0\n\nh3 g5 f4 Nd4 Bxd4 Kf8 Nf6 gxf6 Qd6 Qe7 Qxe7 Kxe7 Nf3 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Nf3 g5 Nd4 Kf8 Nf5 d6 Nxd6 Bxh3 Bxh3 Rxh3 Rxh3 Kg7 Rh1 Rh8 Rg1 Rh4 Rd1 Rh6 Kf1 Rg6 Ke2 Rf6 Kd3 Rg6 Kc4 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg6 Ka5 Rf6 Kb5 Rg",
          "aggressive_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nd4",
            "Bd3",
            "Nf3+",
            "Kh1",
            "b6",
            "Be4",
            "Nd2",
            "Bxa8",
            "Nxf1",
            "Rxf1",
            "Ba6",
            "Rd1",
            "Rxa8",
            "Nf6",
            "Bb7+",
            "Kg1",
            "Bc6",
            "gxf4",
            "Rh8",
            "Rd3",
            "Rh4",
            "Rd4",
            "Rh6",
            "Kf1",
            "Rg6",
            "Ke2",
            "Rg2",
            "Rd3",
            "Rxh2",
            "Rg3",
            "Rh1",
            "Rg8",
            "d6",
            "Rc8",
            "Bb5+",
            "c4",
            "Ba4",
            "b3",
            "h2",
            "Rh8",
            "Bc6",
            "f3",
            "dxe5",
            "fxe5",
            "Ra1",
            "Rxh2",
            "Rxa2+",
            "Ke3",
            "Rxh2",
            "b4",
            "Rh3",
            "b5",
            "Bxf3",
            "Kd4",
            "Be2",
            "c5",
            "bxc5+",
            "Kxc5",
            "Rc3+",
            "Kb4",
            "Rc4+",
            "Ka5",
            "Rc5",
            "Ka6",
            "Bxb5+",
            "Kxa7",
            "Rxe5",
            "Ng8+",
            "Kd6",
            "Kb6",
            "f5",
            "Nf6",
            "f4",
            "Ng4",
            "f3",
            "Nf2",
            "Re2",
            "Ng4",
            "f2",
            "Nxf2",
            "Rxf2",
            "Kxb5",
            "Rc2",
            "Kb4",
            "e5",
            "Kb3",
            "Rc8",
            "Kb4",
            "e4",
            "Kb5",
            "e3",
            "Kb6",
            "e2",
            "Kb7",
            "Rc1",
            "Kb6",
            "e1=Q",
            "Kb5",
            "Qc3",
            "Kb6",
            "Qb2+",
            "Ka5",
            "Ra1#",
            "h3",
            "g5",
            "f4",
            "Nd4",
            "Bxd4",
            "Kf8",
            "Nf6",
            "gxf6",
            "Qd6",
            "Qe7",
            "Qxe7",
            "Kxe7",
            "Nf3",
            "g5",
            "Nxe8",
            "Kf8",
            "Nf6",
            "gxf4",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Nf3",
            "g5",
            "Nd4",
            "Kf8",
            "Nf5",
            "d6",
            "Nxd6",
            "Bxh3",
            "Bxh3",
            "Rxh3",
            "Rxh3",
            "Kg7",
            "Rh1",
            "Rh8",
            "Rg1",
            "Rh4",
            "Rd1",
            "Rh6",
            "Kf1",
            "Rg6",
            "Ke2",
            "Rf6",
            "Kd3",
            "Rg6",
            "Kc4",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5",
            "Rg6",
            "Ka5",
            "Rf6",
            "Kb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g3",
          "positional_uci": "g2g3",
          "positional_response": "19. g3 Nd4 20. Bd3 Nf3+ 21. Kh1 b6 22. Be4 Nd2 23. Bxa8 Nxf1 24. Rxf1 Ba6 25.\nRd1 Rxa8 26. Nf6 Bb7+ 27. Kg1 Bc6 28. gxf4 Rh8 29. Rd3 Rh4 30. Rd4 Rh6 31. Kf1\nRg6 32. Rd3 Bb5 33. Ke2 Bxd3+ 34. cxd3 Rg2 35. Kf3 Rxh2 36. Kg3 Rh1 37. Ng4\nRb1 38. b3 Rb2 39. Kxh3 Rxa2 40. Kg3 Rb2 41. Ne3 Rxb3 42. d4 a5 43. Kf3 a4 44.\nKe2 a3 45. Nc2 a2 46. Kd2 Rb2 47. Kc1 Rxc2+ 48. Kxc2 a1=Q 49. Kd3 Qa3+ 50.\nKe4 b5 51. f3 b4 52. f5 b3 53. f6+ Kd8 54. f4 b2 55. f5 b1=Q+ 56. Kf4 Qf1+ 57.\nKg5 Qg3+ 58. Kh6 Qh1# 19. g3 Nd4 20. Bd3 Nf3+ 21. Kh1 b6 22. Be4 Nd2 23. Bxa8 Nxf1 24. Rxf1 Ba6 25. Rd1 Rxa8 26. Nf6 Bb7+ 27. Kg1 Bc6 28. gxf4 Rh8 29. Rd3 Rh4 30. Rd4 Rh6 31. Kf1 Rg6 32. Rd3 Bb5 33. Ke2 Bxd3+ 34. cxd3 Rg2 35. Kf3 Rxh2 36. Kg3 Rh1 37. Ng4 Rb1 38. b3 Rb2 39. Kxh3 Rxa2 40. Kg3 Rb2 41. Ne3 Rxb3 42. d4 a5 43. Kf3 a4 44. Ke2 a3 45. Nc2 a2 46. Kd2 Rb2 47. Kc1 Rxc2+ 48. Kxc2 a1=Q 49. Kd3 Qa3+ 50. Ke4 b5 51. f3 b4 52. f5 b3 53. f6+ Kd8 54. f4 b2 55. f5 b1=Q+",
          "positional_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nd4",
            "Bd3",
            "Nf3+",
            "Kh1",
            "b6",
            "Be4",
            "Nd2",
            "Bxa8",
            "Nxf1",
            "Rxf1",
            "Ba6",
            "Rd1",
            "Rxa8",
            "Nf6",
            "Bb7+",
            "Kg1",
            "Bc6",
            "gxf4",
            "Rh8",
            "Rd3",
            "Rh4",
            "Rd4",
            "Rh6",
            "Kf1",
            "Rg6",
            "Rd3",
            "Bb5",
            "Ke2",
            "Bxd3+",
            "cxd3",
            "Rg2",
            "Kf3",
            "Rxh2",
            "Kg3",
            "Rh1",
            "Ng4",
            "Rb1",
            "b3",
            "Rb2",
            "Kxh3",
            "Rxa2",
            "Kg3",
            "Rb2",
            "Ne3",
            "Rxb3",
            "d4",
            "a5",
            "Kf3",
            "a4",
            "Ke2",
            "a3",
            "Nc2",
            "a2",
            "Kd2",
            "Rb2",
            "Kc1",
            "Rxc2+",
            "Kxc2",
            "a1=Q",
            "Kd3",
            "Qa3+",
            "Ke4",
            "b5",
            "f3",
            "b4",
            "f5",
            "b3",
            "f6+",
            "Kd8",
            "f4",
            "b2",
            "f5",
            "b1=Q+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kd3",
          "neutral_uci": null,
          "neutral_response": "Re4 Rg8 Rfe1 Rg5 Rxe5\nRxe5 Rxe5 Rg5 Rxf5 Rg5 Rxf4 Rxf4 Rxf4 Kxf4 Kf3 Kf5 Ke3 Ke5 Kd3 Kd5 Kc3 Kc5\nKb3 Kb5 Ka3 Ka5 Kb3 Kb5 Kc3 Kc5 Kd3 Kd5 Ke3 Ke5 Kf3 Kf5 Kg3 Kg5 Kxh3 Kxh4\nKg3 Kf5 Kf3 Ke5 Ke3 Kd5 Kd3 Kc5 Kc3 Kb5 Kb3 Ka5 Ka3 Kb5 Kc3 Kc5 Kd3 Kd5\nKe3 Ke5 Kf3 Kf5 Kg3 Kg5 Kxh3 Kxh4 Kg3 Kf5 Ke3 Kd5 Kc3 Kc5 Kb3 Kb5 Ka3 Kc5 Kc3\nKd5 Kd3 Ke5 Ke3 Kf5 Kf3 Kg5 Kxg2 Kxh5 Kf3 Kg4 Ke3 Kd5 Kd3 Kc5 Kc3 Kb5\nKa3 Ka5 Kb3 Kb5 Kc3 Kd5 Kd3 Ke5 Ke3 Kf5 Kf3 Kg5 Kxg2 Kxh5 Kf3 Kg5 Ke3 Kd5\nKd3 Kc5 Kc3 Kb5 Ka3 Kc5 Kc3 Kd5 Kd3 Ke5 Ke3 Kf5 Kf3 Kg5 Kxg2 Kxh5 Kf3 Kg5\nKe3 Kd5 Kd3 Kc5 Kc3 Kb5 Ka3 Kc5 Kc3 Kd5 Kd3 Ke5 Ke3 Kf5 Kf3 Kg5 Kxg2 Kxh5\nKf3 Kg5 Ke3 Kd5 Kd3 Kc5 Kc3 Kb5 Ka3 Kc5 Kc3 Kd5 Kd3 Ke5 Ke3 Kf5 Kf3 Kg5\nKxg2 Kxh5 Kf3 Kg5 Ke3 Kd5 Kd3 Kc5 Kc3 Kb5 Ka3 Kc5 Kc3 Kd5 Kd3 Ke5 Ke3 Kf5\nKf3 Kg5 Kxg2 Kxh5 Kf3 Kg5 Ke3 Kd5 Kd3 Kc5 Kc3 Kb5 Ka3 Kc5 Kc3 Kd5 Kd3 Ke5\nKe3 Kf5 Kf3 Kg5 Kxg2 Kxh5 Kf3 Kg5 Ke3 Kd5 Kd3 Kc5 Kc3 Kb5 Ka3 Kc5 Kc3 Kd5\nKd3 Ke5 Ke3 Kf5 Kf3 Kg5 Kxg2 Kxh5 Kf3 Kg5 Ke",
          "neutral_tokens": {
            "prompt_tokens": 257,
            "completion_tokens": 640,
            "total_tokens": 897,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke5",
            "Ke3",
            "Kf5",
            "Kf3",
            "Kg5",
            "Kxg2",
            "Kxh5",
            "Kf3",
            "Kg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g2g3",
          "positional_uci": "g2g3",
          "neutral_uci": null,
          "consensus_move": "g2g3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nd4",
              "Bd3",
              "Nf3+",
              "Kh1",
              "b6",
              "Be4",
              "Nd2",
              "Bxa8",
              "Nxf1",
              "Rxf1",
              "Ba6",
              "Rd1",
              "Rxa8",
              "Nf6",
              "Bb7+",
              "Kg1",
              "Bc6",
              "gxf4",
              "Rh8",
              "Rd3",
              "Rh4",
              "Rd4",
              "Rh6",
              "Kf1",
              "Rg6",
              "Ke2",
              "Rg2",
              "Rd3",
              "Rxh2",
              "Rg3",
              "Rh1",
              "Rg8",
              "d6",
              "Rc8",
              "Bb5+",
              "c4",
              "Ba4",
              "b3",
              "h2",
              "Rh8",
              "Bc6",
              "f3",
              "dxe5",
              "fxe5",
              "Ra1",
              "Rxh2",
              "Rxa2+",
              "Ke3",
              "Rxh2",
              "b4",
              "Rh3",
              "b5",
              "Bxf3",
              "Kd4",
              "Be2",
              "c5",
              "bxc5+",
              "Kxc5",
              "Rc3+",
              "Kb4",
              "Rc4+",
              "Ka5",
              "Rc5",
              "Ka6",
              "Bxb5+",
              "Kxa7",
              "Rxe5",
              "Ng8+",
              "Kd6",
              "Kb6",
              "f5",
              "Nf6",
              "f4",
              "Ng4",
              "f3",
              "Nf2",
              "Re2",
              "Ng4",
              "f2",
              "Nxf2",
              "Rxf2",
              "Kxb5",
              "Rc2",
              "Kb4",
              "e5",
              "Kb3",
              "Rc8",
              "Kb4",
              "e4",
              "Kb5",
              "e3",
              "Kb6",
              "e2",
              "Kb7",
              "Rc1",
              "Kb6",
              "e1=Q",
              "Kb5",
              "Qc3",
              "Kb6",
              "Qb2+",
              "Ka5",
              "Ra1#",
              "h3",
              "g5",
              "f4",
              "Nd4",
              "Bxd4",
              "Kf8",
              "Nf6",
              "gxf6",
              "Qd6",
              "Qe7",
              "Qxe7",
              "Kxe7",
              "Nf3",
              "g5",
              "Nxe8",
              "Kf8",
              "Nf6",
              "gxf4",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Nf3",
              "g5",
              "Nd4",
              "Kf8",
              "Nf5",
              "d6",
              "Nxd6",
              "Bxh3",
              "Bxh3",
              "Rxh3",
              "Rxh3",
              "Kg7",
              "Rh1",
              "Rh8",
              "Rg1",
              "Rh4",
              "Rd1",
              "Rh6",
              "Kf1",
              "Rg6",
              "Ke2",
              "Rf6",
              "Kd3",
              "Rg6",
              "Kc4",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5",
              "Rg6",
              "Ka5",
              "Rf6",
              "Kb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nd4",
              "Bd3",
              "Nf3+",
              "Kh1",
              "b6",
              "Be4",
              "Nd2",
              "Bxa8",
              "Nxf1",
              "Rxf1",
              "Ba6",
              "Rd1",
              "Rxa8",
              "Nf6",
              "Bb7+",
              "Kg1",
              "Bc6",
              "gxf4",
              "Rh8",
              "Rd3",
              "Rh4",
              "Rd4",
              "Rh6",
              "Kf1",
              "Rg6",
              "Rd3",
              "Bb5",
              "Ke2",
              "Bxd3+",
              "cxd3",
              "Rg2",
              "Kf3",
              "Rxh2",
              "Kg3",
              "Rh1",
              "Ng4",
              "Rb1",
              "b3",
              "Rb2",
              "Kxh3",
              "Rxa2",
              "Kg3",
              "Rb2",
              "Ne3",
              "Rxb3",
              "d4",
              "a5",
              "Kf3",
              "a4",
              "Ke2",
              "a3",
              "Nc2",
              "a2",
              "Kd2",
              "Rb2",
              "Kc1",
              "Rxc2+",
              "Kxc2",
              "a1=Q",
              "Kd3",
              "Qa3+",
              "Ke4",
              "b5",
              "f3",
              "b4",
              "f5",
              "b3",
              "f6+",
              "Kd8",
              "f4",
              "b2",
              "f5",
              "b1=Q+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke5",
              "Ke3",
              "Kf5",
              "Kf3",
              "Kg5",
              "Kxg2",
              "Kxh5",
              "Kf3",
              "Kg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 257,
            "completion_tokens": 640,
            "total_tokens": 897,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 773,
          "total_completion_tokens": 1920,
          "total_tokens": 2693
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 257,
            "completion_tokens": 640,
            "total_tokens": 897,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b4r/pp1pkp2/2n1p3/4P3/5pN1/7p/PPP1BPPP/R4RK1 w - - 0 19"
    },
    {
      "turn": 39,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bd3",
          "aggressive_uci": "e2d3",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 Nf3+ 21. Kh1 b6 22. Be4 Nd2 23. Bxa8 Nxf1 24. Rxf1 Ba6 25. Rd1 Rxa8 26. Nf6 Bb7+ 27. Kg1 Bc6 28. gxf4 Rh8 29. Rd3 Rh4 30. Rd4 Rh6 31. Kf1 Rg6 32. Ke2 Rg2 33. Rd3 Rxh2 34. Rg3 Rh1 35. Rg8 d6 36. Rc8 Bb5+ 37. c4 Ba4 38. b3 h2 39. Rh8 Bc6 40. f3 dxe5 41. fxe5 Ra1 42. Rxh2 Rxa2+ 43. Ke3 Rxh2 44. Ng4 Rh3 45. Kd4 Rxf3 46. b4 Rf4+ 47. Kc3 Rxg4 48. b5 Bb7 49. Kb4 Re4 50. Kc3 Rxe5 51. Kd4 Re4+ 52. Kd3 f5 53. Kc3 f4 54. Kd3 f3 55. Kc3 f2 56. Kb4 f1=Q 57. Ka4 Qxc4+ 58. Ka3 Re3+ 59. Kb2 Qc3+ 60. Kb1 Be4+ 61. Ka2 Re2#",
          "aggressive_tokens": {
            "prompt_tokens": 265,
            "completion_tokens": 500,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3+",
            "Kh1",
            "b6",
            "Be4",
            "Nd2",
            "Bxa8",
            "Nxf1",
            "Rxf1",
            "Ba6",
            "Rd1",
            "Rxa8",
            "Nf6",
            "Bb7+",
            "Kg1",
            "Bc6",
            "gxf4",
            "Rh8",
            "Rd3",
            "Rh4",
            "Rd4",
            "Rh6",
            "Kf1",
            "Rg6",
            "Ke2",
            "Rg2",
            "Rd3",
            "Rxh2",
            "Rg3",
            "Rh1",
            "Rg8",
            "d6",
            "Rc8",
            "Bb5+",
            "c4",
            "Ba4",
            "b3",
            "h2",
            "Rh8",
            "Bc6",
            "f3",
            "dxe5",
            "fxe5",
            "Ra1",
            "Rxh2",
            "Rxa2+",
            "Ke3",
            "Rxh2",
            "Ng4",
            "Rh3",
            "Kd4",
            "Rxf3",
            "b4",
            "Rf4+",
            "Kc3",
            "Rxg4",
            "b5",
            "Bb7",
            "Kb4",
            "Re4",
            "Kc3",
            "Rxe5",
            "Kd4",
            "Re4+",
            "Kd3",
            "f5",
            "Kc3",
            "f4",
            "Kd3",
            "f3",
            "Kc3",
            "f2",
            "Kb4",
            "f1=Q",
            "Ka4",
            "Qxc4+",
            "Ka3",
            "Re3+",
            "Kb2",
            "Qc3+",
            "Kb1",
            "Be4+",
            "Ka2",
            "Re2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd3",
          "positional_uci": "e2d3",
          "positional_response": "20. Bd3 b6 21. Be4 Rb8 22. c3 Nc6 23. Bxc6 dxc6 24. gxf4 Ba6 25. Rfd1 Rbg8 26. f3 Be2 27. Rd6 Bxf3 28. Kf2 Bxg4 29. Rxc6 Bf5 30. Rc7+ Kd8 31. Rxa7 Rg2+ 32. Ke3 Rhg8 33. Rd1+ Kc8 34. Rdd7 Rxb2 35. Rxf7 Kb8 36. Rfb7+ Kc8 37. Rc7+ Kb8 38. Rcb7+ Kc8 39. Rc7+ Kb8 40. Rcb7+ Kc8 41. Rc7+ Kb8 42. Rcb7+ Kc8 43. Rc7+ Kb8 44. Rcb7+ Kc8 45. Rc7+ Kb8 46. Rcb7+ Kc8 47. Rc7+ Kb8 48. Rcb7+ Kc8 49. Rc7+ Kb8 50. Rcb7+ Kc8 51. Rc7+ Kb8 52. Rcb7+ Kc8 53. Rc7+ Kb8 54. Rcb7+ Kc8 55. Rc7+ Kb8 56. Rcb7+ Kc8 57. Rc7+ Kb8 58. Rcb7+ Kc8 59. Rc7+ Kb8 60. Rcb7+ Kc8 61. Rc7+ Kb8 62. Rcb7+ Kc8 63. Rc7+ Kb8 64. Rcb7+ Kc8 65. Rc7+ Kb8 66. Rcb7+ Kc8 67. Rc7+ Kb8 68. Rcb7+ Kc8 69. Rc7+ Kb8 70. Rcb7+ Kc8 71. Rc7+ Kb8 72. Rcb7+ Kc8 73. Rc7+ Kb8 74. Rcb7+ Kc8 75. Rc7+ Kb8 76. Rcb7+ Kc8 77. Rc7+ Kb8 78. Rcb7+ Kc8 79. Rc7+ Kb8 80. Rcb7+ Kc8 81. Rc7+ Kb8 82. Rcb7+ Kc8 83. Rc7+ Kb8 84. Rcb7+ Kc8 85. Rc7+ Kb8 86. Rcb7+ Kc8 87. Rc7+ Kb8 88. Rcb7+ Kc8 89. Rc7+ Kb8 90. Rcb7+ Kc8 91. Rc7+ Kb8",
          "positional_tokens": {
            "prompt_tokens": 265,
            "completion_tokens": 640,
            "total_tokens": 905,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "b6",
            "Be4",
            "Rb8",
            "c3",
            "Nc6",
            "Bxc6",
            "dxc6",
            "gxf4",
            "Ba6",
            "Rfd1",
            "Rbg8",
            "f3",
            "Be2",
            "Rd6",
            "Bxf3",
            "Kf2",
            "Bxg4",
            "Rxc6",
            "Bf5",
            "Rc7+",
            "Kd8",
            "Rxa7",
            "Rg2+",
            "Ke3",
            "Rhg8",
            "Rd1+",
            "Kc8",
            "Rdd7",
            "Rxb2",
            "Rxf7",
            "Kb8",
            "Rfb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rcb7+",
            "Kc8",
            "Rc7+",
            "Kb8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bd3",
          "neutral_uci": "e2d3",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 Nf3+ 21. Kh1 b6 22. Be4 Nd2 23. Bxa8 Nxf1 24. Rxf1 Ba6 25. Rd1 Rxa8 26. Nf6 Bb7+ 27. Kg1 Bc6 28. gxf4 Rh8 29. Rd3 Rh4 30. Rd4 Rh6 31. Kf1 Rg6 32. Ke2 Rg2 33. Rd3 Rxh2 34. Rg3 Rh1 35. Rg8 d6 36. Rc8 Bb5+ 37. c4 Ba4 38. b3 Bd7 39. Rc7 h2 40. Rxd7+ Kf8 41. Rd8+ Kg7 42. Rg8+ Kh6 43. Ng4+ Kh7 44. Nf6+ Kh6 45. Rh8+ Kg7 46. Rh7+ Kf8 47. exd6 Ra1 48. d7 Rxa2+ 49. Kf3 Rd2 50. Rxh2 Ke7 51. Rh8 Kxf6 52. d8=Q+ Rxd8 53. Rxd8 Ke7 54. Ra8 a5 55. Rb8 Kd6 56. Rxb6+ Kc5 57. Rb5+ Kd4 58. Rxa5 Kc3 59. c5 Kxb3 60. c6 Kb4 61. Ra7 Kb5 62. c7 Kb6 63. c8=Q Kxa7 64. Qc7+ Ka6 65. Qxf7 Kb5 66. Qxe6 Kc5 67. f5 Kd4 68. f6 Kc5 69. f7 Kd4 70. f8=Q Kc3 71. Qd8 Kb4 72. Qc6 Ka3 73. Qb8 Ka2 74. Qa6# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 264,
            "completion_tokens": 615,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3+",
            "Kh1",
            "b6",
            "Be4",
            "Nd2",
            "Bxa8",
            "Nxf1",
            "Rxf1",
            "Ba6",
            "Rd1",
            "Rxa8",
            "Nf6",
            "Bb7+",
            "Kg1",
            "Bc6",
            "gxf4",
            "Rh8",
            "Rd3",
            "Rh4",
            "Rd4",
            "Rh6",
            "Kf1",
            "Rg6",
            "Ke2",
            "Rg2",
            "Rd3",
            "Rxh2",
            "Rg3",
            "Rh1",
            "Rg8",
            "d6",
            "Rc8",
            "Bb5+",
            "c4",
            "Ba4",
            "b3",
            "Bd7",
            "Rc7",
            "h2",
            "Rxd7+",
            "Kf8",
            "Rd8+",
            "Kg7",
            "Rg8+",
            "Kh6",
            "Ng4+",
            "Kh7",
            "Nf6+",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rh7+",
            "Kf8",
            "exd6",
            "Ra1",
            "d7",
            "Rxa2+",
            "Kf3",
            "Rd2",
            "Rxh2",
            "Ke7",
            "Rh8",
            "Kxf6",
            "d8=Q+",
            "Rxd8",
            "Rxd8",
            "Ke7",
            "Ra8",
            "a5",
            "Rb8",
            "Kd6",
            "Rxb6+",
            "Kc5",
            "Rb5+",
            "Kd4",
            "Rxa5",
            "Kc3",
            "c5",
            "Kxb3",
            "c6",
            "Kb4",
            "Ra7",
            "Kb5",
            "c7",
            "Kb6",
            "c8=Q",
            "Kxa7",
            "Qc7+",
            "Ka6",
            "Qxf7",
            "Kb5",
            "Qxe6",
            "Kc5",
            "f5",
            "Kd4",
            "f6",
            "Kc5",
            "f7",
            "Kd4",
            "f8=Q",
            "Kc3",
            "Qd8",
            "Kb4",
            "Qc6",
            "Ka3",
            "Qb8",
            "Ka2",
            "Qa6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2d3",
          "positional_uci": "e2d3",
          "neutral_uci": "e2d3",
          "consensus_move": "e2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3+",
              "Kh1",
              "b6",
              "Be4",
              "Nd2",
              "Bxa8",
              "Nxf1",
              "Rxf1",
              "Ba6",
              "Rd1",
              "Rxa8",
              "Nf6",
              "Bb7+",
              "Kg1",
              "Bc6",
              "gxf4",
              "Rh8",
              "Rd3",
              "Rh4",
              "Rd4",
              "Rh6",
              "Kf1",
              "Rg6",
              "Ke2",
              "Rg2",
              "Rd3",
              "Rxh2",
              "Rg3",
              "Rh1",
              "Rg8",
              "d6",
              "Rc8",
              "Bb5+",
              "c4",
              "Ba4",
              "b3",
              "h2",
              "Rh8",
              "Bc6",
              "f3",
              "dxe5",
              "fxe5",
              "Ra1",
              "Rxh2",
              "Rxa2+",
              "Ke3",
              "Rxh2",
              "Ng4",
              "Rh3",
              "Kd4",
              "Rxf3",
              "b4",
              "Rf4+",
              "Kc3",
              "Rxg4",
              "b5",
              "Bb7",
              "Kb4",
              "Re4",
              "Kc3",
              "Rxe5",
              "Kd4",
              "Re4+",
              "Kd3",
              "f5",
              "Kc3",
              "f4",
              "Kd3",
              "f3",
              "Kc3",
              "f2",
              "Kb4",
              "f1=Q",
              "Ka4",
              "Qxc4+",
              "Ka3",
              "Re3+",
              "Kb2",
              "Qc3+",
              "Kb1",
              "Be4+",
              "Ka2",
              "Re2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "b6",
              "Be4",
              "Rb8",
              "c3",
              "Nc6",
              "Bxc6",
              "dxc6",
              "gxf4",
              "Ba6",
              "Rfd1",
              "Rbg8",
              "f3",
              "Be2",
              "Rd6",
              "Bxf3",
              "Kf2",
              "Bxg4",
              "Rxc6",
              "Bf5",
              "Rc7+",
              "Kd8",
              "Rxa7",
              "Rg2+",
              "Ke3",
              "Rhg8",
              "Rd1+",
              "Kc8",
              "Rdd7",
              "Rxb2",
              "Rxf7",
              "Kb8",
              "Rfb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rcb7+",
              "Kc8",
              "Rc7+",
              "Kb8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3+",
              "Kh1",
              "b6",
              "Be4",
              "Nd2",
              "Bxa8",
              "Nxf1",
              "Rxf1",
              "Ba6",
              "Rd1",
              "Rxa8",
              "Nf6",
              "Bb7+",
              "Kg1",
              "Bc6",
              "gxf4",
              "Rh8",
              "Rd3",
              "Rh4",
              "Rd4",
              "Rh6",
              "Kf1",
              "Rg6",
              "Ke2",
              "Rg2",
              "Rd3",
              "Rxh2",
              "Rg3",
              "Rh1",
              "Rg8",
              "d6",
              "Rc8",
              "Bb5+",
              "c4",
              "Ba4",
              "b3",
              "Bd7",
              "Rc7",
              "h2",
              "Rxd7+",
              "Kf8",
              "Rd8+",
              "Kg7",
              "Rg8+",
              "Kh6",
              "Ng4+",
              "Kh7",
              "Nf6+",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rh7+",
              "Kf8",
              "exd6",
              "Ra1",
              "d7",
              "Rxa2+",
              "Kf3",
              "Rd2",
              "Rxh2",
              "Ke7",
              "Rh8",
              "Kxf6",
              "d8=Q+",
              "Rxd8",
              "Rxd8",
              "Ke7",
              "Ra8",
              "a5",
              "Rb8",
              "Kd6",
              "Rxb6+",
              "Kc5",
              "Rb5+",
              "Kd4",
              "Rxa5",
              "Kc3",
              "c5",
              "Kxb3",
              "c6",
              "Kb4",
              "Ra7",
              "Kb5",
              "c7",
              "Kb6",
              "c8=Q",
              "Kxa7",
              "Qc7+",
              "Ka6",
              "Qxf7",
              "Kb5",
              "Qxe6",
              "Kc5",
              "f5",
              "Kd4",
              "f6",
              "Kc5",
              "f7",
              "Kd4",
              "f8=Q",
              "Kc3",
              "Qd8",
              "Kb4",
              "Qc6",
              "Ka3",
              "Qb8",
              "Ka2",
              "Qa6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 265,
            "completion_tokens": 500,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 265,
            "completion_tokens": 640,
            "total_tokens": 905,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 264,
            "completion_tokens": 615,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 794,
          "total_completion_tokens": 1755,
          "total_tokens": 2549
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 265,
            "completion_tokens": 500,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 265,
            "completion_tokens": 640,
            "total_tokens": 905,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 264,
            "completion_tokens": 615,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b4r/pp1pkp2/4p3/4P3/3n1pN1/6Pp/PPP1BP1P/R4RK1 w - - 1 20"
    },
    {
      "turn": 41,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exd6+",
          "aggressive_uci": "e5d6",
          "aggressive_response": "21. exd6+ Kxd6 22. Rad1 e5 23. Nf6 Ke6 24. Ne4 f5 25. Nc5+ Kf6 26. c3 Nf3+ 27.\nKh1 b6 28. Nb3 Bb7 29. Be2 Nd4+ 30. Kg1 Nxe2# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 272,
            "completion_tokens": 87,
            "total_tokens": 359,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxd6",
            "Rad1",
            "e5",
            "Nf6",
            "Ke6",
            "Ne4",
            "f5",
            "Nc5+",
            "Kf6",
            "c3",
            "Nf3+",
            "Kh1",
            "b6",
            "Nb3",
            "Bb7",
            "Be2",
            "Nd4+",
            "Kg1",
            "Nxe2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "exd6+",
          "positional_uci": "e5d6",
          "positional_response": "21. exd6+ Kxd6 22. Rad1 e5 23. Nf6 Ke6 24. Ne4 f5 25. Nc5+ Kf6 26. c3 Nf3+ 27.\nKh1 b6 28. Nb3 Bb7 29. Be2 Nd4+ 30. Kg1 Nxe2#",
          "positional_tokens": {
            "prompt_tokens": 272,
            "completion_tokens": 83,
            "total_tokens": 355,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxd6",
            "Rad1",
            "e5",
            "Nf6",
            "Ke6",
            "Ne4",
            "f5",
            "Nc5+",
            "Kf6",
            "c3",
            "Nf3+",
            "Kh1",
            "b6",
            "Nb3",
            "Bb7",
            "Be2",
            "Nd4+",
            "Kg1",
            "Nxe2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exd6+",
          "neutral_uci": "e5d6",
          "neutral_response": "21. exd6+ Kxd6 22. Rad1 e5 23. Nf6 Ke6 24. Ne4 Nf3+ 25. Kh1 b6 26. Be2 Nd4 27.\nBc4+ Ke7 28. c3 Bb7 29. f3 Nxf3 30. Bd5 Bxd5 31. Rxd5 Rad8 32. Rxd8 Rxd8 33.\nRxf3 Rd1+ 34. Rf1 Rxf1# 1-0\n1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 *\n21. exd6+ Kxd6 22. Rad1 e5 23. Nf6 Ke6 24. Ne4 Nf3+ 25. Kh1 b6 26. Be2 Nd4 27.\nBc4+ Ke7 28. c3 Bb7 29. f3 Nxf3 30. Bd5 Bxd5 31. Rxd5 Rad8 32. Rxd8 Rxd8 33.\nRxf3 Rd1+ 34. Rf1 Rxf1# 1-0 1-0",
          "neutral_tokens": {
            "prompt_tokens": 271,
            "completion_tokens": 409,
            "total_tokens": 680,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxd6",
            "Rad1",
            "e5",
            "Nf6",
            "Ke6",
            "Ne4",
            "Nf3+",
            "Kh1",
            "b6",
            "Be2",
            "Nd4",
            "Bc4+",
            "Ke7",
            "c3",
            "Bb7",
            "f3",
            "Nxf3",
            "Bd5",
            "Bxd5",
            "Rxd5",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Rxf3",
            "Rd1+",
            "Rf1",
            "Rxf1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5d6",
          "positional_uci": "e5d6",
          "neutral_uci": "e5d6",
          "consensus_move": "e5d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxd6",
              "Rad1",
              "e5",
              "Nf6",
              "Ke6",
              "Ne4",
              "f5",
              "Nc5+",
              "Kf6",
              "c3",
              "Nf3+",
              "Kh1",
              "b6",
              "Nb3",
              "Bb7",
              "Be2",
              "Nd4+",
              "Kg1",
              "Nxe2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxd6",
              "Rad1",
              "e5",
              "Nf6",
              "Ke6",
              "Ne4",
              "f5",
              "Nc5+",
              "Kf6",
              "c3",
              "Nf3+",
              "Kh1",
              "b6",
              "Nb3",
              "Bb7",
              "Be2",
              "Nd4+",
              "Kg1",
              "Nxe2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxd6",
              "Rad1",
              "e5",
              "Nf6",
              "Ke6",
              "Ne4",
              "Nf3+",
              "Kh1",
              "b6",
              "Be2",
              "Nd4",
              "Bc4+",
              "Ke7",
              "c3",
              "Bb7",
              "f3",
              "Nxf3",
              "Bd5",
              "Bxd5",
              "Rxd5",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Rxf3",
              "Rd1+",
              "Rf1",
              "Rxf1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 272,
            "completion_tokens": 87,
            "total_tokens": 359,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 272,
            "completion_tokens": 83,
            "total_tokens": 355,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 271,
            "completion_tokens": 409,
            "total_tokens": 680,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 815,
          "total_completion_tokens": 579,
          "total_tokens": 1394
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 272,
            "completion_tokens": 87,
            "total_tokens": 359,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 272,
            "completion_tokens": 83,
            "total_tokens": 355,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 271,
            "completion_tokens": 409,
            "total_tokens": 680,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b4r/pp2kp2/3pp3/4P3/3n1pN1/3B2Pp/PPP2P1P/R4RK1 w - - 0 21"
    },
    {
      "turn": 43,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rad1",
          "aggressive_uci": "a1d1",
          "aggressive_response": "22. Rad1 Ke7 23. Be4 Nc6 24. Bxc6 bxc6 25. Ne5 Kf6 26. Nxc6 Bb7 27. Nd4 Bg2\n28. Rfe1 fxg3 29. fxg3 Rab8 30. b3 Rhd8 31. Ne2 Rxd1 32. Rxd1 Rc8 33. c4 Rc5 34.\nNf4 Ra5 35. Nxg2 hxg2 36. Rd2 Ke5 37. Kxg2 Ke4 38. Kf2 Rf5+ 39. Ke2 Rh5 40. h4\nRh8 41. Rd7 Rg8 42. Kf2 f5 43. Rxa7 Rd8 44. Ke2 Rd3 45. Rg7 Rc3 46. Kd2 Rf3\n47. h5 Rf2+ 48. Kc3 Rxa2 49. h6 Rh2 50. h7 e5 51. c5 Kd5 52. b4 e4 53. Rd7+ Kc6\n54. Rd6+ Kc7 55. Rf6 Rxh7 56. Rxf5 Re7 57. Rf2 Kc6 58. Kc4 e3 59. Re2 Re4+ 60.\nKd3 Rxb4 61. Rxe3 Kxc5 62. Re5+ Kd6 63. Re4 Rb3+ 64. Kd4 Rxg3 65. Rf4 Rg6 66.\nKe4 Re6+ 67. Kf3 Ke5 68. Re4+ Kd5 69. Rxe6 Kxe6 70. Ke4 Kd6 71. Kd4 Kc6 72. Kc4\nKd6 73. Kd4 Kc6 74. Kc4 Kd6 75. Kd4 Kc6 76. Kc4 Kd6 77. Kd4 Kc6 78. Kc4 Kd6\n79. Kd4 Kc6 80. Kc4 Kd6 81. Kd4 Kc6 82. Kc4 Kd6 83. Kd4 Kc6 84. Kc4 Kd6 85.\nKd4 Kc6 86. Kc4 Kd6 87. Kd4 Kc6 88. Kc4 Kd6 89. Kd4 Kc6 90. Kc4 Kd6 91. Kd4\nKc6 92. Kc4 Kd6 93. Kd4 Kc6 94. Kc4 Kd6 95. Kd4 Kc6 96. Kc4 K",
          "aggressive_tokens": {
            "prompt_tokens": 282,
            "completion_tokens": 640,
            "total_tokens": 922,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke7",
            "Be4",
            "Nc6",
            "Bxc6",
            "bxc6",
            "Ne5",
            "Kf6",
            "Nxc6",
            "Bb7",
            "Nd4",
            "Bg2",
            "Rfe1",
            "fxg3",
            "fxg3",
            "Rab8",
            "b3",
            "Rhd8",
            "Ne2",
            "Rxd1",
            "Rxd1",
            "Rc8",
            "c4",
            "Rc5",
            "Nf4",
            "Ra5",
            "Nxg2",
            "hxg2",
            "Rd2",
            "Ke5",
            "Kxg2",
            "Ke4",
            "Kf2",
            "Rf5+",
            "Ke2",
            "Rh5",
            "h4",
            "Rh8",
            "Rd7",
            "Rg8",
            "Kf2",
            "f5",
            "Rxa7",
            "Rd8",
            "Ke2",
            "Rd3",
            "Rg7",
            "Rc3",
            "Kd2",
            "Rf3",
            "h5",
            "Rf2+",
            "Kc3",
            "Rxa2",
            "h6",
            "Rh2",
            "h7",
            "e5",
            "c5",
            "Kd5",
            "b4",
            "e4",
            "Rd7+",
            "Kc6",
            "Rd6+",
            "Kc7",
            "Rf6",
            "Rxh7",
            "Rxf5",
            "Re7",
            "Rf2",
            "Kc6",
            "Kc4",
            "e3",
            "Re2",
            "Re4+",
            "Kd3",
            "Rxb4",
            "Rxe3",
            "Kxc5",
            "Re5+",
            "Kd6",
            "Re4",
            "Rb3+",
            "Kd4",
            "Rxg3",
            "Rf4",
            "Rg6",
            "Ke4",
            "Re6+",
            "Kf3",
            "Ke5",
            "Re4+",
            "Kd5",
            "Rxe6",
            "Kxe6",
            "Ke4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4",
            "Kd6",
            "Kd4",
            "Kc6",
            "Kc4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rad1",
          "positional_uci": "a1d1",
          "positional_response": "22. Rad1 Ke7 23. Ne5 Rh5 24. Rfe1 Rxe5 25. Rxe5 Nf3+ 26. Kh1 Nxe5 27. gxf4\nNxd3 28. Rxd3 Bd7 29. Rxh3 Rg8 30. Rg3 Bc6+ 31. Kg1 Rd8 32. Rd3 Rxd3 33. cxd3\nKf6 34. Kf1 Kf5 35. Ke2 Kxf4 36. b3 Bf3+ 37. Kd2 Kg4 38. Ke3 f5 39. h3+ Kxh3\n40. Kxf3 e5 41. a3 b5 42. b4 a6 43. Ke3 Kg4 44. d4 exd4+ 45. Kxd4 Kf3 46. Ke5\nf4 47. Kf5 Kxf2 48. Kxf4 Ke2 49. Ke4 Kd2 50. Kd4 Kc2 51. Kc5 Kb3 52. Kb6 Kxa3\n53. Kxa6 Kxb4 54. Kb6 Kc4 55. Ka5 b4 56. Ka4 Kc3 57. Kb5 b3 58. Ka4 b2 59. Ka3\nb1=Q 60. Ka4 Qb4# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6 Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Ng4 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 Ke7 Ne5 Rh5 Rfe1 Rxe5 Rxe5 Nf3+ Kh1 Nxe5 gxf4 Nxd3 Rxd3 Bd7 Rxh3 Rg8 Rg3 Bc6+ Kg1 Rd8 Rd3 Rxd3 cxd3 Kf6 Kf1 Kf5 Ke2 Kxf4 b3 Bf3+ Kd2 d6 exd6 Kxd6 Ke3 Bd5 f4 f5 h3 Kc5 Kd2 Kd4 Ke2 Kc3 Ke3 Kb2 Kd4 Kxa2 Kc5 Kxb3 Kxb4 Kc3 Kc5 Kd3 Kd6 Ke3 Ke6 Kf2 Kf6 Kg3 Kg6 Kh4 Kh6 Kg3 Kh5 Kh2 Kh4 Kg1 Kg3 Kf1 Kxf4 Ke2 Kg3 Kf1 f4 Kg1 f3 Kf1 f2 Ke2 Kg2 Ke3 f1=Q",
          "positional_tokens": {
            "prompt_tokens": 282,
            "completion_tokens": 640,
            "total_tokens": 922,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke7",
            "Ne5",
            "Rh5",
            "Rfe1",
            "Rxe5",
            "Rxe5",
            "Nf3+",
            "Kh1",
            "Nxe5",
            "gxf4",
            "Nxd3",
            "Rxd3",
            "Bd7",
            "Rxh3",
            "Rg8",
            "Rg3",
            "Bc6+",
            "Kg1",
            "Rd8",
            "Rd3",
            "Rxd3",
            "cxd3",
            "Kf6",
            "Kf1",
            "Kf5",
            "Ke2",
            "Kxf4",
            "b3",
            "Bf3+",
            "Kd2",
            "d6",
            "exd6",
            "Kxd6",
            "Ke3",
            "Bd5",
            "f4",
            "f5",
            "h3",
            "Kc5",
            "Kd2",
            "Kd4",
            "Ke2",
            "Kc3",
            "Ke3",
            "Kb2",
            "Kd4",
            "Kxa2",
            "Kc5",
            "Kxb3",
            "Kxb4",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd6",
            "Ke3",
            "Ke6",
            "Kf2",
            "Kf6",
            "Kg3",
            "Kg6",
            "Kh4",
            "Kh6",
            "Kg3",
            "Kh5",
            "Kh2",
            "Kh4",
            "Kg1",
            "Kg3",
            "Kf1",
            "Kxf4",
            "Ke2",
            "Kg3",
            "Kf1",
            "f4",
            "Kg1",
            "f3",
            "Kf1",
            "f2",
            "Ke2",
            "Kg2",
            "Ke3",
            "f1=Q"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rad1",
          "neutral_uci": "a1d1",
          "neutral_response": "22. Rad1 Ke7 23. Ne5 Rh5 24. Rfe1 Rxe5 25. Rxe5 Nf3+ 26. Kh1 Nxe5 27. gxf4 Nxd3 28. Rxd3 Bd7 29. Rxh3 Rg8 30. Rg3 Bc6+ 31. Kg1 Rd8 32. Rd3 Rxd3 33. cxd3 Kf6 34. Kf1 Kf5 35. Ke2 Kxf4 36. b3 Bf3+ 37. Kd2 Kg4 38. Ke3 f5 39. h3+ Kxh3 40. Kxf3 e5 41. Ke3 Kg4 42. d4 exd4+ 43. Kxd4 Kf3 44. Ke5 f4 45. Kf5 b5 46. b4 a6 47. a3 Kxf2 48. Kxf4 Ke2 49. Ke4 Kd2 50. Kd4 Kc2 51. Kc5 Kb3 52. Kb6 Kxa3 53. Kxa6 Kxb4 54. Kb6 Kc4 55. Ka5 b4 56. Ka4 Kc3 57. Kb5 b3 58. Ka4 b2 59. Ka3 b1=Q 60. Ka4 Qb4# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 281,
            "completion_tokens": 324,
            "total_tokens": 605,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "Ne5",
            "Rh5",
            "Rfe1",
            "Rxe5",
            "Rxe5",
            "Nf3+",
            "Kh1",
            "Nxe5",
            "gxf4",
            "Nxd3",
            "Rxd3",
            "Bd7",
            "Rxh3",
            "Rg8",
            "Rg3",
            "Bc6+",
            "Kg1",
            "Rd8",
            "Rd3",
            "Rxd3",
            "cxd3",
            "Kf6",
            "Kf1",
            "Kf5",
            "Ke2",
            "Kxf4",
            "b3",
            "Bf3+",
            "Kd2",
            "Kg4",
            "Ke3",
            "f5",
            "h3+",
            "Kxh3",
            "Kxf3",
            "e5",
            "Ke3",
            "Kg4",
            "d4",
            "exd4+",
            "Kxd4",
            "Kf3",
            "Ke5",
            "f4",
            "Kf5",
            "b5",
            "b4",
            "a6",
            "a3",
            "Kxf2",
            "Kxf4",
            "Ke2",
            "Ke4",
            "Kd2",
            "Kd4",
            "Kc2",
            "Kc5",
            "Kb3",
            "Kb6",
            "Kxa3",
            "Kxa6",
            "Kxb4",
            "Kb6",
            "Kc4",
            "Ka5",
            "b4",
            "Ka4",
            "Kc3",
            "Kb5",
            "b3",
            "Ka4",
            "b2",
            "Ka3",
            "b1=Q",
            "Ka4",
            "Qb4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a1d1",
          "positional_uci": "a1d1",
          "neutral_uci": "a1d1",
          "consensus_move": "a1d1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ke7",
              "Be4",
              "Nc6",
              "Bxc6",
              "bxc6",
              "Ne5",
              "Kf6",
              "Nxc6",
              "Bb7",
              "Nd4",
              "Bg2",
              "Rfe1",
              "fxg3",
              "fxg3",
              "Rab8",
              "b3",
              "Rhd8",
              "Ne2",
              "Rxd1",
              "Rxd1",
              "Rc8",
              "c4",
              "Rc5",
              "Nf4",
              "Ra5",
              "Nxg2",
              "hxg2",
              "Rd2",
              "Ke5",
              "Kxg2",
              "Ke4",
              "Kf2",
              "Rf5+",
              "Ke2",
              "Rh5",
              "h4",
              "Rh8",
              "Rd7",
              "Rg8",
              "Kf2",
              "f5",
              "Rxa7",
              "Rd8",
              "Ke2",
              "Rd3",
              "Rg7",
              "Rc3",
              "Kd2",
              "Rf3",
              "h5",
              "Rf2+",
              "Kc3",
              "Rxa2",
              "h6",
              "Rh2",
              "h7",
              "e5",
              "c5",
              "Kd5",
              "b4",
              "e4",
              "Rd7+",
              "Kc6",
              "Rd6+",
              "Kc7",
              "Rf6",
              "Rxh7",
              "Rxf5",
              "Re7",
              "Rf2",
              "Kc6",
              "Kc4",
              "e3",
              "Re2",
              "Re4+",
              "Kd3",
              "Rxb4",
              "Rxe3",
              "Kxc5",
              "Re5+",
              "Kd6",
              "Re4",
              "Rb3+",
              "Kd4",
              "Rxg3",
              "Rf4",
              "Rg6",
              "Ke4",
              "Re6+",
              "Kf3",
              "Ke5",
              "Re4+",
              "Kd5",
              "Rxe6",
              "Kxe6",
              "Ke4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4",
              "Kd6",
              "Kd4",
              "Kc6",
              "Kc4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "Ne5",
              "Rh5",
              "Rfe1",
              "Rxe5",
              "Rxe5",
              "Nf3+",
              "Kh1",
              "Nxe5",
              "gxf4",
              "Nxd3",
              "Rxd3",
              "Bd7",
              "Rxh3",
              "Rg8",
              "Rg3",
              "Bc6+",
              "Kg1",
              "Rd8",
              "Rd3",
              "Rxd3",
              "cxd3",
              "Kf6",
              "Kf1",
              "Kf5",
              "Ke2",
              "Kxf4",
              "b3",
              "Bf3+",
              "Kd2",
              "d6",
              "exd6",
              "Kxd6",
              "Ke3",
              "Bd5",
              "f4",
              "f5",
              "h3",
              "Kc5",
              "Kd2",
              "Kd4",
              "Ke2",
              "Kc3",
              "Ke3",
              "Kb2",
              "Kd4",
              "Kxa2",
              "Kc5",
              "Kxb3",
              "Kxb4",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd6",
              "Ke3",
              "Ke6",
              "Kf2",
              "Kf6",
              "Kg3",
              "Kg6",
              "Kh4",
              "Kh6",
              "Kg3",
              "Kh5",
              "Kh2",
              "Kh4",
              "Kg1",
              "Kg3",
              "Kf1",
              "Kxf4",
              "Ke2",
              "Kg3",
              "Kf1",
              "f4",
              "Kg1",
              "f3",
              "Kf1",
              "f2",
              "Ke2",
              "Kg2",
              "Ke3",
              "f1=Q"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke7",
              "Ne5",
              "Rh5",
              "Rfe1",
              "Rxe5",
              "Rxe5",
              "Nf3+",
              "Kh1",
              "Nxe5",
              "gxf4",
              "Nxd3",
              "Rxd3",
              "Bd7",
              "Rxh3",
              "Rg8",
              "Rg3",
              "Bc6+",
              "Kg1",
              "Rd8",
              "Rd3",
              "Rxd3",
              "cxd3",
              "Kf6",
              "Kf1",
              "Kf5",
              "Ke2",
              "Kxf4",
              "b3",
              "Bf3+",
              "Kd2",
              "Kg4",
              "Ke3",
              "f5",
              "h3+",
              "Kxh3",
              "Kxf3",
              "e5",
              "Ke3",
              "Kg4",
              "d4",
              "exd4+",
              "Kxd4",
              "Kf3",
              "Ke5",
              "f4",
              "Kf5",
              "b5",
              "b4",
              "a6",
              "a3",
              "Kxf2",
              "Kxf4",
              "Ke2",
              "Ke4",
              "Kd2",
              "Kd4",
              "Kc2",
              "Kc5",
              "Kb3",
              "Kb6",
              "Kxa3",
              "Kxa6",
              "Kxb4",
              "Kb6",
              "Kc4",
              "Ka5",
              "b4",
              "Ka4",
              "Kc3",
              "Kb5",
              "b3",
              "Ka4",
              "b2",
              "Ka3",
              "b1=Q",
              "Ka4",
              "Qb4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 282,
            "completion_tokens": 640,
            "total_tokens": 922,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 282,
            "completion_tokens": 640,
            "total_tokens": 922,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 281,
            "completion_tokens": 324,
            "total_tokens": 605,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 845,
          "total_completion_tokens": 1604,
          "total_tokens": 2449
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 282,
            "completion_tokens": 640,
            "total_tokens": 922,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 282,
            "completion_tokens": 640,
            "total_tokens": 922,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 281,
            "completion_tokens": 324,
            "total_tokens": 605,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b4r/pp3p2/3kp3/8/3n1pN1/3B2Pp/PPP2P1P/R4RK1 w - - 0 22"
    },
    {
      "turn": 45,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf5",
          "aggressive_uci": "d3f5",
          "aggressive_response": "23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rxf4 fxg4 26. Re1 Rd8 27. b4+ Kb6 28. c4 a5\n29. c5+ Kb5 30. a3 axb4 31. axb4 Ra4 32. Rb1 Be6 33. Re4 Bf5 34. c6 Bxe4 35.\nc7 Rc8 36. Rc1 Rxb4 37. f3 Bxf3 38. Kf2 Rb2+ 39. Ke3 Rxh2 40. Kf4 Re2 41. Kg5\nh2 42. Kh4 h1=Q+ 43. Rxh1 Bxh1 44. Kxg4 Rxc7 45. Kf4 Rf7+ 46. Kg5 Re5+ 47. Kg6\nRf3 48. g4 Re4 49. g5 Rg4 50. Kh5 Rfg3 51. g6 Rxg6 52. Kh4 Rg8 53. Kh5 Rh8# Rg1\nRg8 55. Kh4 Rh8# Rg1 Rg8 55. Kh3 Rh8# Rg1 Rg8 55. Kh4 Rh8#",
          "aggressive_tokens": {
            "prompt_tokens": 289,
            "completion_tokens": 302,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exf5",
            "Rxd4+",
            "Kc5",
            "Rxf4",
            "fxg4",
            "Re1",
            "Rd8",
            "b4+",
            "Kb6",
            "c4",
            "a5",
            "c5+",
            "Kb5",
            "a3",
            "axb4",
            "axb4",
            "Ra4",
            "Rb1",
            "Be6",
            "Re4",
            "Bf5",
            "c6",
            "Bxe4",
            "c7",
            "Rc8",
            "Rc1",
            "Rxb4",
            "f3",
            "Bxf3",
            "Kf2",
            "Rb2+",
            "Ke3",
            "Rxh2",
            "Kf4",
            "Re2",
            "Kg5",
            "h2",
            "Kh4",
            "h1=Q+",
            "Rxh1",
            "Bxh1",
            "Kxg4",
            "Rxc7",
            "Kf4",
            "Rf7+",
            "Kg5",
            "Re5+",
            "Kg6",
            "Rf3",
            "g4",
            "Re4",
            "g5",
            "Rg4",
            "Kh5",
            "Rfg3",
            "g6",
            "Rxg6",
            "Kh4",
            "Rg8",
            "Kh5",
            "Rh8#",
            "Rg1",
            "Rg8",
            "Kh4",
            "Rh8#",
            "Rg1",
            "Rg8",
            "Kh3",
            "Rh8#",
            "Rg1",
            "Rg8",
            "Kh4",
            "Rh8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf5",
          "positional_uci": "d3f5",
          "positional_response": "23. Bxf5 Kc5 24. b4+ Kc4 25. Ne5+ Kd5 26. Nf7 Rf8 27. c4+ Kxc4 28. Nd6+ Kd5\n29. Nxc8 Raxc8 30. Bxh3 Ke5 31. Rfe1+ Kd5 32. Bxe6+ Kd6 33. Rxd4+ Ke7 34. Bxc8+ Kf6\n35. Rxf4+ Kg7 36. Re7+ Kg8 37. Be6+ Kh8 38. Rxf8# e4 c6 d5",
          "positional_tokens": {
            "prompt_tokens": 289,
            "completion_tokens": 150,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc5",
            "b4+",
            "Kc4",
            "Ne5+",
            "Kd5",
            "Nf7",
            "Rf8",
            "c4+",
            "Kxc4",
            "Nd6+",
            "Kd5",
            "Nxc8",
            "Raxc8",
            "Bxh3",
            "Ke5",
            "Rfe1+",
            "Kd5",
            "Bxe6+",
            "Kd6",
            "Rxd4+",
            "Ke7",
            "Bxc8+",
            "Kf6",
            "Rxf4+",
            "Kg7",
            "Re7+",
            "Kg8",
            "Be6+",
            "Kh8",
            "Rxf8#",
            "e4",
            "c6",
            "d5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf5",
          "neutral_uci": "d3f5",
          "neutral_response": "23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rxf4 fxg4 26. Re1 Rd8 27. b4+ Kb6 28. c4 a5\n29. c5+ Kb5 30. a3 axb4 31. axb4 Ra4 32. Rb1 Be6 33. Re4 Bf5 34. c6 Bxe4 35.\nc7 Rc8 36. Rc1 Rxb4 37. f3 Bxf3 38. Kf2 Rb2+ 39. Ke3 Rxh2 40. Kf4 Re2 41. Kg5\nh2 42. Kf6 h1=Q 43. Rxh1 Bxh1 44. Kg5 Rxc7 45. Kxg4 Rc4+ 46. Kh3 Bg2+ 47. Kh2\nBf3+ 48. Kh3 Bg4+ 49. Kh4 Be6+ 50. Kg5 Rg4+ 51. Kf6 Rxg3 52. Ke7 Bc4+ 53. Kd6\nRd3+ 54. Kc7 Re7+ 55. Kc8 Be6+ 56. Kb8 Rd8+ 57. Ka7 b6# e4 c5 d4 Nc6 Nf6 e6\nNdb5 Be7 Nd6 Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6 Qe7 Qxe7+ Kxe7 Ng4 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 f5 Bxf5 exf5 Rxd4+ Kc5 Rxf4 fxg4 Re1 Rd8 b4+ Kb6 c4 a5 c5+ Kb5 a3 axb4 axb4 Ra4 Rb1 Be6 Re4 Bf5 c6 Bxe4 c7 Rc8 Rc1 Rxb4 f3 Bxf3 Kf2 Bg2 Ke3 Rb3+ Kf4 Rf3+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+ Kg5 Rg8+ Kh4 Rh8+",
          "neutral_tokens": {
            "prompt_tokens": 288,
            "completion_tokens": 640,
            "total_tokens": 928,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "exf5",
            "Rxd4+",
            "Kc5",
            "Rxf4",
            "fxg4",
            "Re1",
            "Rd8",
            "b4+",
            "Kb6",
            "c4",
            "a5",
            "c5+",
            "Kb5",
            "a3",
            "axb4",
            "axb4",
            "Ra4",
            "Rb1",
            "Be6",
            "Re4",
            "Bf5",
            "c6",
            "Bxe4",
            "c7",
            "Rc8",
            "Rc1",
            "Rxb4",
            "f3",
            "Bxf3",
            "Kf2",
            "Bg2",
            "Ke3",
            "Rb3+",
            "Kf4",
            "Rf3+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+",
            "Kg5",
            "Rg8+",
            "Kh4",
            "Rh8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3f5",
          "positional_uci": "d3f5",
          "neutral_uci": "d3f5",
          "consensus_move": "d3f5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "exf5",
              "Rxd4+",
              "Kc5",
              "Rxf4",
              "fxg4",
              "Re1",
              "Rd8",
              "b4+",
              "Kb6",
              "c4",
              "a5",
              "c5+",
              "Kb5",
              "a3",
              "axb4",
              "axb4",
              "Ra4",
              "Rb1",
              "Be6",
              "Re4",
              "Bf5",
              "c6",
              "Bxe4",
              "c7",
              "Rc8",
              "Rc1",
              "Rxb4",
              "f3",
              "Bxf3",
              "Kf2",
              "Rb2+",
              "Ke3",
              "Rxh2",
              "Kf4",
              "Re2",
              "Kg5",
              "h2",
              "Kh4",
              "h1=Q+",
              "Rxh1",
              "Bxh1",
              "Kxg4",
              "Rxc7",
              "Kf4",
              "Rf7+",
              "Kg5",
              "Re5+",
              "Kg6",
              "Rf3",
              "g4",
              "Re4",
              "g5",
              "Rg4",
              "Kh5",
              "Rfg3",
              "g6",
              "Rxg6",
              "Kh4",
              "Rg8",
              "Kh5",
              "Rh8#",
              "Rg1",
              "Rg8",
              "Kh4",
              "Rh8#",
              "Rg1",
              "Rg8",
              "Kh3",
              "Rh8#",
              "Rg1",
              "Rg8",
              "Kh4",
              "Rh8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kc5",
              "b4+",
              "Kc4",
              "Ne5+",
              "Kd5",
              "Nf7",
              "Rf8",
              "c4+",
              "Kxc4",
              "Nd6+",
              "Kd5",
              "Nxc8",
              "Raxc8",
              "Bxh3",
              "Ke5",
              "Rfe1+",
              "Kd5",
              "Bxe6+",
              "Kd6",
              "Rxd4+",
              "Ke7",
              "Bxc8+",
              "Kf6",
              "Rxf4+",
              "Kg7",
              "Re7+",
              "Kg8",
              "Be6+",
              "Kh8",
              "Rxf8#",
              "e4",
              "c6",
              "d5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "exf5",
              "Rxd4+",
              "Kc5",
              "Rxf4",
              "fxg4",
              "Re1",
              "Rd8",
              "b4+",
              "Kb6",
              "c4",
              "a5",
              "c5+",
              "Kb5",
              "a3",
              "axb4",
              "axb4",
              "Ra4",
              "Rb1",
              "Be6",
              "Re4",
              "Bf5",
              "c6",
              "Bxe4",
              "c7",
              "Rc8",
              "Rc1",
              "Rxb4",
              "f3",
              "Bxf3",
              "Kf2",
              "Bg2",
              "Ke3",
              "Rb3+",
              "Kf4",
              "Rf3+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+",
              "Kg5",
              "Rg8+",
              "Kh4",
              "Rh8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 289,
            "completion_tokens": 302,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 289,
            "completion_tokens": 150,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 288,
            "completion_tokens": 640,
            "total_tokens": 928,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 866,
          "total_completion_tokens": 1092,
          "total_tokens": 1958
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 289,
            "completion_tokens": 302,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 289,
            "completion_tokens": 150,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 288,
            "completion_tokens": 640,
            "total_tokens": 928,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b4r/pp6/3kp3/5p2/3n1pN1/3B2Pp/PPP2P1P/3R1RK1 w - - 0 23"
    },
    {
      "turn": 47,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxd4+",
          "aggressive_uci": "d1d4",
          "aggressive_response": "24. Rxd4+ Kc5 25. Rxf4 fxg4 26. Re1 Rd8 27. b4+ Kb5 28. c4+ Kxb4 29. c5+ Kxc5 30.\nRe5+ Rd5 31. Re1 Bd7 32. Rc1+ Kd6 33. Rf6+ Ke7 34. Rh6 Rc8 35. Re1+ Kd8 36. Rh8+\nKc7 37. Rc1+ Kb8 38. Rhxc8+ Bxc8 39. Kf1 Rd2 40. a4 Bd7 41. a5 Bb5+ 42. Kg1\nb6 43. axb6 axb6 44. Rb1 Kb7 45. f4 Rg2+ 46. Kh1 Bc6 47. Rxb6+ Kxb6 48. f5\nRf2+ 49. Kg1 Rxf5 50. Kh2 Rf2+ 51. Kg1 Rg2+ 52. Kh1 Rxg3+ 53. Kh2 Rg2+ 54.\nKh1 Ra2+ 55. Kg1 h2+ 56. Kf1 h1=Q# g5 h6 gxf6",
          "aggressive_tokens": {
            "prompt_tokens": 298,
            "completion_tokens": 292,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc5",
            "Rxf4",
            "fxg4",
            "Re1",
            "Rd8",
            "b4+",
            "Kb5",
            "c4+",
            "Kxb4",
            "c5+",
            "Kxc5",
            "Re5+",
            "Rd5",
            "Re1",
            "Bd7",
            "Rc1+",
            "Kd6",
            "Rf6+",
            "Ke7",
            "Rh6",
            "Rc8",
            "Re1+",
            "Kd8",
            "Rh8+",
            "Kc7",
            "Rc1+",
            "Kb8",
            "Rhxc8+",
            "Bxc8",
            "Kf1",
            "Rd2",
            "a4",
            "Bd7",
            "a5",
            "Bb5+",
            "Kg1",
            "b6",
            "axb6",
            "axb6",
            "Rb1",
            "Kb7",
            "f4",
            "Rg2+",
            "Kh1",
            "Bc6",
            "Rxb6+",
            "Kxb6",
            "f5",
            "Rf2+",
            "Kg1",
            "Rxf5",
            "Kh2",
            "Rf2+",
            "Kg1",
            "Rg2+",
            "Kh1",
            "Rxg3+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Ra2+",
            "Kg1",
            "h2+",
            "Kf1",
            "h1=Q#",
            "g5",
            "h6",
            "gxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxd4+",
          "positional_uci": "d1d4",
          "positional_response": "24. Rxd4+ Kc5 25. Rxf4 fxg4 26. Re1 Rd8 27. b4+ Kb6 28. a4 a5 29. b5 Rd2 30. c4\nBe6 31. Rf6 Re8 32. Kf1 Kc5 33. Rfxe6 Rxe6 34. Rxe6 Kxc4 35. Re4+ Rd4 36. Re7\nKb4 37. Rxb7 Kxa4 38. b6 Kb5 39. Rb8 a4 40. b7 Kb6 41. Ra8 Kxb7 42. Ra5 Kb6 43.\nRa8 Kb5 44. Ke2 Kb4 45. Ke3 Rc4 46. Kd3 Rc3+ 47. Kd2 Rf3 48. Ke2 a3 49. Rb8+\nKc3 50. Rc8+ Kb2 51. Rb8+ Rb3 52. Ra8 a2 53. Kd2 a1=Q 54. Rxa1 Kxa1 55. Ke2\nKb2 56. Kd2 Rf3 57. Ke2 Kc2 58. Ke1 Kd3 59. Kf1 Kd2 60. Kg1 Ke2 61. Kh1 Rxf2\n62. Kg1 Rf1# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Ng4 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 f5 Bxf5 exf5 Rxd4+ Kc5 Rxf4 fxg4 Re1 Rd8 b4+ Kb6 a4 Rd2 c4 Be6 Rf6 Re8 Kf1 Kc5 Rfxe6 Rxe6 Rxe6 Kxc4 Re4+ Rd4 Re7 Kxb4 Rxb7+ Kxa4 b6 Kb5 Ra7 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7 Ra5 Kb6 Ra8 Kb7",
          "positional_tokens": {
            "prompt_tokens": 298,
            "completion_tokens": 640,
            "total_tokens": 938,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kc5",
            "Rxf4",
            "fxg4",
            "Re1",
            "Rd8",
            "b4+",
            "Kb6",
            "a4",
            "Rd2",
            "c4",
            "Be6",
            "Rf6",
            "Re8",
            "Kf1",
            "Kc5",
            "Rfxe6",
            "Rxe6",
            "Rxe6",
            "Kxc4",
            "Re4+",
            "Rd4",
            "Re7",
            "Kxb4",
            "Rxb7+",
            "Kxa4",
            "b6",
            "Kb5",
            "Ra7",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7",
            "Ra5",
            "Kb6",
            "Ra8",
            "Kb7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxd4+",
          "neutral_uci": "d1d4",
          "neutral_response": "24. Rxd4+ Kc5 25. Rxf4 fxg4 26. Re1 Rd8 27. b4+ Kb6 28. a4 a5 29. b5 Rd2 30. c4\nBe6 31. Rf6 Re8 32. Kf1 Kc5 33. Rfxe6 Rxe6 34. Rxe6 Kxc4 35. Re4+ Rd4 36. Rxd4+\nKxd4 37. Ke2 Kc4 38. f4 gxf3+ 39. Kxf3 Kb4 40. g4 Kxa4 41. g5 Kxb5 42. g6 a4\n43. g7 a3 44. g8=Q Kb4 45. Qa2 Ka4 46. Ke3 b5 47. Kd3 b4 48. Kc4 Ka5 49. Qb3\n1-0\n\n1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rxf4 fxg4 26. Re1 Rd8 27.\nb4+ Kb6 28. a4 a5 29. b5 Rd2 30. c4 Be6 31. Rf6 Re8 32. Kf1 Kc5 33. Rfxe6 Rxe6\n34. Rxe6 Kxc4 35. Re4+ Rd4 36. Rxd4+ Kxd4 37. Ke2 Kc4 38. f4 gxf3+ 39. Kxf3 Kb4\n40. g4 Kxa4 41. g5 Kxb5 42. g6 a4 43. g7 a3 44. g8=Q Kb4 45. Qa2 Ka4 46. Ke3 b5\n47. Kd3 b4 48. Kc4 Ka5 49. Qb3 1-0 e5 d5 Nf3 Nc6 Bb5 Be7 Bxd6 exd6 Re",
          "neutral_tokens": {
            "prompt_tokens": 297,
            "completion_tokens": 640,
            "total_tokens": 937,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxd4",
            "Ke2",
            "Kc4",
            "f4",
            "gxf3+",
            "Kxf3",
            "Kb4",
            "g4",
            "Kxa4",
            "g5",
            "Kxb5",
            "g6",
            "a4",
            "g7",
            "a3",
            "g8=Q",
            "Kb4",
            "Qa2",
            "Ka4",
            "Ke3",
            "b5",
            "Kd3",
            "b4",
            "Kc4",
            "Ka5",
            "Qb3",
            "e5",
            "d5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Be7",
            "Bxd6",
            "exd6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1d4",
          "positional_uci": "d1d4",
          "neutral_uci": "d1d4",
          "consensus_move": "d1d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kc5",
              "Rxf4",
              "fxg4",
              "Re1",
              "Rd8",
              "b4+",
              "Kb5",
              "c4+",
              "Kxb4",
              "c5+",
              "Kxc5",
              "Re5+",
              "Rd5",
              "Re1",
              "Bd7",
              "Rc1+",
              "Kd6",
              "Rf6+",
              "Ke7",
              "Rh6",
              "Rc8",
              "Re1+",
              "Kd8",
              "Rh8+",
              "Kc7",
              "Rc1+",
              "Kb8",
              "Rhxc8+",
              "Bxc8",
              "Kf1",
              "Rd2",
              "a4",
              "Bd7",
              "a5",
              "Bb5+",
              "Kg1",
              "b6",
              "axb6",
              "axb6",
              "Rb1",
              "Kb7",
              "f4",
              "Rg2+",
              "Kh1",
              "Bc6",
              "Rxb6+",
              "Kxb6",
              "f5",
              "Rf2+",
              "Kg1",
              "Rxf5",
              "Kh2",
              "Rf2+",
              "Kg1",
              "Rg2+",
              "Kh1",
              "Rxg3+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Ra2+",
              "Kg1",
              "h2+",
              "Kf1",
              "h1=Q#",
              "g5",
              "h6",
              "gxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kc5",
              "Rxf4",
              "fxg4",
              "Re1",
              "Rd8",
              "b4+",
              "Kb6",
              "a4",
              "Rd2",
              "c4",
              "Be6",
              "Rf6",
              "Re8",
              "Kf1",
              "Kc5",
              "Rfxe6",
              "Rxe6",
              "Rxe6",
              "Kxc4",
              "Re4+",
              "Rd4",
              "Re7",
              "Kxb4",
              "Rxb7+",
              "Kxa4",
              "b6",
              "Kb5",
              "Ra7",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7",
              "Ra5",
              "Kb6",
              "Ra8",
              "Kb7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxd4",
              "Ke2",
              "Kc4",
              "f4",
              "gxf3+",
              "Kxf3",
              "Kb4",
              "g4",
              "Kxa4",
              "g5",
              "Kxb5",
              "g6",
              "a4",
              "g7",
              "a3",
              "g8=Q",
              "Kb4",
              "Qa2",
              "Ka4",
              "Ke3",
              "b5",
              "Kd3",
              "b4",
              "Kc4",
              "Ka5",
              "Qb3",
              "e5",
              "d5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Be7",
              "Bxd6",
              "exd6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 298,
            "completion_tokens": 292,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 298,
            "completion_tokens": 640,
            "total_tokens": 938,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 297,
            "completion_tokens": 640,
            "total_tokens": 937,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 893,
          "total_completion_tokens": 1572,
          "total_tokens": 2465
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 298,
            "completion_tokens": 292,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 298,
            "completion_tokens": 640,
            "total_tokens": 938,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 297,
            "completion_tokens": 640,
            "total_tokens": 937,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b4r/pp6/3k4/5p2/3n1pN1/6Pp/PPP2P1P/3R1RK1 w - - 0 24"
    },
    {
      "turn": 49,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rfd1",
          "aggressive_uci": "f1d1",
          "aggressive_response": "25. Rfd1 fxg4 26. Rd5+ Kc6 27. Rd6+ Kc7 28. R6d4 fxg3 29. fxg3 Be6 30. Re1 Rae8\n31. Rde4 Bd7 32. Rc4+ Kb8 33. Rd1 Bc6 34. Rxg4 Re2 35. Rc1 Rg2+ 36. Kf1 Rf8+\n37. Ke1 Rxh2 38. Rh4 Rh1+ 39. Kd2 Rf2+ 40. Ke3 Rf3+ 41. Kd2 Rh2+ 42. Ke1 Re3+\n43. Kf1 Bg2+ 44. Kf2 Rf3+ 45. Ke2 Rxg3 46. Rh8+ Kc7 47. Rh7+ Kb6 48. Rh6+ Bc6+\n49. Kf1 Rh1+ 50. Kf2 Rg2+ 51. Ke3 Rxc1 52. Rxh3 Rcxc2 53. Rh6 Rxb2 54. Kd3 Rxa2\n55. Kc3 Ra3+ 56. Kb4 Rf3 57. Kc4 Rg4# Rfd8 Rxd8 Rxd8",
          "aggressive_tokens": {
            "prompt_tokens": 308,
            "completion_tokens": 296,
            "total_tokens": 604,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxg4",
            "Rd5+",
            "Kc6",
            "Rd6+",
            "Kc7",
            "R6d4",
            "fxg3",
            "fxg3",
            "Be6",
            "Re1",
            "Rae8",
            "Rde4",
            "Bd7",
            "Rc4+",
            "Kb8",
            "Rd1",
            "Bc6",
            "Rxg4",
            "Re2",
            "Rc1",
            "Rg2+",
            "Kf1",
            "Rf8+",
            "Ke1",
            "Rxh2",
            "Rh4",
            "Rh1+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rh2+",
            "Ke1",
            "Re3+",
            "Kf1",
            "Bg2+",
            "Kf2",
            "Rf3+",
            "Ke2",
            "Rxg3",
            "Rh8+",
            "Kc7",
            "Rh7+",
            "Kb6",
            "Rh6+",
            "Bc6+",
            "Kf1",
            "Rh1+",
            "Kf2",
            "Rg2+",
            "Ke3",
            "Rxc1",
            "Rxh3",
            "Rcxc2",
            "Rh6",
            "Rxb2",
            "Kd3",
            "Rxa2",
            "Kc3",
            "Ra3+",
            "Kb4",
            "Rf3",
            "Kc4",
            "Rg4#",
            "Rfd8",
            "Rxd8",
            "Rxd8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rfd1",
          "positional_uci": "f1d1",
          "positional_response": "25. Rfd1 fxg4 26. Rd5+ Kc6 27. Rd6+ Kc7",
          "positional_tokens": {
            "prompt_tokens": 308,
            "completion_tokens": 27,
            "total_tokens": 335,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxg4",
            "Rd5+",
            "Kc6",
            "Rd6+",
            "Kc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxf4",
          "neutral_uci": "d4f4",
          "neutral_response": "25. Rxf4 fxg4 26. Rd1 Be6 27. b4+ Kb5 28. Rd6 Bxa2 29. Rf5+ Kxb4 30. Rd4+ Kc3\n31. Rxg4 Rad8 32. Rc5+ Kb2 33. Rb4+ Kc1 34. f4 Rd2 35. Rxb7 Re8 36. Re5 Rxe5\n37. fxe5 Rg2+ 38. Kf1 Bc4+ 39. Ke1 Rxh2 40. Rxa7 Re2+ 41. Kf1 h2 42. Rh7 Rxc2+ 43. Ke1 Re2+ 44. Kf1 Kd1 45. Rd7+ Rd2+ 46. Rd3 Bxd3# h3 Rxc2 Rh1+ Kc2 Rh2+ Kc3 Rh3+ Kc4 Rh4+ Kc5 Rh5+ Kc6 Rh6+ Kc7 Rh7+ Kc8 Rh8+ Kc7 Rh7+ Kc6 Rh6+ Kc5 Rh5+ Kc4 Rh4+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3+ Kc2 Rh2+ Kc3 Rh3",
          "neutral_tokens": {
            "prompt_tokens": 307,
            "completion_tokens": 640,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxg4",
            "Rd1",
            "Be6",
            "b4+",
            "Kb5",
            "Rd6",
            "Bxa2",
            "Rf5+",
            "Kxb4",
            "Rd4+",
            "Kc3",
            "Rxg4",
            "Rad8",
            "Rc5+",
            "Kb2",
            "Rb4+",
            "Kc1",
            "f4",
            "Rd2",
            "Rxb7",
            "Re8",
            "Re5",
            "Rxe5",
            "fxe5",
            "Rg2+",
            "Kf1",
            "Bc4+",
            "Ke1",
            "Rxh2",
            "Rxa7",
            "Re2+",
            "Kf1",
            "h2",
            "Rh7",
            "Rxc2+",
            "Ke1",
            "Re2+",
            "Kf1",
            "Kd1",
            "Rd7+",
            "Rd2+",
            "Rd3",
            "Bxd3#",
            "h3",
            "Rxc2",
            "Rh1+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc4",
            "Rh4+",
            "Kc5",
            "Rh5+",
            "Kc6",
            "Rh6+",
            "Kc7",
            "Rh7+",
            "Kc8",
            "Rh8+",
            "Kc7",
            "Rh7+",
            "Kc6",
            "Rh6+",
            "Kc5",
            "Rh5+",
            "Kc4",
            "Rh4+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc3",
            "Rh3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d1",
          "positional_uci": "f1d1",
          "neutral_uci": "d4f4",
          "consensus_move": "f1d1",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxg4",
              "Rd5+",
              "Kc6",
              "Rd6+",
              "Kc7",
              "R6d4",
              "fxg3",
              "fxg3",
              "Be6",
              "Re1",
              "Rae8",
              "Rde4",
              "Bd7",
              "Rc4+",
              "Kb8",
              "Rd1",
              "Bc6",
              "Rxg4",
              "Re2",
              "Rc1",
              "Rg2+",
              "Kf1",
              "Rf8+",
              "Ke1",
              "Rxh2",
              "Rh4",
              "Rh1+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rh2+",
              "Ke1",
              "Re3+",
              "Kf1",
              "Bg2+",
              "Kf2",
              "Rf3+",
              "Ke2",
              "Rxg3",
              "Rh8+",
              "Kc7",
              "Rh7+",
              "Kb6",
              "Rh6+",
              "Bc6+",
              "Kf1",
              "Rh1+",
              "Kf2",
              "Rg2+",
              "Ke3",
              "Rxc1",
              "Rxh3",
              "Rcxc2",
              "Rh6",
              "Rxb2",
              "Kd3",
              "Rxa2",
              "Kc3",
              "Ra3+",
              "Kb4",
              "Rf3",
              "Kc4",
              "Rg4#",
              "Rfd8",
              "Rxd8",
              "Rxd8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "fxg4",
              "Rd5+",
              "Kc6",
              "Rd6+",
              "Kc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "fxg4",
              "Rd1",
              "Be6",
              "b4+",
              "Kb5",
              "Rd6",
              "Bxa2",
              "Rf5+",
              "Kxb4",
              "Rd4+",
              "Kc3",
              "Rxg4",
              "Rad8",
              "Rc5+",
              "Kb2",
              "Rb4+",
              "Kc1",
              "f4",
              "Rd2",
              "Rxb7",
              "Re8",
              "Re5",
              "Rxe5",
              "fxe5",
              "Rg2+",
              "Kf1",
              "Bc4+",
              "Ke1",
              "Rxh2",
              "Rxa7",
              "Re2+",
              "Kf1",
              "h2",
              "Rh7",
              "Rxc2+",
              "Ke1",
              "Re2+",
              "Kf1",
              "Kd1",
              "Rd7+",
              "Rd2+",
              "Rd3",
              "Bxd3#",
              "h3",
              "Rxc2",
              "Rh1+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc4",
              "Rh4+",
              "Kc5",
              "Rh5+",
              "Kc6",
              "Rh6+",
              "Kc7",
              "Rh7+",
              "Kc8",
              "Rh8+",
              "Kc7",
              "Rh7+",
              "Kc6",
              "Rh6+",
              "Kc5",
              "Rh5+",
              "Kc4",
              "Rh4+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc3",
              "Rh3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 308,
            "completion_tokens": 296,
            "total_tokens": 604,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 308,
            "completion_tokens": 27,
            "total_tokens": 335,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 307,
            "completion_tokens": 640,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 923,
          "total_completion_tokens": 963,
          "total_tokens": 1886
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 308,
            "completion_tokens": 296,
            "total_tokens": 604,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 308,
            "completion_tokens": 27,
            "total_tokens": 335,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 307,
            "completion_tokens": 640,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b4r/pp6/8/2k2p2/3R1pN1/6Pp/PPP2P1P/5RK1 w - - 1 25"
    },
    {
      "turn": 51,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd6",
          "aggressive_uci": "d4d6",
          "aggressive_response": "26. Rd6 Be6 27. Rxe6 Rad8 28. Rde1 Rd2 29. R6e5+ Kd6 30. Re6+ Kd7 31. Re7+ Kc6\n32. R7e6+ Kc7 33. Re7+ Kc6 34. R7e6+ Kc7 35. Re7+ Kc6 36. R7e6+ Kc7 37. Re7+ Kc6 38. R7e6+ Kc7 39. Re7+ Kc6 40. R7e6+ Kc7 41. Re7+ Kc6 42. R7e6+ Kc7 43. Re7+ Kc6 44. R7e6+ Kc7 45. Re7+ Kc6 46. R7e6+ Kc7 47. Re7+ Kc6 48. R7e6+ Kc7 49. Re7+ Kc6 50. R7e6+ Kc7 51. Re7+ Kc6 52. R7e6+ Kc7 53. Re7+ Kc6 54. R7e6+ Kc7 55. Re7+ Kc6 56. R7e6+ Kc7 57. Re7+ Kc6 58. R7e6+ Kc7 59. Re7+ Kc6 60. R7e6+ Kc7 61. Re7+ Kc6 62. R7e6+ Kc7 63. Re7+ Kc6 64. R7e6+ Kc7 65. Re7+ Kc6 66. R7e6+ Kc7 67. Re7+ Kc6 68. R7e6+ Kc7 69. Re7+ Kc6 70. R7e6+ Kc7 71. Re7+ Kc6 72. R7e6+ Kc7 73. Re7+ Kc6 74. R7e6+ Kc7 75. Re7+ Kc6 76. R7e6+ Kc7 77. Re7+ Kc6 78. R7e6+ Kc7 79. Re7+ Kc6 80. R7e6+ Kc7 81. Re7+ Kc6 82. R7e6+ Kc7 83. Re7+ Kc6 84. R7e6+ Kc7 85. Re7+ Kc6 86. R7e6+ Kc7 87. Re7+ Kc6 88. R7e6+ Kc7 89. Re7+ Kc6 90. R7e6+",
          "aggressive_tokens": {
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be6",
            "Rxe6",
            "Rad8",
            "Rde1",
            "Rd2",
            "R6e5+",
            "Kd6",
            "Re6+",
            "Kd7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+",
            "Kc7",
            "Re7+",
            "Kc6",
            "R7e6+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd5+",
          "positional_uci": "d4d5",
          "positional_response": "26. Rd5+ Kb6 27. Rd6+ Kc7 28. R6d4 fxg3 29. fxg3 Be6 30. Re1 Rae8 31. Rde4 Bd7\n32. Rc4+ Bc6 33. Rxe8 Rxe8 34. Rxg4 Re2 35. Rc4 Rg2+ 36. Kf1 Rxh2 37. g4 Rg2\n38. Rc3 h2 39. Rh3 Rg1+ 40. Kf2 h1=Q 41. Rxh1 Rxh1 42. Kg3 Rc1 43. g5 Rxc2\n44. g6 Rxb2 45. g7 Bd5 46. Kf4 Rxa2 47. Ke5 Bg8 48. Kf6 Rf2+ 49. Ke7 Rf7+ 50.\nKe8 Rxg7 51. Kf8 Rf7+ 52. Kxg8 Rf1 53. Kg7 Kd6 54. Kg6 Ke5 55. Kg5 Rg1+ 56.\nKh4 Kf5 57. Kh3 Kf4 58. Kh2 Rg8 59. Kh3 Rg7 60. Kh2 Kf3 61. Kh1 Kf2 62. Kh2 Rh7#\n63. Kh1 Rh3# 64. Kh2 Rg3 65. Kh1 Rh3# 66. Kh2 Rh8 67. Kh1 Rh7 68. Kh2 Rh6 69.\nKh1 Rh5 70. Kh2 Rh4 71. Kh1 Rh3# 72. Kh2 Rh8 73. Kh1 Rh7 74. Kh2 Rh6 75. Kh1 Rh5\n76. Kh2 Rh4 77. Kh1 Rh3# 78. Kh2 Rh8 79. Kh1 Rh7 80. Kh2 Rh6 81. Kh1 Rh5 82.\nKh2 Rh4 83. Kh1 Rh3# 84. Kh2 Rh8 85. Kh1 Rh7 86. Kh2 Rh6 87. Kh1 Rh5 88. Kh2\nRh4 89. Kh1 Rh3# 90. Kh2 Rh8 91. Kh1 Rh7 92. Kh2 Rh6 93. Kh1 Rh5 94. Kh2 Rh4\n95. Kh1 Rh3# 96. Kh2 Rh8 97. Kh1 Rh7 98. Kh2 Rh6 99. Kh1 Rh5 100. Kh2 Rh4 101.\nKh1 Rh3# 102. Kh2 Rh8 103. Kh1 Rh7 104. Kh2 Rh6 105. Kh1 Rh5 106. Kh2 Rh4 107.\nKh1 Rh3# 108.",
          "positional_tokens": {
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb6",
            "Rd6+",
            "Kc7",
            "R6d4",
            "fxg3",
            "fxg3",
            "Be6",
            "Re1",
            "Rae8",
            "Rde4",
            "Bd7",
            "Rc4+",
            "Bc6",
            "Rxe8",
            "Rxe8",
            "Rxg4",
            "Re2",
            "Rc4",
            "Rg2+",
            "Kf1",
            "Rxh2",
            "g4",
            "Rg2",
            "Rc3",
            "h2",
            "Rh3",
            "Rg1+",
            "Kf2",
            "h1=Q",
            "Rxh1",
            "Rxh1",
            "Kg3",
            "Rc1",
            "g5",
            "Rxc2",
            "g6",
            "Rxb2",
            "g7",
            "Bd5",
            "Kf4",
            "Rxa2",
            "Ke5",
            "Bg8",
            "Kf6",
            "Rf2+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rxg7",
            "Kf8",
            "Rf7+",
            "Kxg8",
            "Rf1",
            "Kg7",
            "Kd6",
            "Kg6",
            "Ke5",
            "Kg5",
            "Rg1+",
            "Kh4",
            "Kf5",
            "Kh3",
            "Kf4",
            "Kh2",
            "Rg8",
            "Kh3",
            "Rg7",
            "Kh2",
            "Kf3",
            "Kh1",
            "Kf2",
            "Kh2",
            "Rh7#",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rg3",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rh8",
            "Kh1",
            "Rh7",
            "Kh2",
            "Rh6",
            "Kh1",
            "Rh5",
            "Kh2",
            "Rh4",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rh8",
            "Kh1",
            "Rh7",
            "Kh2",
            "Rh6",
            "Kh1",
            "Rh5",
            "Kh2",
            "Rh4",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rh8",
            "Kh1",
            "Rh7",
            "Kh2",
            "Rh6",
            "Kh1",
            "Rh5",
            "Kh2",
            "Rh4",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rh8",
            "Kh1",
            "Rh7",
            "Kh2",
            "Rh6",
            "Kh1",
            "Rh5",
            "Kh2",
            "Rh4",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rh8",
            "Kh1",
            "Rh7",
            "Kh2",
            "Rh6",
            "Kh1",
            "Rh5",
            "Kh2",
            "Rh4",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rh8",
            "Kh1",
            "Rh7",
            "Kh2",
            "Rh6",
            "Kh1",
            "Rh5",
            "Kh2",
            "Rh4",
            "Kh1",
            "Rh3#",
            "Kh2",
            "Rh8",
            "Kh1",
            "Rh7",
            "Kh2",
            "Rh6",
            "Kh1",
            "Rh5",
            "Kh2",
            "Rh4",
            "Kh1",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b4+",
          "neutral_uci": "b2b4",
          "neutral_response": "26. b4+ Kb5 27. c4+ Kxb4 28. c5+ Kxc5 29. Rd5+ Kc6 30. Rd6+ Kc7 31. R6d4 Be6\n32. Rc1+ Kb8 33. Rxf4 Bxa2 34. Rxg4 a5 35. Ra4 Bb3 36. Ra3 a4 37. f4 b5 38.\nRc5 Bc4 39. Ra1 a3 40. f5 a2 41. f6 Rf8 42. Rc6 Kb7 43. Rd6 Kc7 44. Rd2 Rxf6\n45. Rc2 Kb6 46. Rb2 Kc5 47. Rc2 b4 48. Rac1 a1=Q 49. Rxc4+ Kb5 50. Rc5+ Kb6\n51. Rc6+ Rxc6 52. Rxa1 Rxa1+ 53. Kf2 Ra3 54. Ke2 Rc2+ 55. Kd1 Rxh2 56. Kc1 Ra1# Kg1 Rg2 58. Kh1 Ra1#",
          "neutral_tokens": {
            "prompt_tokens": 316,
            "completion_tokens": 269,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rac1",
            "a1=Q",
            "Rxc4+",
            "Kb5",
            "Rc5+",
            "Kb6",
            "Rc6+",
            "Rxc6",
            "Rxa1",
            "Rxa1+",
            "Kf2",
            "Ra3",
            "Ke2",
            "Rc2+",
            "Kd1",
            "Rxh2",
            "Kc1",
            "Ra1#",
            "Kg1",
            "Rg2",
            "Kh1",
            "Ra1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4d6",
          "positional_uci": "d4d5",
          "neutral_uci": "b2b4",
          "consensus_move": "b2b4",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be6",
              "Rxe6",
              "Rad8",
              "Rde1",
              "Rd2",
              "R6e5+",
              "Kd6",
              "Re6+",
              "Kd7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+",
              "Kc7",
              "Re7+",
              "Kc6",
              "R7e6+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kb6",
              "Rd6+",
              "Kc7",
              "R6d4",
              "fxg3",
              "fxg3",
              "Be6",
              "Re1",
              "Rae8",
              "Rde4",
              "Bd7",
              "Rc4+",
              "Bc6",
              "Rxe8",
              "Rxe8",
              "Rxg4",
              "Re2",
              "Rc4",
              "Rg2+",
              "Kf1",
              "Rxh2",
              "g4",
              "Rg2",
              "Rc3",
              "h2",
              "Rh3",
              "Rg1+",
              "Kf2",
              "h1=Q",
              "Rxh1",
              "Rxh1",
              "Kg3",
              "Rc1",
              "g5",
              "Rxc2",
              "g6",
              "Rxb2",
              "g7",
              "Bd5",
              "Kf4",
              "Rxa2",
              "Ke5",
              "Bg8",
              "Kf6",
              "Rf2+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rxg7",
              "Kf8",
              "Rf7+",
              "Kxg8",
              "Rf1",
              "Kg7",
              "Kd6",
              "Kg6",
              "Ke5",
              "Kg5",
              "Rg1+",
              "Kh4",
              "Kf5",
              "Kh3",
              "Kf4",
              "Kh2",
              "Rg8",
              "Kh3",
              "Rg7",
              "Kh2",
              "Kf3",
              "Kh1",
              "Kf2",
              "Kh2",
              "Rh7#",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rg3",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rh8",
              "Kh1",
              "Rh7",
              "Kh2",
              "Rh6",
              "Kh1",
              "Rh5",
              "Kh2",
              "Rh4",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rh8",
              "Kh1",
              "Rh7",
              "Kh2",
              "Rh6",
              "Kh1",
              "Rh5",
              "Kh2",
              "Rh4",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rh8",
              "Kh1",
              "Rh7",
              "Kh2",
              "Rh6",
              "Kh1",
              "Rh5",
              "Kh2",
              "Rh4",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rh8",
              "Kh1",
              "Rh7",
              "Kh2",
              "Rh6",
              "Kh1",
              "Rh5",
              "Kh2",
              "Rh4",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rh8",
              "Kh1",
              "Rh7",
              "Kh2",
              "Rh6",
              "Kh1",
              "Rh5",
              "Kh2",
              "Rh4",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rh8",
              "Kh1",
              "Rh7",
              "Kh2",
              "Rh6",
              "Kh1",
              "Rh5",
              "Kh2",
              "Rh4",
              "Kh1",
              "Rh3#",
              "Kh2",
              "Rh8",
              "Kh1",
              "Rh7",
              "Kh2",
              "Rh6",
              "Kh1",
              "Rh5",
              "Kh2",
              "Rh4",
              "Kh1",
              "Rh3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rac1",
              "a1=Q",
              "Rxc4+",
              "Kb5",
              "Rc5+",
              "Kb6",
              "Rc6+",
              "Rxc6",
              "Rxa1",
              "Rxa1+",
              "Kf2",
              "Ra3",
              "Ke2",
              "Rc2+",
              "Kd1",
              "Rxh2",
              "Kc1",
              "Ra1#",
              "Kg1",
              "Rg2",
              "Kh1",
              "Ra1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 316,
            "completion_tokens": 269,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 950,
          "total_completion_tokens": 1549,
          "total_tokens": 2499
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 316,
            "completion_tokens": 269,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b4r/pp6/8/2k5/3R1pp1/6Pp/PPP2P1P/3R2K1 w - - 0 26"
    },
    {
      "turn": 53,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd6+",
          "aggressive_uci": "d4d6",
          "aggressive_response": "27. Rd6+ Kb5 28. R1d5+ Kxb4 29. Rd4+ Kc3 30. Rd3+ Kxc2 31. Rd2+ Kc3 32. R2d3+ Kc4 33. R3d4+ Kc5 34. R4d5+ Kc4 35. Rd4+ Kc3 36. Rd3+ Kc2 37. Rd2+ Kc1 38. Rd1+ Kc2 39. R1d2+ Kc3 40. R2d3+ Kc4 41. R3d4+ Kc5 42. R4d5+ Kc4 43. Rd4+ Kc3 44. Rd3+ Kc2 45. Rd2+ Kc1 46. Rd1+ Kc2 47. R1d2+ Kc3 48. R2d3+ Kc4 49. R3d4+ Kc5 50. R4d5+ Kc4 51. Rd4+ Kc3 52. Rd3+ Kc2 53. Rd2+ Kc1 54. Rd1+ Kc2 55. R1d2+ Kc3 56. R2d3+ Kc4 57. R3d4+ Kc5 58. R4d5+ Kc4 59. Rd4+ Kc3 60. Rd3+ Kc2 61. Rd2+ Kc1 62. Rd1+ Kc2 63. R1d2+ Kc3 64. R2d3+ Kc4 65. R3d4+ Kc5 66. R4d5+ Kc4 67. Rd4+ Kc3 68. Rd3+ Kc2 69. Rd2+ Kc1 70. Rd1+ Kc2 71. R1d2+ Kc3 72. R2d3+ Kc4 73. R3d4+ Kc5 74. R4d5+ Kc4 75. Rd4+ Kc3 76. Rd3+ Kc2 77. Rd2+ Kc1 78. Rd1+ Kc2 79. R1d2+ Kc3 80. R2d3+ Kc4 81. R3d4+ Kc5 82. R4d5+ Kc4 83. Rd4+ Kc3 84. Rd3+ Kc2 85. Rd2+ Kc1 86. Rd1+ Kc2 87. R1d2+ Kc3 88. R2d3+ Kc4 89. R3d4+ Kc5 90. R4d5+ Kc4",
          "aggressive_tokens": {
            "prompt_tokens": 325,
            "completion_tokens": 640,
            "total_tokens": 965,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb5",
            "R1d5+",
            "Kxb4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kxc2",
            "Rd2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd6+",
          "positional_uci": "d4d6",
          "positional_response": "27. Rd6+ Kb5 28. R1d5+ Kxb4 29. Rd4+ Kc3 30. Rd3+ Kxc2 31. Rd2+ Kc3 32. R2d3+ Kc4 33. R3d4+ Kc5 34. R4d5+ Kc4 35. Rd4+ Kc3 36. Rd3+ Kc2 37. Rd2+ Kc1 38. Rd1+ Kc2 39. R1d2+ Kc3 40. R2d3+ Kc4 41. R3d4+ Kc5 42. R4d5+ Kc4 43. Rd4+ Kc3 44. Rd3+ Kc2 45. Rd2+ Kc1 46. Rd1+ Kc2 47. R1d2+ Kc3 48. R2d3+ Kc4 49. R3d4+ Kc5 50. R4d5+ Kc4 51. Rd4+ Kc3 52. Rd3+ Kc2 53. Rd2+ Kc1 54. Rd1+ Kc2 55. R1d2+ Kc3 56. R2d3+ Kc4 57. R3d4+ Kc5 58. R4d5+ Kc4 59. Rd4+ Kc3 60. Rd3+ Kc2 61. Rd2+ Kc1 62. Rd1+ Kc2 63. R1d2+ Kc3 64. R2d3+ Kc4 65. R3d4+ Kc5 66. R4d5+ Kc4 67. Rd4+ Kc3 68. Rd3+ Kc2 69. Rd2+ Kc1 70. Rd1+ Kc2 71. R1d2+ Kc3 72. R2d3+ Kc4 73. R3d4+ Kc5 74. R4d5+ Kc4 75. Rd4+ Kc3 76. Rd3+ Kc2 77. Rd2+ Kc1 78. Rd1+ Kc2 79. R1d2+ Kc3 80. R2d3+ Kc4 81. R3d4+ Kc5 82. R4d5+ Kc4 83. Rd4+ Kc3 84. Rd3+ Kc2 85. Rd2+ Kc1 86. Rd1+ Kc2 87. R1d2+ Kc3 88. R2d3+ Kc4 89. R3d4+ Kc5 90. R4d5+ Kc4",
          "positional_tokens": {
            "prompt_tokens": 325,
            "completion_tokens": 640,
            "total_tokens": 965,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb5",
            "R1d5+",
            "Kxb4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kxc2",
            "Rd2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd6+",
          "neutral_uci": "d4d6",
          "neutral_response": "27. Rd6+ Kb5 28. R1d5+ Kxb4 29. Rd4+ Kc3 30. Rd3+ Kxc2 31. Rd2+ Kc3 32. R2d3+ Kc4 33. R3d4+ Kc5 34. R4d5+ Kc4 35. Rd4+ Kc3 36. Rd3+ Kc2 37. Rd2+ Kc1 38. Rd1+ Kc2 39. R1d2+ Kc3 40. R2d3+ Kc4 41. R3d4+ Kc5 42. R4d5+ Kc4 43. Rd4+ Kc3 44. Rd3+ Kc2 45. Rd2+ Kc1 46. Rd1+ Kc2 47. R1d2+ Kc3 48. R2d3+ Kc4 49. R3d4+ Kc5 50. R4d5+ Kc4 51. Rd4+ Kc3 52. Rd3+ Kc2 53. Rd2+ Kc1 54. Rd1+ Kc2 55. R1d2+ Kc3 56. R2d3+ Kc4 57. R3d4+ Kc5 58. R4d5+ Kc4 59. Rd4+ Kc3 60. Rd3+ Kc2 61. Rd2+ Kc1 62. Rd1+ Kc2 63. R1d2+ Kc3 64. R2d3+ Kc4 65. R3d4+ Kc5 66. R4d5+ Kc4 67. Rd4+ Kc3 68. Rd3+ Kc2 69. Rd2+ Kc1 70. Rd1+ Kc2 71. R1d2+ Kc3 72. R2d3+ Kc4 73. R3d4+ Kc5 74. R4d5+ Kc4 75. Rd4+ Kc3 76. Rd3+ Kc2 77. Rd2+ Kc1 78. Rd1+ Kc2 79. R1d2+ Kc3 80. R2d3+ Kc4 81. R3d4+ Kc5 82. R4d5+ Kc4 83. Rd4+ Kc3 84. Rd3+ Kc2 85. Rd2+ Kc1 86. Rd1+ Kc2 87. R1d2+ Kc3 88. R2d3+ Kc4 89. R3d4+ Kc5 90. R4d5+ Kc4",
          "neutral_tokens": {
            "prompt_tokens": 324,
            "completion_tokens": 640,
            "total_tokens": 964,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb5",
            "R1d5+",
            "Kxb4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kxc2",
            "Rd2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4",
            "Rd4+",
            "Kc3",
            "Rd3+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "R1d2+",
            "Kc3",
            "R2d3+",
            "Kc4",
            "R3d4+",
            "Kc5",
            "R4d5+",
            "Kc4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4d6",
          "positional_uci": "d4d6",
          "neutral_uci": "d4d6",
          "consensus_move": "d4d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kb5",
              "R1d5+",
              "Kxb4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kxc2",
              "Rd2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kb5",
              "R1d5+",
              "Kxb4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kxc2",
              "Rd2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kb5",
              "R1d5+",
              "Kxb4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kxc2",
              "Rd2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4",
              "Rd4+",
              "Kc3",
              "Rd3+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "R1d2+",
              "Kc3",
              "R2d3+",
              "Kc4",
              "R3d4+",
              "Kc5",
              "R4d5+",
              "Kc4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 325,
            "completion_tokens": 640,
            "total_tokens": 965,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 325,
            "completion_tokens": 640,
            "total_tokens": 965,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 324,
            "completion_tokens": 640,
            "total_tokens": 964,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 974,
          "total_completion_tokens": 1920,
          "total_tokens": 2894
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 325,
            "completion_tokens": 640,
            "total_tokens": 965,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 325,
            "completion_tokens": 640,
            "total_tokens": 965,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 324,
            "completion_tokens": 640,
            "total_tokens": 964,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b4r/pp6/1k6/8/1P1R1pp1/6Pp/P1P2P1P/3R2K1 w - - 1 27"
    },
    {
      "turn": 55,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "R1d5",
          "aggressive_uci": "d1d5",
          "aggressive_response": "28. R1d5 Re8 29. Kf1 Be6 30. Rd4 Rad8 31. Rxd8 Rxd8 32. Rxf4 Rd1+ 33. Ke2 Rh1 34. Re4 Kd6 35. Rd4+ Ke5 36. Rd8 Rxh2 37. Rh8 Rh1 38. Rh5+ Kd4 39. Rh6 Bc4+ 40. Kd2 Rf1 41. Rd6+ Ke5 42. Rd7 Rxf2+ 43. Kc3 h2 44. Rh7 Bd5 45. Rh5+ Kd6 46. Rh6+ Kc7 47. Rh7+ Kb6 48. Rh6+ Kb5 49. Rh5 h1=Q 50. a4+ Kxa4 51. Rxh1 Bxh1 52. Kd3 Kxb4 53. c3+ Kc5 54. Ke3 Rf3+ 55. Ke4 Rxc3+ 56. Kf4 Bf3 57. Kg5 a5 58. Kf4 a4 59. Kg5 a3 60. Kf4 a2 61. Kg5 a1=Q 62. Kf4 Qc1+ 63. Kf5 Qh6 64. Ke5 Re3+ 65. Kf5 Be4+ 66. Ke5 Bc2#",
          "aggressive_tokens": {
            "prompt_tokens": 334,
            "completion_tokens": 330,
            "total_tokens": 664,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Kf1",
            "Be6",
            "Rd4",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Rxf4",
            "Rd1+",
            "Ke2",
            "Rh1",
            "Re4",
            "Kd6",
            "Rd4+",
            "Ke5",
            "Rd8",
            "Rxh2",
            "Rh8",
            "Rh1",
            "Rh5+",
            "Kd4",
            "Rh6",
            "Bc4+",
            "Kd2",
            "Rf1",
            "Rd6+",
            "Ke5",
            "Rd7",
            "Rxf2+",
            "Kc3",
            "h2",
            "Rh7",
            "Bd5",
            "Rh5+",
            "Kd6",
            "Rh6+",
            "Kc7",
            "Rh7+",
            "Kb6",
            "Rh6+",
            "Kb5",
            "Rh5",
            "h1=Q",
            "a4+",
            "Kxa4",
            "Rxh1",
            "Bxh1",
            "Kd3",
            "Kxb4",
            "c3+",
            "Kc5",
            "Ke3",
            "Rf3+",
            "Ke4",
            "Rxc3+",
            "Kf4",
            "Bf3",
            "Kg5",
            "a5",
            "Kf4",
            "a4",
            "Kg5",
            "a3",
            "Kf4",
            "a2",
            "Kg5",
            "a1=Q",
            "Kf4",
            "Qc1+",
            "Kf5",
            "Qh6",
            "Ke5",
            "Re3+",
            "Kf5",
            "Be4+",
            "Ke5",
            "Bc2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "R1d5",
          "positional_uci": "d1d5",
          "positional_response": "28. R1d5 Re8 29. Kf1 Be6 30. Rd4 Rad8 31. Rxd8 Rxd8 32. Rxf4 Rd1+ 33. Ke2 Rh1 34. Re4 Kd6 35. Rd4+ Ke5 36. Rd8 Rxh2 37. Re8 Rh1 38. Rh8 h2 39. Rh5+ Kd4 40. Rh4 Bc4+ 41. Kd2 Be6 42. c3+ Ke4 43. a4 Kf3 44. Rh6 Bf5 45. Rf6 Rd1+ 46. Kxd1 h1=Q+ 47. Kd2 Qh7 48. Rd6 Kxf2 49. Rd4 Qh6+ 50. Rf4+ Kxg3 51. Ke3 Qxf4+ 52. Ke2 Qf3+ 53. Kd2 Qd3+ 54. Ke1 Kf3 55. c4 Qe2#",
          "positional_tokens": {
            "prompt_tokens": 334,
            "completion_tokens": 239,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Kf1",
            "Be6",
            "Rd4",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Rxf4",
            "Rd1+",
            "Ke2",
            "Rh1",
            "Re4",
            "Kd6",
            "Rd4+",
            "Ke5",
            "Rd8",
            "Rxh2",
            "Re8",
            "Rh1",
            "Rh8",
            "h2",
            "Rh5+",
            "Kd4",
            "Rh4",
            "Bc4+",
            "Kd2",
            "Be6",
            "c3+",
            "Ke4",
            "a4",
            "Kf3",
            "Rh6",
            "Bf5",
            "Rf6",
            "Rd1+",
            "Kxd1",
            "h1=Q+",
            "Kd2",
            "Qh7",
            "Rd6",
            "Kxf2",
            "Rd4",
            "Qh6+",
            "Rf4+",
            "Kxg3",
            "Ke3",
            "Qxf4+",
            "Ke2",
            "Qf3+",
            "Kd2",
            "Qd3+",
            "Ke1",
            "Kf3",
            "c4",
            "Qe2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "R1d5",
          "neutral_uci": "d1d5",
          "neutral_response": "28. R1d5 Re8 29. Kf1 Be6 30. Rd4 Rad8 31. Rxd8 Rxd8 32. Rxf4 Rd1+ 33. Ke2 Rh1 34. Re4 Kd6 35. Rd4+ Ke5 36. Rd8 Rxh2 37. Rb8 Bc4+ 38. Ke3 Rh1 39. Rxb7 Re1+ 40. Kd2 Re2+ 41. Kc3 Bd5 42. Rxa7 h2 43. Rh7 h1=Q 44. Rxh1 Bxh1 45. a4 Rxf2 46. b5 Rf3+ 47. Kb4 Rxg3 48. c4 Rf3 49. b6 g3 50. b7 Rf8 51. a5 g2 52. a6 g1=Q 53. Kb5 Qb1+ 54. Kc5 Qg1+ 55. Kb5 Qa7 56. c5 Bxb7 57. axb7 Qxb7+ 58. Kc4 Qd5+ 59. Kb5 Rb8+ 60. Ka6 Qa2#",
          "neutral_tokens": {
            "prompt_tokens": 333,
            "completion_tokens": 280,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Kf1",
            "Be6",
            "Rd4",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Rxf4",
            "Rd1+",
            "Ke2",
            "Rh1",
            "Re4",
            "Kd6",
            "Rd4+",
            "Ke5",
            "Rd8",
            "Rxh2",
            "Rb8",
            "Bc4+",
            "Ke3",
            "Rh1",
            "Rxb7",
            "Re1+",
            "Kd2",
            "Re2+",
            "Kc3",
            "Bd5",
            "Rxa7",
            "h2",
            "Rh7",
            "h1=Q",
            "Rxh1",
            "Bxh1",
            "a4",
            "Rxf2",
            "b5",
            "Rf3+",
            "Kb4",
            "Rxg3",
            "c4",
            "Rf3",
            "b6",
            "g3",
            "b7",
            "Rf8",
            "a5",
            "g2",
            "a6",
            "g1=Q",
            "Kb5",
            "Qb1+",
            "Kc5",
            "Qg1+",
            "Kb5",
            "Qa7",
            "c5",
            "Bxb7",
            "axb7",
            "Qxb7+",
            "Kc4",
            "Qd5+",
            "Kb5",
            "Rb8+",
            "Ka6",
            "Qa2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1d5",
          "positional_uci": "d1d5",
          "neutral_uci": "d1d5",
          "consensus_move": "d1d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re8",
              "Kf1",
              "Be6",
              "Rd4",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Rxf4",
              "Rd1+",
              "Ke2",
              "Rh1",
              "Re4",
              "Kd6",
              "Rd4+",
              "Ke5",
              "Rd8",
              "Rxh2",
              "Rh8",
              "Rh1",
              "Rh5+",
              "Kd4",
              "Rh6",
              "Bc4+",
              "Kd2",
              "Rf1",
              "Rd6+",
              "Ke5",
              "Rd7",
              "Rxf2+",
              "Kc3",
              "h2",
              "Rh7",
              "Bd5",
              "Rh5+",
              "Kd6",
              "Rh6+",
              "Kc7",
              "Rh7+",
              "Kb6",
              "Rh6+",
              "Kb5",
              "Rh5",
              "h1=Q",
              "a4+",
              "Kxa4",
              "Rxh1",
              "Bxh1",
              "Kd3",
              "Kxb4",
              "c3+",
              "Kc5",
              "Ke3",
              "Rf3+",
              "Ke4",
              "Rxc3+",
              "Kf4",
              "Bf3",
              "Kg5",
              "a5",
              "Kf4",
              "a4",
              "Kg5",
              "a3",
              "Kf4",
              "a2",
              "Kg5",
              "a1=Q",
              "Kf4",
              "Qc1+",
              "Kf5",
              "Qh6",
              "Ke5",
              "Re3+",
              "Kf5",
              "Be4+",
              "Ke5",
              "Bc2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Kf1",
              "Be6",
              "Rd4",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Rxf4",
              "Rd1+",
              "Ke2",
              "Rh1",
              "Re4",
              "Kd6",
              "Rd4+",
              "Ke5",
              "Rd8",
              "Rxh2",
              "Re8",
              "Rh1",
              "Rh8",
              "h2",
              "Rh5+",
              "Kd4",
              "Rh4",
              "Bc4+",
              "Kd2",
              "Be6",
              "c3+",
              "Ke4",
              "a4",
              "Kf3",
              "Rh6",
              "Bf5",
              "Rf6",
              "Rd1+",
              "Kxd1",
              "h1=Q+",
              "Kd2",
              "Qh7",
              "Rd6",
              "Kxf2",
              "Rd4",
              "Qh6+",
              "Rf4+",
              "Kxg3",
              "Ke3",
              "Qxf4+",
              "Ke2",
              "Qf3+",
              "Kd2",
              "Qd3+",
              "Ke1",
              "Kf3",
              "c4",
              "Qe2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re8",
              "Kf1",
              "Be6",
              "Rd4",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Rxf4",
              "Rd1+",
              "Ke2",
              "Rh1",
              "Re4",
              "Kd6",
              "Rd4+",
              "Ke5",
              "Rd8",
              "Rxh2",
              "Rb8",
              "Bc4+",
              "Ke3",
              "Rh1",
              "Rxb7",
              "Re1+",
              "Kd2",
              "Re2+",
              "Kc3",
              "Bd5",
              "Rxa7",
              "h2",
              "Rh7",
              "h1=Q",
              "Rxh1",
              "Bxh1",
              "a4",
              "Rxf2",
              "b5",
              "Rf3+",
              "Kb4",
              "Rxg3",
              "c4",
              "Rf3",
              "b6",
              "g3",
              "b7",
              "Rf8",
              "a5",
              "g2",
              "a6",
              "g1=Q",
              "Kb5",
              "Qb1+",
              "Kc5",
              "Qg1+",
              "Kb5",
              "Qa7",
              "c5",
              "Bxb7",
              "axb7",
              "Qxb7+",
              "Kc4",
              "Qd5+",
              "Kb5",
              "Rb8+",
              "Ka6",
              "Qa2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 334,
            "completion_tokens": 330,
            "total_tokens": 664,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 334,
            "completion_tokens": 239,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 333,
            "completion_tokens": 280,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1001,
          "total_completion_tokens": 849,
          "total_tokens": 1850
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 334,
            "completion_tokens": 330,
            "total_tokens": 664,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 334,
            "completion_tokens": 239,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 333,
            "completion_tokens": 280,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b4r/ppk5/3R4/8/1P3pp1/6Pp/P1P2P1P/3R2K1 w - - 3 28"
    },
    {
      "turn": 57,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c4",
          "aggressive_uci": "c2c4",
          "aggressive_response": "29. c4 Re7 30. Kf1 Be6 31. Rd4 Rae8 32. f3 Bxc4+ 33. Rxc4+ Kxd6 34. Rd4+ Kc6 35. Rc4+ Kb5 36. Rc5+ Kxb4 37. Rc1 Re2 38. Rb1+ Ka3 39. Rb3+ Kxa2 40. Rxb7 Re1+ 41. Kf2 R8e2#",
          "aggressive_tokens": {
            "prompt_tokens": 343,
            "completion_tokens": 113,
            "total_tokens": 456,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re7",
            "Kf1",
            "Be6",
            "Rd4",
            "Rae8",
            "f3",
            "Bxc4+",
            "Rxc4+",
            "Kxd6",
            "Rd4+",
            "Kc6",
            "Rc4+",
            "Kb5",
            "Rc5+",
            "Kxb4",
            "Rc1",
            "Re2",
            "Rb1+",
            "Ka3",
            "Rb3+",
            "Kxa2",
            "Rxb7",
            "Re1+",
            "Kf2",
            "R8e2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c4",
          "positional_uci": "c2c4",
          "positional_response": "29. c4 Re7 30. Kf1 Be6 31. Rd4 Rae8 32. gxf4 Bxc4+ 33. Rxc4+ Kxd6 34. Rc1 Re2 35. a4 Ra2 36. a5 Ree2 37. Rd1+ Ke6 38. Re1 Rxe1+ 39. Kxe1 Kf5 40. Kf1 Kxf4 41. Ke1 Kf3 42. Kd1 Rxf2 43. Ke1 Rxh2 44. Kd1 Rf2 45. Ke1 h2 46. Kd1 h1=Q#",
          "positional_tokens": {
            "prompt_tokens": 343,
            "completion_tokens": 150,
            "total_tokens": 493,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re7",
            "Kf1",
            "Be6",
            "Rd4",
            "Rae8",
            "gxf4",
            "Bxc4+",
            "Rxc4+",
            "Kxd6",
            "Rc1",
            "Re2",
            "a4",
            "Ra2",
            "a5",
            "Ree2",
            "Rd1+",
            "Ke6",
            "Re1",
            "Rxe1+",
            "Kxe1",
            "Kf5",
            "Kf1",
            "Kxf4",
            "Ke1",
            "Kf3",
            "Kd1",
            "Rxf2",
            "Ke1",
            "Rxh2",
            "Kd1",
            "Rf2",
            "Ke1",
            "h2",
            "Kd1",
            "h1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c4",
          "neutral_uci": "c2c4",
          "neutral_response": "29. c4 Re7 30. Kf1 Be6 31. Rd4 Rae8 32. f3 Bxc4+ 33. Rxc4+ Kxd6 34. Rd4+ Kc6\n35. Rc4+ Kb5 36. Rc5+ Kxb4 37. Rc1 Re2 38. Rb1+ Ka3 39. Rb3+ Kxa2 40. Rb1 Kxb1\n41. Kg1 Re1+ 42. Kf2 R8e2#",
          "neutral_tokens": {
            "prompt_tokens": 342,
            "completion_tokens": 121,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re7",
            "Kf1",
            "Be6",
            "Rd4",
            "Rae8",
            "f3",
            "Bxc4+",
            "Rxc4+",
            "Kxd6",
            "Rd4+",
            "Kc6",
            "Rc4+",
            "Kb5",
            "Rc5+",
            "Kxb4",
            "Rc1",
            "Re2",
            "Rb1+",
            "Ka3",
            "Rb3+",
            "Kxa2",
            "Rb1",
            "Kxb1",
            "Kg1",
            "Re1+",
            "Kf2",
            "R8e2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c4",
          "positional_uci": "c2c4",
          "neutral_uci": "c2c4",
          "consensus_move": "c2c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re7",
              "Kf1",
              "Be6",
              "Rd4",
              "Rae8",
              "f3",
              "Bxc4+",
              "Rxc4+",
              "Kxd6",
              "Rd4+",
              "Kc6",
              "Rc4+",
              "Kb5",
              "Rc5+",
              "Kxb4",
              "Rc1",
              "Re2",
              "Rb1+",
              "Ka3",
              "Rb3+",
              "Kxa2",
              "Rxb7",
              "Re1+",
              "Kf2",
              "R8e2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re7",
              "Kf1",
              "Be6",
              "Rd4",
              "Rae8",
              "gxf4",
              "Bxc4+",
              "Rxc4+",
              "Kxd6",
              "Rc1",
              "Re2",
              "a4",
              "Ra2",
              "a5",
              "Ree2",
              "Rd1+",
              "Ke6",
              "Re1",
              "Rxe1+",
              "Kxe1",
              "Kf5",
              "Kf1",
              "Kxf4",
              "Ke1",
              "Kf3",
              "Kd1",
              "Rxf2",
              "Ke1",
              "Rxh2",
              "Kd1",
              "Rf2",
              "Ke1",
              "h2",
              "Kd1",
              "h1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re7",
              "Kf1",
              "Be6",
              "Rd4",
              "Rae8",
              "f3",
              "Bxc4+",
              "Rxc4+",
              "Kxd6",
              "Rd4+",
              "Kc6",
              "Rc4+",
              "Kb5",
              "Rc5+",
              "Kxb4",
              "Rc1",
              "Re2",
              "Rb1+",
              "Ka3",
              "Rb3+",
              "Kxa2",
              "Rb1",
              "Kxb1",
              "Kg1",
              "Re1+",
              "Kf2",
              "R8e2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 343,
            "completion_tokens": 113,
            "total_tokens": 456,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 343,
            "completion_tokens": 150,
            "total_tokens": 493,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 342,
            "completion_tokens": 121,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1028,
          "total_completion_tokens": 384,
          "total_tokens": 1412
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 343,
            "completion_tokens": 113,
            "total_tokens": 456,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 343,
            "completion_tokens": 150,
            "total_tokens": 493,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 342,
            "completion_tokens": 121,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b5/ppk4r/3R4/3R4/1P3pp1/6Pp/P1P2P1P/6K1 w - - 5 29"
    },
    {
      "turn": 59,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b5",
          "aggressive_uci": "b4b5",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 b6 31. Rc6+ Kb7 32. Rdd6 Ka7 33. Rxb6 Rb8 34. Rbc6 Bb7 35. b6+ Ka8 36. Rc5 Re8 37. Rxa5+ Kb8 38. Rd1 Rhe7 39. Kf1 Bg2+ 40. Kg1 Re1+ 41. Rxe1 Rxe1#",
          "aggressive_tokens": {
            "prompt_tokens": 350,
            "completion_tokens": 341,
            "total_tokens": 691,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b6",
            "Rc6+",
            "Kb7",
            "Rdd6",
            "Ka7",
            "Rxb6",
            "Rb8",
            "Rbc6",
            "Bb7",
            "b6+",
            "Ka8",
            "Rc5",
            "Re8",
            "Rxa5+",
            "Kb8",
            "Rd1",
            "Rhe7",
            "Kf1",
            "Bg2+",
            "Kg1",
            "Re1+",
            "Rxe1",
            "Rxe1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b5",
          "positional_uci": "b4b5",
          "positional_response": "30. b5 b6 31. Rc6+ Kb7 32. Rdd6 Ka7 33. Rxb6 Bb7 34. c5 Re8 35. Kf1 Rhe7 36. Rd1 Bg2+ 37. Kg1 Re1+ 38. Rxe1 Rxe1#",
          "positional_tokens": {
            "prompt_tokens": 350,
            "completion_tokens": 74,
            "total_tokens": 424,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b6",
            "Rc6+",
            "Kb7",
            "Rdd6",
            "Ka7",
            "Rxb6",
            "Bb7",
            "c5",
            "Re8",
            "Kf1",
            "Rhe7",
            "Rd1",
            "Bg2+",
            "Kg1",
            "Re1+",
            "Rxe1",
            "Rxe1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b5",
          "neutral_uci": "b4b5",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 b6 31. Rc6+ Kb7 32. Rdd6 Ka7 33. Rxb6 Bb7 34. c5 Re8 35. Kf1 Bg2+ 36. Kg1 Re1# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 349,
            "completion_tokens": 302,
            "total_tokens": 651,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b6",
            "Rc6+",
            "Kb7",
            "Rdd6",
            "Ka7",
            "Rxb6",
            "Bb7",
            "c5",
            "Re8",
            "Kf1",
            "Bg2+",
            "Kg1",
            "Re1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b4b5",
          "positional_uci": "b4b5",
          "neutral_uci": "b4b5",
          "consensus_move": "b4b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b6",
              "Rc6+",
              "Kb7",
              "Rdd6",
              "Ka7",
              "Rxb6",
              "Rb8",
              "Rbc6",
              "Bb7",
              "b6+",
              "Ka8",
              "Rc5",
              "Re8",
              "Rxa5+",
              "Kb8",
              "Rd1",
              "Rhe7",
              "Kf1",
              "Bg2+",
              "Kg1",
              "Re1+",
              "Rxe1",
              "Rxe1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "b6",
              "Rc6+",
              "Kb7",
              "Rdd6",
              "Ka7",
              "Rxb6",
              "Bb7",
              "c5",
              "Re8",
              "Kf1",
              "Rhe7",
              "Rd1",
              "Bg2+",
              "Kg1",
              "Re1+",
              "Rxe1",
              "Rxe1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "b6",
              "Rc6+",
              "Kb7",
              "Rdd6",
              "Ka7",
              "Rxb6",
              "Bb7",
              "c5",
              "Re8",
              "Kf1",
              "Bg2+",
              "Kg1",
              "Re1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 350,
            "completion_tokens": 341,
            "total_tokens": 691,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 350,
            "completion_tokens": 74,
            "total_tokens": 424,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 349,
            "completion_tokens": 302,
            "total_tokens": 651,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1049,
          "total_completion_tokens": 717,
          "total_tokens": 1766
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 350,
            "completion_tokens": 341,
            "total_tokens": 691,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 350,
            "completion_tokens": 74,
            "total_tokens": 424,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 349,
            "completion_tokens": 302,
            "total_tokens": 651,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b5/1pk4r/3R4/p2R4/1PP2pp1/6Pp/P4P1P/6K1 w - - 0 30"
    },
    {
      "turn": 61,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c5",
          "aggressive_uci": "c4c5",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 fxg3 32. b6+ Kb8 33. Rd8 gxf2+ 34. Kf1 g3 35. hxg3 h2 36. Rh5 h1=Q+ 37. Rxh1 Ra6 38. Rhh8 Rxb6 39. cxb6 Rc7 40. bxc7+ Kxc7 41. Rxc8+ Kb6 42. Rh6+ Ka7 43. Rc7 Kb8 44. Rhh7 Ka8 45. Rxb7 a4 46. Rbg7 a3 47. Rg8#",
          "aggressive_tokens": {
            "prompt_tokens": 358,
            "completion_tokens": 390,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxg3",
            "b6+",
            "Kb8",
            "Rd8",
            "gxf2+",
            "Kf1",
            "g3",
            "hxg3",
            "h2",
            "Rh5",
            "h1=Q+",
            "Rxh1",
            "Ra6",
            "Rhh8",
            "Rxb6",
            "cxb6",
            "Rc7",
            "bxc7+",
            "Kxc7",
            "Rxc8+",
            "Kb6",
            "Rh6+",
            "Ka7",
            "Rc7",
            "Kb8",
            "Rhh7",
            "Ka8",
            "Rxb7",
            "a4",
            "Rbg7",
            "a3",
            "Rg8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b6+",
          "positional_uci": "b5b6",
          "positional_response": "31. b6+ Kb8 32. Rd8 Ra6 33. Rc5 Rxb6",
          "positional_tokens": {
            "prompt_tokens": 358,
            "completion_tokens": 23,
            "total_tokens": 381,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kb8",
            "Rd8",
            "Ra6",
            "Rc5",
            "Rxb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c5",
          "neutral_uci": "c4c5",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 fxg3 32. b6+ Kb8 33. Rd8 gxf2+ 34. Kf1 Ra6 35. Rxc8+ Kxc8 36. Rd4 a4 37. Rxg4 Ra5 38. Rg8+ Kd7 39. Rg5 Kc6 40. Rg6+ Kxc5 41. Rg5+ Kxb6 42. Rg6+ Ka7 43. Rg3 Re5 44. Rxh3 Re1+ 45. Kg2 f1=Q+ 46. Kg3 Re3+ 47. Kg4 Qxh3+ 48. Kg5 Re5+ 49. Kg6 Qh5#",
          "neutral_tokens": {
            "prompt_tokens": 357,
            "completion_tokens": 417,
            "total_tokens": 774,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxg3",
            "b6+",
            "Kb8",
            "Rd8",
            "gxf2+",
            "Kf1",
            "Ra6",
            "Rxc8+",
            "Kxc8",
            "Rd4",
            "a4",
            "Rxg4",
            "Ra5",
            "Rg8+",
            "Kd7",
            "Rg5",
            "Kc6",
            "Rg6+",
            "Kxc5",
            "Rg5+",
            "Kxb6",
            "Rg6+",
            "Ka7",
            "Rg3",
            "Re5",
            "Rxh3",
            "Re1+",
            "Kg2",
            "f1=Q+",
            "Kg3",
            "Re3+",
            "Kg4",
            "Qxh3+",
            "Kg5",
            "Re5+",
            "Kg6",
            "Qh5#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4c5",
          "positional_uci": "b5b6",
          "neutral_uci": "c4c5",
          "consensus_move": "c4c5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxg3",
              "b6+",
              "Kb8",
              "Rd8",
              "gxf2+",
              "Kf1",
              "g3",
              "hxg3",
              "h2",
              "Rh5",
              "h1=Q+",
              "Rxh1",
              "Ra6",
              "Rhh8",
              "Rxb6",
              "cxb6",
              "Rc7",
              "bxc7+",
              "Kxc7",
              "Rxc8+",
              "Kb6",
              "Rh6+",
              "Ka7",
              "Rc7",
              "Kb8",
              "Rhh7",
              "Ka8",
              "Rxb7",
              "a4",
              "Rbg7",
              "a3",
              "Rg8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kb8",
              "Rd8",
              "Ra6",
              "Rc5",
              "Rxb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "fxg3",
              "b6+",
              "Kb8",
              "Rd8",
              "gxf2+",
              "Kf1",
              "Ra6",
              "Rxc8+",
              "Kxc8",
              "Rd4",
              "a4",
              "Rxg4",
              "Ra5",
              "Rg8+",
              "Kd7",
              "Rg5",
              "Kc6",
              "Rg6+",
              "Kxc5",
              "Rg5+",
              "Kxb6",
              "Rg6+",
              "Ka7",
              "Rg3",
              "Re5",
              "Rxh3",
              "Re1+",
              "Kg2",
              "f1=Q+",
              "Kg3",
              "Re3+",
              "Kg4",
              "Qxh3+",
              "Kg5",
              "Re5+",
              "Kg6",
              "Qh5#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 358,
            "completion_tokens": 390,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 358,
            "completion_tokens": 23,
            "total_tokens": 381,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 357,
            "completion_tokens": 417,
            "total_tokens": 774,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1073,
          "total_completion_tokens": 830,
          "total_tokens": 1903
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 358,
            "completion_tokens": 390,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 358,
            "completion_tokens": 23,
            "total_tokens": 381,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 357,
            "completion_tokens": 417,
            "total_tokens": 774,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b5/1pk2r2/3R4/pP1R4/2P2pp1/6Pp/P4P1P/6K1 w - - 1 31"
    },
    {
      "turn": 63,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b6+",
          "aggressive_uci": "b5b6",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Rd8 Re1#",
          "aggressive_tokens": {
            "prompt_tokens": 365,
            "completion_tokens": 273,
            "total_tokens": 638,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kb8",
            "Rd8",
            "Re1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b6+",
          "positional_uci": "b5b6",
          "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Rd8 Re1#",
          "positional_tokens": {
            "prompt_tokens": 365,
            "completion_tokens": 272,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kb8",
            "Rd8",
            "Re1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b6+",
          "neutral_uci": "b5b6",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Rd8 Re1#",
          "neutral_tokens": {
            "prompt_tokens": 364,
            "completion_tokens": 272,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kb8",
            "Rd8",
            "Re1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b5b6",
          "positional_uci": "b5b6",
          "neutral_uci": "b5b6",
          "consensus_move": "b5b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kb8",
              "Rd8",
              "Re1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kb8",
              "Rd8",
              "Re1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kb8",
              "Rd8",
              "Re1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 365,
            "completion_tokens": 273,
            "total_tokens": 638,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 365,
            "completion_tokens": 272,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 364,
            "completion_tokens": 272,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1094,
          "total_completion_tokens": 817,
          "total_tokens": 1911
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 365,
            "completion_tokens": 273,
            "total_tokens": 638,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 365,
            "completion_tokens": 272,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 364,
            "completion_tokens": 272,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b5/1pk1r3/3R4/pPPR4/5pp1/6Pp/P4P1P/6K1 w - - 1 32"
    },
    {
      "turn": 65,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf1",
          "aggressive_uci": "g1f1",
          "aggressive_response": "33. Kf1 Ra6 34. Rd8 Rxb6 35. cxb6 Re6 36. R5d6 Re4 37. gxf4 Rxf4 38. Rg6 Rc4\n39. Rgg8 Rc1+ 40. Ke2 Rc2+ 41. Ke3 Rc3+ 42. Kd4 Rc2 43. Ke5 Rc5+ 44. Kd6 Rc6+\n45. Ke7 Rc2 46. Rxc8+ Rxc8 47. Rxc8+ Kxc8 48. Kf6 Kd7 49. Kg5 Kc6 50. Kxg4 Kxb6\n51. f4 Kc6 52. f5 Kd7 53. Kg5 Ke7 54. Kg6 Kf8 55. Kf6 b5 56. Ke5 b4 57. Kd4 a4\n58. Kc4 b3 59. axb3 a3 60. Kc3 Kf7 61. b4 Kf6 62. b5 Kxf5 63. b6 Ke6 64. b7 a2\n65. Kb2 Kd7 66. b8=Q Kc6 67. Kxa2 Kd5 68. Qg3 Ke4 69. Qxh3 Kf4 70. Qg3+ Kf5\n71. h4 Kf6 72. h5 Kf7 73. h6 Kf8 74. h7 Kf7 75. h8=Q Ke6 76. Qhe5+ Kd7\n77. Qgg7+ Kc6 78. Qgc7# Kd8 79. Qee7# Kd7 80. Qcd6+ Kc8 81. Qec7# Kd8 82. Qcd7# Kc8 83. Q6c7# Kd8",
          "aggressive_tokens": {
            "prompt_tokens": 373,
            "completion_tokens": 440,
            "total_tokens": 813,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ra6",
            "Rd8",
            "Rxb6",
            "cxb6",
            "Re6",
            "R5d6",
            "Re4",
            "gxf4",
            "Rxf4",
            "Rg6",
            "Rc4",
            "Rgg8",
            "Rc1+",
            "Ke2",
            "Rc2+",
            "Ke3",
            "Rc3+",
            "Kd4",
            "Rc2",
            "Ke5",
            "Rc5+",
            "Kd6",
            "Rc6+",
            "Ke7",
            "Rc2",
            "Rxc8+",
            "Rxc8",
            "Rxc8+",
            "Kxc8",
            "Kf6",
            "Kd7",
            "Kg5",
            "Kc6",
            "Kxg4",
            "Kxb6",
            "f4",
            "Kc6",
            "f5",
            "Kd7",
            "Kg5",
            "Ke7",
            "Kg6",
            "Kf8",
            "Kf6",
            "b5",
            "Ke5",
            "b4",
            "Kd4",
            "a4",
            "Kc4",
            "b3",
            "axb3",
            "a3",
            "Kc3",
            "Kf7",
            "b4",
            "Kf6",
            "b5",
            "Kxf5",
            "b6",
            "Ke6",
            "b7",
            "a2",
            "Kb2",
            "Kd7",
            "b8=Q",
            "Kc6",
            "Kxa2",
            "Kd5",
            "Qg3",
            "Ke4",
            "Qxh3",
            "Kf4",
            "Qg3+",
            "Kf5",
            "h4",
            "Kf6",
            "h5",
            "Kf7",
            "h6",
            "Kf8",
            "h7",
            "Kf7",
            "h8=Q",
            "Ke6",
            "Qhe5+",
            "Kd7",
            "Qgg7+",
            "Kc6",
            "Qgc7#",
            "Kd8",
            "Qee7#",
            "Kd7",
            "Qcd6+",
            "Kc8",
            "Qec7#",
            "Kd8",
            "Qcd7#",
            "Kc8",
            "Q6c7#",
            "Kd8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd8",
          "positional_uci": "d6d8",
          "positional_response": "33. Rd8 Re1#",
          "positional_tokens": {
            "prompt_tokens": 373,
            "completion_tokens": 8,
            "total_tokens": 381,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kf1",
          "neutral_uci": "g1f1",
          "neutral_response": "33. Kf1 Ra6 34. Rd8 Rxb6 35. cxb6 Re1+ 36. Kxe1 a4 37. Rc5 a3 38. Rdxc8# Bxc8\n39. gxf4 Be6 40. f5 Bxa2 41. f6 Bf7 42. Rc7 a2 43. Rc1 Bg6 44. Kd2 Bb1 45.\nf7 a1=Q 46. f8=Q# Bg6 47. Qd8# Bf7 48. Qc7+ Ka8 49. Qc8# Bg8 50. Qxg8# Bf7\n51. Qxf7# Bg8 52. Qxg8# Bf7 53. Qxf7# Bg8 54. Qxg8# Bf7 55. Qxf7# Bg8 56.\nQxg8# Bf7 57. Qxf7# Bg8 58. Qxg8# Bf7 59. Qxf7# Bg8 60. Qxg8# Bf7 61. Qxf7# Bg8 62. Qxg8# Bf7 63. Qxf7# Bg8 64. Qxg8# Bf7 65. Qxf7# Bg8 66. Qxg8# Bf7 67. Qxf7# Bg8 68. Qxg8# Bf7 69. Qxf7# Bg8 70. Qxg8# Bf7 71. Qxf7# Bg8 72. Qxg8# Bf7 73. Qxf7# Bg8 74. Qxg8# Bf7 75. Qxf7# Bg8 76. Qxg8# Bf7 77. Qxf7# Bg8 78. Qxg8# Bf7 79. Qxf7# Bg8 80. Qxg8# Bf7 81. Qxf7# Bg8 82. Qxg8# Bf7 83. Qxf7# Bg8 84. Qxg8# Bf7 85. Qxf7# Bg8 86. Qxg8# Bf7 87. Qxf7# Bg8 88. Qxg8# Bf7 89. Qxf7# Bg8 90. Qxg8# Bf7 91. Qxf7# Bg8 92. Qxg8# Bf7 93. Qxf7# Bg8 94. Qxg8# Bf7 95. Qxf7# Bg8 96. Qxg8# Bf",
          "neutral_tokens": {
            "prompt_tokens": 372,
            "completion_tokens": 640,
            "total_tokens": 1012,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ra6",
            "Rd8",
            "Rxb6",
            "cxb6",
            "Re1+",
            "Kxe1",
            "a4",
            "Rc5",
            "a3",
            "Rdxc8#",
            "Bxc8",
            "gxf4",
            "Be6",
            "f5",
            "Bxa2",
            "f6",
            "Bf7",
            "Rc7",
            "a2",
            "Rc1",
            "Bg6",
            "Kd2",
            "Bb1",
            "f7",
            "a1=Q",
            "f8=Q#",
            "Bg6",
            "Qd8#",
            "Bf7",
            "Qc7+",
            "Ka8",
            "Qc8#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#",
            "Bf7",
            "Qxf7#",
            "Bg8",
            "Qxg8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f1",
          "positional_uci": "d6d8",
          "neutral_uci": "g1f1",
          "consensus_move": "g1f1",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ra6",
              "Rd8",
              "Rxb6",
              "cxb6",
              "Re6",
              "R5d6",
              "Re4",
              "gxf4",
              "Rxf4",
              "Rg6",
              "Rc4",
              "Rgg8",
              "Rc1+",
              "Ke2",
              "Rc2+",
              "Ke3",
              "Rc3+",
              "Kd4",
              "Rc2",
              "Ke5",
              "Rc5+",
              "Kd6",
              "Rc6+",
              "Ke7",
              "Rc2",
              "Rxc8+",
              "Rxc8",
              "Rxc8+",
              "Kxc8",
              "Kf6",
              "Kd7",
              "Kg5",
              "Kc6",
              "Kxg4",
              "Kxb6",
              "f4",
              "Kc6",
              "f5",
              "Kd7",
              "Kg5",
              "Ke7",
              "Kg6",
              "Kf8",
              "Kf6",
              "b5",
              "Ke5",
              "b4",
              "Kd4",
              "a4",
              "Kc4",
              "b3",
              "axb3",
              "a3",
              "Kc3",
              "Kf7",
              "b4",
              "Kf6",
              "b5",
              "Kxf5",
              "b6",
              "Ke6",
              "b7",
              "a2",
              "Kb2",
              "Kd7",
              "b8=Q",
              "Kc6",
              "Kxa2",
              "Kd5",
              "Qg3",
              "Ke4",
              "Qxh3",
              "Kf4",
              "Qg3+",
              "Kf5",
              "h4",
              "Kf6",
              "h5",
              "Kf7",
              "h6",
              "Kf8",
              "h7",
              "Kf7",
              "h8=Q",
              "Ke6",
              "Qhe5+",
              "Kd7",
              "Qgg7+",
              "Kc6",
              "Qgc7#",
              "Kd8",
              "Qee7#",
              "Kd7",
              "Qcd6+",
              "Kc8",
              "Qec7#",
              "Kd8",
              "Qcd7#",
              "Kc8",
              "Q6c7#",
              "Kd8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ra6",
              "Rd8",
              "Rxb6",
              "cxb6",
              "Re1+",
              "Kxe1",
              "a4",
              "Rc5",
              "a3",
              "Rdxc8#",
              "Bxc8",
              "gxf4",
              "Be6",
              "f5",
              "Bxa2",
              "f6",
              "Bf7",
              "Rc7",
              "a2",
              "Rc1",
              "Bg6",
              "Kd2",
              "Bb1",
              "f7",
              "a1=Q",
              "f8=Q#",
              "Bg6",
              "Qd8#",
              "Bf7",
              "Qc7+",
              "Ka8",
              "Qc8#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#",
              "Bf7",
              "Qxf7#",
              "Bg8",
              "Qxg8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 373,
            "completion_tokens": 440,
            "total_tokens": 813,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 373,
            "completion_tokens": 8,
            "total_tokens": 381,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 372,
            "completion_tokens": 640,
            "total_tokens": 1012,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1118,
          "total_completion_tokens": 1088,
          "total_tokens": 2206
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 373,
            "completion_tokens": 440,
            "total_tokens": 813,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 373,
            "completion_tokens": 8,
            "total_tokens": 381,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 372,
            "completion_tokens": 640,
            "total_tokens": 1012,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rkb5/1p2r3/1P1R4/p1PR4/5pp1/6Pp/P4P1P/6K1 w - - 1 33"
    },
    {
      "turn": 67,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd8",
          "aggressive_uci": "d6d8",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 Ra5 35. Rxc8+ Kxc8 36. Rg5 Rb5 37. Rg8+ Kd7 38. Rb8 Rb1# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6 Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Nf6 gxf6 Qd6+ Qe6 Qxe6+ Kxe6 Rad1 f5 Bxf5+ Kxf5 Rd4 Rhg8+ Kh1 Rg4 Rfd1 Rxd4 Rxd4 Re8 Kg1 Re1#",
          "aggressive_tokens": {
            "prompt_tokens": 382,
            "completion_tokens": 461,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ra5",
            "Rxc8+",
            "Kxc8",
            "Rg5",
            "Rb5",
            "Rg8+",
            "Kd7",
            "Rb8",
            "Rb1#",
            "e4",
            "c5",
            "Nf3",
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Ndb5",
            "Be7",
            "Nd6",
            "Kf8",
            "Be2",
            "Kg8",
            "O-O",
            "h5",
            "Bf4",
            "h4",
            "e5",
            "Ne8",
            "Nce4",
            "Bxd6",
            "Nxd6",
            "g5",
            "Nxe8",
            "Kf8",
            "Nf6",
            "gxf4",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Nf6",
            "gxf6",
            "Qd6+",
            "Qe6",
            "Qxe6+",
            "Kxe6",
            "Rad1",
            "f5",
            "Bxf5+",
            "Kxf5",
            "Rd4",
            "Rhg8+",
            "Kh1",
            "Rg4",
            "Rfd1",
            "Rxd4",
            "Rxd4",
            "Re8",
            "Kg1",
            "Re1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd8",
          "positional_uci": "d6d8",
          "positional_response": "34. Rd8 Ra5 35. Rf5 Rb5 36. Rxf4 Rb1+ 37. Rd1 Rxd1#",
          "positional_tokens": {
            "prompt_tokens": 382,
            "completion_tokens": 35,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ra5",
            "Rf5",
            "Rb5",
            "Rxf4",
            "Rb1+",
            "Rd1",
            "Rxd1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd8",
          "neutral_uci": "d6d8",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 Ra5 35. Rxc8+ Kxc8 36. Rg5 Rb5 37. Rg8+ Kd7 38. f3 Rb1+ 39. Kf2 Rb2+ 40. Kf1 fxg3 41. hxg3 h2 42. Rh8 h1=Q+ 43. Rxh1 Rb1+ 44. Kg2 Re2# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 381,
            "completion_tokens": 376,
            "total_tokens": 757,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ra5",
            "Rxc8+",
            "Kxc8",
            "Rg5",
            "Rb5",
            "Rg8+",
            "Kd7",
            "f3",
            "Rb1+",
            "Kf2",
            "Rb2+",
            "Kf1",
            "fxg3",
            "hxg3",
            "h2",
            "Rh8",
            "h1=Q+",
            "Rxh1",
            "Rb1+",
            "Kg2",
            "Re2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d6d8",
          "positional_uci": "d6d8",
          "neutral_uci": "d6d8",
          "consensus_move": "d6d8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ra5",
              "Rxc8+",
              "Kxc8",
              "Rg5",
              "Rb5",
              "Rg8+",
              "Kd7",
              "Rb8",
              "Rb1#",
              "e4",
              "c5",
              "Nf3",
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Ndb5",
              "Be7",
              "Nd6",
              "Kf8",
              "Be2",
              "Kg8",
              "O-O",
              "h5",
              "Bf4",
              "h4",
              "e5",
              "Ne8",
              "Nce4",
              "Bxd6",
              "Nxd6",
              "g5",
              "Nxe8",
              "Kf8",
              "Nf6",
              "gxf4",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Nf6",
              "gxf6",
              "Qd6+",
              "Qe6",
              "Qxe6+",
              "Kxe6",
              "Rad1",
              "f5",
              "Bxf5+",
              "Kxf5",
              "Rd4",
              "Rhg8+",
              "Kh1",
              "Rg4",
              "Rfd1",
              "Rxd4",
              "Rxd4",
              "Re8",
              "Kg1",
              "Re1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ra5",
              "Rf5",
              "Rb5",
              "Rxf4",
              "Rb1+",
              "Rd1",
              "Rxd1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ra5",
              "Rxc8+",
              "Kxc8",
              "Rg5",
              "Rb5",
              "Rg8+",
              "Kd7",
              "f3",
              "Rb1+",
              "Kf2",
              "Rb2+",
              "Kf1",
              "fxg3",
              "hxg3",
              "h2",
              "Rh8",
              "h1=Q+",
              "Rxh1",
              "Rb1+",
              "Kg2",
              "Re2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 382,
            "completion_tokens": 461,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 382,
            "completion_tokens": 35,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 381,
            "completion_tokens": 376,
            "total_tokens": 757,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1145,
          "total_completion_tokens": 872,
          "total_tokens": 2017
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 382,
            "completion_tokens": 461,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 382,
            "completion_tokens": 35,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 381,
            "completion_tokens": 376,
            "total_tokens": 757,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rkb5/1p2r3/1P1R4/2PR4/p4pp1/6Pp/P4P1P/5K2 w - - 0 34"
    },
    {
      "turn": 69,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc8+",
          "aggressive_uci": "d8c8",
          "aggressive_response": "35. Rxc8+ Kxc8 36. Rg5 Ra5 37. Rxg4 Rxc5 38. Rg8+ Kd7 39. Rg4 Rc1#",
          "aggressive_tokens": {
            "prompt_tokens": 389,
            "completion_tokens": 46,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxc8",
            "Rg5",
            "Ra5",
            "Rxg4",
            "Rxc5",
            "Rg8+",
            "Kd7",
            "Rg4",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc8+",
          "positional_uci": "d8c8",
          "positional_response": "35. Rxc8+ Kxc8 36. Rg5 Ra5 37. Rxg4 Rxc5 38. Rg8+ Kd7 39. Rg4 Rc1#",
          "positional_tokens": {
            "prompt_tokens": 389,
            "completion_tokens": 46,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxc8",
            "Rg5",
            "Ra5",
            "Rxg4",
            "Rxc5",
            "Rg8+",
            "Kd7",
            "Rg4",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc8+",
          "neutral_uci": "d8c8",
          "neutral_response": "35. Rxc8+ Kxc8 36. Rg5 Ra5 37. Rxg4 Rxc5 38. Rg8+ Kd7 39. Rg4 Rc1#",
          "neutral_tokens": {
            "prompt_tokens": 388,
            "completion_tokens": 46,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxc8",
            "Rg5",
            "Ra5",
            "Rxg4",
            "Rxc5",
            "Rg8+",
            "Kd7",
            "Rg4",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8c8",
          "positional_uci": "d8c8",
          "neutral_uci": "d8c8",
          "consensus_move": "d8c8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxc8",
              "Rg5",
              "Ra5",
              "Rxg4",
              "Rxc5",
              "Rg8+",
              "Kd7",
              "Rg4",
              "Rc1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxc8",
              "Rg5",
              "Ra5",
              "Rxg4",
              "Rxc5",
              "Rg8+",
              "Kd7",
              "Rg4",
              "Rc1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxc8",
              "Rg5",
              "Ra5",
              "Rxg4",
              "Rxc5",
              "Rg8+",
              "Kd7",
              "Rg4",
              "Rc1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 389,
            "completion_tokens": 46,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 389,
            "completion_tokens": 46,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 388,
            "completion_tokens": 46,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1166,
          "total_completion_tokens": 138,
          "total_tokens": 1304
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 389,
            "completion_tokens": 46,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 389,
            "completion_tokens": 46,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 388,
            "completion_tokens": 46,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rkbR4/1p2r3/1P6/2PR4/p5p1/5pPp/P4P1P/5K2 w - - 0 35"
    },
    {
      "turn": 71,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd4",
          "aggressive_uci": "d5d4",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rd4 Ra5 37. Rxg4 Rxc5 38. Rg8+ Kd7 39. Rg4 Rc1#",
          "aggressive_tokens": {
            "prompt_tokens": 399,
            "completion_tokens": 324,
            "total_tokens": 723,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ra5",
            "Rxg4",
            "Rxc5",
            "Rg8+",
            "Kd7",
            "Rg4",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd8+",
          "positional_uci": "d5d8",
          "positional_response": "36. Rd8+ Kxd8 37. c6 bxc6 38. b7 Rxb7 39. Ke1 Rb2 40. Kd1 Rxf2 41. Kc1 Rxh2 42. Kb1 Rg2 43. Kc1 h2 44. Kb1 h1=Q#",
          "positional_tokens": {
            "prompt_tokens": 399,
            "completion_tokens": 77,
            "total_tokens": 476,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxd8",
            "c6",
            "bxc6",
            "b7",
            "Rxb7",
            "Ke1",
            "Rb2",
            "Kd1",
            "Rxf2",
            "Kc1",
            "Rxh2",
            "Kb1",
            "Rg2",
            "Kc1",
            "h2",
            "Kb1",
            "h1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rg5",
          "neutral_uci": "d5g5",
          "neutral_response": "36. Rg5 Ra5 37. Rg8+ Kd7 38. Rb8 Rxc5 39. Rxb7+ Kd6 40. Rxe7 Kxe7 41. b7 Rc1# Rxc1#",
          "neutral_tokens": {
            "prompt_tokens": 398,
            "completion_tokens": 58,
            "total_tokens": 456,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ra5",
            "Rg8+",
            "Kd7",
            "Rb8",
            "Rxc5",
            "Rxb7+",
            "Kd6",
            "Rxe7",
            "Kxe7",
            "b7",
            "Rc1#",
            "Rxc1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d5d4",
          "positional_uci": "d5d8",
          "neutral_uci": "d5g5",
          "consensus_move": "d5g5",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ra5",
              "Rxg4",
              "Rxc5",
              "Rg8+",
              "Kd7",
              "Rg4",
              "Rc1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxd8",
              "c6",
              "bxc6",
              "b7",
              "Rxb7",
              "Ke1",
              "Rb2",
              "Kd1",
              "Rxf2",
              "Kc1",
              "Rxh2",
              "Kb1",
              "Rg2",
              "Kc1",
              "h2",
              "Kb1",
              "h1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ra5",
              "Rg8+",
              "Kd7",
              "Rb8",
              "Rxc5",
              "Rxb7+",
              "Kd6",
              "Rxe7",
              "Kxe7",
              "b7",
              "Rc1#",
              "Rxc1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 399,
            "completion_tokens": 324,
            "total_tokens": 723,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 399,
            "completion_tokens": 77,
            "total_tokens": 476,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 398,
            "completion_tokens": 58,
            "total_tokens": 456,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1196,
          "total_completion_tokens": 459,
          "total_tokens": 1655
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 399,
            "completion_tokens": 324,
            "total_tokens": 723,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 399,
            "completion_tokens": 77,
            "total_tokens": 476,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 398,
            "completion_tokens": 58,
            "total_tokens": 456,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1k5/1p2r3/1P6/2PR4/p5p1/5pPp/P4P1P/5K2 w - - 0 36"
    },
    {
      "turn": 73,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxg4",
          "aggressive_uci": "g5g4",
          "aggressive_response": "37. Rxg4 Rae8 38. Rd4+ Kc6 39. Rd1 Kxc5 40. g4 Kxb6 41. g5 Re2 42. g6 Rxa2 43. g7\nRg8 44. Rb1+ Ka7 45. Ke1 Rxg7 46. Kd1 Rg1# Rg1#",
          "aggressive_tokens": {
            "prompt_tokens": 408,
            "completion_tokens": 88,
            "total_tokens": 496,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Rd4+",
            "Kc6",
            "Rd1",
            "Kxc5",
            "g4",
            "Kxb6",
            "g5",
            "Re2",
            "g6",
            "Rxa2",
            "g7",
            "Rg8",
            "Rb1+",
            "Ka7",
            "Ke1",
            "Rxg7",
            "Kd1",
            "Rg1#",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd5+",
          "positional_uci": "g5d5",
          "positional_response": "37. Rd5+ Kc6 38. Rd6+ Kxc5 39. Rd1 Rae8 40. Rc1+ Kxb6 41. Rb1+ Ka5 42. Rc1 b5\n43. Rb1 b4 44. Rc1 b3 45. axb3 axb3 46. Ra1+ Kb4 47. Rb1 b2 48. Rd1 Kb3 49.\nRb1 Ka2 50. Rd1 b1=Q 51. Rxb1 Kxb1 52. Kg1 Re1#",
          "positional_tokens": {
            "prompt_tokens": 408,
            "completion_tokens": 131,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "Rd6+",
            "Kxc5",
            "Rd1",
            "Rae8",
            "Rc1+",
            "Kxb6",
            "Rb1+",
            "Ka5",
            "Rc1",
            "b5",
            "Rb1",
            "b4",
            "Rc1",
            "b3",
            "axb3",
            "axb3",
            "Ra1+",
            "Kb4",
            "Rb1",
            "b2",
            "Rd1",
            "Kb3",
            "Rb1",
            "Ka2",
            "Rd1",
            "b1=Q",
            "Rxb1",
            "Kxb1",
            "Kg1",
            "Re1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxg4",
          "neutral_uci": "g5g4",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rae8 38. Rd4+ Kc6 39. Rd1 Re2 40. a3 Ra2 41. g4 Ree2 42. g5 Rxf2+ 43. Kg1 Rg2+ 44. Kh1 Rxh2+ 45. Kg1 Rag2+ 46. Kf1 Rh1#",
          "neutral_tokens": {
            "prompt_tokens": 407,
            "completion_tokens": 380,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Rd4+",
            "Kc6",
            "Rd1",
            "Re2",
            "a3",
            "Ra2",
            "g4",
            "Ree2",
            "g5",
            "Rxf2+",
            "Kg1",
            "Rg2+",
            "Kh1",
            "Rxh2+",
            "Kg1",
            "Rag2+",
            "Kf1",
            "Rh1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5g4",
          "positional_uci": "g5d5",
          "neutral_uci": "g5g4",
          "consensus_move": "g5g4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rae8",
              "Rd4+",
              "Kc6",
              "Rd1",
              "Kxc5",
              "g4",
              "Kxb6",
              "g5",
              "Re2",
              "g6",
              "Rxa2",
              "g7",
              "Rg8",
              "Rb1+",
              "Ka7",
              "Ke1",
              "Rxg7",
              "Kd1",
              "Rg1#",
              "Rg1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kc6",
              "Rd6+",
              "Kxc5",
              "Rd1",
              "Rae8",
              "Rc1+",
              "Kxb6",
              "Rb1+",
              "Ka5",
              "Rc1",
              "b5",
              "Rb1",
              "b4",
              "Rc1",
              "b3",
              "axb3",
              "axb3",
              "Ra1+",
              "Kb4",
              "Rb1",
              "b2",
              "Rd1",
              "Kb3",
              "Rb1",
              "Ka2",
              "Rd1",
              "b1=Q",
              "Rxb1",
              "Kxb1",
              "Kg1",
              "Re1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rae8",
              "Rd4+",
              "Kc6",
              "Rd1",
              "Re2",
              "a3",
              "Ra2",
              "g4",
              "Ree2",
              "g5",
              "Rxf2+",
              "Kg1",
              "Rg2+",
              "Kh1",
              "Rxh2+",
              "Kg1",
              "Rag2+",
              "Kf1",
              "Rh1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 408,
            "completion_tokens": 88,
            "total_tokens": 496,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 408,
            "completion_tokens": 131,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 407,
            "completion_tokens": 380,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1223,
          "total_completion_tokens": 599,
          "total_tokens": 1822
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 408,
            "completion_tokens": 88,
            "total_tokens": 496,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 408,
            "completion_tokens": 131,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 407,
            "completion_tokens": 380,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r7/1p1kr3/1P6/2P3R1/p5p1/5pPp/P4P1P/5K2 w - - 2 37"
    },
    {
      "turn": 75,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re7",
          "aggressive_uci": null,
          "aggressive_response": "Re7 Rf8 Rg4",
          "aggressive_tokens": {
            "prompt_tokens": 417,
            "completion_tokens": 8,
            "total_tokens": 425,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rf8",
            "Rg4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd4+",
          "positional_uci": "g4d4",
          "positional_response": "37... Rf8 38. Rd4+ Kc6 39. Rd6+ Kxc5",
          "positional_tokens": {
            "prompt_tokens": 417,
            "completion_tokens": 24,
            "total_tokens": 441,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "Rd6+",
            "Kxc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd4+",
          "neutral_uci": "g4d4",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Kc6 39. Rxa4 Rd8 40. Rd4 Rxd4 41. a4 Rd1# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 416,
            "completion_tokens": 344,
            "total_tokens": 760,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxd4",
            "a4",
            "Rd1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g4d4",
          "neutral_uci": "g4d4",
          "consensus_move": "g4d4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rf8",
              "Rg4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kc6",
              "Rd6+",
              "Kxc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxd4",
              "a4",
              "Rd1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 417,
            "completion_tokens": 8,
            "total_tokens": 425,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 417,
            "completion_tokens": 24,
            "total_tokens": 441,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 416,
            "completion_tokens": 344,
            "total_tokens": 760,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1250,
          "total_completion_tokens": 376,
          "total_tokens": 1626
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 417,
            "completion_tokens": 8,
            "total_tokens": 425,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 417,
            "completion_tokens": 24,
            "total_tokens": 441,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 416,
            "completion_tokens": 344,
            "total_tokens": 760,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r2/1p1kr3/1P6/2P5/p5R1/5pPp/P4P1P/5K2 w - - 1 38"
    },
    {
      "turn": 77,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd8#",
          "aggressive_uci": "d4d8",
          "aggressive_response": "Re7 Rxe7\nRd8#",
          "aggressive_tokens": {
            "prompt_tokens": 425,
            "completion_tokens": 10,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxa4",
          "positional_uci": "d4a4",
          "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Rd7 40. Re4+ Kd8 41. Ke1 Re8 42. Rxe8+ Kxe8 43. a4 Rd5 44. a5 Rxc5 45. a6 bxa6 46. b7 Rb5 47. Kd2 Rxb7 48. Ke3 Rb3+ 49. Kf4 a5 50. Kg4 a4 51. Kxh3 a3 52. Kg4 a2 53. h4 a1=Q 54. h5 Qg7+ 55. Kh4 Rb4+ 56. Kh3 Qg4+ 57. Kh2 Qxh5+ 58. Kg1 Rb1#",
          "positional_tokens": {
            "prompt_tokens": 425,
            "completion_tokens": 484,
            "total_tokens": 909,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd7",
            "Re4+",
            "Kd8",
            "Ke1",
            "Re8",
            "Rxe8+",
            "Kxe8",
            "a4",
            "Rd5",
            "a5",
            "Rxc5",
            "a6",
            "bxa6",
            "b7",
            "Rb5",
            "Kd2",
            "Rxb7",
            "Ke3",
            "Rb3+",
            "Kf4",
            "a5",
            "Kg4",
            "a4",
            "Kxh3",
            "a3",
            "Kg4",
            "a2",
            "h4",
            "a1=Q",
            "h5",
            "Qg7+",
            "Kh4",
            "Rb4+",
            "Kh3",
            "Qg4+",
            "Kh2",
            "Qxh5+",
            "Kg1",
            "Rb1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxa4",
          "neutral_uci": "d4a4",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Kc6 41. Rc4 Rfe8 42. Rc1 Re2 43. a4 Ra2 44. g4 Ree2 45. g5 Rxf2+ 46. Kg1 Rg2+ 47. Kf1 Rxh2 48. Kg1 Rag2+ 49. Kf1 Rh1# e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6 Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Nf6 gxf6 Qd6+ Qe6 Qxe6+ Kxe6 Rfd1 Rhg8+ Kh1 Rg2 Rd2 Rag8 Rad1 Kf5 Rd5+ Ke6 Rd6+ Ke7 Rd7+ Ke6 R1d6+ Kf5 Rd5+ Ke6 R7d6+ Ke7 Rd7+ Ke6 R5d6+ Kf5 Rd5+ Ke6 R7d6+ Ke7 R5d6 Rg1#",
          "neutral_tokens": {
            "prompt_tokens": 424,
            "completion_tokens": 600,
            "total_tokens": 1024,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd7",
            "Rd4+",
            "Kc6",
            "Rc4",
            "Rfe8",
            "Rc1",
            "Re2",
            "a4",
            "Ra2",
            "g4",
            "Ree2",
            "g5",
            "Rxf2+",
            "Kg1",
            "Rg2+",
            "Kf1",
            "Rxh2",
            "Kg1",
            "Rag2+",
            "Kf1",
            "Rh1#",
            "e4",
            "c5",
            "Nf3",
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Ndb5",
            "Be7",
            "Nd6",
            "Kf8",
            "Be2",
            "Kg8",
            "O-O",
            "h5",
            "Bf4",
            "h4",
            "e5",
            "Ne8",
            "Nce4",
            "Bxd6",
            "Nxd6",
            "g5",
            "Nxe8",
            "Kf8",
            "Nf6",
            "gxf4",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Nf6",
            "gxf6",
            "Qd6+",
            "Qe6",
            "Qxe6+",
            "Kxe6",
            "Rfd1",
            "Rhg8+",
            "Kh1",
            "Rg2",
            "Rd2",
            "Rag8",
            "Rad1",
            "Kf5",
            "Rd5+",
            "Ke6",
            "Rd6+",
            "Ke7",
            "Rd7+",
            "Ke6",
            "R1d6+",
            "Kf5",
            "Rd5+",
            "Ke6",
            "R7d6+",
            "Ke7",
            "Rd7+",
            "Ke6",
            "R5d6+",
            "Kf5",
            "Rd5+",
            "Ke6",
            "R7d6+",
            "Ke7",
            "R5d6",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4d8",
          "positional_uci": "d4a4",
          "neutral_uci": "d4a4",
          "consensus_move": "d4a4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Rd7",
              "Re4+",
              "Kd8",
              "Ke1",
              "Re8",
              "Rxe8+",
              "Kxe8",
              "a4",
              "Rd5",
              "a5",
              "Rxc5",
              "a6",
              "bxa6",
              "b7",
              "Rb5",
              "Kd2",
              "Rxb7",
              "Ke3",
              "Rb3+",
              "Kf4",
              "a5",
              "Kg4",
              "a4",
              "Kxh3",
              "a3",
              "Kg4",
              "a2",
              "h4",
              "a1=Q",
              "h5",
              "Qg7+",
              "Kh4",
              "Rb4+",
              "Kh3",
              "Qg4+",
              "Kh2",
              "Qxh5+",
              "Kg1",
              "Rb1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd7",
              "Rd4+",
              "Kc6",
              "Rc4",
              "Rfe8",
              "Rc1",
              "Re2",
              "a4",
              "Ra2",
              "g4",
              "Ree2",
              "g5",
              "Rxf2+",
              "Kg1",
              "Rg2+",
              "Kf1",
              "Rxh2",
              "Kg1",
              "Rag2+",
              "Kf1",
              "Rh1#",
              "e4",
              "c5",
              "Nf3",
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Ndb5",
              "Be7",
              "Nd6",
              "Kf8",
              "Be2",
              "Kg8",
              "O-O",
              "h5",
              "Bf4",
              "h4",
              "e5",
              "Ne8",
              "Nce4",
              "Bxd6",
              "Nxd6",
              "g5",
              "Nxe8",
              "Kf8",
              "Nf6",
              "gxf4",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Nf6",
              "gxf6",
              "Qd6+",
              "Qe6",
              "Qxe6+",
              "Kxe6",
              "Rfd1",
              "Rhg8+",
              "Kh1",
              "Rg2",
              "Rd2",
              "Rag8",
              "Rad1",
              "Kf5",
              "Rd5+",
              "Ke6",
              "Rd6+",
              "Ke7",
              "Rd7+",
              "Ke6",
              "R1d6+",
              "Kf5",
              "Rd5+",
              "Ke6",
              "R7d6+",
              "Ke7",
              "Rd7+",
              "Ke6",
              "R5d6+",
              "Kf5",
              "Rd5+",
              "Ke6",
              "R7d6+",
              "Ke7",
              "R5d6",
              "Rg1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 425,
            "completion_tokens": 10,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 425,
            "completion_tokens": 484,
            "total_tokens": 909,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 424,
            "completion_tokens": 600,
            "total_tokens": 1024,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1274,
          "total_completion_tokens": 1094,
          "total_tokens": 2368
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 425,
            "completion_tokens": 10,
            "total_tokens": 435,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 425,
            "completion_tokens": 484,
            "total_tokens": 909,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 424,
            "completion_tokens": 600,
            "total_tokens": 1024,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4kr2/1p2r3/1P6/2P5/p2R4/5pPp/P4P1P/5K2 w - - 3 39"
    },
    {
      "turn": 79,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd4+",
          "aggressive_uci": "a4d4",
          "aggressive_response": "40. Rd4+ Ke8 41. Ra4 Kd7 42. Rd4+ Ke8 43. Ra4 Kd7 44. Rd4+ Ke8 45. Ra4 Kd7 46. Rd4+ Ke8 47. Ra4 Kd7 48. Rd4+ Ke8 49. Ra4 Kd7 50. Rd4+ Ke8 51. Ra4 Kd7 52. Rd4+ Ke8 53. Ra4 Kd7 54. Rd4+ Ke8 55. Ra4 Kd7 56. Rd4+ Ke8 57. Ra4 Kd7 58. Rd4+ Ke8 59. Ra4 Kd7 60. Rd4+ Ke8 61. Ra4 Kd7 62. Rd4+ Ke8 63. Ra4 Kd7 64. Rd4+ Ke8 65. Ra4 Kd7 66. Rd4+ Ke8 67. Ra4 Kd7 68. Rd4+ Ke8 69. Ra4 Kd7 70. Rd4+ Ke8 71. Ra4 Kd7 72. Rd4+ Ke8 73. Ra4 Kd7 74. Rd4+ Ke8 75. Ra4 Kd7 76. Rd4+ Ke8 77. Ra4 Kd7 78. Rd4+ Ke8 79. Ra4 Kd7 80. Rd4+ Ke8 81. Ra4 Kd7 82. Rd4+ Ke8 83. Ra4 Kd7 84. Rd4+ Ke8 85. Ra4 Kd7 86. Rd4+ Ke8 87. Ra4 Kd7 88. Rd4+ Ke8 89. Ra4 Kd7 90. Rd4+ Ke8 91. Ra4 Kd7 92. Rd4+ Ke8 93. Ra4 Kd7 94. Rd4+ Ke8 95. Ra4 Kd7 96. Rd4+ Ke8 97. Ra4 Kd7 98. Rd4+ Ke8 99. Ra4 Kd7 100. Rd4+ Ke8 101. Ra4 Kd7 102. Rd4+ Ke8 103. Ra4 Kd7 104. Rd4+ Ke8 105. Ra4 Kd7 106. Rd4+ Ke8 107. Ra4 Kd7 108. Rd4+ Ke8 109. Ra4 Kd7 110. Rd4+ Ke8 111. Ra4 Kd7 112. Rd4+ Ke8 113. Ra4 Kd7 114. Rd4+ Ke8 115. Ra4 Kd7 116. Rd4+ Ke8 117. Ra4 Kd7 118. Rd4+ Ke8 119. Ra4 Kd7",
          "aggressive_tokens": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke8",
            "Ra4",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd4+",
          "positional_uci": "a4d4",
          "positional_response": "40. Rd4+ Kc6 41. Rc4 Kb5 42. Rc3 Kb4 43. Rc2 Kb5 44. Rc3 Kc6 45. a4 Rf5 46.\nRc4 Rxc5 47. Rxc5+ Kxc5 48. a5 Kb5 49. a6 Kxa6 50. g4 Kxb6 51. g5 Kc5 52. g6\nKd6 53. g7 Rxg7 54. Ke1 Rg2 55. Kd2 Rxf2+ 56. Ke3 Rxh2 57. Kxf3 Rg2 58. Ke3\nh2 59. Kf3 h1=Q 60. Ke3 Qh3+ 61. Kf4 Rg4+ 62. Kf5 Qh5+ 63. Kf6 Rg6+ 64. Kf7\nQh7+ 65. Kf8 Rg8# Rf8+ Kxf8 Kxf8",
          "positional_tokens": {
            "prompt_tokens": 435,
            "completion_tokens": 236,
            "total_tokens": 671,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "Rc4",
            "Kb5",
            "Rc3",
            "Kb4",
            "Rc2",
            "Kb5",
            "Rc3",
            "Kc6",
            "a4",
            "Rf5",
            "Rc4",
            "Rxc5",
            "Rxc5+",
            "Kxc5",
            "a5",
            "Kb5",
            "a6",
            "Kxa6",
            "g4",
            "Kxb6",
            "g5",
            "Kc5",
            "g6",
            "Kd6",
            "g7",
            "Rxg7",
            "Ke1",
            "Rg2",
            "Kd2",
            "Rxf2+",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "Kf3",
            "h1=Q",
            "Ke3",
            "Qh3+",
            "Kf4",
            "Rg4+",
            "Kf5",
            "Qh5+",
            "Kf6",
            "Rg6+",
            "Kf7",
            "Qh7+",
            "Kf8",
            "Rg8#",
            "Rf8+",
            "Kxf8",
            "Kxf8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd4+",
          "neutral_uci": "a4d4",
          "neutral_response": "40. Rd4+ Kc6 41. Rc4 Rfe8 42. Rc1 Re2 43. a4 Ra2 44. Rd1 Ree2 45. Rd6+ Kxc5\n46. Rd1 Rxf2+ 47. Kg1 Rg2+ 48. Kf1 Rxh2 49. Rc1+ Kxb6 50. Rb1+ Ka7 51. Kg1 Rag2+ 52. Kf1 Rh1# Rg1+ Kxg1 54. Kxg1 f2+ 55. Kf1 h2 56. Kg2 h1=Q+ 57. Kxh1 f1=Q+ 58. Kh2 Qf2+ 59. Kh3 Qf3 60. Kh4 Qf5 61. g4 Qf4 62. Kh5 Qxa4 63. g5 Qf4 64. g6 Qf5+ 65. Kh6 Qxg6+ 66. Kxg6 b5 67. Kf5 b4 68. Ke4 b3 69. Kd3 b2 70. Kc2 b1=Q+ 71. Kxb1",
          "neutral_tokens": {
            "prompt_tokens": 434,
            "completion_tokens": 275,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "Rc4",
            "Rfe8",
            "Rc1",
            "Re2",
            "a4",
            "Ra2",
            "Rd1",
            "Ree2",
            "Rd6+",
            "Kxc5",
            "Rd1",
            "Rxf2+",
            "Kg1",
            "Rg2+",
            "Kf1",
            "Rxh2",
            "Rc1+",
            "Kxb6",
            "Rb1+",
            "Ka7",
            "Kg1",
            "Rag2+",
            "Kf1",
            "Rh1#",
            "Rg1+",
            "Kxg1",
            "Kxg1",
            "f2+",
            "Kf1",
            "h2",
            "Kg2",
            "h1=Q+",
            "Kxh1",
            "f1=Q+",
            "Kh2",
            "Qf2+",
            "Kh3",
            "Qf3",
            "Kh4",
            "Qf5",
            "g4",
            "Qf4",
            "Kh5",
            "Qxa4",
            "g5",
            "Qf4",
            "g6",
            "Qf5+",
            "Kh6",
            "Qxg6+",
            "Kxg6",
            "b5",
            "Kf5",
            "b4",
            "Ke4",
            "b3",
            "Kd3",
            "b2",
            "Kc2",
            "b1=Q+",
            "Kxb1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a4d4",
          "positional_uci": "a4d4",
          "neutral_uci": "a4d4",
          "consensus_move": "a4d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ke8",
              "Ra4",
              "Kd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kc6",
              "Rc4",
              "Kb5",
              "Rc3",
              "Kb4",
              "Rc2",
              "Kb5",
              "Rc3",
              "Kc6",
              "a4",
              "Rf5",
              "Rc4",
              "Rxc5",
              "Rxc5+",
              "Kxc5",
              "a5",
              "Kb5",
              "a6",
              "Kxa6",
              "g4",
              "Kxb6",
              "g5",
              "Kc5",
              "g6",
              "Kd6",
              "g7",
              "Rxg7",
              "Ke1",
              "Rg2",
              "Kd2",
              "Rxf2+",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "Kf3",
              "h1=Q",
              "Ke3",
              "Qh3+",
              "Kf4",
              "Rg4+",
              "Kf5",
              "Qh5+",
              "Kf6",
              "Rg6+",
              "Kf7",
              "Qh7+",
              "Kf8",
              "Rg8#",
              "Rf8+",
              "Kxf8",
              "Kxf8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kc6",
              "Rc4",
              "Rfe8",
              "Rc1",
              "Re2",
              "a4",
              "Ra2",
              "Rd1",
              "Ree2",
              "Rd6+",
              "Kxc5",
              "Rd1",
              "Rxf2+",
              "Kg1",
              "Rg2+",
              "Kf1",
              "Rxh2",
              "Rc1+",
              "Kxb6",
              "Rb1+",
              "Ka7",
              "Kg1",
              "Rag2+",
              "Kf1",
              "Rh1#",
              "Rg1+",
              "Kxg1",
              "Kxg1",
              "f2+",
              "Kf1",
              "h2",
              "Kg2",
              "h1=Q+",
              "Kxh1",
              "f1=Q+",
              "Kh2",
              "Qf2+",
              "Kh3",
              "Qf3",
              "Kh4",
              "Qf5",
              "g4",
              "Qf4",
              "Kh5",
              "Qxa4",
              "g5",
              "Qf4",
              "g6",
              "Qf5+",
              "Kh6",
              "Qxg6+",
              "Kxg6",
              "b5",
              "Kf5",
              "b4",
              "Ke4",
              "b3",
              "Kd3",
              "b2",
              "Kc2",
              "b1=Q+",
              "Kxb1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 435,
            "completion_tokens": 236,
            "total_tokens": 671,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 434,
            "completion_tokens": 275,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1304,
          "total_completion_tokens": 1151,
          "total_tokens": 2455
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 435,
            "completion_tokens": 236,
            "total_tokens": 671,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 434,
            "completion_tokens": 275,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r2/1p1kr3/1P6/2P5/R7/5pPp/P4P1P/5K2 w - - 1 40"
    },
    {
      "turn": 81,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re4+",
          "aggressive_uci": "d4e4",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kd5 42. Rxe7 Kxc5 43. Rxb7 Rd8 44. Ke1 Re8+ 45. Kd1 Re2 46. Rf7 Rxf2 47. b7 Rb2 48. Rxf3 Rxb7 49. g4 Rb1+ 50. Kc2 Rh1 51. Rxh3 Rg1 52. Rg3 Rh1 53. h3 Kd4 54. g5 Rh2+ 55. Kb3 Ke5 56. g6 Kf6 57. g7 *",
          "aggressive_tokens": {
            "prompt_tokens": 442,
            "completion_tokens": 472,
            "total_tokens": 914,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd5",
            "Rxe7",
            "Kxc5",
            "Rxb7",
            "Rd8",
            "Ke1",
            "Re8+",
            "Kd1",
            "Re2",
            "Rf7",
            "Rxf2",
            "b7",
            "Rb2",
            "Rxf3",
            "Rxb7",
            "g4",
            "Rb1+",
            "Kc2",
            "Rh1",
            "Rxh3",
            "Rg1",
            "Rg3",
            "Rh1",
            "h3",
            "Kd4",
            "g5",
            "Rh2+",
            "Kb3",
            "Ke5",
            "g6",
            "Kf6",
            "g7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re7+",
          "positional_uci": null,
          "positional_response": "Re7+ Kd5 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+ Ke7 Rf5+ Ke6 Rxf3+",
          "positional_tokens": {
            "prompt_tokens": 442,
            "completion_tokens": 640,
            "total_tokens": 1082,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kd5",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+",
            "Ke7",
            "Rf5+",
            "Ke6",
            "Rxf3+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re7+",
          "neutral_uci": null,
          "neutral_response": "Re7+ Kd5 Kc4",
          "neutral_tokens": {
            "prompt_tokens": 441,
            "completion_tokens": 9,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd5",
            "Kc4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e4",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "d4e4",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kd5",
              "Rxe7",
              "Kxc5",
              "Rxb7",
              "Rd8",
              "Ke1",
              "Re8+",
              "Kd1",
              "Re2",
              "Rf7",
              "Rxf2",
              "b7",
              "Rb2",
              "Rxf3",
              "Rxb7",
              "g4",
              "Rb1+",
              "Kc2",
              "Rh1",
              "Rxh3",
              "Rg1",
              "Rg3",
              "Rh1",
              "h3",
              "Kd4",
              "g5",
              "Rh2+",
              "Kb3",
              "Ke5",
              "g6",
              "Kf6",
              "g7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kd5",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+",
              "Ke7",
              "Rf5+",
              "Ke6",
              "Rxf3+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd5",
              "Kc4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 442,
            "completion_tokens": 472,
            "total_tokens": 914,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 442,
            "completion_tokens": 640,
            "total_tokens": 1082,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 441,
            "completion_tokens": 9,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1325,
          "total_completion_tokens": 1121,
          "total_tokens": 2446
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 442,
            "completion_tokens": 472,
            "total_tokens": 914,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 442,
            "completion_tokens": 640,
            "total_tokens": 1082,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 441,
            "completion_tokens": 9,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r2/1p2r3/1P2k3/2P5/3R4/5pPp/P4P1P/5K2 w - - 3 41"
    },
    {
      "turn": 83,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf4+",
          "aggressive_uci": "e4f4",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Kg7 43. Rg4+ Kh6 44. Rh4+ Kg5 45. Rxh3 Rd8 46. Rh5+ Kxh5 47. g4+ Kxg4 48. h3+ Kxh3 49. c6 Rd1#",
          "aggressive_tokens": {
            "prompt_tokens": 451,
            "completion_tokens": 413,
            "total_tokens": 864,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg7",
            "Rg4+",
            "Kh6",
            "Rh4+",
            "Kg5",
            "Rxh3",
            "Rd8",
            "Rh5+",
            "Kxh5",
            "g4+",
            "Kxg4",
            "h3+",
            "Kxh3",
            "c6",
            "Rd1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf4+",
          "positional_uci": "e4f4",
          "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Kg7 43. Rg4+ Kh6 44. Rh4+ Kg5 45. Rxh3 Rd8 46. Rh5+ Kxh5 47. g4+ Kxg4 48. h3+ Kxh3 49. c6 Rd1#",
          "positional_tokens": {
            "prompt_tokens": 451,
            "completion_tokens": 413,
            "total_tokens": 864,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg7",
            "Rg4+",
            "Kh6",
            "Rh4+",
            "Kg5",
            "Rxh3",
            "Rd8",
            "Rh5+",
            "Kxh5",
            "g4+",
            "Kxg4",
            "h3+",
            "Kxh3",
            "c6",
            "Rd1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re7+",
          "neutral_uci": "e4e7",
          "neutral_response": "Re7+ Kg8 Rg7+ Kh8 Rg8+ Kh7 Rg7+ Kh6 Rg8+ Kh5 Rg7+ Kh4 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh3 Rg7+ Kh2 Rg8+ Kh",
          "neutral_tokens": {
            "prompt_tokens": 450,
            "completion_tokens": 640,
            "total_tokens": 1090,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rg8+",
            "Kh7",
            "Rg7+",
            "Kh6",
            "Rg8+",
            "Kh5",
            "Rg7+",
            "Kh4",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+",
            "Kh3",
            "Rg7+",
            "Kh2",
            "Rg8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f4",
          "positional_uci": "e4f4",
          "neutral_uci": "e4e7",
          "consensus_move": "e4f4",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg7",
              "Rg4+",
              "Kh6",
              "Rh4+",
              "Kg5",
              "Rxh3",
              "Rd8",
              "Rh5+",
              "Kxh5",
              "g4+",
              "Kxg4",
              "h3+",
              "Kxh3",
              "c6",
              "Rd1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg7",
              "Rg4+",
              "Kh6",
              "Rh4+",
              "Kg5",
              "Rxh3",
              "Rd8",
              "Rh5+",
              "Kxh5",
              "g4+",
              "Kxg4",
              "h3+",
              "Kxh3",
              "c6",
              "Rd1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rg8+",
              "Kh7",
              "Rg7+",
              "Kh6",
              "Rg8+",
              "Kh5",
              "Rg7+",
              "Kh4",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+",
              "Kh3",
              "Rg7+",
              "Kh2",
              "Rg8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 451,
            "completion_tokens": 413,
            "total_tokens": 864,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 451,
            "completion_tokens": 413,
            "total_tokens": 864,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 450,
            "completion_tokens": 640,
            "total_tokens": 1090,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1352,
          "total_completion_tokens": 1466,
          "total_tokens": 2818
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 451,
            "completion_tokens": 413,
            "total_tokens": 864,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 451,
            "completion_tokens": 413,
            "total_tokens": 864,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 450,
            "completion_tokens": 640,
            "total_tokens": 1090,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "5r2/1p2rk2/1P6/2P5/4R3/5pPp/P4P1P/5K2 w - - 5 42"
    },
    {
      "turn": 85,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxf8+",
          "aggressive_uci": "f4f8",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Ke8 45. a5 Kd7\n46. a6 bxa6 47. b7 Kc7 48. c6 a5 49. Ke1 a4 50. Kd2 a3 51. Kc2 a2 52. Kb2 a1=Q+\n53. Kxa1 Kb8 54. Kb2 Kc7 55. Kc3 Kb8 56. Kd4 Kc7 57. Ke4 Kb8 58. Kxf3 Kc7\n59. Kg4 Kb8 60. Kxh3 Kc7 61. Kg4 Kb8 62. h4 Kc7 63. h5 Kb8 64. h6 Kc7 65. h7 Kb8\n66. h8=Q+ Kc7 67. b8=Q+ Kxc6 68. Qhc8+ Kd5 69. Qb5+ Kd4 70. Qcc4# Kd3 71. Qxd4+ Kxd4\n72. Kf5 Kd5 73. g4 Kd6 74. Kf6 Kd7 75. g5 Ke8 76. Kg7 Ke7 77. g",
          "aggressive_tokens": {
            "prompt_tokens": 460,
            "completion_tokens": 640,
            "total_tokens": 1100,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf8",
            "a4",
            "Ke8",
            "a5",
            "Kd7",
            "a6",
            "bxa6",
            "b7",
            "Kc7",
            "c6",
            "a5",
            "Ke1",
            "a4",
            "Kd2",
            "a3",
            "Kc2",
            "a2",
            "Kb2",
            "a1=Q+",
            "Kxa1",
            "Kb8",
            "Kb2",
            "Kc7",
            "Kc3",
            "Kb8",
            "Kd4",
            "Kc7",
            "Ke4",
            "Kb8",
            "Kxf3",
            "Kc7",
            "Kg4",
            "Kb8",
            "Kxh3",
            "Kc7",
            "Kg4",
            "Kb8",
            "h4",
            "Kc7",
            "h5",
            "Kb8",
            "h6",
            "Kc7",
            "h7",
            "Kb8",
            "h8=Q+",
            "Kc7",
            "b8=Q+",
            "Kxc6",
            "Qhc8+",
            "Kd5",
            "Qb5+",
            "Kd4",
            "Qcc4#",
            "Kd3",
            "Qxd4+",
            "Kxd4",
            "Kf5",
            "Kd5",
            "g4",
            "Kd6",
            "Kf6",
            "Kd7",
            "g5",
            "Ke8",
            "Kg7",
            "Ke7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra4",
          "positional_uci": "f4a4",
          "positional_response": "43. Ra4 Kd7 44. Rd4+ Ke6 45. Re4+ Kf7 46. Rf4+ Ke8 47. Ra4 Kd7 48. Rd4+ Ke6 49.\nRe4+ Kf7 50. Rf4+ Ke8 51. Ra4 Kd7 52. Rd4+ Ke6 53. Re4+ Kf7 54. Rf4+ Ke8 55.\nRa4 Kd7 56. Rd4+ Ke6 57. Re4+ Kf7 58. Rf4+ Ke8 59. Ra4 Kd7 60. Rd4+ Ke6 61.\nRe4+ Kf7 62. Rf4+ Ke8 63. Ra4 Kd7 64. Rd4+ Ke6 65. Re4+ Kf7 66. Rf4+ Ke8 67.\nRa4 Kd7 68. Rd4+ Ke6 69. Re4+ Kf7 70. Rf4+ Ke8 71. Ra4 Kd7 72. Rd4+ Ke6 73.\nRe4+ Kf7 74. Rf4+ Ke8 75. Ra4 Kd7 76. Rd4+ Ke6 77. Re4+ Kf7 78. Rf4+ Ke8 79.\nRa4 Kd7 80. Rd4+ Ke6 81. Re4+ Kf7 82. Rf4+ Ke8 83. Ra4 Kd7 84. Rd4+ Ke6 85.\nRe4+ Kf7 86. Rf4+ Ke8 87. Ra4 Kd7 88. Rd4+ Ke6 89. Re4+ Kf7 90. Rf4+ Ke8 91.\nRa4 Kd7 92. Rd4+ Ke6 93. Re4+ Kf7 94. Rf4+ Ke8 95. Ra4 Kd7 96. Rd4+ Ke6 97.\nRe4+ Kf7 98. Rf4+ Ke8 99. Ra4 Kd7 100. Rd4+ Ke6 101. Re4+ Kf7 102. Rf4+ Ke8 103.\nRa4 Kd7 104. Rd4+ Ke6 105. Re4+ Kf7 106. Rf4+ Ke8 107. Ra4 Kd7 108. Rd4+ Ke6 109.\nRe4+ Kf7 110. Rf4+ Ke8 111. Ra4 Kd7 112. Rd4+ Ke6 113. Re4+ Kf7 114. Rf4+ Ke8 115.\nRa4 Kd7 116. Rd4+ Ke6 117. Re4+ Kf7 118.",
          "positional_tokens": {
            "prompt_tokens": 460,
            "completion_tokens": 640,
            "total_tokens": 1100,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kd7",
            "Rd4+",
            "Ke6",
            "Re4+",
            "Kf7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxf8+",
          "neutral_uci": "f4f8",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Ke8 45. a5 Kd7\n46. a6 bxa6 47. b7 Kc7 48. c6 a5 49. Ke1 a4 50. Kd2 a3 51. Kc2 a2 52. Kb2 a1=Q+\n53. Kxa1 Kb8 54. Kb2 Kc7 55. Kc3 Kb8 56. Kd4 Kc7 57. Ke4 Kb8 58. Kxf3 Kc7\n59. Kg4 Kb8 60. Kxh3 Kc7 61. Kg4 Kb8 62. h4 Kc7 63. h5 Kb8 64. h6 Kc7 65. h7 Kb8\n66. h8=Q+ Kc7 67. b8=Q+ Kxc6 68. Qhc8+ Kd5 69. Qb5+ Kd4 70. Qcc4# Kd3",
          "neutral_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 587,
            "total_tokens": 1046,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxf8",
            "a4",
            "Ke8",
            "a5",
            "Kd7",
            "a6",
            "bxa6",
            "b7",
            "Kc7",
            "c6",
            "a5",
            "Ke1",
            "a4",
            "Kd2",
            "a3",
            "Kc2",
            "a2",
            "Kb2",
            "a1=Q+",
            "Kxa1",
            "Kb8",
            "Kb2",
            "Kc7",
            "Kc3",
            "Kb8",
            "Kd4",
            "Kc7",
            "Ke4",
            "Kb8",
            "Kxf3",
            "Kc7",
            "Kg4",
            "Kb8",
            "Kxh3",
            "Kc7",
            "Kg4",
            "Kb8",
            "h4",
            "Kc7",
            "h5",
            "Kb8",
            "h6",
            "Kc7",
            "h7",
            "Kb8",
            "h8=Q+",
            "Kc7",
            "b8=Q+",
            "Kxc6",
            "Qhc8+",
            "Kd5",
            "Qb5+",
            "Kd4",
            "Qcc4#",
            "Kd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f4f8",
          "positional_uci": "f4a4",
          "neutral_uci": "f4f8",
          "consensus_move": "f4f8",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxf8",
              "a4",
              "Ke8",
              "a5",
              "Kd7",
              "a6",
              "bxa6",
              "b7",
              "Kc7",
              "c6",
              "a5",
              "Ke1",
              "a4",
              "Kd2",
              "a3",
              "Kc2",
              "a2",
              "Kb2",
              "a1=Q+",
              "Kxa1",
              "Kb8",
              "Kb2",
              "Kc7",
              "Kc3",
              "Kb8",
              "Kd4",
              "Kc7",
              "Ke4",
              "Kb8",
              "Kxf3",
              "Kc7",
              "Kg4",
              "Kb8",
              "Kxh3",
              "Kc7",
              "Kg4",
              "Kb8",
              "h4",
              "Kc7",
              "h5",
              "Kb8",
              "h6",
              "Kc7",
              "h7",
              "Kb8",
              "h8=Q+",
              "Kc7",
              "b8=Q+",
              "Kxc6",
              "Qhc8+",
              "Kd5",
              "Qb5+",
              "Kd4",
              "Qcc4#",
              "Kd3",
              "Qxd4+",
              "Kxd4",
              "Kf5",
              "Kd5",
              "g4",
              "Kd6",
              "Kf6",
              "Kd7",
              "g5",
              "Ke8",
              "Kg7",
              "Ke7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kd7",
              "Rd4+",
              "Ke6",
              "Re4+",
              "Kf7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxf8",
              "a4",
              "Ke8",
              "a5",
              "Kd7",
              "a6",
              "bxa6",
              "b7",
              "Kc7",
              "c6",
              "a5",
              "Ke1",
              "a4",
              "Kd2",
              "a3",
              "Kc2",
              "a2",
              "Kb2",
              "a1=Q+",
              "Kxa1",
              "Kb8",
              "Kb2",
              "Kc7",
              "Kc3",
              "Kb8",
              "Kd4",
              "Kc7",
              "Ke4",
              "Kb8",
              "Kxf3",
              "Kc7",
              "Kg4",
              "Kb8",
              "Kxh3",
              "Kc7",
              "Kg4",
              "Kb8",
              "h4",
              "Kc7",
              "h5",
              "Kb8",
              "h6",
              "Kc7",
              "h7",
              "Kb8",
              "h8=Q+",
              "Kc7",
              "b8=Q+",
              "Kxc6",
              "Qhc8+",
              "Kd5",
              "Qb5+",
              "Kd4",
              "Qcc4#",
              "Kd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 460,
            "completion_tokens": 640,
            "total_tokens": 1100,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 460,
            "completion_tokens": 640,
            "total_tokens": 1100,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 459,
            "completion_tokens": 587,
            "total_tokens": 1046,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1379,
          "total_completion_tokens": 1867,
          "total_tokens": 3246
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 460,
            "completion_tokens": 640,
            "total_tokens": 1100,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 460,
            "completion_tokens": 640,
            "total_tokens": 1100,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 459,
            "completion_tokens": 587,
            "total_tokens": 1046,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4kr2/1p2r3/1P6/2P5/5R2/5pPp/P4P1P/5K2 w - - 7 43"
    },
    {
      "turn": 87,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8+",
          "aggressive_uci": null,
          "aggressive_response": "Re8+ Kf7 45. a4 Re5 46.\na5 Rxc5 47. a6 Rc1# Rxc1#",
          "aggressive_tokens": {
            "prompt_tokens": 470,
            "completion_tokens": 33,
            "total_tokens": 503,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf7",
            "a4",
            "Re5",
            "a5",
            "Rxc5",
            "a6",
            "Rc1#",
            "Rxc1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a4",
          "positional_uci": "a2a4",
          "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re5 45. a5 Rxc5 46. a6 Rc1#",
          "positional_tokens": {
            "prompt_tokens": 470,
            "completion_tokens": 383,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re5",
            "a5",
            "Rxc5",
            "a6",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a4",
          "neutral_uci": "a2a4",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Ke8 45. a5 Kd7 46. a6 bxa6 47. b7 Kc7 48. c6 a5 49. g4 a4 50. g5 a3 51. g6 a2 52. g7 a1=Q#",
          "neutral_tokens": {
            "prompt_tokens": 469,
            "completion_tokens": 429,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "a3",
            "g6",
            "a2",
            "g7",
            "a1=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "a2a4",
          "neutral_uci": "a2a4",
          "consensus_move": "a2a4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf7",
              "a4",
              "Re5",
              "a5",
              "Rxc5",
              "a6",
              "Rc1#",
              "Rxc1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re5",
              "a5",
              "Rxc5",
              "a6",
              "Rc1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "g5",
              "a3",
              "g6",
              "a2",
              "g7",
              "a1=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 470,
            "completion_tokens": 33,
            "total_tokens": 503,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 470,
            "completion_tokens": 383,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 469,
            "completion_tokens": 429,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1409,
          "total_completion_tokens": 845,
          "total_tokens": 2254
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 470,
            "completion_tokens": 33,
            "total_tokens": 503,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 470,
            "completion_tokens": 383,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 469,
            "completion_tokens": 429,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5k2/1p2r3/1P6/2P5/8/5pPp/P4P1P/5K2 w - - 0 44"
    },
    {
      "turn": 89,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Ng4 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 f5 Bxf5 exf5 Rxd4+ Kc5 Rd1 fxg4 b4+ Kb6 Rd6+ Kc7 Rd5 Rh7 c4 Re7 b5 Re1+ * e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Ng4 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 f5 Bxf5 exf5 Rxd4+ Kc5 Rd5+ fxg4 b4+ Kb6 Rd6+ Kc7 Rd5 Rh7 c4 Re7 b5 Re1+ * e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Ng4 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 f5 Bxf5 exf5 Rxd4+ Kc5 Rd5+ fxg4 b4+ Kb6 Rd6+ Kc7 Rd5 Rh7 c4 Re7 b5 Re1+ * e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Ng4 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 f5 Bxf5 exf5 Rxd4+ Kc5 Rd5+ fxg4 b4+ Kb6 Rd6+ Kc7 Rd5 Rh7 c4 Re7 b5 Re1+ * e4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Ndb5 Be7 Nd6+",
          "aggressive_tokens": {
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "Nf3",
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Ndb5",
            "Be7",
            "Nd6+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a5",
          "positional_uci": "a4a5",
          "positional_response": "45. a5 Re2 46. a6 Ra2 47. Ke1 bxa6 48. b7 Rb2 49. c6 Ke7 50. c7 Rxb7 51. c8=Q Rb1+ 52. Kd2 Rb2+ 53. Ke3 Rb3+ 54. Kf4 Rb4+ 55. Kxf3 Rb3+ 56. Kg4 Rb4+ 57. Kxh3 Rb6 58. Qc7+ Ke6 59. Qxb6+ Kd5 60. Qxa6 Ke4 61. Qe2+ Kd4 62. f4 Kd5 63. f5 Kd6 64. f6 Kd5 65. f7 Kd4 66. f8=Q Kd5 67. Qd8+ Kc5 68. Qc2+ Kb4 69. Qb8+ Ka3 70. Qcb3#",
          "positional_tokens": {
            "prompt_tokens": 477,
            "completion_tokens": 228,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re2",
            "a6",
            "Ra2",
            "Ke1",
            "bxa6",
            "b7",
            "Rb2",
            "c6",
            "Ke7",
            "c7",
            "Rxb7",
            "c8=Q",
            "Rb1+",
            "Kd2",
            "Rb2+",
            "Ke3",
            "Rb3+",
            "Kf4",
            "Rb4+",
            "Kxf3",
            "Rb3+",
            "Kg4",
            "Rb4+",
            "Kxh3",
            "Rb6",
            "Qc7+",
            "Ke6",
            "Qxb6+",
            "Kd5",
            "Qxa6",
            "Ke4",
            "Qe2+",
            "Kd4",
            "f4",
            "Kd5",
            "f5",
            "Kd6",
            "f6",
            "Kd5",
            "f7",
            "Kd4",
            "f8=Q",
            "Kd5",
            "Qd8+",
            "Kc5",
            "Qc2+",
            "Kb4",
            "Qb8+",
            "Ka3",
            "Qcb3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rf8 Rg8",
          "neutral_tokens": {
            "prompt_tokens": 476,
            "completion_tokens": 8,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rf8",
            "Rg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "a4a5",
          "neutral_uci": null,
          "consensus_move": "a4a5",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "Nf3",
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Ndb5",
              "Be7",
              "Nd6+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re2",
              "a6",
              "Ra2",
              "Ke1",
              "bxa6",
              "b7",
              "Rb2",
              "c6",
              "Ke7",
              "c7",
              "Rxb7",
              "c8=Q",
              "Rb1+",
              "Kd2",
              "Rb2+",
              "Ke3",
              "Rb3+",
              "Kf4",
              "Rb4+",
              "Kxf3",
              "Rb3+",
              "Kg4",
              "Rb4+",
              "Kxh3",
              "Rb6",
              "Qc7+",
              "Ke6",
              "Qxb6+",
              "Kd5",
              "Qxa6",
              "Ke4",
              "Qe2+",
              "Kd4",
              "f4",
              "Kd5",
              "f5",
              "Kd6",
              "f6",
              "Kd5",
              "f7",
              "Kd4",
              "f8=Q",
              "Kd5",
              "Qd8+",
              "Kc5",
              "Qc2+",
              "Kb4",
              "Qb8+",
              "Ka3",
              "Qcb3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rf8",
              "Rg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 477,
            "completion_tokens": 228,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 476,
            "completion_tokens": 8,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1430,
          "total_completion_tokens": 876,
          "total_tokens": 2306
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 477,
            "completion_tokens": 228,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 476,
            "completion_tokens": 8,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4rk2/1p6/1P6/2P5/P7/5pPp/5P1P/5K2 w - - 1 45"
    },
    {
      "turn": 91,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8",
          "aggressive_uci": null,
          "aggressive_response": "Re8 Kd7 47. a6 bxa6 48. b7 Kc7 49. c6 Kxc6 50. b8=Q Rxb8 51. Ke1 Rd8 52. g4 a5 53. g5 a4 54. g6 a3 55. g7 a2 56. g8=Q a1=Q#",
          "aggressive_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 86,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd7",
            "a6",
            "bxa6",
            "b7",
            "Kc7",
            "c6",
            "Kxc6",
            "b8=Q",
            "Rxb8",
            "Ke1",
            "Rd8",
            "g4",
            "a5",
            "g5",
            "a4",
            "g6",
            "a3",
            "g7",
            "a2",
            "g8=Q",
            "a1=Q#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c6",
          "positional_uci": "c5c6",
          "positional_response": "46. c6 bxc6 47. a6 Kd7 48. b7 Kc7 49. g4 Kb6 50. g5 Kxa6 51. g6 Kxb7 52. g7\nKb6 53. g8=Q Rxg8 54. Ke1 Rd8 55. Kf1 Rd1# 1-0\ne4 c5 Nf3 Nc6 d4 cxd4 Nxd4 Nf6 Nc3 e6 Ndb5 Be7 Nd6+ Kf8 Be2 Kg8 O-O h5 Bf4 h4 e5 Ne8 Nce4 Bxd6 Nxd6 g5 Nxe8 Kf8 Nf6 gxf4 Qd6+ Qe7 Qxe7+ Kxe7 Nf6 gxf6 Qd6+ Qe7 Qxe7+ Kxe7 Rad1 h3 g3 Nd4 Bd3 d6 exd6+ Kxd6 Rad1 f5 Bxf5 exf5 Rxd4+ Kc5 Rfd1 fxg3 b4+ Kb6 Rd6+ Kc7 Rd7+ Kb8 Rd8+ Kc7 R1d7+ Kb6 Rd6+ Kc7 Rd7+ Kb8 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d7+ Kb6 Rd8+ Kc7 R1d",
          "positional_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "bxc6",
            "a6",
            "Kd7",
            "b7",
            "Kc7",
            "g4",
            "Kb6",
            "g5",
            "Kxa6",
            "g6",
            "Kxb7",
            "g7",
            "Kb6",
            "g8=Q",
            "Rxg8",
            "Ke1",
            "Rd8",
            "Kf1",
            "Rd1#",
            "e4",
            "c5",
            "Nf3",
            "Nc6",
            "d4",
            "cxd4",
            "Nxd4",
            "Nf6",
            "Nc3",
            "e6",
            "Ndb5",
            "Be7",
            "Nd6+",
            "Kf8",
            "Be2",
            "Kg8",
            "O-O",
            "h5",
            "Bf4",
            "h4",
            "e5",
            "Ne8",
            "Nce4",
            "Bxd6",
            "Nxd6",
            "g5",
            "Nxe8",
            "Kf8",
            "Nf6",
            "gxf4",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Nf6",
            "gxf6",
            "Qd6+",
            "Qe7",
            "Qxe7+",
            "Kxe7",
            "Rad1",
            "h3",
            "g3",
            "Nd4",
            "Bd3",
            "d6",
            "exd6+",
            "Kxd6",
            "Rad1",
            "f5",
            "Bxf5",
            "exf5",
            "Rxd4+",
            "Kc5",
            "Rfd1",
            "fxg3",
            "b4+",
            "Kb6",
            "Rd6+",
            "Kc7",
            "Rd7+",
            "Kb8",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd6+",
            "Kc7",
            "Rd7+",
            "Kb8",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7",
            "R1d7+",
            "Kb6",
            "Rd8+",
            "Kc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a5a6",
          "neutral_response": "Re8\n46. a6 Kd7 47. axb7 Kc6 48. g4 Kxb7 49. g5 Kc6 50. g6 Kxc5 51. g7 Kxb6 52.\ng8=Q Rxg8 53. Ke1 Kc5 54. Kd2 Kd4 55. Kc2 Rg2 56. Kb3 Rxf2 57. Kb4 Rxh2 58.\nKb5 Rc2 59. Kb6 f2 60. Kb5 f1=Q+ 61. Kb6 Qb1+ 62. Ka5 Ra2# f2 63. Ka4 f1=Q 64.\nKa5 Qfb5# f2 65. Ka4 f1=Q 66. Ka5 Qfb5# f2 67. Ka4 f1=Q 68. Ka5 Qfb5# f2 69.\nKa4 f1=Q 70. Ka5 Qfb5# f2 71. Ka4 f1=Q 72. Ka5 Qfb5# f2 73. Ka4 f1=Q 74. Ka5\nQfb5# f2 75. Ka4 f1=Q 76. Ka5 Qfb5# f2 77. Ka4 f1=Q 78. Ka5 Qfb5# f2 79. Ka4\nf1=Q 80. Ka5 Qfb5# f2 81. Ka4 f1=Q 82. Ka5 Qfb5# f2 83. Ka4 f1=Q 84. Ka5\nQfb5# f2 85. Ka4 Qf4+ 86. Ka3 Qfb4# f2 87. Ka2 Qb3# f2 88. Ka1 Qb2# f2 89.\nKa2 Qb1# f2 90. Ka3 Q1b3# f2 91. Ka4 Q3b4# f2 92. Ka3 Q4b3# f2 93. Ka4 Q3b4#\nf2 94. Ka3 Q4b3# f2 95. Ka4 Q3b4# f2 96. Ka3 Q4b3# f2 97. Ka4 Q3b4# f2 98.\nKa3 Q3b3# f2 99. Ka4 Q3b4# f2 100. Ka3 Q3b3# f2 101. Ka4 Q3b4# f2 102. Ka3\nQ3b3# f2 103. Ka4 Q3b4# f2 104. Ka3 Q3b3# f2 105. Ka4 Q3b4# f2 106. Ka3 Q3b3#\nf2 107. Ka4 Q3b4# f",
          "neutral_tokens": {
            "prompt_tokens": 483,
            "completion_tokens": 640,
            "total_tokens": 1123,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kd7",
            "axb7",
            "Kc6",
            "g4",
            "Kxb7",
            "g5",
            "Kc6",
            "g6",
            "Kxc5",
            "g7",
            "Kxb6",
            "g8=Q",
            "Rxg8",
            "Ke1",
            "Kc5",
            "Kd2",
            "Kd4",
            "Kc2",
            "Rg2",
            "Kb3",
            "Rxf2",
            "Kb4",
            "Rxh2",
            "Kb5",
            "Rc2",
            "Kb6",
            "f2",
            "Kb5",
            "f1=Q+",
            "Kb6",
            "Qb1+",
            "Ka5",
            "Ra2#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "f1=Q",
            "Ka5",
            "Qfb5#",
            "f2",
            "Ka4",
            "Qf4+",
            "Ka3",
            "Qfb4#",
            "f2",
            "Ka2",
            "Qb3#",
            "f2",
            "Ka1",
            "Qb2#",
            "f2",
            "Ka2",
            "Qb1#",
            "f2",
            "Ka3",
            "Q1b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q4b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q4b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q4b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q3b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q3b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q3b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q3b3#",
            "f2",
            "Ka4",
            "Q3b4#",
            "f2",
            "Ka3",
            "Q3b3#",
            "f2",
            "Ka4",
            "Q3b4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c5c6",
          "neutral_uci": "a5a6",
          "consensus_move": "a5a6",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kd7",
              "a6",
              "bxa6",
              "b7",
              "Kc7",
              "c6",
              "Kxc6",
              "b8=Q",
              "Rxb8",
              "Ke1",
              "Rd8",
              "g4",
              "a5",
              "g5",
              "a4",
              "g6",
              "a3",
              "g7",
              "a2",
              "g8=Q",
              "a1=Q#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "bxc6",
              "a6",
              "Kd7",
              "b7",
              "Kc7",
              "g4",
              "Kb6",
              "g5",
              "Kxa6",
              "g6",
              "Kxb7",
              "g7",
              "Kb6",
              "g8=Q",
              "Rxg8",
              "Ke1",
              "Rd8",
              "Kf1",
              "Rd1#",
              "e4",
              "c5",
              "Nf3",
              "Nc6",
              "d4",
              "cxd4",
              "Nxd4",
              "Nf6",
              "Nc3",
              "e6",
              "Ndb5",
              "Be7",
              "Nd6+",
              "Kf8",
              "Be2",
              "Kg8",
              "O-O",
              "h5",
              "Bf4",
              "h4",
              "e5",
              "Ne8",
              "Nce4",
              "Bxd6",
              "Nxd6",
              "g5",
              "Nxe8",
              "Kf8",
              "Nf6",
              "gxf4",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Nf6",
              "gxf6",
              "Qd6+",
              "Qe7",
              "Qxe7+",
              "Kxe7",
              "Rad1",
              "h3",
              "g3",
              "Nd4",
              "Bd3",
              "d6",
              "exd6+",
              "Kxd6",
              "Rad1",
              "f5",
              "Bxf5",
              "exf5",
              "Rxd4+",
              "Kc5",
              "Rfd1",
              "fxg3",
              "b4+",
              "Kb6",
              "Rd6+",
              "Kc7",
              "Rd7+",
              "Kb8",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd6+",
              "Kc7",
              "Rd7+",
              "Kb8",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7",
              "R1d7+",
              "Kb6",
              "Rd8+",
              "Kc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd7",
              "axb7",
              "Kc6",
              "g4",
              "Kxb7",
              "g5",
              "Kc6",
              "g6",
              "Kxc5",
              "g7",
              "Kxb6",
              "g8=Q",
              "Rxg8",
              "Ke1",
              "Kc5",
              "Kd2",
              "Kd4",
              "Kc2",
              "Rg2",
              "Kb3",
              "Rxf2",
              "Kb4",
              "Rxh2",
              "Kb5",
              "Rc2",
              "Kb6",
              "f2",
              "Kb5",
              "f1=Q+",
              "Kb6",
              "Qb1+",
              "Ka5",
              "Ra2#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "f1=Q",
              "Ka5",
              "Qfb5#",
              "f2",
              "Ka4",
              "Qf4+",
              "Ka3",
              "Qfb4#",
              "f2",
              "Ka2",
              "Qb3#",
              "f2",
              "Ka1",
              "Qb2#",
              "f2",
              "Ka2",
              "Qb1#",
              "f2",
              "Ka3",
              "Q1b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q4b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q4b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q4b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q3b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q3b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q3b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q3b3#",
              "f2",
              "Ka4",
              "Q3b4#",
              "f2",
              "Ka3",
              "Q3b3#",
              "f2",
              "Ka4",
              "Q3b4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 484,
            "completion_tokens": 86,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 483,
            "completion_tokens": 640,
            "total_tokens": 1123,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1451,
          "total_completion_tokens": 1366,
          "total_tokens": 2817
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 484,
            "completion_tokens": 86,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 483,
            "completion_tokens": 640,
            "total_tokens": 1123,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "4r3/1p2k3/1P6/P1P5/8/5pPp/5P1P/5K2 w - - 1 46"
    },
    {
      "turn": 93,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "axb7",
          "aggressive_uci": "a6b7",
          "aggressive_response": "47. axb7 Kc6 48. g4 Kxb7 49. g5 Kc6 50. g6 Kxc5 51. g7 Kxb6 52. g8=Q Rxg8 53. Ke1 Kc5 54. Kd2 Kd4 55. Kc2 Rg2 56. Kd2 Rxf2+ 57. Ke1 Rxh2 58. Kf1 Ke3 59. Kg1 Rg2+ 60. Kh1 Ra2 61. Kg1 f2+ 62. Kh2 f1=Q+ 63. Kg3 Qf4+ 64. Kxh3 Rh2#",
          "aggressive_tokens": {
            "prompt_tokens": 492,
            "completion_tokens": 156,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "g4",
            "Kxb7",
            "g5",
            "Kc6",
            "g6",
            "Kxc5",
            "g7",
            "Kxb6",
            "g8=Q",
            "Rxg8",
            "Ke1",
            "Kc5",
            "Kd2",
            "Kd4",
            "Kc2",
            "Rg2",
            "Kd2",
            "Rxf2+",
            "Ke1",
            "Rxh2",
            "Kf1",
            "Ke3",
            "Kg1",
            "Rg2+",
            "Kh1",
            "Ra2",
            "Kg1",
            "f2+",
            "Kh2",
            "f1=Q+",
            "Kg3",
            "Qf4+",
            "Kxh3",
            "Rh2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a7",
          "positional_uci": "a6a7",
          "positional_response": "47. a7 Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7 51. g7 Rg8 52. Ke1 Rxg7 53. Kd2\nRg2 54. Ke3 Rxh2 55. Kxf3 Rg2 56. Ke3 h2 57. f4 h1=Q 58. f5 Qh4 59. f6 Rg3+ 60.\nKe2 Qh2+ 61. Kf1 Rg1#",
          "positional_tokens": {
            "prompt_tokens": 492,
            "completion_tokens": 127,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "g4",
            "Kxc5",
            "g5",
            "Kxb6",
            "g6",
            "Kxa7",
            "g7",
            "Rg8",
            "Ke1",
            "Rxg7",
            "Kd2",
            "Rg2",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "f4",
            "h1=Q",
            "f5",
            "Qh4",
            "f6",
            "Rg3+",
            "Ke2",
            "Qh2+",
            "Kf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a7",
          "neutral_uci": "a6a7",
          "neutral_response": "47. a7 Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7 51. g7 Rg8 52. Ke1 Rxg7 53. Kd2\nRg2 54. Ke3 Rxh2 55. Kxf3 Rg2 56. Ke3 h2 57. f4 h1=Q 58. f5 Qh3+ 59. Ke4 Rg4+\n60. Ke5 Qe3+ 61. Kf6 Qg5+ 62. Ke6 Re4+ 63. Kd5 Qxf5+ 64. Kd6 Re6+ 65. Kd7 Qf7+ 66. Kd8 Re8# Rg2 Rg3 Rg4",
          "neutral_tokens": {
            "prompt_tokens": 491,
            "completion_tokens": 182,
            "total_tokens": 673,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "g4",
            "Kxc5",
            "g5",
            "Kxb6",
            "g6",
            "Kxa7",
            "g7",
            "Rg8",
            "Ke1",
            "Rxg7",
            "Kd2",
            "Rg2",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "f4",
            "h1=Q",
            "f5",
            "Qh3+",
            "Ke4",
            "Rg4+",
            "Ke5",
            "Qe3+",
            "Kf6",
            "Qg5+",
            "Ke6",
            "Re4+",
            "Kd5",
            "Qxf5+",
            "Kd6",
            "Re6+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Re8#",
            "Rg2",
            "Rg3",
            "Rg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a6b7",
          "positional_uci": "a6a7",
          "neutral_uci": "a6a7",
          "consensus_move": "a6a7",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kc6",
              "g4",
              "Kxb7",
              "g5",
              "Kc6",
              "g6",
              "Kxc5",
              "g7",
              "Kxb6",
              "g8=Q",
              "Rxg8",
              "Ke1",
              "Kc5",
              "Kd2",
              "Kd4",
              "Kc2",
              "Rg2",
              "Kd2",
              "Rxf2+",
              "Ke1",
              "Rxh2",
              "Kf1",
              "Ke3",
              "Kg1",
              "Rg2+",
              "Kh1",
              "Ra2",
              "Kg1",
              "f2+",
              "Kh2",
              "f1=Q+",
              "Kg3",
              "Qf4+",
              "Kxh3",
              "Rh2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kc6",
              "g4",
              "Kxc5",
              "g5",
              "Kxb6",
              "g6",
              "Kxa7",
              "g7",
              "Rg8",
              "Ke1",
              "Rxg7",
              "Kd2",
              "Rg2",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "f4",
              "h1=Q",
              "f5",
              "Qh4",
              "f6",
              "Rg3+",
              "Ke2",
              "Qh2+",
              "Kf1",
              "Rg1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kc6",
              "g4",
              "Kxc5",
              "g5",
              "Kxb6",
              "g6",
              "Kxa7",
              "g7",
              "Rg8",
              "Ke1",
              "Rxg7",
              "Kd2",
              "Rg2",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "f4",
              "h1=Q",
              "f5",
              "Qh3+",
              "Ke4",
              "Rg4+",
              "Ke5",
              "Qe3+",
              "Kf6",
              "Qg5+",
              "Ke6",
              "Re4+",
              "Kd5",
              "Qxf5+",
              "Kd6",
              "Re6+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Re8#",
              "Rg2",
              "Rg3",
              "Rg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 492,
            "completion_tokens": 156,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 492,
            "completion_tokens": 127,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 491,
            "completion_tokens": 182,
            "total_tokens": 673,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1475,
          "total_completion_tokens": 465,
          "total_tokens": 1940
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 492,
            "completion_tokens": 156,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 492,
            "completion_tokens": 127,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 491,
            "completion_tokens": 182,
            "total_tokens": 673,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r3/1p1k4/PP6/2P5/8/5pPp/5P1P/5K2 w - - 1 47"
    },
    {
      "turn": 95,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g4",
          "aggressive_uci": "g3g4",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46.\na6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7 51. g7 Rg8 52. Ke1 Rxg7\n53. Kd2 Rg2 54. Ke3 Rxh2 55. Kxf3 Rg2 56. Ke3 h2 57. f4 h1=Q 58. f5 Qh4 59. f6 Rg3+ 60. Kf2 Qh2+ 61. Kf1 Rg1#",
          "aggressive_tokens": {
            "prompt_tokens": 500,
            "completion_tokens": 510,
            "total_tokens": 1010,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxc5",
            "g5",
            "Kxb6",
            "g6",
            "Kxa7",
            "g7",
            "Rg8",
            "Ke1",
            "Rxg7",
            "Kd2",
            "Rg2",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "f4",
            "h1=Q",
            "f5",
            "Qh4",
            "f6",
            "Rg3+",
            "Kf2",
            "Qh2+",
            "Kf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g4",
          "positional_uci": "g3g4",
          "positional_response": "47. ... Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7",
          "positional_tokens": {
            "prompt_tokens": 500,
            "completion_tokens": 31,
            "total_tokens": 531,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxc5",
            "g5",
            "Kxb6",
            "g6",
            "Kxa7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g4",
          "neutral_uci": "g3g4",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46. a6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7 51. g7 Rg8 52. Ke1 Rxg7 53. Kd2 Rg2 54. Ke3 Rxh2 55. Kxf3 Rg2 56. Ke3 h2 57. f4 h1=Q 58. f5 Qh4 59. f6 Rg3+ 60. Kf2 Qh2+ 61. Kf1 Rg1#",
          "neutral_tokens": {
            "prompt_tokens": 499,
            "completion_tokens": 509,
            "total_tokens": 1008,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxc5",
            "g5",
            "Kxb6",
            "g6",
            "Kxa7",
            "g7",
            "Rg8",
            "Ke1",
            "Rxg7",
            "Kd2",
            "Rg2",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "f4",
            "h1=Q",
            "f5",
            "Qh4",
            "f6",
            "Rg3+",
            "Kf2",
            "Qh2+",
            "Kf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3g4",
          "positional_uci": "g3g4",
          "neutral_uci": "g3g4",
          "consensus_move": "g3g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxc5",
              "g5",
              "Kxb6",
              "g6",
              "Kxa7",
              "g7",
              "Rg8",
              "Ke1",
              "Rxg7",
              "Kd2",
              "Rg2",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "f4",
              "h1=Q",
              "f5",
              "Qh4",
              "f6",
              "Rg3+",
              "Kf2",
              "Qh2+",
              "Kf1",
              "Rg1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxc5",
              "g5",
              "Kxb6",
              "g6",
              "Kxa7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxc5",
              "g5",
              "Kxb6",
              "g6",
              "Kxa7",
              "g7",
              "Rg8",
              "Ke1",
              "Rxg7",
              "Kd2",
              "Rg2",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "f4",
              "h1=Q",
              "f5",
              "Qh4",
              "f6",
              "Rg3+",
              "Kf2",
              "Qh2+",
              "Kf1",
              "Rg1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 500,
            "completion_tokens": 510,
            "total_tokens": 1010,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 500,
            "completion_tokens": 31,
            "total_tokens": 531,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 499,
            "completion_tokens": 509,
            "total_tokens": 1008,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1499,
          "total_completion_tokens": 1050,
          "total_tokens": 2549
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 500,
            "completion_tokens": 510,
            "total_tokens": 1010,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 500,
            "completion_tokens": 31,
            "total_tokens": 531,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 499,
            "completion_tokens": 509,
            "total_tokens": 1008,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r3/Pp6/1Pk5/2P5/8/5pPp/5P1P/5K2 w - - 1 48"
    },
    {
      "turn": 97,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g5",
          "aggressive_uci": "g4g5",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46.\na6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7 51. g7 Rg8 52. Ke1 Rxg7\n53. Kd2 Rg2 54. Ke3 Rxh2 55. Kxf3 Rg2 56. Ke3 h2 57. f4 h1=Q 58. f5 Qh4 59. f6 Rg3+ 60. Kf2 Qh2+ 61. Kf1 Rg1#",
          "aggressive_tokens": {
            "prompt_tokens": 508,
            "completion_tokens": 510,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxb6",
            "g6",
            "Kxa7",
            "g7",
            "Rg8",
            "Ke1",
            "Rxg7",
            "Kd2",
            "Rg2",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "f4",
            "h1=Q",
            "f5",
            "Qh4",
            "f6",
            "Rg3+",
            "Kf2",
            "Qh2+",
            "Kf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g5",
          "positional_uci": "g4g5",
          "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46.\na6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7 51. g7 Rg8 52. Ke1 Rxg7\n53. Kd2 Rg2 54. Ke3 Rxh2 55. Kxf3 Rg2 56. Ke3 h2 57. f4 h1=Q 58. f5 Qh4 59. f6\nRg3+ 60. Kf2 Qh2+ 61. Kf1 Rg1#",
          "positional_tokens": {
            "prompt_tokens": 508,
            "completion_tokens": 511,
            "total_tokens": 1019,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxb6",
            "g6",
            "Kxa7",
            "g7",
            "Rg8",
            "Ke1",
            "Rxg7",
            "Kd2",
            "Rg2",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "f4",
            "h1=Q",
            "f5",
            "Qh4",
            "f6",
            "Rg3+",
            "Kf2",
            "Qh2+",
            "Kf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g5",
          "neutral_uci": "g4g5",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46.\na6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Kxb6 50. g6 Kxa7 51. g7 Rg8 52. Ke1 Rxg7\n53. Kd2 Rg2 54. Ke3 Rxh2 55. Kxf3 Rg2 56. Ke3 h2 57. f4 h1=Q 58. f5 Qh3+ 59.\nKf4 Rg4+ 60. Ke5 Qe3+ 61. Kf6 Qg5+ 62. Ke6 Re4+ 63. Kd5 Qxf5+ 64. Kd6 Re6+ 65.\nKd7 Qf7+ 66. Kd8 Re8#",
          "neutral_tokens": {
            "prompt_tokens": 507,
            "completion_tokens": 557,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxb6",
            "g6",
            "Kxa7",
            "g7",
            "Rg8",
            "Ke1",
            "Rxg7",
            "Kd2",
            "Rg2",
            "Ke3",
            "Rxh2",
            "Kxf3",
            "Rg2",
            "Ke3",
            "h2",
            "f4",
            "h1=Q",
            "f5",
            "Qh3+",
            "Kf4",
            "Rg4+",
            "Ke5",
            "Qe3+",
            "Kf6",
            "Qg5+",
            "Ke6",
            "Re4+",
            "Kd5",
            "Qxf5+",
            "Kd6",
            "Re6+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Re8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4g5",
          "positional_uci": "g4g5",
          "neutral_uci": "g4g5",
          "consensus_move": "g4g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxb6",
              "g6",
              "Kxa7",
              "g7",
              "Rg8",
              "Ke1",
              "Rxg7",
              "Kd2",
              "Rg2",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "f4",
              "h1=Q",
              "f5",
              "Qh4",
              "f6",
              "Rg3+",
              "Kf2",
              "Qh2+",
              "Kf1",
              "Rg1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxb6",
              "g6",
              "Kxa7",
              "g7",
              "Rg8",
              "Ke1",
              "Rxg7",
              "Kd2",
              "Rg2",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "f4",
              "h1=Q",
              "f5",
              "Qh4",
              "f6",
              "Rg3+",
              "Kf2",
              "Qh2+",
              "Kf1",
              "Rg1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxb6",
              "g6",
              "Kxa7",
              "g7",
              "Rg8",
              "Ke1",
              "Rxg7",
              "Kd2",
              "Rg2",
              "Ke3",
              "Rxh2",
              "Kxf3",
              "Rg2",
              "Ke3",
              "h2",
              "f4",
              "h1=Q",
              "f5",
              "Qh3+",
              "Kf4",
              "Rg4+",
              "Ke5",
              "Qe3+",
              "Kf6",
              "Qg5+",
              "Ke6",
              "Re4+",
              "Kd5",
              "Qxf5+",
              "Kd6",
              "Re6+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Re8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 508,
            "completion_tokens": 510,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 508,
            "completion_tokens": 511,
            "total_tokens": 1019,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 507,
            "completion_tokens": 557,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1523,
          "total_completion_tokens": 1578,
          "total_tokens": 3101
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 508,
            "completion_tokens": 510,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 508,
            "completion_tokens": 511,
            "total_tokens": 1019,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 507,
            "completion_tokens": 557,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r3/Pp6/1P6/2k5/6P1/5p1p/5P1P/5K2 w - - 0 49"
    },
    {
      "turn": 99,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ke1",
          "aggressive_uci": "f1e1",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46.\na6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Rc8 50. Ke1 Kxb6 51. Kd2 Kxa7 52. Ke3 b5\n53. Kxf3 b4 54. Kg4 b3 55. Kxh3 b2 56. Kg4 b1=Q 57. h4 Qe4+ 58. f4 Rc4 59. Kh5 Qxf4\n60. Kg6 Rc6+ 61. Kh5 Qf3#",
          "aggressive_tokens": {
            "prompt_tokens": 515,
            "completion_tokens": 504,
            "total_tokens": 1019,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxb6",
            "Kd2",
            "Kxa7",
            "Ke3",
            "b5",
            "Kxf3",
            "b4",
            "Kg4",
            "b3",
            "Kxh3",
            "b2",
            "Kg4",
            "b1=Q",
            "h4",
            "Qe4+",
            "f4",
            "Rc4",
            "Kh5",
            "Qxf4",
            "Kg6",
            "Rc6+",
            "Kh5",
            "Qf3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g6",
          "positional_uci": "g5g6",
          "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46. a6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Rc8 50. g6 Kd4 51. Ke1 Kd3 52. Kd1 Rg8 53. Kc1 Ke2 54. Kc2 Kxf2 55. Kd3 Kg2 56. Ke4 f2 57. Kf5 f1=Q+ 58. Kg5 Qc1+ 59. Kf6 Qc6+ 60. Kf7 Qxg6+ 61. Ke7 Re8+ 62. Kd7 Qe6+ 63. Kc7 Qc6#",
          "positional_tokens": {
            "prompt_tokens": 515,
            "completion_tokens": 531,
            "total_tokens": 1046,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd4",
            "Ke1",
            "Kd3",
            "Kd1",
            "Rg8",
            "Kc1",
            "Ke2",
            "Kc2",
            "Kxf2",
            "Kd3",
            "Kg2",
            "Ke4",
            "f2",
            "Kf5",
            "f1=Q+",
            "Kg5",
            "Qc1+",
            "Kf6",
            "Qc6+",
            "Kf7",
            "Qxg6+",
            "Ke7",
            "Re8+",
            "Kd7",
            "Qe6+",
            "Kc7",
            "Qc6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g6",
          "neutral_uci": "g5g6",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46. a6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Rc8 50. g6 Kd4 51. Ke1 Kd3 52. Kd1 Rg8 53. Kc1 Ke2 54. Kc2 Kxf2 55. Kd3 Kg2 56. Ke4 f2 57. Kf5 f1=Q+ 58. Kg5 Qc1+ 59. Kf6 Qc6+ 60. Kf7 Qxg6+ 61. Ke7 Re8+ 62. Kd7 Qe6+ 63. Kc7 Qc6#",
          "neutral_tokens": {
            "prompt_tokens": 514,
            "completion_tokens": 531,
            "total_tokens": 1045,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd4",
            "Ke1",
            "Kd3",
            "Kd1",
            "Rg8",
            "Kc1",
            "Ke2",
            "Kc2",
            "Kxf2",
            "Kd3",
            "Kg2",
            "Ke4",
            "f2",
            "Kf5",
            "f1=Q+",
            "Kg5",
            "Qc1+",
            "Kf6",
            "Qc6+",
            "Kf7",
            "Qxg6+",
            "Ke7",
            "Re8+",
            "Kd7",
            "Qe6+",
            "Kc7",
            "Qc6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1e1",
          "positional_uci": "g5g6",
          "neutral_uci": "g5g6",
          "consensus_move": "g5g6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxb6",
              "Kd2",
              "Kxa7",
              "Ke3",
              "b5",
              "Kxf3",
              "b4",
              "Kg4",
              "b3",
              "Kxh3",
              "b2",
              "Kg4",
              "b1=Q",
              "h4",
              "Qe4+",
              "f4",
              "Rc4",
              "Kh5",
              "Qxf4",
              "Kg6",
              "Rc6+",
              "Kh5",
              "Qf3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kd4",
              "Ke1",
              "Kd3",
              "Kd1",
              "Rg8",
              "Kc1",
              "Ke2",
              "Kc2",
              "Kxf2",
              "Kd3",
              "Kg2",
              "Ke4",
              "f2",
              "Kf5",
              "f1=Q+",
              "Kg5",
              "Qc1+",
              "Kf6",
              "Qc6+",
              "Kf7",
              "Qxg6+",
              "Ke7",
              "Re8+",
              "Kd7",
              "Qe6+",
              "Kc7",
              "Qc6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd4",
              "Ke1",
              "Kd3",
              "Kd1",
              "Rg8",
              "Kc1",
              "Ke2",
              "Kc2",
              "Kxf2",
              "Kd3",
              "Kg2",
              "Ke4",
              "f2",
              "Kf5",
              "f1=Q+",
              "Kg5",
              "Qc1+",
              "Kf6",
              "Qc6+",
              "Kf7",
              "Qxg6+",
              "Ke7",
              "Re8+",
              "Kd7",
              "Qe6+",
              "Kc7",
              "Qc6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 515,
            "completion_tokens": 504,
            "total_tokens": 1019,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 515,
            "completion_tokens": 531,
            "total_tokens": 1046,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 514,
            "completion_tokens": 531,
            "total_tokens": 1045,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1544,
          "total_completion_tokens": 1566,
          "total_tokens": 3110
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 515,
            "completion_tokens": 504,
            "total_tokens": 1019,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 515,
            "completion_tokens": 531,
            "total_tokens": 1046,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 514,
            "completion_tokens": 531,
            "total_tokens": 1045,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r5/Pp6/1P6/2k3P1/8/5p1p/5P1P/5K2 w - - 1 50"
    },
    {
      "turn": 101,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ke1",
          "aggressive_uci": "f1e1",
          "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46.\na6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Rc8 50. g6 Rg8 51. Ke1 Kxb6 52. Kd2 Kxa7\n53. Ke3 Rxg6 54. Kxf3 b5 55. Ke3 b4 56. Kd3 b3 57. Kc3 Rg2 58. Kxb3 Rxf2 59.\nKc3 Rxh2 60. Kd3 Rg2 61. Ke3 h2 62. Kf3 h1=Q 63. Ke3 Qh3+ 64. Kf4 Rg4+ 65. Kf5\nQh5+ 66. Kf6 Rg6+ 67. Kf7 Qh7+ 68. Kf8 Rg8#",
          "aggressive_tokens": {
            "prompt_tokens": 523,
            "completion_tokens": 575,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxb6",
            "Kd2",
            "Kxa7",
            "Ke3",
            "Rxg6",
            "Kxf3",
            "b5",
            "Ke3",
            "b4",
            "Kd3",
            "b3",
            "Kc3",
            "Rg2",
            "Kxb3",
            "Rxf2",
            "Kc3",
            "Rxh2",
            "Kd3",
            "Rg2",
            "Ke3",
            "h2",
            "Kf3",
            "h1=Q",
            "Ke3",
            "Qh3+",
            "Kf4",
            "Rg4+",
            "Kf5",
            "Qh5+",
            "Kf6",
            "Rg6+",
            "Kf7",
            "Qh7+",
            "Kf8",
            "Rg8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ke1",
          "positional_uci": "f1e1",
          "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8.\nBe2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8\n15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21.\nexd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6\n27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1\na4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7\n40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46.\na6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Rc8 50. g6 Rg8 51. Ke1 Kxb6 52. Kd2 Kxa7\n53. Ke3 Rxg6 54. Kxf3 Rg2 55. Ke3 Rxh2 56. f4 Ra2 57. f5 h2 58. f6 h1=Q 59. f7 Qh3+ 60. Kd4 Ra4+ 61. Kc5 Qh5+ 62. Kd6 Ra6+ 63. Ke7 Qe5+ 64. Kf8 Qh8+ 65. Ke7 Qf6+ 66. Kf8 Qh6+ 67. Ke7 Re6+ 68. Kd7 Rd6+ 69. Ke7 Qf6+ 70. Kf8 Rd8#",
          "positional_tokens": {
            "prompt_tokens": 523,
            "completion_tokens": 589,
            "total_tokens": 1112,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxb6",
            "Kd2",
            "Kxa7",
            "Ke3",
            "Rxg6",
            "Kxf3",
            "Rg2",
            "Ke3",
            "Rxh2",
            "f4",
            "Ra2",
            "f5",
            "h2",
            "f6",
            "h1=Q",
            "f7",
            "Qh3+",
            "Kd4",
            "Ra4+",
            "Kc5",
            "Qh5+",
            "Kd6",
            "Ra6+",
            "Ke7",
            "Qe5+",
            "Kf8",
            "Qh8+",
            "Ke7",
            "Qf6+",
            "Kf8",
            "Qh6+",
            "Ke7",
            "Re6+",
            "Kd7",
            "Rd6+",
            "Ke7",
            "Qf6+",
            "Kf8",
            "Rd8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ke1",
          "neutral_uci": "f1e1",
          "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Ndb5 Be7 7. Nd6+ Kf8 8. Be2 Kg8 9. O-O h5 10. Bf4 h4 11. e5 Ne8 12. Nce4 Bxd6 13. Nxd6 g5 14. Nxe8 Kf8 15. Nf6 gxf4 16. Qd6+ Qe7 17. Qxe7+ Kxe7 18. Ng4 h3 19. g3 Nd4 20. Bd3 d6 21. exd6+ Kxd6 22. Rad1 f5 23. Bxf5 exf5 24. Rxd4+ Kc5 25. Rfd1 fxg4 26. b4+ Kb6 27. Rd6+ Kc7 28. R1d5 Rh7 29. c4 a5 30. b5 Rf7 31. c5 Re7 32. b6+ Kb8 33. Kf1 a4 34. Rd8 f3 35. Rxc8+ Kxc8 36. Rg5 Kd7 37. Rxg4 Rf8 38. Rd4+ Ke8 39. Rxa4 Kd7 40. Rd4+ Ke6 41. Re4+ Kf7 42. Rf4+ Ke8 43. Rxf8+ Kxf8 44. a4 Re8 45. a5 Ke7 46. a6 Kd7 47. a7 Kc6 48. g4 Kxc5 49. g5 Rc8 50. g6 Rg8 51. Ke1 Kxb6 52. Kd2 Kxa7 53. Ke3 Rxg6 54. Kxf3 Rg2 55. Ke3 Rxh2 56. f4 Ra2 57. f5 h2 58. f6 h1=Q 59. f7 Qh3+ 60. Kf4 Ra4+ 61. Ke5 Qh5+ 62. Kf6 Ra6+ 63. Kg7 Qg6+ 64. Kf8 Qd6+ 65. Kg7 Qh6+ 66. Kg8 Rg6#",
          "neutral_tokens": {
            "prompt_tokens": 522,
            "completion_tokens": 551,
            "total_tokens": 1073,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxb6",
            "Kd2",
            "Kxa7",
            "Ke3",
            "Rxg6",
            "Kxf3",
            "Rg2",
            "Ke3",
            "Rxh2",
            "f4",
            "Ra2",
            "f5",
            "h2",
            "f6",
            "h1=Q",
            "f7",
            "Qh3+",
            "Kf4",
            "Ra4+",
            "Ke5",
            "Qh5+",
            "Kf6",
            "Ra6+",
            "Kg7",
            "Qg6+",
            "Kf8",
            "Qd6+",
            "Kg7",
            "Qh6+",
            "Kg8",
            "Rg6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1e1",
          "positional_uci": "f1e1",
          "neutral_uci": "f1e1",
          "consensus_move": "f1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxb6",
              "Kd2",
              "Kxa7",
              "Ke3",
              "Rxg6",
              "Kxf3",
              "b5",
              "Ke3",
              "b4",
              "Kd3",
              "b3",
              "Kc3",
              "Rg2",
              "Kxb3",
              "Rxf2",
              "Kc3",
              "Rxh2",
              "Kd3",
              "Rg2",
              "Ke3",
              "h2",
              "Kf3",
              "h1=Q",
              "Ke3",
              "Qh3+",
              "Kf4",
              "Rg4+",
              "Kf5",
              "Qh5+",
              "Kf6",
              "Rg6+",
              "Kf7",
              "Qh7+",
              "Kf8",
              "Rg8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxb6",
              "Kd2",
              "Kxa7",
              "Ke3",
              "Rxg6",
              "Kxf3",
              "Rg2",
              "Ke3",
              "Rxh2",
              "f4",
              "Ra2",
              "f5",
              "h2",
              "f6",
              "h1=Q",
              "f7",
              "Qh3+",
              "Kd4",
              "Ra4+",
              "Kc5",
              "Qh5+",
              "Kd6",
              "Ra6+",
              "Ke7",
              "Qe5+",
              "Kf8",
              "Qh8+",
              "Ke7",
              "Qf6+",
              "Kf8",
              "Qh6+",
              "Ke7",
              "Re6+",
              "Kd7",
              "Rd6+",
              "Ke7",
              "Qf6+",
              "Kf8",
              "Rd8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxb6",
              "Kd2",
              "Kxa7",
              "Ke3",
              "Rxg6",
              "Kxf3",
              "Rg2",
              "Ke3",
              "Rxh2",
              "f4",
              "Ra2",
              "f5",
              "h2",
              "f6",
              "h1=Q",
              "f7",
              "Qh3+",
              "Kf4",
              "Ra4+",
              "Ke5",
              "Qh5+",
              "Kf6",
              "Ra6+",
              "Kg7",
              "Qg6+",
              "Kf8",
              "Qd6+",
              "Kg7",
              "Qh6+",
              "Kg8",
              "Rg6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 523,
            "completion_tokens": 575,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 523,
            "completion_tokens": 589,
            "total_tokens": 1112,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 522,
            "completion_tokens": 551,
            "total_tokens": 1073,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1568,
          "total_completion_tokens": 1715,
          "total_tokens": 3283
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 523,
            "completion_tokens": 575,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 523,
            "completion_tokens": 589,
            "total_tokens": 1112,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 522,
            "completion_tokens": 551,
            "total_tokens": 1073,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6r1/Pp6/1P4P1/2k5/8/5p1p/5P1P/5K2 w - - 1 51"
    },
    {
      "turn": 103,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kc6",
          "aggressive_uci": null,
          "aggressive_response": "Kc6 Kc6",
          "aggressive_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kc6",
          "positional_uci": null,
          "positional_response": "Kc6 Kc6",
          "positional_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kc6",
          "neutral_uci": null,
          "neutral_response": "Kc6 Kd7 Kc6",
          "neutral_tokens": {
            "prompt_tokens": 530,
            "completion_tokens": 9,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 530,
            "completion_tokens": 9,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1592,
          "total_completion_tokens": 21,
          "total_tokens": 1613
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 530,
            "completion_tokens": 9,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6r1/Pp6/1Pk3P1/8/8/5p1p/5P1P/4K3 w - - 3 52"
    },
    {
      "turn": 103,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kc6",
          "aggressive_uci": null,
          "aggressive_response": "Kc6 Kc6",
          "aggressive_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kc6",
          "positional_uci": null,
          "positional_response": "Kc6 Kc6",
          "positional_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kc6",
          "neutral_uci": null,
          "neutral_response": "Kc6 Kc6",
          "neutral_tokens": {
            "prompt_tokens": 530,
            "completion_tokens": 6,
            "total_tokens": 536,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 530,
            "completion_tokens": 6,
            "total_tokens": 536,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1592,
          "total_completion_tokens": 18,
          "total_tokens": 1610
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 530,
            "completion_tokens": 6,
            "total_tokens": 536,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6r1/Pp6/1Pk3P1/8/8/5p1p/5P1P/4K3 w - - 3 52"
    },
    {
      "turn": 103,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kc6",
          "aggressive_uci": null,
          "aggressive_response": "Kc6 Kc6",
          "aggressive_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kc6",
          "positional_uci": null,
          "positional_response": "Kc6 Kc6",
          "positional_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kc6",
          "neutral_uci": null,
          "neutral_response": "Kc6 Kc6",
          "neutral_tokens": {
            "prompt_tokens": 530,
            "completion_tokens": 6,
            "total_tokens": 536,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 530,
            "completion_tokens": 6,
            "total_tokens": 536,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1592,
          "total_completion_tokens": 18,
          "total_tokens": 1610
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 531,
            "completion_tokens": 6,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 530,
            "completion_tokens": 6,
            "total_tokens": 536,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6r1/Pp6/1Pk3P1/8/8/5p1p/5P1P/4K3 w - - 3 52"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "1... d5 2. c4 * dxc4 3. Nf3 * Nf6 4. e3 * e6 5. Bxc4 * a6 6. O-O * b5 7. Bb3 * Bb7 8. Nc3 * Nbd7 9. Qe2 * c5 10. Rd1 * Qc7 11. d5 * c4 12. dxe6 * fxe6 13. Bc2 * Bd6 14. h3 * O-O 15. Ng5 * Rae8 16. Nce4 * Nxe4 17. Nxe4 * Bh2+ 18. Kh1 * Be5 19. f4 * Bf6 20. Nd6 * Rb8 21. Nxb7 * Rxb7 22. Qh5 * g6 23. Qg4 * Nc5 24. Rb1 * Qc6 25. Bd2 * Rd7 26. Bb4 * Rfd8 27. Rxd7 * Rxd7 28. Bxc5 * Qxc5 29. Qxe6+ * Rf7 30. Rd1 * Kg7 31. Rd7 * Rxd7 32. Qxd7+ * Kh6 33. Qe6 * Bxb2 34. g4 * Qb4 35. g5+ * Kg7 36. Qd7+ * Kf8 37. Qd8+ * Kf7 38. Qd7+ * Qe7 39. Qxe7+ * Kxe7 40. Kg2 * a5 41. Kf3 * a4 42. Ke4 * Kd6 43. h4 * Kc5 44. h5 * b4 45. hxg6 * hxg6 46. f5 * gxf5+ 47. Kxf5 * b3 48. axb3 * a3 49. Bb1 * cxb3 50. g6 * a2 51. Bxa2 * bxa2 52. e4 * a1=Q 53. e5 * Bxe5 54. Ke6 * Qa6+ 55. Kf7 * Qf6+ 56. Ke8 * Qxg6+ 57. Kd7 * Qd6+ 58. Ke8 * Qc7 59. Kf8 * Kd6 60. Kg8 * Ke6 61. Kf8 * Qf7# d4 c5 Nf3 Nc6 e3 e6 Bxc4 a6 O-O b5 Bb3 Bb7 Nc3 Nbd7 Qe2 c5 Rd1 Qc7 d5 c4 dxe6 fxe6 Bc2 Bd6 h3 O-O Ng5 Rae8",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4",
            "dxe6",
            "fxe6",
            "Bc2",
            "Bd6",
            "h3",
            "O-O",
            "Ng5",
            "Rae8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d7d5",
          "positional_response": "1... d5 2. c4 * dxc4 3. Nf3 * Nf6 4. e3 * e6 5. Bxc4 * a6 6. O-O * b5 7. Bd3 * Bb7 8. Nc3 * c5 9. dxc5 * Bxc5 10. a3 * O-O 11. b4 * Bb6 12. Bb2 * Nbd7 13. Qe2 * Rc8 14. Rfd1 * Qe7 15. Rac1 * Rfd8 16. Bb1 * Nf8 17. Rxd8 * Rxd8 18. Rd1 * Rxd1+ 19. Qxd1 * Qd7 20. Qxd7 * N8xd7 21. Nd2 * Nd5 22. Nxd5 * Bxd5 23. Be4 * Bxe4 24. Nxe4 * Bc7 25. Bd4 * Kf8 26. Nc5 * Nxc5 27. Bxc5+ * Ke8 28. Kf1 * Kd7 29. Ke2 * Kc6 30. Kd3 * Kd5 31. e4+ * Kc6 32. h3 * Be5 33. Bd4 * Bxd4 34. Kxd4 * Kd6 35. e5+ * Kc6 36. f4 * g6 37. g4 * h6 38. h4 * Kb6 39. Ke4 * Kc6 40. f5 * gxf5+ 41. gxf5 * Kd7 42. f6 * Kc6 43. Kd4 * Kb6 44. Ke4 * Kc6 45. Kd4 * Kb6 46. Ke4 * Kc6 47. Kd4 * Kb6 48. Ke4 * Kc6 49. Kd4 * Kb6 50. Ke4 * Kc6 51. Kd4 * Kb6 52. Ke4 * Kc6 53. Kd4 * Kb6 54. Ke4 * Kc6 55. Kd4 * Kb6 56. Ke4 * Kc6 57. Kd4 * Kb6 58. Ke4 * Kc6 59. Kd4 * Kb6 60. Ke4 * Kc6 61. Kd4 * Kb6 62. Ke4 * Kc6 63. Kd4 * Kb6 64. Ke4 * Kc6 65. Kd4 * Kb6 66. Ke4 * Kc6 67. Kd4 * Kb6 68. Ke4 * Kc6 69. Kd4 * Kb6 70. Ke4 * Kc6",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4",
            "dxc4",
            "Nf3",
            "Nf6",
            "e3",
            "e6",
            "Bxc4",
            "a6",
            "O-O",
            "b5",
            "Bd3",
            "Bb7",
            "Nc3",
            "c5",
            "dxc5",
            "Bxc5",
            "a3",
            "O-O",
            "b4",
            "Bb6",
            "Bb2",
            "Nbd7",
            "Qe2",
            "Rc8",
            "Rfd1",
            "Qe7",
            "Rac1",
            "Rfd8",
            "Bb1",
            "Nf8",
            "Rxd8",
            "Rxd8",
            "Rd1",
            "Rxd1+",
            "Qxd1",
            "Qd7",
            "Qxd7",
            "N8xd7",
            "Nd2",
            "Nd5",
            "Nxd5",
            "Bxd5",
            "Be4",
            "Bxe4",
            "Nxe4",
            "Bc7",
            "Bd4",
            "Kf8",
            "Nc5",
            "Nxc5",
            "Bxc5+",
            "Ke8",
            "Kf1",
            "Kd7",
            "Ke2",
            "Kc6",
            "Kd3",
            "Kd5",
            "e4+",
            "Kc6",
            "h3",
            "Be5",
            "Bd4",
            "Bxd4",
            "Kxd4",
            "Kd6",
            "e5+",
            "Kc6",
            "f4",
            "g6",
            "g4",
            "h6",
            "h4",
            "Kb6",
            "Ke4",
            "Kc6",
            "f5",
            "gxf5+",
            "gxf5",
            "Kd7",
            "f6",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6",
            "Kd4",
            "Kb6",
            "Ke4",
            "Kc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d5",
          "neutral_uci": "d7d5",
          "neutral_response": "1... d5 2. c4 * dxc4 3. Nf3 * Nf6 4. e3 * e6 5. Bxc4 * a6 6. O-O * b5 7. Bb3 * Bb7 8. Nc3 * Nbd7 9. Qe2 * c5 10. Rd1 * Qc7 11. d5 * c4 12. dxe6 * fxe6 13. Bc2 * Bd6 14. h3 * O-O 15. Ng5 * Rae8 16. Nce4 * Nxe4 17. Nxe4 * Bh2+ 18. Kh1 * Be5 19. Ng5 * Nf6 20. f4 * Bd6 21. Qd2 * Bc5 22. Qe2 * h6 23. Nf3 * Nh5 24. Qe1 * Bxf3 25. gxf3 * e5 26. Bg6 * Nxf4 27. Bxe8 * Nxh3 28. Bh5 * e4 29. f4 * Nxf4 30. exf4 * Rxf4 31. Bxf4 * Qxf4 32. Rd8+ * Kh7 33. Qe2 * Qh4+ 34. Kg2 * Qxd8 35. Qxe4+ * Kh8 36. Rd1 * Qg5+ 37. Qg4 * Qf6 38. Qc8+ * Kh7 39. Qxc5 * Qxb2+ 40. Qf2 * Qe5 41. Qc2+ * Kg8 42. Rd8+ * Qe8 43. Rxe8# Qe8 44. Rxe8# Qe8 45. Rxe8# Qe8",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 419,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "dxe6",
            "fxe6",
            "Bc2",
            "Bd6",
            "h3",
            "O-O",
            "Ng5",
            "Rae8",
            "Nce4",
            "Nxe4",
            "Nxe4",
            "Bh2+",
            "Kh1",
            "Be5",
            "Ng5",
            "Nf6",
            "f4",
            "Bd6",
            "Qd2",
            "Bc5",
            "Qe2",
            "h6",
            "Nf3",
            "Nh5",
            "Qe1",
            "Bxf3",
            "gxf3",
            "e5",
            "Bg6",
            "Nxf4",
            "Bxe8",
            "Nxh3",
            "Bh5",
            "e4",
            "f4",
            "Nxf4",
            "exf4",
            "Rxf4",
            "Bxf4",
            "Qxf4",
            "Rd8+",
            "Kh7",
            "Qe2",
            "Qh4+",
            "Kg2",
            "Qxd8",
            "Qxe4+",
            "Kh8",
            "Rd1",
            "Qg5+",
            "Qg4",
            "Qf6",
            "Qc8+",
            "Kh7",
            "Qxc5",
            "Qxb2+",
            "Qf2",
            "Qe5",
            "Qc2+",
            "Kg8",
            "Rd8+",
            "Qe8",
            "Rxe8#",
            "Qe8",
            "Rxe8#",
            "Qe8",
            "Rxe8#",
            "Qe8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": "d7d5",
          "neutral_uci": "d7d5",
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c4",
              "dxe6",
              "fxe6",
              "Bc2",
              "Bd6",
              "h3",
              "O-O",
              "Ng5",
              "Rae8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "c4",
              "dxc4",
              "Nf3",
              "Nf6",
              "e3",
              "e6",
              "Bxc4",
              "a6",
              "O-O",
              "b5",
              "Bd3",
              "Bb7",
              "Nc3",
              "c5",
              "dxc5",
              "Bxc5",
              "a3",
              "O-O",
              "b4",
              "Bb6",
              "Bb2",
              "Nbd7",
              "Qe2",
              "Rc8",
              "Rfd1",
              "Qe7",
              "Rac1",
              "Rfd8",
              "Bb1",
              "Nf8",
              "Rxd8",
              "Rxd8",
              "Rd1",
              "Rxd1+",
              "Qxd1",
              "Qd7",
              "Qxd7",
              "N8xd7",
              "Nd2",
              "Nd5",
              "Nxd5",
              "Bxd5",
              "Be4",
              "Bxe4",
              "Nxe4",
              "Bc7",
              "Bd4",
              "Kf8",
              "Nc5",
              "Nxc5",
              "Bxc5+",
              "Ke8",
              "Kf1",
              "Kd7",
              "Ke2",
              "Kc6",
              "Kd3",
              "Kd5",
              "e4+",
              "Kc6",
              "h3",
              "Be5",
              "Bd4",
              "Bxd4",
              "Kxd4",
              "Kd6",
              "e5+",
              "Kc6",
              "f4",
              "g6",
              "g4",
              "h6",
              "h4",
              "Kb6",
              "Ke4",
              "Kc6",
              "f5",
              "gxf5+",
              "gxf5",
              "Kd7",
              "f6",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6",
              "Kd4",
              "Kb6",
              "Ke4",
              "Kc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c4",
              "dxe6",
              "fxe6",
              "Bc2",
              "Bd6",
              "h3",
              "O-O",
              "Ng5",
              "Rae8",
              "Nce4",
              "Nxe4",
              "Nxe4",
              "Bh2+",
              "Kh1",
              "Be5",
              "Ng5",
              "Nf6",
              "f4",
              "Bd6",
              "Qd2",
              "Bc5",
              "Qe2",
              "h6",
              "Nf3",
              "Nh5",
              "Qe1",
              "Bxf3",
              "gxf3",
              "e5",
              "Bg6",
              "Nxf4",
              "Bxe8",
              "Nxh3",
              "Bh5",
              "e4",
              "f4",
              "Nxf4",
              "exf4",
              "Rxf4",
              "Bxf4",
              "Qxf4",
              "Rd8+",
              "Kh7",
              "Qe2",
              "Qh4+",
              "Kg2",
              "Qxd8",
              "Qxe4+",
              "Kh8",
              "Rd1",
              "Qg5+",
              "Qg4",
              "Qf6",
              "Qc8+",
              "Kh7",
              "Qxc5",
              "Qxb2+",
              "Qf2",
              "Qe5",
              "Qc2+",
              "Kg8",
              "Rd8+",
              "Qe8",
              "Rxe8#",
              "Qe8",
              "Rxe8#",
              "Qe8",
              "Rxe8#",
              "Qe8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 419,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1699,
          "total_tokens": 2040
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 419,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "2... Nf6 3. Bf4 e6 4. e3 Bd6 5. Bg3 O-O 6. Nbd2 c5 7. c3 Nc6 8. Bd3 b6 9. Ne5 Bb7 10. f4 Ne7 11. Qf3 Nf5 12. Bf2 Be7 13. g4 Nd6 14. g5 Nfe4 15. O-O-O c4 16. Bc2 b5 17. h4 a5 18. h5 b4 19. g6 fxg6 20. hxg6 h6 21. Nxe4 dxe4 22. Qh3 Rf5 23. Ng4 Bf8 24. Bh4 Qe8 25. Rdg1 bxc3 26. bxc3 Nb5 27. Bg5 Nxc3 28. Bxh6 gxh6 29. Nxh6+ Bxh6 30. Qxh6 Ne2+ 31. Kd2 c3+ 32. Ke1 Nxg1 33. Qh8# Nf3+ 34. Kf2 Qxh8 35. Rxh8+ Kxh8 36. g7+ Kxg7 37. Bxe4 Bxe4 38. d5 exd5 39. a4 c2 40. Kg3 c1=Q 41. Kg4 Qg1+ 42. Kh3 Rh5# Nf3 44. f5 Bxf5# Nxf5 46. e4 dxe4# Nxe4 48. Kg4 Rh4# Nf3 50. Kxf5 Rf8# Nxe4 52. Kg4 Rh4# Nf3 54. Kxf3 Rfxf4+ 55. Kg3 Rhg4+ 56. Kh3 Rg6# Nf3 58. Kg3 Rf5# Nxe4 60. Kg4 Rf1# Nf3 62. Kg3 Rg1+ 63. Kh3 Rh6# Nxe4 65. Kg4 Rf1# Nf3 67. Kg3 Rg6# Nxe4 69. Kg4 Rf1# Nf3 71. Kg3 Rg1+ 72. Kh3 Rh6# Nxe4 74. Kg4 Rf1# Nf3 76. Kg3 Rg6# Nxe4 78. Kg4 Rf1# Nf3 80. Kg3 Rg1+ 81. Kh3 Rh6# Nxe4 83. Kg4 Rf1# Nf3 85. Kg3 Rg6# Nxe4 87. Kg4 Rf1# Nf3 89. Kg3 Rg1+",
          "aggressive_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bf4",
            "e6",
            "e3",
            "Bd6",
            "Bg3",
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "Bd3",
            "b6",
            "Ne5",
            "Bb7",
            "f4",
            "Ne7",
            "Qf3",
            "Nf5",
            "Bf2",
            "Be7",
            "g4",
            "Nd6",
            "g5",
            "Nfe4",
            "O-O-O",
            "c4",
            "Bc2",
            "b5",
            "h4",
            "a5",
            "h5",
            "b4",
            "g6",
            "fxg6",
            "hxg6",
            "h6",
            "Nxe4",
            "dxe4",
            "Qh3",
            "Rf5",
            "Ng4",
            "Bf8",
            "Bh4",
            "Qe8",
            "Rdg1",
            "bxc3",
            "bxc3",
            "Nb5",
            "Bg5",
            "Nxc3",
            "Bxh6",
            "gxh6",
            "Nxh6+",
            "Bxh6",
            "Qxh6",
            "Ne2+",
            "Kd2",
            "c3+",
            "Ke1",
            "Nxg1",
            "Qh8#",
            "Nf3+",
            "Kf2",
            "Qxh8",
            "Rxh8+",
            "Kxh8",
            "g7+",
            "Kxg7",
            "Bxe4",
            "Bxe4",
            "d5",
            "exd5",
            "a4",
            "c2",
            "Kg3",
            "c1=Q",
            "Kg4",
            "Qg1+",
            "Kh3",
            "Rh5#",
            "Nf3",
            "f5",
            "Bxf5#",
            "Nxf5",
            "e4",
            "dxe4#",
            "Nxe4",
            "Kg4",
            "Rh4#",
            "Nf3",
            "Kxf5",
            "Rf8#",
            "Nxe4",
            "Kg4",
            "Rh4#",
            "Nf3",
            "Kxf3",
            "Rfxf4+",
            "Kg3",
            "Rhg4+",
            "Kh3",
            "Rg6#",
            "Nf3",
            "Kg3",
            "Rf5#",
            "Nxe4",
            "Kg4",
            "Rf1#",
            "Nf3",
            "Kg3",
            "Rg1+",
            "Kh3",
            "Rh6#",
            "Nxe4",
            "Kg4",
            "Rf1#",
            "Nf3",
            "Kg3",
            "Rg6#",
            "Nxe4",
            "Kg4",
            "Rf1#",
            "Nf3",
            "Kg3",
            "Rg1+",
            "Kh3",
            "Rh6#",
            "Nxe4",
            "Kg4",
            "Rf1#",
            "Nf3",
            "Kg3",
            "Rg6#",
            "Nxe4",
            "Kg4",
            "Rf1#",
            "Nf3",
            "Kg3",
            "Rg1+",
            "Kh3",
            "Rh6#",
            "Nxe4",
            "Kg4",
            "Rf1#",
            "Nf3",
            "Kg3",
            "Rg6#",
            "Nxe4",
            "Kg4",
            "Rf1#",
            "Nf3",
            "Kg3",
            "Rg1+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "2... Nf6 3. c4 e6 4. Nc3 Be7 5. Bg5 O-O 6. e3 Nbd7 7. Rc1 c6 8. Bd3 dxc4 9. Bxc4 Nd5 10. Bxe7 Qxe7 11. O-O Nxc3 12. Rxc3 e5 13. dxe5 Nxe5 14. Nxe5 Qxe5 15. f4 Qe7 16. f5 Qf6 17. e4 Rd8 18. Qh5 b5 19. Bb3 Bb7 20. Rh3 h6 21. e5 Qxe5 22. Qxf7+ Kh8 23. f6 Qd4+ 24. Kh1 Rd7 25. fxg7+ Qxg7 26. Qe6 Re7 27. Rxh6+ Qh7 28. Qf6+ Rg7 29. Rxh7+ Kxh7 30. Qh4+ Kg6 31. Rf6# Bb8 32. Bc2# Kh5 33. Rh6# Kg5 34. Rg6# 1-0\n34... Kh5 35. Qg4# Kg5 36. Qg3# 1-0",
          "positional_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 305,
            "total_tokens": 427,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bg5",
            "O-O",
            "e3",
            "Nbd7",
            "Rc1",
            "c6",
            "Bd3",
            "dxc4",
            "Bxc4",
            "Nd5",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Nxc3",
            "Rxc3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "f4",
            "Qe7",
            "f5",
            "Qf6",
            "e4",
            "Rd8",
            "Qh5",
            "b5",
            "Bb3",
            "Bb7",
            "Rh3",
            "h6",
            "e5",
            "Qxe5",
            "Qxf7+",
            "Kh8",
            "f6",
            "Qd4+",
            "Kh1",
            "Rd7",
            "fxg7+",
            "Qxg7",
            "Qe6",
            "Re7",
            "Rxh6+",
            "Qh7",
            "Qf6+",
            "Rg7",
            "Rxh7+",
            "Kxh7",
            "Qh4+",
            "Kg6",
            "Rf6#",
            "Bb8",
            "Bc2#",
            "Kh5",
            "Rh6#",
            "Kg5",
            "Rg6#",
            "Kh5",
            "Qg4#",
            "Kg5",
            "Qg3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "2... Nf6 3. Bf4 e6 4. e3 Bd6 5. Bg3 O-O 6. Nbd2 c5 7. c3 Nc6 8. Bd3 b6 9. Ne5 Bb7 10. f4 Ne7 11. Qf3 Nf5 12. Bf2 Be7 13. g4 Nd6 14. g5 Nfe4 15. O-O-O c4 16. Bc2 b5 17. h4 a5 18. h5 b4 19. g6 fxg6 20. hxg6 h6 21. Nxe4 dxe4 22. Qh3 Rf5 23. Ng4 Bf8 24. Bh4 Qe8 25. Rdg1 bxc3 26. bxc3 Nb5 27. Bg5 Nxc3 28. Bxh6 gxh6 29. Nxh6+ Bxh6 30. Qxh6 Ne2+ 31. Kd2 Nxg1 32. Qh8# Nf3+ 33. Kc1 Qxh8 34. Rxh8+ Kxh8 35. g7+ Kxg7 36. Bxe4 Bxe4 37. d5 exd5 38. a4 Rb8 39. Kd1 Rb2 40. Kc1 Rc2+ 41. Kd1 Rh5 42. f5 Rh1# Nf3+ 44. Kxc2 Kf6 45. Kc3 Kxf5 46. Kc2 Ke5 47. Kc3 Rc1+ 48. Kb2 Rc2+ 49. Ka3 Rc3+ 50. Kb2 Rb3+ 51. Ka2 Bb1+ 52. Ka1 Nd2 53. e4 Kd4 54. exd5 Kc3 55. d6 Ra3# Nc4 57. d7 Ra1# Nc4 59. d8=Q Nb3# Nc4 61. Qd4+ Kxd4 62. Kb1 Kc3 63. Kc1 Nd2 64. Kd1 Kd3 65. Ke1 Ke3 66. Kd1 Nb3 67. Ke1 Ra1# Nc4 69. Kd1 Kd3 70. Ke1 Nd2 71. Kd1 Nf3# Nc4 73. Kc1 Kc3 74. Kb1 Nd2+ 75. Kc1 Ra1# Nc4 77. Kd1 Kd3 78. Ke1 Ke3 79. Kd1 Nb2+ 80. Kc1 Nd3+ 81. Kd1 Ra1#",
          "neutral_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bf4",
            "e6",
            "e3",
            "Bd6",
            "Bg3",
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "Bd3",
            "b6",
            "Ne5",
            "Bb7",
            "f4",
            "Ne7",
            "Qf3",
            "Nf5",
            "Bf2",
            "Be7",
            "g4",
            "Nd6",
            "g5",
            "Nfe4",
            "O-O-O",
            "c4",
            "Bc2",
            "b5",
            "h4",
            "a5",
            "h5",
            "b4",
            "g6",
            "fxg6",
            "hxg6",
            "h6",
            "Nxe4",
            "dxe4",
            "Qh3",
            "Rf5",
            "Ng4",
            "Bf8",
            "Bh4",
            "Qe8",
            "Rdg1",
            "bxc3",
            "bxc3",
            "Nb5",
            "Bg5",
            "Nxc3",
            "Bxh6",
            "gxh6",
            "Nxh6+",
            "Bxh6",
            "Qxh6",
            "Ne2+",
            "Kd2",
            "Nxg1",
            "Qh8#",
            "Nf3+",
            "Kc1",
            "Qxh8",
            "Rxh8+",
            "Kxh8",
            "g7+",
            "Kxg7",
            "Bxe4",
            "Bxe4",
            "d5",
            "exd5",
            "a4",
            "Rb8",
            "Kd1",
            "Rb2",
            "Kc1",
            "Rc2+",
            "Kd1",
            "Rh5",
            "f5",
            "Rh1#",
            "Nf3+",
            "Kxc2",
            "Kf6",
            "Kc3",
            "Kxf5",
            "Kc2",
            "Ke5",
            "Kc3",
            "Rc1+",
            "Kb2",
            "Rc2+",
            "Ka3",
            "Rc3+",
            "Kb2",
            "Rb3+",
            "Ka2",
            "Bb1+",
            "Ka1",
            "Nd2",
            "e4",
            "Kd4",
            "exd5",
            "Kc3",
            "d6",
            "Ra3#",
            "Nc4",
            "d7",
            "Ra1#",
            "Nc4",
            "d8=Q",
            "Nb3#",
            "Nc4",
            "Qd4+",
            "Kxd4",
            "Kb1",
            "Kc3",
            "Kc1",
            "Nd2",
            "Kd1",
            "Kd3",
            "Ke1",
            "Ke3",
            "Kd1",
            "Nb3",
            "Ke1",
            "Ra1#",
            "Nc4",
            "Kd1",
            "Kd3",
            "Ke1",
            "Nd2",
            "Kd1",
            "Nf3#",
            "Nc4",
            "Kc1",
            "Kc3",
            "Kb1",
            "Nd2+",
            "Kc1",
            "Ra1#",
            "Nc4",
            "Kd1",
            "Kd3",
            "Ke1",
            "Ke3",
            "Kd1",
            "Nb2+",
            "Kc1",
            "Nd3+",
            "Kd1",
            "Ra1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf4",
              "e6",
              "e3",
              "Bd6",
              "Bg3",
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "Bd3",
              "b6",
              "Ne5",
              "Bb7",
              "f4",
              "Ne7",
              "Qf3",
              "Nf5",
              "Bf2",
              "Be7",
              "g4",
              "Nd6",
              "g5",
              "Nfe4",
              "O-O-O",
              "c4",
              "Bc2",
              "b5",
              "h4",
              "a5",
              "h5",
              "b4",
              "g6",
              "fxg6",
              "hxg6",
              "h6",
              "Nxe4",
              "dxe4",
              "Qh3",
              "Rf5",
              "Ng4",
              "Bf8",
              "Bh4",
              "Qe8",
              "Rdg1",
              "bxc3",
              "bxc3",
              "Nb5",
              "Bg5",
              "Nxc3",
              "Bxh6",
              "gxh6",
              "Nxh6+",
              "Bxh6",
              "Qxh6",
              "Ne2+",
              "Kd2",
              "c3+",
              "Ke1",
              "Nxg1",
              "Qh8#",
              "Nf3+",
              "Kf2",
              "Qxh8",
              "Rxh8+",
              "Kxh8",
              "g7+",
              "Kxg7",
              "Bxe4",
              "Bxe4",
              "d5",
              "exd5",
              "a4",
              "c2",
              "Kg3",
              "c1=Q",
              "Kg4",
              "Qg1+",
              "Kh3",
              "Rh5#",
              "Nf3",
              "f5",
              "Bxf5#",
              "Nxf5",
              "e4",
              "dxe4#",
              "Nxe4",
              "Kg4",
              "Rh4#",
              "Nf3",
              "Kxf5",
              "Rf8#",
              "Nxe4",
              "Kg4",
              "Rh4#",
              "Nf3",
              "Kxf3",
              "Rfxf4+",
              "Kg3",
              "Rhg4+",
              "Kh3",
              "Rg6#",
              "Nf3",
              "Kg3",
              "Rf5#",
              "Nxe4",
              "Kg4",
              "Rf1#",
              "Nf3",
              "Kg3",
              "Rg1+",
              "Kh3",
              "Rh6#",
              "Nxe4",
              "Kg4",
              "Rf1#",
              "Nf3",
              "Kg3",
              "Rg6#",
              "Nxe4",
              "Kg4",
              "Rf1#",
              "Nf3",
              "Kg3",
              "Rg1+",
              "Kh3",
              "Rh6#",
              "Nxe4",
              "Kg4",
              "Rf1#",
              "Nf3",
              "Kg3",
              "Rg6#",
              "Nxe4",
              "Kg4",
              "Rf1#",
              "Nf3",
              "Kg3",
              "Rg1+",
              "Kh3",
              "Rh6#",
              "Nxe4",
              "Kg4",
              "Rf1#",
              "Nf3",
              "Kg3",
              "Rg6#",
              "Nxe4",
              "Kg4",
              "Rf1#",
              "Nf3",
              "Kg3",
              "Rg1+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bg5",
              "O-O",
              "e3",
              "Nbd7",
              "Rc1",
              "c6",
              "Bd3",
              "dxc4",
              "Bxc4",
              "Nd5",
              "Bxe7",
              "Qxe7",
              "O-O",
              "Nxc3",
              "Rxc3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "f4",
              "Qe7",
              "f5",
              "Qf6",
              "e4",
              "Rd8",
              "Qh5",
              "b5",
              "Bb3",
              "Bb7",
              "Rh3",
              "h6",
              "e5",
              "Qxe5",
              "Qxf7+",
              "Kh8",
              "f6",
              "Qd4+",
              "Kh1",
              "Rd7",
              "fxg7+",
              "Qxg7",
              "Qe6",
              "Re7",
              "Rxh6+",
              "Qh7",
              "Qf6+",
              "Rg7",
              "Rxh7+",
              "Kxh7",
              "Qh4+",
              "Kg6",
              "Rf6#",
              "Bb8",
              "Bc2#",
              "Kh5",
              "Rh6#",
              "Kg5",
              "Rg6#",
              "Kh5",
              "Qg4#",
              "Kg5",
              "Qg3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bf4",
              "e6",
              "e3",
              "Bd6",
              "Bg3",
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "Bd3",
              "b6",
              "Ne5",
              "Bb7",
              "f4",
              "Ne7",
              "Qf3",
              "Nf5",
              "Bf2",
              "Be7",
              "g4",
              "Nd6",
              "g5",
              "Nfe4",
              "O-O-O",
              "c4",
              "Bc2",
              "b5",
              "h4",
              "a5",
              "h5",
              "b4",
              "g6",
              "fxg6",
              "hxg6",
              "h6",
              "Nxe4",
              "dxe4",
              "Qh3",
              "Rf5",
              "Ng4",
              "Bf8",
              "Bh4",
              "Qe8",
              "Rdg1",
              "bxc3",
              "bxc3",
              "Nb5",
              "Bg5",
              "Nxc3",
              "Bxh6",
              "gxh6",
              "Nxh6+",
              "Bxh6",
              "Qxh6",
              "Ne2+",
              "Kd2",
              "Nxg1",
              "Qh8#",
              "Nf3+",
              "Kc1",
              "Qxh8",
              "Rxh8+",
              "Kxh8",
              "g7+",
              "Kxg7",
              "Bxe4",
              "Bxe4",
              "d5",
              "exd5",
              "a4",
              "Rb8",
              "Kd1",
              "Rb2",
              "Kc1",
              "Rc2+",
              "Kd1",
              "Rh5",
              "f5",
              "Rh1#",
              "Nf3+",
              "Kxc2",
              "Kf6",
              "Kc3",
              "Kxf5",
              "Kc2",
              "Ke5",
              "Kc3",
              "Rc1+",
              "Kb2",
              "Rc2+",
              "Ka3",
              "Rc3+",
              "Kb2",
              "Rb3+",
              "Ka2",
              "Bb1+",
              "Ka1",
              "Nd2",
              "e4",
              "Kd4",
              "exd5",
              "Kc3",
              "d6",
              "Ra3#",
              "Nc4",
              "d7",
              "Ra1#",
              "Nc4",
              "d8=Q",
              "Nb3#",
              "Nc4",
              "Qd4+",
              "Kxd4",
              "Kb1",
              "Kc3",
              "Kc1",
              "Nd2",
              "Kd1",
              "Kd3",
              "Ke1",
              "Ke3",
              "Kd1",
              "Nb3",
              "Ke1",
              "Ra1#",
              "Nc4",
              "Kd1",
              "Kd3",
              "Ke1",
              "Nd2",
              "Kd1",
              "Nf3#",
              "Nc4",
              "Kc1",
              "Kc3",
              "Kb1",
              "Nd2+",
              "Kc1",
              "Ra1#",
              "Nc4",
              "Kd1",
              "Kd3",
              "Ke1",
              "Ke3",
              "Kd1",
              "Nb2+",
              "Kc1",
              "Nd3+",
              "Kd1",
              "Ra1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 122,
            "completion_tokens": 305,
            "total_tokens": 427,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 365,
          "total_completion_tokens": 1585,
          "total_tokens": 1950
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 122,
            "completion_tokens": 305,
            "total_tokens": 427,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e6",
          "aggressive_uci": "e7e6",
          "aggressive_response": "3... e6 4. Bd3 c5 5. c3 Nc6 6. Nbd2 Bd6 7. O-O O-O 8. dxc5 Bxc5 9. e4 dxe4 10. Nxe4 Nxe4 11. Bxe4 Qxd1 12. Rxd1 Rd8 13. Bf4 Bd7 14. Bc7 Rdc8 15. Rxd7 f5 16. Bxc6 bxc6 17. Be5 Bf8 18. Rad1 h6 19. Rb7 Rd8 20. Rdd7 Rxd7 21. Rxd7 a5 22. Nd4 Re8 23. Nxc6 a4 24. Ra7 Rc8 25. Nd4 Rc5 26. f4 Rc4 27. Nxe6 Re4 28. Ra8 Kf7 29. Nxf8 Re2 30. Nd7 Rxb2 31. Rxa4 Ke6 32. Nc5+ Kd5 33. Nd3 Rd2 34. Rd4+ Ke6 35. Nc5+ Kf7 36. Rxd2 g5 37. Rd7+ Kg6 38. Rg7+ Kh5 39. fxg5 hxg5 40. Ne6 g4 41. Nf4+ Kh6 42. Rg6+ Kh7 43. Rg5 Kh6 44. Rh5# e4 e5 e6",
          "aggressive_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 342,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e6",
          "positional_uci": "e7e6",
          "positional_response": "3... e6 4. Bd3 c5 5. b3 Nc6 6. O-O Bd6 7. Bb2 O-O 8. Nbd2 b6 9. Ne5 Bb7 10. f4 Qc7 11. a3 Rac8 12. Qe2 Ne7 13. Rac1 Ne4 14. c4 f6 15. Nef3 Nf5 16. cxd5 exd5 17. g4 Ne7 18. Bxe4 dxe4 19. Nh4 Qd7 20. Nc4 Ba6 21. Rfd1 Qe6 22. f5 Qd7 23. Qg2 Bb7 24. Nxd6 Qxd6 25. dxc5 Qb8 26. cxb6 axb6 27. Qd2 Rfd8 28. Rxc8 Qxc8 29. Qxd8+ Qxd8 30. Rxd8+ Kf7 31. Rd7 Bc6 32. Rc7 Ke8 33. Bd4 Kd8 34. Bxb6 Ke8 35. Bc5 Nd5 36. Rxc6 Kd7 37. Rd6+ Kc7 38. Rxd5 Kc6 39. Rd4 Kxc5 40. Rxe4 Kd5 41. Re7 Kd6 42. Rxg7 Ke5 43. Rxh7 Ke4 44. Rf7 Kxe3 45. Rxf6 Kf4 46. Re6 Kxg4 47. f6 Kxh4 48. f7 Kg5 49. f8=Q Kh5 50. Qf5+ Kh4 51. Re4# e4 d4 g5",
          "positional_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 409,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3",
            "c5",
            "b3",
            "Nc6",
            "O-O",
            "Bd6",
            "Bb2",
            "O-O",
            "Nbd2",
            "b6",
            "Ne5",
            "Bb7",
            "f4",
            "Qc7",
            "a3",
            "Rac8",
            "Qe2",
            "Ne7",
            "Rac1",
            "Ne4",
            "c4",
            "f6",
            "Nef3",
            "Nf5",
            "cxd5",
            "exd5",
            "g4",
            "Ne7",
            "Bxe4",
            "dxe4",
            "Nh4",
            "Qd7",
            "Nc4",
            "Ba6",
            "Rfd1",
            "Qe6",
            "f5",
            "Qd7",
            "Qg2",
            "Bb7",
            "Nxd6",
            "Qxd6",
            "dxc5",
            "Qb8",
            "cxb6",
            "axb6",
            "Qd2",
            "Rfd8",
            "Rxc8",
            "Qxc8",
            "Qxd8+",
            "Qxd8",
            "Rxd8+",
            "Kf7",
            "Rd7",
            "Bc6",
            "Rc7",
            "Ke8",
            "Bd4",
            "Kd8",
            "Bxb6",
            "Ke8",
            "Bc5",
            "Nd5",
            "Rxc6",
            "Kd7",
            "Rd6+",
            "Kc7",
            "Rxd5",
            "Kc6",
            "Rd4",
            "Kxc5",
            "Rxe4",
            "Kd5",
            "Re7",
            "Kd6",
            "Rxg7",
            "Ke5",
            "Rxh7",
            "Ke4",
            "Rf7",
            "Kxe3",
            "Rxf6",
            "Kf4",
            "Re6",
            "Kxg4",
            "f6",
            "Kxh4",
            "f7",
            "Kg5",
            "f8=Q",
            "Kh5",
            "Qf5+",
            "Kh4",
            "Re4#",
            "e4",
            "d4",
            "g5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e6",
          "neutral_uci": "e7e6",
          "neutral_response": "3... e6 4. Bd3 c5 5. c3 Nc6 6. O-O Bd6 7. Nbd2 O-O 8. dxc5 Bxc5 9. e4 dxe4 10. Nxe4 Nxe4 11. Bxe4 Qxd1 12. Rxd1 Rd8 13. Bf4 Bd7 14. Bc7 Rdc8 15. Rxd7 f5 16. Bxc6 bxc6 17. Rad1 h6 18. Be5 Bf8 19. Nd4 Re8 20. Nxc6 a5 21. Rb7 Ra6 22. Nd4 Rd8 23. Re1 Rd5 24. f4 g5 25. g3 gxf4 26. gxf4 a4 27. Kf2 a3 28. Rg1+ Bg7 29. Rgxg7+ Kf8 30. Rb8+ Rd8 31. Rxd8# e5 dxe5 Nxe5 fxe5 Nxe5 Bxe5+ Kxe5 Rf8+ Ke6 Rf6+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7+ Ke8 Rf8+ Ke7 Rf7",
          "neutral_tokens": {
            "prompt_tokens": 129,
            "completion_tokens": 640,
            "total_tokens": 769,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "c5",
            "c3",
            "Nc6",
            "O-O",
            "Bd6",
            "Nbd2",
            "O-O",
            "dxc5",
            "Bxc5",
            "e4",
            "dxe4",
            "Nxe4",
            "Nxe4",
            "Bxe4",
            "Qxd1",
            "Rxd1",
            "Rd8",
            "Bf4",
            "Bd7",
            "Bc7",
            "Rdc8",
            "Rxd7",
            "f5",
            "Bxc6",
            "bxc6",
            "Rad1",
            "h6",
            "Be5",
            "Bf8",
            "Nd4",
            "Re8",
            "Nxc6",
            "a5",
            "Rb7",
            "Ra6",
            "Nd4",
            "Rd8",
            "Re1",
            "Rd5",
            "f4",
            "g5",
            "g3",
            "gxf4",
            "gxf4",
            "a4",
            "Kf2",
            "a3",
            "Rg1+",
            "Bg7",
            "Rgxg7+",
            "Kf8",
            "Rb8+",
            "Rd8",
            "Rxd8#",
            "e5",
            "dxe5",
            "Nxe5",
            "fxe5",
            "Nxe5",
            "Bxe5+",
            "Kxe5",
            "Rf8+",
            "Ke6",
            "Rf6+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rf8+",
            "Ke7",
            "Rf7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e6",
          "positional_uci": "e7e6",
          "neutral_uci": "e7e6",
          "consensus_move": "e7e6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd3",
              "c5",
              "b3",
              "Nc6",
              "O-O",
              "Bd6",
              "Bb2",
              "O-O",
              "Nbd2",
              "b6",
              "Ne5",
              "Bb7",
              "f4",
              "Qc7",
              "a3",
              "Rac8",
              "Qe2",
              "Ne7",
              "Rac1",
              "Ne4",
              "c4",
              "f6",
              "Nef3",
              "Nf5",
              "cxd5",
              "exd5",
              "g4",
              "Ne7",
              "Bxe4",
              "dxe4",
              "Nh4",
              "Qd7",
              "Nc4",
              "Ba6",
              "Rfd1",
              "Qe6",
              "f5",
              "Qd7",
              "Qg2",
              "Bb7",
              "Nxd6",
              "Qxd6",
              "dxc5",
              "Qb8",
              "cxb6",
              "axb6",
              "Qd2",
              "Rfd8",
              "Rxc8",
              "Qxc8",
              "Qxd8+",
              "Qxd8",
              "Rxd8+",
              "Kf7",
              "Rd7",
              "Bc6",
              "Rc7",
              "Ke8",
              "Bd4",
              "Kd8",
              "Bxb6",
              "Ke8",
              "Bc5",
              "Nd5",
              "Rxc6",
              "Kd7",
              "Rd6+",
              "Kc7",
              "Rxd5",
              "Kc6",
              "Rd4",
              "Kxc5",
              "Rxe4",
              "Kd5",
              "Re7",
              "Kd6",
              "Rxg7",
              "Ke5",
              "Rxh7",
              "Ke4",
              "Rf7",
              "Kxe3",
              "Rxf6",
              "Kf4",
              "Re6",
              "Kxg4",
              "f6",
              "Kxh4",
              "f7",
              "Kg5",
              "f8=Q",
              "Kh5",
              "Qf5+",
              "Kh4",
              "Re4#",
              "e4",
              "d4",
              "g5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd3",
              "c5",
              "c3",
              "Nc6",
              "O-O",
              "Bd6",
              "Nbd2",
              "O-O",
              "dxc5",
              "Bxc5",
              "e4",
              "dxe4",
              "Nxe4",
              "Nxe4",
              "Bxe4",
              "Qxd1",
              "Rxd1",
              "Rd8",
              "Bf4",
              "Bd7",
              "Bc7",
              "Rdc8",
              "Rxd7",
              "f5",
              "Bxc6",
              "bxc6",
              "Rad1",
              "h6",
              "Be5",
              "Bf8",
              "Nd4",
              "Re8",
              "Nxc6",
              "a5",
              "Rb7",
              "Ra6",
              "Nd4",
              "Rd8",
              "Re1",
              "Rd5",
              "f4",
              "g5",
              "g3",
              "gxf4",
              "gxf4",
              "a4",
              "Kf2",
              "a3",
              "Rg1+",
              "Bg7",
              "Rgxg7+",
              "Kf8",
              "Rb8+",
              "Rd8",
              "Rxd8#",
              "e5",
              "dxe5",
              "Nxe5",
              "fxe5",
              "Nxe5",
              "Bxe5+",
              "Kxe5",
              "Rf8+",
              "Ke6",
              "Rf6+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rf8+",
              "Ke7",
              "Rf7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 130,
            "completion_tokens": 342,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 130,
            "completion_tokens": 409,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 129,
            "completion_tokens": 640,
            "total_tokens": 769,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 389,
          "total_completion_tokens": 1391,
          "total_tokens": 1780
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 130,
            "completion_tokens": 342,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 130,
            "completion_tokens": 409,
            "total_tokens": 539,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 129,
            "completion_tokens": 640,
            "total_tokens": 769,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p4/3P4/4PN2/PPP2PPP/RNBQKB1R b KQkq - 0 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c5",
          "aggressive_uci": "c7c5",
          "aggressive_response": "4... c5 5. Nc3 Nc6 6. Bd3 dxc4 7. Bxc4 a6 8. O-O b5 9. Bd3 Bb7 10. a3 cxd4 11. exd4 Be7 12. Be3 O-O 13. Rc1 Rc8 14. Qe2 Na5 15. Ne5 Nb3 16. Rcd1 Qc7 17. Bc2 Na5 18. Bf4 Bd6 19. Rd3 Nc4 20. Rh3 g6 21. Bb1 Rfe8 22. Re1 Nd5 23. Nxd5 Bxd5 24. Qg4 Nxe5 25. dxe5 Bf8 26. Qh4 h5 27. Rg3 Bg7 28. Qg5 Qe7 29. Qxe7 Rxe7 30. Rc3 Rec7 31. Rxc7 Rxc7 32. Rc1 Rxc1+ 33. Bxc1 Bxe5 34. b4 Bc4 35. Be4 Bd5 36. Bd3 Kf8 37. Kf1 Ke7 38. h3 Kd6 39. f3 Bc4 40. Ke2 Kd5 41. Ke3 Bd4+ 42. Kd2 Bxd3 43. Kxd3 f5 44. g4 hxg4 45. hxg4 e5 46. gxf5 gxf5 47. Kc2 Kc4 48. Bd2 e4 49. fxe4 fxe4 50. Bc1 e3 51. Kd1 Kd3 52. Ke1 Bc3+ 53. Kd1 e2# e4 d5 Nf3 Nf6 e3 e6 c4 c5 Nc3 Nc6 Bd3 dxc4 Bxc4 a6 O-O b5 Bd3 Bb7 a3 cxd4 exd4 Be7 Be3 O-O Rc1 Rc8 Qe2 Na5 Ne5 Nb3 Rcd1 Qc7 Bc2 Na5 Bf4 Bd6 Rd3 Nc4 Rh3 g6 Bb1 Rfe8 Re1 Nd5 Nxd5 Bxd5 Qg4 Nxe5 dxe5 Bf8 Qh4 h5 Rg3 Bg7 Qg5 Qe7 Qxe7 Rxe7 Rc3 Rec7 Rxc7 Rxc7 Rc1 Rxc1+ Bxc1 Bxe5 b4 Bc4 Be3 Kf8 f3 Ke7 Kf2 Kd6 Bc5+ Kd5 Ke3 Bb2 Be4+ Kc4 Bb7 Bxa3 Bxa3 Kxb4 Kf2 Kc3 Ke3 Bc5+ Ke2 K",
          "aggressive_tokens": {
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Nc6",
            "Bd3",
            "dxc4",
            "Bxc4",
            "a6",
            "O-O",
            "b5",
            "Bd3",
            "Bb7",
            "a3",
            "cxd4",
            "exd4",
            "Be7",
            "Be3",
            "O-O",
            "Rc1",
            "Rc8",
            "Qe2",
            "Na5",
            "Ne5",
            "Nb3",
            "Rcd1",
            "Qc7",
            "Bc2",
            "Na5",
            "Bf4",
            "Bd6",
            "Rd3",
            "Nc4",
            "Rh3",
            "g6",
            "Bb1",
            "Rfe8",
            "Re1",
            "Nd5",
            "Nxd5",
            "Bxd5",
            "Qg4",
            "Nxe5",
            "dxe5",
            "Bf8",
            "Qh4",
            "h5",
            "Rg3",
            "Bg7",
            "Qg5",
            "Qe7",
            "Qxe7",
            "Rxe7",
            "Rc3",
            "Rec7",
            "Rxc7",
            "Rxc7",
            "Rc1",
            "Rxc1+",
            "Bxc1",
            "Bxe5",
            "b4",
            "Bc4",
            "Be3",
            "Kf8",
            "f3",
            "Ke7",
            "Kf2",
            "Kd6",
            "Bc5+",
            "Kd5",
            "Ke3",
            "Bb2",
            "Be4+",
            "Kc4",
            "Bb7",
            "Bxa3",
            "Bxa3",
            "Kxb4",
            "Kf2",
            "Kc3",
            "Ke3",
            "Bc5+",
            "Ke2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c6",
          "positional_uci": "c7c6",
          "positional_response": "4... c6 5. Nc3 Nbd7 6. Bd3 dxc4 7. Bxc4 b5 8. Bd3 a6 9. O-O c5 10. a4 b4 11. Ne4 Bb7 12. Nxf6+ Nxf6 13. b3 cxd4 14. Nxd4 Bc5 15. Bb2 O-O 16. Rc1 Rc8 17. Qe2 Qd5 18. f3 Rfd8 19. Bxa6 Bxa6 20. Qxa6 e5 21. Nf5 Qxb3 22. Bxe5 Bxe3+ 23. Kh1 Rxc1 24. Nxe3 Qxe3 25. Bxf6 gxf6 26. h3 Rdd1 27. Rxd1 Rxd1+ 28. Kh2 Qf4+ 29. g3 Qd2+ 30. Qe2 Qxe2# e4 d5 Nf3 Nf6 e3 e6 c4 c6 Nc3 Nbd7 Bd3 dxc4 Bxc4 b5 Bd3 a6 O-O c5 a4 b4 Ne4 Bb7 Nxf6+ Nxf6 b3 cxd4 Nxd4 Bc5 Bb2 O-O Rc1 Rc8 Qe2 Qd5 f3 Rfd8 Bxa6 Bxa6 Qxa6 e5 Nf5 Qxb3 Bxe3+ Kh1 Bxe3 Nxe3 Qxe3 Bxf6 gxf6 h3 Rxc1 Rxc1 Qxc1+ Kh2 Qf4+ g3 Qd2+ Qe2 Qxe2#",
          "positional_tokens": {
            "prompt_tokens": 137,
            "completion_tokens": 384,
            "total_tokens": 521,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Bd3",
            "dxc4",
            "Bxc4",
            "b5",
            "Bd3",
            "a6",
            "O-O",
            "c5",
            "a4",
            "b4",
            "Ne4",
            "Bb7",
            "Nxf6+",
            "Nxf6",
            "b3",
            "cxd4",
            "Nxd4",
            "Bc5",
            "Bb2",
            "O-O",
            "Rc1",
            "Rc8",
            "Qe2",
            "Qd5",
            "f3",
            "Rfd8",
            "Bxa6",
            "Bxa6",
            "Qxa6",
            "e5",
            "Nf5",
            "Qxb3",
            "Bxe3+",
            "Kh1",
            "Bxe3",
            "Nxe3",
            "Qxe3",
            "Bxf6",
            "gxf6",
            "h3",
            "Rxc1",
            "Rxc1",
            "Qxc1+",
            "Kh2",
            "Qf4+",
            "g3",
            "Qd2+",
            "Qe2",
            "Qxe2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c5",
          "neutral_uci": "c7c5",
          "neutral_response": "4... c5 5. Nc3 Nc6 6. Bd3 dxc4 7. Bxc4 a6 8. O-O b5 9. Bd3 Bb7 10. a3 cxd4 11. exd4 Be7 12. Be3 O-O 13. Rc1 Rc8 14. Qe2 Na5 15. Ne5 Nb3 16. Rcd1 Nd5 17. Qc2 Nxc3 18. bxc3 Qd5 19. f3 f5 20. c4 Nxd4 21. cxd5 Nxc2 22. Bxc2 Rxc2 23. d6 Bf6 24. Nd7 Rd8 25. Nxf6+ gxf6 26. Bb6 Rd7 27. Rfe1 Kf7 28. Bc7 e5 29. Rc1 Rxc1 30. Rxc1 Ke6 31. Kf2 f4 32. g3 fxg3+ 33. hxg3 Rg7 34. Rh1 Bc6 35. Rh6 Rf7 36. Ke3 Kd5 37. Rh4 f5 38. Rh5 Bd7 39. Rh1 Rg7 40. Rd1+ Ke6 41. Kf2 Rg6 42. Rh1 h6 43. Rh5 Kd5 44. Rh4 Kc6 45. Rh1 Be6 46. Rc1+ Kd7 47. Re1 e4 48. fxe4 fxe4 49. Rxe4 Rf6+ 50. Ke3 Rf1 51. Rh4 Rf6 52. Kd4 Rg6 53. Kc5 Rxg3 54. Rxh6 Rg5+ 55. Kb6 Rg7 56. Kxa6 Kc6 57. Rxe6 Rg8 58. Ka5 Ra8+ 59. Kb4 Ra4+ 60. Kb3 Rd4 61. Re3 Rd1 62. Rc3+ Kd7 63. Kb4 Rb1+ 64. Rb3 Rd1 65. Kxb5 Rd5+ 66. Kb6 Rd1 67. a4 Ra1 68. a5 Ra2 69. a6 Ra1 70. a7 Ra2 71. Kb7 Ra1 72. a8=Q Rxa8 73. Kxa8 1-0\n73... Kc6 74. Rc3+ Kd7 75. Kb7",
          "neutral_tokens": {
            "prompt_tokens": 136,
            "completion_tokens": 586,
            "total_tokens": 722,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nc6",
            "Bd3",
            "dxc4",
            "Bxc4",
            "a6",
            "O-O",
            "b5",
            "Bd3",
            "Bb7",
            "a3",
            "cxd4",
            "exd4",
            "Be7",
            "Be3",
            "O-O",
            "Rc1",
            "Rc8",
            "Qe2",
            "Na5",
            "Ne5",
            "Nb3",
            "Rcd1",
            "Nd5",
            "Qc2",
            "Nxc3",
            "bxc3",
            "Qd5",
            "f3",
            "f5",
            "c4",
            "Nxd4",
            "cxd5",
            "Nxc2",
            "Bxc2",
            "Rxc2",
            "d6",
            "Bf6",
            "Nd7",
            "Rd8",
            "Nxf6+",
            "gxf6",
            "Bb6",
            "Rd7",
            "Rfe1",
            "Kf7",
            "Bc7",
            "e5",
            "Rc1",
            "Rxc1",
            "Rxc1",
            "Ke6",
            "Kf2",
            "f4",
            "g3",
            "fxg3+",
            "hxg3",
            "Rg7",
            "Rh1",
            "Bc6",
            "Rh6",
            "Rf7",
            "Ke3",
            "Kd5",
            "Rh4",
            "f5",
            "Rh5",
            "Bd7",
            "Rh1",
            "Rg7",
            "Rd1+",
            "Ke6",
            "Kf2",
            "Rg6",
            "Rh1",
            "h6",
            "Rh5",
            "Kd5",
            "Rh4",
            "Kc6",
            "Rh1",
            "Be6",
            "Rc1+",
            "Kd7",
            "Re1",
            "e4",
            "fxe4",
            "fxe4",
            "Rxe4",
            "Rf6+",
            "Ke3",
            "Rf1",
            "Rh4",
            "Rf6",
            "Kd4",
            "Rg6",
            "Kc5",
            "Rxg3",
            "Rxh6",
            "Rg5+",
            "Kb6",
            "Rg7",
            "Kxa6",
            "Kc6",
            "Rxe6",
            "Rg8",
            "Ka5",
            "Ra8+",
            "Kb4",
            "Ra4+",
            "Kb3",
            "Rd4",
            "Re3",
            "Rd1",
            "Rc3+",
            "Kd7",
            "Kb4",
            "Rb1+",
            "Rb3",
            "Rd1",
            "Kxb5",
            "Rd5+",
            "Kb6",
            "Rd1",
            "a4",
            "Ra1",
            "a5",
            "Ra2",
            "a6",
            "Ra1",
            "a7",
            "Ra2",
            "Kb7",
            "Ra1",
            "a8=Q",
            "Rxa8",
            "Kxa8",
            "Kc6",
            "Rc3+",
            "Kd7",
            "Kb7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7c5",
          "positional_uci": "c7c6",
          "neutral_uci": "c7c5",
          "consensus_move": "c7c5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Nc6",
              "Bd3",
              "dxc4",
              "Bxc4",
              "a6",
              "O-O",
              "b5",
              "Bd3",
              "Bb7",
              "a3",
              "cxd4",
              "exd4",
              "Be7",
              "Be3",
              "O-O",
              "Rc1",
              "Rc8",
              "Qe2",
              "Na5",
              "Ne5",
              "Nb3",
              "Rcd1",
              "Qc7",
              "Bc2",
              "Na5",
              "Bf4",
              "Bd6",
              "Rd3",
              "Nc4",
              "Rh3",
              "g6",
              "Bb1",
              "Rfe8",
              "Re1",
              "Nd5",
              "Nxd5",
              "Bxd5",
              "Qg4",
              "Nxe5",
              "dxe5",
              "Bf8",
              "Qh4",
              "h5",
              "Rg3",
              "Bg7",
              "Qg5",
              "Qe7",
              "Qxe7",
              "Rxe7",
              "Rc3",
              "Rec7",
              "Rxc7",
              "Rxc7",
              "Rc1",
              "Rxc1+",
              "Bxc1",
              "Bxe5",
              "b4",
              "Bc4",
              "Be3",
              "Kf8",
              "f3",
              "Ke7",
              "Kf2",
              "Kd6",
              "Bc5+",
              "Kd5",
              "Ke3",
              "Bb2",
              "Be4+",
              "Kc4",
              "Bb7",
              "Bxa3",
              "Bxa3",
              "Kxb4",
              "Kf2",
              "Kc3",
              "Ke3",
              "Bc5+",
              "Ke2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Nbd7",
              "Bd3",
              "dxc4",
              "Bxc4",
              "b5",
              "Bd3",
              "a6",
              "O-O",
              "c5",
              "a4",
              "b4",
              "Ne4",
              "Bb7",
              "Nxf6+",
              "Nxf6",
              "b3",
              "cxd4",
              "Nxd4",
              "Bc5",
              "Bb2",
              "O-O",
              "Rc1",
              "Rc8",
              "Qe2",
              "Qd5",
              "f3",
              "Rfd8",
              "Bxa6",
              "Bxa6",
              "Qxa6",
              "e5",
              "Nf5",
              "Qxb3",
              "Bxe3+",
              "Kh1",
              "Bxe3",
              "Nxe3",
              "Qxe3",
              "Bxf6",
              "gxf6",
              "h3",
              "Rxc1",
              "Rxc1",
              "Qxc1+",
              "Kh2",
              "Qf4+",
              "g3",
              "Qd2+",
              "Qe2",
              "Qxe2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "Nc6",
              "Bd3",
              "dxc4",
              "Bxc4",
              "a6",
              "O-O",
              "b5",
              "Bd3",
              "Bb7",
              "a3",
              "cxd4",
              "exd4",
              "Be7",
              "Be3",
              "O-O",
              "Rc1",
              "Rc8",
              "Qe2",
              "Na5",
              "Ne5",
              "Nb3",
              "Rcd1",
              "Nd5",
              "Qc2",
              "Nxc3",
              "bxc3",
              "Qd5",
              "f3",
              "f5",
              "c4",
              "Nxd4",
              "cxd5",
              "Nxc2",
              "Bxc2",
              "Rxc2",
              "d6",
              "Bf6",
              "Nd7",
              "Rd8",
              "Nxf6+",
              "gxf6",
              "Bb6",
              "Rd7",
              "Rfe1",
              "Kf7",
              "Bc7",
              "e5",
              "Rc1",
              "Rxc1",
              "Rxc1",
              "Ke6",
              "Kf2",
              "f4",
              "g3",
              "fxg3+",
              "hxg3",
              "Rg7",
              "Rh1",
              "Bc6",
              "Rh6",
              "Rf7",
              "Ke3",
              "Kd5",
              "Rh4",
              "f5",
              "Rh5",
              "Bd7",
              "Rh1",
              "Rg7",
              "Rd1+",
              "Ke6",
              "Kf2",
              "Rg6",
              "Rh1",
              "h6",
              "Rh5",
              "Kd5",
              "Rh4",
              "Kc6",
              "Rh1",
              "Be6",
              "Rc1+",
              "Kd7",
              "Re1",
              "e4",
              "fxe4",
              "fxe4",
              "Rxe4",
              "Rf6+",
              "Ke3",
              "Rf1",
              "Rh4",
              "Rf6",
              "Kd4",
              "Rg6",
              "Kc5",
              "Rxg3",
              "Rxh6",
              "Rg5+",
              "Kb6",
              "Rg7",
              "Kxa6",
              "Kc6",
              "Rxe6",
              "Rg8",
              "Ka5",
              "Ra8+",
              "Kb4",
              "Ra4+",
              "Kb3",
              "Rd4",
              "Re3",
              "Rd1",
              "Rc3+",
              "Kd7",
              "Kb4",
              "Rb1+",
              "Rb3",
              "Rd1",
              "Kxb5",
              "Rd5+",
              "Kb6",
              "Rd1",
              "a4",
              "Ra1",
              "a5",
              "Ra2",
              "a6",
              "Ra1",
              "a7",
              "Ra2",
              "Kb7",
              "Ra1",
              "a8=Q",
              "Rxa8",
              "Kxa8",
              "Kc6",
              "Rc3+",
              "Kd7",
              "Kb7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 137,
            "completion_tokens": 384,
            "total_tokens": 521,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 136,
            "completion_tokens": 586,
            "total_tokens": 722,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 410,
          "total_completion_tokens": 1610,
          "total_tokens": 2020
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 137,
            "completion_tokens": 384,
            "total_tokens": 521,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 136,
            "completion_tokens": 586,
            "total_tokens": 722,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p4/2PP4/4PN2/PP3PPP/RNBQKB1R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exd5",
          "aggressive_uci": "e6d5",
          "aggressive_response": "5... exd5 6. Nc3 Nc6 7. Bb5 Bd6 8. O-O O-O 9. dxc5 Bxc5 10. b3 Bg4 11. Bb2 Rc8 12. Rc1 Qd6 13. Be2 Rfd8 14. Nb5 Qe7 15. Bxf6 gxf6 16. Nfd4 Bxe2 17. Nxe2 a6 18. Nbd4 Nxd4 19. Nxd4 Bxd4 20. Qxd4 Qe5 21. Qg4+ Qg5 22. Qxc8 Rxc8 23. Rxc8+ Kg7 24. Rd1 Qe5 25. Rc2 f5 26. Rcd2 f4 27. exf4 Qxf4 28. Rxd5 Qe4 29. R5d2 b5 30. h3 a5 31. Rd5 Qe2 32. R1d2 Qe1+ 33. Kh2 a4 34. bxa4 bxa4 35. R5d4 Qe5+ 36. g3 a3 37. R4d3 Qc5 38. Rf3 Qb4 39. Rd7 Qc4 40. Rxa3 Qe2 41. Kg1 Qe1+ 42. Kg2 Qe4+ 43. Rf3 Qe6 44. Rfxf7+ Kg6 45. Rg7+ Kh6 46. Rxh7+ Kg6 47. Rdg7+ Kf6 48. Rh6+ Kxg7 49. Rxe6 Kf7 50. Re3 Kf6 51. a4 Kf5 52. a5 Kf6 53. a6 Kf5 54. a7 Kf6 55. a8=Q Kf5 56. Qf8+ Kg6 57. Re6+ Kh7 58. Rh6# Qd6 Qe5 Qe6",
          "aggressive_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 472,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nc6",
            "Bb5",
            "Bd6",
            "O-O",
            "O-O",
            "dxc5",
            "Bxc5",
            "b3",
            "Bg4",
            "Bb2",
            "Rc8",
            "Rc1",
            "Qd6",
            "Be2",
            "Rfd8",
            "Nb5",
            "Qe7",
            "Bxf6",
            "gxf6",
            "Nfd4",
            "Bxe2",
            "Nxe2",
            "a6",
            "Nbd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Qxd4",
            "Qe5",
            "Qg4+",
            "Qg5",
            "Qxc8",
            "Rxc8",
            "Rxc8+",
            "Kg7",
            "Rd1",
            "Qe5",
            "Rc2",
            "f5",
            "Rcd2",
            "f4",
            "exf4",
            "Qxf4",
            "Rxd5",
            "Qe4",
            "R5d2",
            "b5",
            "h3",
            "a5",
            "Rd5",
            "Qe2",
            "R1d2",
            "Qe1+",
            "Kh2",
            "a4",
            "bxa4",
            "bxa4",
            "R5d4",
            "Qe5+",
            "g3",
            "a3",
            "R4d3",
            "Qc5",
            "Rf3",
            "Qb4",
            "Rd7",
            "Qc4",
            "Rxa3",
            "Qe2",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe4+",
            "Rf3",
            "Qe6",
            "Rfxf7+",
            "Kg6",
            "Rg7+",
            "Kh6",
            "Rxh7+",
            "Kg6",
            "Rdg7+",
            "Kf6",
            "Rh6+",
            "Kxg7",
            "Rxe6",
            "Kf7",
            "Re3",
            "Kf6",
            "a4",
            "Kf5",
            "a5",
            "Kf6",
            "a6",
            "Kf5",
            "a7",
            "Kf6",
            "a8=Q",
            "Kf5",
            "Qf8+",
            "Kg6",
            "Re6+",
            "Kh7",
            "Rh6#",
            "Qd6",
            "Qe5",
            "Qe6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "exd5",
          "positional_uci": "e6d5",
          "positional_response": "5... exd5 6. Nc3 Nc6 7. Bb5 Bd6 8. O-O O-O 9. dxc5 Bxc5 10. b3 Bg4 11. Bb2 Rc8 12. Rc1 a6 13. Be2 Ba7 14. h3 Bh5 15. Na4 Ne4 16. Nd4 Bxe2 17. Nxe2 Qd6 18. Nac3 Nxc3 19. Bxc3 Rfd8 20. Nd4 Nxd4 21. Bxd4 Rxc1 22. Qxc1 Bxd4 23. exd4 Re8 24. Re1 Rxe1+ 25. Qxe1 Kf8 26. Qc3 Qc6 27. Qxc6 bxc6 28. Kf1 Ke7 29. Ke2 Kd6 30. Kd3 c5 31. dxc5+ Kxc5 32. a3 a5 33. Kc3 d4+ 34. Kd3 Kd5 35. b4 axb4 36. axb4 f5 37. b5 Kc5 38. b6 Kxb6 39. Kxd4 Kc6 40. Ke5 Kd7 41. Kxf5 Ke7 42. Ke5 Kf7 43. f4 Ke7 44. g4 Kf7 45. h4 Ke7 46. h5 Kf7 47. g5 Ke7 48. f5 Kf7 49. Kd6 Kf8 50. Ke6 Ke8 51. f6 gxf6 52. Kxf6 Kf8 53. g6 hxg6 54. hxg6 Kg8 55. g7 Kh7 56. Kf7 Kh6 57. g8=Q Kh5 58. Qg3 Kh6 59. Qg6# Kg8 60. Qg8# Kxg8 61. Kg6 Kh8 62. Kf7 Kh7 63. Kf6 Kh6 64. Kf5 Kh5 65. Kf4 Kh4 66. Kf3 Kh3 67. Kf2 Kh2 68. Kf1 Kh1 69. Kf2 Kh2 70. Kf1 Kh1 71. Kf2 Kh2 72. Kf1 Kh1 73. Kf2 Kh2 74. Kf1 Kh1 75. Kf2 Kh2 76. Kf1 Kh1 77. Kf2 Kh2 78. Kf1 Kh1 79. Kf2 Kh2 80. Kf1 Kh1 81. Kf2 Kh2 82. Kf1 Kh1 83. Kf2 Kh",
          "positional_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Nc6",
            "Bb5",
            "Bd6",
            "O-O",
            "O-O",
            "dxc5",
            "Bxc5",
            "b3",
            "Bg4",
            "Bb2",
            "Rc8",
            "Rc1",
            "a6",
            "Be2",
            "Ba7",
            "h3",
            "Bh5",
            "Na4",
            "Ne4",
            "Nd4",
            "Bxe2",
            "Nxe2",
            "Qd6",
            "Nac3",
            "Nxc3",
            "Bxc3",
            "Rfd8",
            "Nd4",
            "Nxd4",
            "Bxd4",
            "Rxc1",
            "Qxc1",
            "Bxd4",
            "exd4",
            "Re8",
            "Re1",
            "Rxe1+",
            "Qxe1",
            "Kf8",
            "Qc3",
            "Qc6",
            "Qxc6",
            "bxc6",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd6",
            "Kd3",
            "c5",
            "dxc5+",
            "Kxc5",
            "a3",
            "a5",
            "Kc3",
            "d4+",
            "Kd3",
            "Kd5",
            "b4",
            "axb4",
            "axb4",
            "f5",
            "b5",
            "Kc5",
            "b6",
            "Kxb6",
            "Kxd4",
            "Kc6",
            "Ke5",
            "Kd7",
            "Kxf5",
            "Ke7",
            "Ke5",
            "Kf7",
            "f4",
            "Ke7",
            "g4",
            "Kf7",
            "h4",
            "Ke7",
            "h5",
            "Kf7",
            "g5",
            "Ke7",
            "f5",
            "Kf7",
            "Kd6",
            "Kf8",
            "Ke6",
            "Ke8",
            "f6",
            "gxf6",
            "Kxf6",
            "Kf8",
            "g6",
            "hxg6",
            "hxg6",
            "Kg8",
            "g7",
            "Kh7",
            "Kf7",
            "Kh6",
            "g8=Q",
            "Kh5",
            "Qg3",
            "Kh6",
            "Qg6#",
            "Kg8",
            "Qg8#",
            "Kxg8",
            "Kg6",
            "Kh8",
            "Kf7",
            "Kh7",
            "Kf6",
            "Kh6",
            "Kf5",
            "Kh5",
            "Kf4",
            "Kh4",
            "Kf3",
            "Kh3",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2",
            "Kh2",
            "Kf1",
            "Kh1",
            "Kf2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exd5",
          "neutral_uci": "e6d5",
          "neutral_response": "5... exd5 6. Nc3 Nc6 7. Bb5 Bd6 8. O-O O-O 9. dxc5 Bxc5 10. b3 Bg4 11. Bb2 Rc8 12. Rc1 a6 13. Be2 Ba7 14. h3 Bh5 15. Na4 Ne4 16. Nd4 Bxe2 17. Nxe2 Qg5 18. Nac3 Rfd8 19. Nxe4 dxe4 20. Qe1 Ne5 21. Bxe5 Qxe5 22. Qb4 b5 23. Rxc8 Rxc8 24. Rd1 h6 25. Qd2 Bb8 26. g3 Qh5 27. Kg2 Qf3+ 28. Kg1 Be5 29. Nd4 Qh5 30. Kg2 Rd8 31. Qc2 Bxd4 32. Rxd4 Qf3+ 33. Kg1 Rxd4 34. exd4 e3 35. fxe3 Qxg3+ 36. Kf1 Qxh3+ 37. Ke2 Qg2+ 38. Kd3 Qxc2+ 39. Kxc2 h5 40. Kd3 h4 41. Ke4 g5 42. Kf3 f5 43. e4 fxe4+ 44. Kxe4 Kf7 45. Kf3 Ke6 46. Kg4 Kd5 47. a4 Kxd4 48. axb5 axb5 49. Kxg5 h3 50. Kf5 h2 51. Ke6 h1=Q 52. Kd6 Qd5+ 53. Kc7 Qxb3 54. Kb6 Qc4 55. Ka5 b4 56. Ka4 b3+ 57. Ka3 Qc2 58. Kb4 b2 59. Ka5 b1=Q 60. Ka6 Qca2# Qd1 61. Kb5 Qc4+ 62. Kb6 Qdb3+ 63. Ka5 Qca4#",
          "neutral_tokens": {
            "prompt_tokens": 144,
            "completion_tokens": 496,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nc6",
            "Bb5",
            "Bd6",
            "O-O",
            "O-O",
            "dxc5",
            "Bxc5",
            "b3",
            "Bg4",
            "Bb2",
            "Rc8",
            "Rc1",
            "a6",
            "Be2",
            "Ba7",
            "h3",
            "Bh5",
            "Na4",
            "Ne4",
            "Nd4",
            "Bxe2",
            "Nxe2",
            "Qg5",
            "Nac3",
            "Rfd8",
            "Nxe4",
            "dxe4",
            "Qe1",
            "Ne5",
            "Bxe5",
            "Qxe5",
            "Qb4",
            "b5",
            "Rxc8",
            "Rxc8",
            "Rd1",
            "h6",
            "Qd2",
            "Bb8",
            "g3",
            "Qh5",
            "Kg2",
            "Qf3+",
            "Kg1",
            "Be5",
            "Nd4",
            "Qh5",
            "Kg2",
            "Rd8",
            "Qc2",
            "Bxd4",
            "Rxd4",
            "Qf3+",
            "Kg1",
            "Rxd4",
            "exd4",
            "e3",
            "fxe3",
            "Qxg3+",
            "Kf1",
            "Qxh3+",
            "Ke2",
            "Qg2+",
            "Kd3",
            "Qxc2+",
            "Kxc2",
            "h5",
            "Kd3",
            "h4",
            "Ke4",
            "g5",
            "Kf3",
            "f5",
            "e4",
            "fxe4+",
            "Kxe4",
            "Kf7",
            "Kf3",
            "Ke6",
            "Kg4",
            "Kd5",
            "a4",
            "Kxd4",
            "axb5",
            "axb5",
            "Kxg5",
            "h3",
            "Kf5",
            "h2",
            "Ke6",
            "h1=Q",
            "Kd6",
            "Qd5+",
            "Kc7",
            "Qxb3",
            "Kb6",
            "Qc4",
            "Ka5",
            "b4",
            "Ka4",
            "b3+",
            "Ka3",
            "Qc2",
            "Kb4",
            "b2",
            "Ka5",
            "b1=Q",
            "Ka6",
            "Qca2#",
            "Qd1",
            "Kb5",
            "Qc4+",
            "Kb6",
            "Qdb3+",
            "Ka5",
            "Qca4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e6d5",
          "positional_uci": "e6d5",
          "neutral_uci": "e6d5",
          "consensus_move": "e6d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Nc6",
              "Bb5",
              "Bd6",
              "O-O",
              "O-O",
              "dxc5",
              "Bxc5",
              "b3",
              "Bg4",
              "Bb2",
              "Rc8",
              "Rc1",
              "Qd6",
              "Be2",
              "Rfd8",
              "Nb5",
              "Qe7",
              "Bxf6",
              "gxf6",
              "Nfd4",
              "Bxe2",
              "Nxe2",
              "a6",
              "Nbd4",
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Qxd4",
              "Qe5",
              "Qg4+",
              "Qg5",
              "Qxc8",
              "Rxc8",
              "Rxc8+",
              "Kg7",
              "Rd1",
              "Qe5",
              "Rc2",
              "f5",
              "Rcd2",
              "f4",
              "exf4",
              "Qxf4",
              "Rxd5",
              "Qe4",
              "R5d2",
              "b5",
              "h3",
              "a5",
              "Rd5",
              "Qe2",
              "R1d2",
              "Qe1+",
              "Kh2",
              "a4",
              "bxa4",
              "bxa4",
              "R5d4",
              "Qe5+",
              "g3",
              "a3",
              "R4d3",
              "Qc5",
              "Rf3",
              "Qb4",
              "Rd7",
              "Qc4",
              "Rxa3",
              "Qe2",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe4+",
              "Rf3",
              "Qe6",
              "Rfxf7+",
              "Kg6",
              "Rg7+",
              "Kh6",
              "Rxh7+",
              "Kg6",
              "Rdg7+",
              "Kf6",
              "Rh6+",
              "Kxg7",
              "Rxe6",
              "Kf7",
              "Re3",
              "Kf6",
              "a4",
              "Kf5",
              "a5",
              "Kf6",
              "a6",
              "Kf5",
              "a7",
              "Kf6",
              "a8=Q",
              "Kf5",
              "Qf8+",
              "Kg6",
              "Re6+",
              "Kh7",
              "Rh6#",
              "Qd6",
              "Qe5",
              "Qe6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Nc6",
              "Bb5",
              "Bd6",
              "O-O",
              "O-O",
              "dxc5",
              "Bxc5",
              "b3",
              "Bg4",
              "Bb2",
              "Rc8",
              "Rc1",
              "a6",
              "Be2",
              "Ba7",
              "h3",
              "Bh5",
              "Na4",
              "Ne4",
              "Nd4",
              "Bxe2",
              "Nxe2",
              "Qd6",
              "Nac3",
              "Nxc3",
              "Bxc3",
              "Rfd8",
              "Nd4",
              "Nxd4",
              "Bxd4",
              "Rxc1",
              "Qxc1",
              "Bxd4",
              "exd4",
              "Re8",
              "Re1",
              "Rxe1+",
              "Qxe1",
              "Kf8",
              "Qc3",
              "Qc6",
              "Qxc6",
              "bxc6",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd6",
              "Kd3",
              "c5",
              "dxc5+",
              "Kxc5",
              "a3",
              "a5",
              "Kc3",
              "d4+",
              "Kd3",
              "Kd5",
              "b4",
              "axb4",
              "axb4",
              "f5",
              "b5",
              "Kc5",
              "b6",
              "Kxb6",
              "Kxd4",
              "Kc6",
              "Ke5",
              "Kd7",
              "Kxf5",
              "Ke7",
              "Ke5",
              "Kf7",
              "f4",
              "Ke7",
              "g4",
              "Kf7",
              "h4",
              "Ke7",
              "h5",
              "Kf7",
              "g5",
              "Ke7",
              "f5",
              "Kf7",
              "Kd6",
              "Kf8",
              "Ke6",
              "Ke8",
              "f6",
              "gxf6",
              "Kxf6",
              "Kf8",
              "g6",
              "hxg6",
              "hxg6",
              "Kg8",
              "g7",
              "Kh7",
              "Kf7",
              "Kh6",
              "g8=Q",
              "Kh5",
              "Qg3",
              "Kh6",
              "Qg6#",
              "Kg8",
              "Qg8#",
              "Kxg8",
              "Kg6",
              "Kh8",
              "Kf7",
              "Kh7",
              "Kf6",
              "Kh6",
              "Kf5",
              "Kh5",
              "Kf4",
              "Kh4",
              "Kf3",
              "Kh3",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2",
              "Kh2",
              "Kf1",
              "Kh1",
              "Kf2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "Nc6",
              "Bb5",
              "Bd6",
              "O-O",
              "O-O",
              "dxc5",
              "Bxc5",
              "b3",
              "Bg4",
              "Bb2",
              "Rc8",
              "Rc1",
              "a6",
              "Be2",
              "Ba7",
              "h3",
              "Bh5",
              "Na4",
              "Ne4",
              "Nd4",
              "Bxe2",
              "Nxe2",
              "Qg5",
              "Nac3",
              "Rfd8",
              "Nxe4",
              "dxe4",
              "Qe1",
              "Ne5",
              "Bxe5",
              "Qxe5",
              "Qb4",
              "b5",
              "Rxc8",
              "Rxc8",
              "Rd1",
              "h6",
              "Qd2",
              "Bb8",
              "g3",
              "Qh5",
              "Kg2",
              "Qf3+",
              "Kg1",
              "Be5",
              "Nd4",
              "Qh5",
              "Kg2",
              "Rd8",
              "Qc2",
              "Bxd4",
              "Rxd4",
              "Qf3+",
              "Kg1",
              "Rxd4",
              "exd4",
              "e3",
              "fxe3",
              "Qxg3+",
              "Kf1",
              "Qxh3+",
              "Ke2",
              "Qg2+",
              "Kd3",
              "Qxc2+",
              "Kxc2",
              "h5",
              "Kd3",
              "h4",
              "Ke4",
              "g5",
              "Kf3",
              "f5",
              "e4",
              "fxe4+",
              "Kxe4",
              "Kf7",
              "Kf3",
              "Ke6",
              "Kg4",
              "Kd5",
              "a4",
              "Kxd4",
              "axb5",
              "axb5",
              "Kxg5",
              "h3",
              "Kf5",
              "h2",
              "Ke6",
              "h1=Q",
              "Kd6",
              "Qd5+",
              "Kc7",
              "Qxb3",
              "Kb6",
              "Qc4",
              "Ka5",
              "b4",
              "Ka4",
              "b3+",
              "Ka3",
              "Qc2",
              "Kb4",
              "b2",
              "Ka5",
              "b1=Q",
              "Ka6",
              "Qca2#",
              "Qd1",
              "Kb5",
              "Qc4+",
              "Kb6",
              "Qdb3+",
              "Ka5",
              "Qca4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 145,
            "completion_tokens": 472,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 144,
            "completion_tokens": 496,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 434,
          "total_completion_tokens": 1608,
          "total_tokens": 2042
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 145,
            "completion_tokens": 472,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 144,
            "completion_tokens": 496,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pp3ppp/4pn2/2pP4/3P4/4PN2/PP3PPP/RNBQKB1R b KQkq - 0 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "6... Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. a3 O-O 10. b4 Bd6 11. Bb2 Re8 12. Nc3 Be6 13. Rc1 Rc8 14. Nb5 Bb8 15. Nbd4 Ne4 16. Nxc6 bxc6 17. Ba6 Rc7 18. Be5 Rce7 19. Bxb8 Qxb8 20. Rxc6 Bd7 21. Rc1 Qd6 22. Bd3 Bg4 23. h3 Bh5 24. Be2 Bxf3 25. Bxf3 Qe5 26. Qd3 Rd7 27. Rfd1 f5 28. Qd4 Qe6 29. Rc2 Red8 30. Rdc1 Qa6 31. Rc7 Qxa3 32. Ra1 Qb3 33. Raxa7 Rxc7 34. Rxc7 Nf6 35. Qa7 Ne8 36. Rd7 Rxd7 37. Qxd7 Nf6 38. Qe6+ Kf8 39. Qxf5 Qxb4 40. Bxd5 Qe1+ 41. Kh2 Qd2 42. Qc8+ Ke7 43. Qc7+ Ke8 44. Bc6+ Kf8 45. Qb8+ Kf7 46. Qb3+ Kf8 47. Qa3+ Kf7 48. Qa7+ Kf8 49. Qb8+ Kf7 50. Qc7+ Kf8 51. Qf4 Kf7 52. g4 h6 53. h4 Kg8 54. g5 hxg5 55. hxg5 Nh7 56. Qb8+ Nf8 57. Qb3+ Kh8 58. Qf7 Qd6+ 59. f4 Qxc6 60. Qxf8+ Kh7 61. Qf5+ Kh8 62. g6 Qe8 63. Qh5+ Kg8 64. Qh7+ Kf8 65. Qh8+ Ke7 66. Qxg7+ Kd6 67. Qd4+ Kc7 68. Qe5+ Qxe5 69. fxe5 Kd7 70. g7 Ke6 71. g8=Q+ Kxe5 72. Qg4 Kd5 73. Qd4+ Ke6 74. Qc5 Kf6 75. Qd5 Kg6 76. Qe5 Kh6 77. Qf5 Kg7 78. Qe6 Kh7 79. Qf6 Kg8 80.",
          "aggressive_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 640,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Bd6",
            "dxc5",
            "Bxc5",
            "a3",
            "O-O",
            "b4",
            "Bd6",
            "Bb2",
            "Re8",
            "Nc3",
            "Be6",
            "Rc1",
            "Rc8",
            "Nb5",
            "Bb8",
            "Nbd4",
            "Ne4",
            "Nxc6",
            "bxc6",
            "Ba6",
            "Rc7",
            "Be5",
            "Rce7",
            "Bxb8",
            "Qxb8",
            "Rxc6",
            "Bd7",
            "Rc1",
            "Qd6",
            "Bd3",
            "Bg4",
            "h3",
            "Bh5",
            "Be2",
            "Bxf3",
            "Bxf3",
            "Qe5",
            "Qd3",
            "Rd7",
            "Rfd1",
            "f5",
            "Qd4",
            "Qe6",
            "Rc2",
            "Red8",
            "Rdc1",
            "Qa6",
            "Rc7",
            "Qxa3",
            "Ra1",
            "Qb3",
            "Raxa7",
            "Rxc7",
            "Rxc7",
            "Nf6",
            "Qa7",
            "Ne8",
            "Rd7",
            "Rxd7",
            "Qxd7",
            "Nf6",
            "Qe6+",
            "Kf8",
            "Qxf5",
            "Qxb4",
            "Bxd5",
            "Qe1+",
            "Kh2",
            "Qd2",
            "Qc8+",
            "Ke7",
            "Qc7+",
            "Ke8",
            "Bc6+",
            "Kf8",
            "Qb8+",
            "Kf7",
            "Qb3+",
            "Kf8",
            "Qa3+",
            "Kf7",
            "Qa7+",
            "Kf8",
            "Qb8+",
            "Kf7",
            "Qc7+",
            "Kf8",
            "Qf4",
            "Kf7",
            "g4",
            "h6",
            "h4",
            "Kg8",
            "g5",
            "hxg5",
            "hxg5",
            "Nh7",
            "Qb8+",
            "Nf8",
            "Qb3+",
            "Kh8",
            "Qf7",
            "Qd6+",
            "f4",
            "Qxc6",
            "Qxf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "g6",
            "Qe8",
            "Qh5+",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh8+",
            "Ke7",
            "Qxg7+",
            "Kd6",
            "Qd4+",
            "Kc7",
            "Qe5+",
            "Qxe5",
            "fxe5",
            "Kd7",
            "g7",
            "Ke6",
            "g8=Q+",
            "Kxe5",
            "Qg4",
            "Kd5",
            "Qd4+",
            "Ke6",
            "Qc5",
            "Kf6",
            "Qd5",
            "Kg6",
            "Qe5",
            "Kh6",
            "Qf5",
            "Kg7",
            "Qe6",
            "Kh7",
            "Qf6",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "6... Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. Nc3 O-O 10. b3 Be6 11. Bb2 Rc8 12. Rc1 Qe7 13. Nb5 Ne4 14. Nbd4 Nxd4 15. Nxd4 Ba3 16. Bxa3 Qxa3 17. Rxc8 Rxc8 18. Qa1 Nc3 19. Bd3 Qxa2 20. Qxa2 Nxa2 21. Ra1 Nb4 22. Bf1 a6 23. f4 g6 24. Kf2 Nc2 25. Rd1 Nxd4 26. Rxd4 Rc2+ 27. Kf3 h5 28. h3 Kg7 29. g4 hxg4+ 30. hxg4 f5 31. gxf5 gxf5 32. Rb4 b5 33. Rd4 Kf6 34. Rd1 Rb2 35. Ra1 Bc8 36. Ra3 Bb7 37. Kg3 Ke6 38. Bd3 Rd2 39. Bf1 Kd6 40. Bh3 Rd3 41. Kf2 d4 42. Bxf5 Rxe3 43. Bg4 Rc3 44. Bd1 Kc5 45. Ra2 Kb4 46. Rd2 d3 47. Ke3 Bd5 48. Rxd3 Rxd3+ 49. Kxd3 Bxb3 50. Bxb3 Kxb3 51. f5 a5 52. f6 a4 53. f7 a3 54. f8=Q a2 55. Qf6 Ka3 56. Kc2 b4 57. Qa6# Bb7 58. Qa5# Qc7 59. Qa7# Qc3",
          "positional_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 438,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bd6",
            "dxc5",
            "Bxc5",
            "Nc3",
            "O-O",
            "b3",
            "Be6",
            "Bb2",
            "Rc8",
            "Rc1",
            "Qe7",
            "Nb5",
            "Ne4",
            "Nbd4",
            "Nxd4",
            "Nxd4",
            "Ba3",
            "Bxa3",
            "Qxa3",
            "Rxc8",
            "Rxc8",
            "Qa1",
            "Nc3",
            "Bd3",
            "Qxa2",
            "Qxa2",
            "Nxa2",
            "Ra1",
            "Nb4",
            "Bf1",
            "a6",
            "f4",
            "g6",
            "Kf2",
            "Nc2",
            "Rd1",
            "Nxd4",
            "Rxd4",
            "Rc2+",
            "Kf3",
            "h5",
            "h3",
            "Kg7",
            "g4",
            "hxg4+",
            "hxg4",
            "f5",
            "gxf5",
            "gxf5",
            "Rb4",
            "b5",
            "Rd4",
            "Kf6",
            "Rd1",
            "Rb2",
            "Ra1",
            "Bc8",
            "Ra3",
            "Bb7",
            "Kg3",
            "Ke6",
            "Bd3",
            "Rd2",
            "Bf1",
            "Kd6",
            "Bh3",
            "Rd3",
            "Kf2",
            "d4",
            "Bxf5",
            "Rxe3",
            "Bg4",
            "Rc3",
            "Bd1",
            "Kc5",
            "Ra2",
            "Kb4",
            "Rd2",
            "d3",
            "Ke3",
            "Bd5",
            "Rxd3",
            "Rxd3+",
            "Kxd3",
            "Bxb3",
            "Bxb3",
            "Kxb3",
            "f5",
            "a5",
            "f6",
            "a4",
            "f7",
            "a3",
            "f8=Q",
            "a2",
            "Qf6",
            "Ka3",
            "Kc2",
            "b4",
            "Qa6#",
            "Bb7",
            "Qa5#",
            "Qc7",
            "Qa7#",
            "Qc3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "6... Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. a3 O-O 10. b4 Bd6 11. Bb2 Re8 12. Nc3 Be6 13. Rc1 Rc8 14. Nb5 Bb8 15. Nbd4 Ne4 16. Nxc6 bxc6 17. Ba6 Rc7 18. Be5 Rce7 19. Bxb8 Qxb8 20. Rxc6 Bg4 21. Be2 Qb7 22. Rc1 a5 23. bxa5 Qb2 24. Rc2 Qxa3 25. Qxd5 Nc3 26. Qc4 Nxe2+ 27. Qxe2 Qxa5 28. h3 Bh5 29. Rfc1 h6 30. Rc5 Bxf3 31. Qxf3 Qd2 32. Rc8 Qd7 33. Rxe8+ Rxe8 34. Rd1 Qe6 35. Qd5 Qf6 36. Qd7 Re7 37. Qd8+ Kh7 38. Qd3+ g6 39. Qd4 Qe6 40. Qd5 Qf6 41. Qd6 Re6 42. Qd8 Qf5 43. Qd5 Qf6 44. Qd4 Qf5 45. Ra1 Rf6 46. e4 Qf4 47. g3 Qf3 48. Ra8 g5 49. e5 Re6 50. Ra7 Kg7 51. Rd7 Qf5 52. Rd5 Qxh3 53. Rd6 Qf5 54. Rxe6 Qxe6 55. Kg2 Kg6 56. Qe4+ Qf5 57. Qd5 Qe6 58. Qe4+ Qf5 59. Qd5 Qe6 60. Qe4+ Qf5 61. Qd5 Qe6 62. Qe4+ Qf5 63. Qd5 Qe6 64. Qe4+ Qf5 65. Qd5 Qe6 66. Qe4+ Qf5 67. Qd5 Qe6 68. Qe4+ Qf5 69. Qd5 Qe6 70. Qe4+ Qf5 71. Qd5 Qe6 72. Qe4+ Qf5 73. Qd5 Qe6 74. Qe4+ Qf5 75. Qd5 Qe6 76. Qe4+ Qf5 77. Qd5 Qe6 78. Qe4+ Qf5 79. Qd5 Qe6 80.",
          "neutral_tokens": {
            "prompt_tokens": 152,
            "completion_tokens": 640,
            "total_tokens": 792,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Bd6",
            "dxc5",
            "Bxc5",
            "a3",
            "O-O",
            "b4",
            "Bd6",
            "Bb2",
            "Re8",
            "Nc3",
            "Be6",
            "Rc1",
            "Rc8",
            "Nb5",
            "Bb8",
            "Nbd4",
            "Ne4",
            "Nxc6",
            "bxc6",
            "Ba6",
            "Rc7",
            "Be5",
            "Rce7",
            "Bxb8",
            "Qxb8",
            "Rxc6",
            "Bg4",
            "Be2",
            "Qb7",
            "Rc1",
            "a5",
            "bxa5",
            "Qb2",
            "Rc2",
            "Qxa3",
            "Qxd5",
            "Nc3",
            "Qc4",
            "Nxe2+",
            "Qxe2",
            "Qxa5",
            "h3",
            "Bh5",
            "Rfc1",
            "h6",
            "Rc5",
            "Bxf3",
            "Qxf3",
            "Qd2",
            "Rc8",
            "Qd7",
            "Rxe8+",
            "Rxe8",
            "Rd1",
            "Qe6",
            "Qd5",
            "Qf6",
            "Qd7",
            "Re7",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "g6",
            "Qd4",
            "Qe6",
            "Qd5",
            "Qf6",
            "Qd6",
            "Re6",
            "Qd8",
            "Qf5",
            "Qd5",
            "Qf6",
            "Qd4",
            "Qf5",
            "Ra1",
            "Rf6",
            "e4",
            "Qf4",
            "g3",
            "Qf3",
            "Ra8",
            "g5",
            "e5",
            "Re6",
            "Ra7",
            "Kg7",
            "Rd7",
            "Qf5",
            "Rd5",
            "Qxh3",
            "Rd6",
            "Qf5",
            "Rxe6",
            "Qxe6",
            "Kg2",
            "Kg6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6",
            "Qe4+",
            "Qf5",
            "Qd5",
            "Qe6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Bd6",
              "dxc5",
              "Bxc5",
              "a3",
              "O-O",
              "b4",
              "Bd6",
              "Bb2",
              "Re8",
              "Nc3",
              "Be6",
              "Rc1",
              "Rc8",
              "Nb5",
              "Bb8",
              "Nbd4",
              "Ne4",
              "Nxc6",
              "bxc6",
              "Ba6",
              "Rc7",
              "Be5",
              "Rce7",
              "Bxb8",
              "Qxb8",
              "Rxc6",
              "Bd7",
              "Rc1",
              "Qd6",
              "Bd3",
              "Bg4",
              "h3",
              "Bh5",
              "Be2",
              "Bxf3",
              "Bxf3",
              "Qe5",
              "Qd3",
              "Rd7",
              "Rfd1",
              "f5",
              "Qd4",
              "Qe6",
              "Rc2",
              "Red8",
              "Rdc1",
              "Qa6",
              "Rc7",
              "Qxa3",
              "Ra1",
              "Qb3",
              "Raxa7",
              "Rxc7",
              "Rxc7",
              "Nf6",
              "Qa7",
              "Ne8",
              "Rd7",
              "Rxd7",
              "Qxd7",
              "Nf6",
              "Qe6+",
              "Kf8",
              "Qxf5",
              "Qxb4",
              "Bxd5",
              "Qe1+",
              "Kh2",
              "Qd2",
              "Qc8+",
              "Ke7",
              "Qc7+",
              "Ke8",
              "Bc6+",
              "Kf8",
              "Qb8+",
              "Kf7",
              "Qb3+",
              "Kf8",
              "Qa3+",
              "Kf7",
              "Qa7+",
              "Kf8",
              "Qb8+",
              "Kf7",
              "Qc7+",
              "Kf8",
              "Qf4",
              "Kf7",
              "g4",
              "h6",
              "h4",
              "Kg8",
              "g5",
              "hxg5",
              "hxg5",
              "Nh7",
              "Qb8+",
              "Nf8",
              "Qb3+",
              "Kh8",
              "Qf7",
              "Qd6+",
              "f4",
              "Qxc6",
              "Qxf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "g6",
              "Qe8",
              "Qh5+",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh8+",
              "Ke7",
              "Qxg7+",
              "Kd6",
              "Qd4+",
              "Kc7",
              "Qe5+",
              "Qxe5",
              "fxe5",
              "Kd7",
              "g7",
              "Ke6",
              "g8=Q+",
              "Kxe5",
              "Qg4",
              "Kd5",
              "Qd4+",
              "Ke6",
              "Qc5",
              "Kf6",
              "Qd5",
              "Kg6",
              "Qe5",
              "Kh6",
              "Qf5",
              "Kg7",
              "Qe6",
              "Kh7",
              "Qf6",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Bd6",
              "dxc5",
              "Bxc5",
              "Nc3",
              "O-O",
              "b3",
              "Be6",
              "Bb2",
              "Rc8",
              "Rc1",
              "Qe7",
              "Nb5",
              "Ne4",
              "Nbd4",
              "Nxd4",
              "Nxd4",
              "Ba3",
              "Bxa3",
              "Qxa3",
              "Rxc8",
              "Rxc8",
              "Qa1",
              "Nc3",
              "Bd3",
              "Qxa2",
              "Qxa2",
              "Nxa2",
              "Ra1",
              "Nb4",
              "Bf1",
              "a6",
              "f4",
              "g6",
              "Kf2",
              "Nc2",
              "Rd1",
              "Nxd4",
              "Rxd4",
              "Rc2+",
              "Kf3",
              "h5",
              "h3",
              "Kg7",
              "g4",
              "hxg4+",
              "hxg4",
              "f5",
              "gxf5",
              "gxf5",
              "Rb4",
              "b5",
              "Rd4",
              "Kf6",
              "Rd1",
              "Rb2",
              "Ra1",
              "Bc8",
              "Ra3",
              "Bb7",
              "Kg3",
              "Ke6",
              "Bd3",
              "Rd2",
              "Bf1",
              "Kd6",
              "Bh3",
              "Rd3",
              "Kf2",
              "d4",
              "Bxf5",
              "Rxe3",
              "Bg4",
              "Rc3",
              "Bd1",
              "Kc5",
              "Ra2",
              "Kb4",
              "Rd2",
              "d3",
              "Ke3",
              "Bd5",
              "Rxd3",
              "Rxd3+",
              "Kxd3",
              "Bxb3",
              "Bxb3",
              "Kxb3",
              "f5",
              "a5",
              "f6",
              "a4",
              "f7",
              "a3",
              "f8=Q",
              "a2",
              "Qf6",
              "Ka3",
              "Kc2",
              "b4",
              "Qa6#",
              "Bb7",
              "Qa5#",
              "Qc7",
              "Qa7#",
              "Qc3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Bd6",
              "dxc5",
              "Bxc5",
              "a3",
              "O-O",
              "b4",
              "Bd6",
              "Bb2",
              "Re8",
              "Nc3",
              "Be6",
              "Rc1",
              "Rc8",
              "Nb5",
              "Bb8",
              "Nbd4",
              "Ne4",
              "Nxc6",
              "bxc6",
              "Ba6",
              "Rc7",
              "Be5",
              "Rce7",
              "Bxb8",
              "Qxb8",
              "Rxc6",
              "Bg4",
              "Be2",
              "Qb7",
              "Rc1",
              "a5",
              "bxa5",
              "Qb2",
              "Rc2",
              "Qxa3",
              "Qxd5",
              "Nc3",
              "Qc4",
              "Nxe2+",
              "Qxe2",
              "Qxa5",
              "h3",
              "Bh5",
              "Rfc1",
              "h6",
              "Rc5",
              "Bxf3",
              "Qxf3",
              "Qd2",
              "Rc8",
              "Qd7",
              "Rxe8+",
              "Rxe8",
              "Rd1",
              "Qe6",
              "Qd5",
              "Qf6",
              "Qd7",
              "Re7",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "g6",
              "Qd4",
              "Qe6",
              "Qd5",
              "Qf6",
              "Qd6",
              "Re6",
              "Qd8",
              "Qf5",
              "Qd5",
              "Qf6",
              "Qd4",
              "Qf5",
              "Ra1",
              "Rf6",
              "e4",
              "Qf4",
              "g3",
              "Qf3",
              "Ra8",
              "g5",
              "e5",
              "Re6",
              "Ra7",
              "Kg7",
              "Rd7",
              "Qf5",
              "Rd5",
              "Qxh3",
              "Rd6",
              "Qf5",
              "Rxe6",
              "Qxe6",
              "Kg2",
              "Kg6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6",
              "Qe4+",
              "Qf5",
              "Qd5",
              "Qe6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 153,
            "completion_tokens": 640,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 153,
            "completion_tokens": 438,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 152,
            "completion_tokens": 640,
            "total_tokens": 792,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 458,
          "total_completion_tokens": 1718,
          "total_tokens": 2176
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 153,
            "completion_tokens": 640,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 153,
            "completion_tokens": 438,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 152,
            "completion_tokens": 640,
            "total_tokens": 792,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pp3ppp/5n2/2pp4/3P4/4PN2/PP2BPPP/RNBQK2R b KQkq - 1 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd4",
          "aggressive_uci": "c5d4",
          "aggressive_response": "7... cxd4 8. Nxd4 Bd6 9. Nc3 O-O 10. Bf3 Be5 11. Nce2 Ne4 12. b3 Qh4 13. g3 Qf6 14. Bg2 Bg4 15. f3 Nxd4 16. exd4 Nc3 17. Nxc3 Bxd4+ 18. Kh1 Bxc3 19. fxg4 Bxa1 20. Rxf6 Bxf6 21. g5 Be5 22. Qxd5 Rfe8 23. Qxb7 Rad8 24. Bd5 Kh8 25. Kg2 f6 26. gxf6 Bxf6 27. Bf4 Re2+ 28. Kh3 Rxa2 29. b4 Rb2 30. b5 h6 31. Bc7 Rf8 32. Bd6 Rd8 33. Qc6 Rd2 34. Bc7 R8xd5 35. Qe8+ Kh7 36. Qe4+ Kg8 37. Qe8+ Kh7 38. Qe4+ g6 39. Qe6 Bg7 40. b6 axb6 41. Bxb6 Rh5+ 42. Kg4 Rhxh2 43. Be3 Rde2 44. Kf3 h5 45. Qf7 Re1 46. Bd4 Rf1+ 47. Bf2 Rfxf2+ 48. Ke3 Rxf7 49. Ke4 Re2+ 50. Kd3 Re8 51. Kc4 Rd7 52. Kc5 Rc8+ 53. Kb6 Bd4+ 54. Kb5 Rb7+ 55. Ka6 Rb6+ 56. Ka7 Rb1+ 57. Ka6 Ra8# 0-1 d4 d5 Nf3 Nf6 e3 e6 c4 c5 cxd5 exd5 Be2 Nc6 O-O cxd4 Nxd4 Bd6 Nc3 O-O Bf3 Be5 Nce2 Ne4 b3 Qh4 g3 Qf6 Bg2 Bg4 f3 Nxd4 Nxd4 Nc3 Nxc3 Bxd4+ Kh1 Bxa1 fxg4 Bxf6 Bxf6 gxf6 Qxd5 Rfe8 Qxb7 Rad8 Qxa7 Rd2 Qa6 Ree2 Qxf6 Rxh2+ Kg1 Rdg2# 0-1 d4 d5 Nf3 Nf6 e3 e6 c4 c5 cxd5 exd5 Be2 Nc6 O-O cxd4 Nxd4 Bd6 Nc3 O-O Bf3 Be5 Nce2 Ne4 b3 Qh4 g3 Qf6 B",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd4",
            "Bd6",
            "Nc3",
            "O-O",
            "Bf3",
            "Be5",
            "Nce2",
            "Ne4",
            "b3",
            "Qh4",
            "g3",
            "Qf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd6",
          "positional_uci": "f8d6",
          "positional_response": "7... Bd6 8. dxc5 Bxc5 9. a3 O-O 10. b4 Bb6 11. Bb2 Be6 12. Nbd2 Qe7 13. Nb3 Rfd8 14. Nbd4 Nxd4 15. Nxd4 Rac8 16. Rc1 Rxc1 17. Qxc1 Rc8 18. Qa1 Ne4 19. Rc1 Rxc1+ 20. Qxc1 Qc7 21. Qxc7 Bxc7 22. Nb5 Bb6 23. Bd4 Bxd4 24. Nxd4 Kf8 25. Bd3 Nd6 26. Kf1 h6 27. Ke2 Ke7 28. Kd2 Bd7 29. Kc3 a6 30. Nb3 Bb5 31. Bxb5 Nxb5+ 32. Kb2 Kd6 33. a4 Nc7 34. Kc3 Ne6 35. Nd4 Nxd4 36. Kxd4 b6 37. f3 f6 38. g3 g6 39. h3 h5 40. h4 g5 41. f4 g4 42. f5 Kc6 43. e4 dxe4 44. Kxe4 Kd6 45. Kd4 Kc6 46. Kc4 Kd6 47. a5 bxa5 48. bxa5 Kc6 49. Kd4 Kd6 50. Ke4 Kc5 51. Kd3 Kd5 52. Ke3 Ke5 53. Kd3 Kxf5 54. Kd4 Ke6 55. Kc5 f5 56. Kb6 f4 57. gxf4 g3 58. Kxa6 g2 59. Kb7 g1=Q 60. a6 Qb1+ 61. Kc7 Qc2+ 62. Kb7 Qb3+ 63. Kc7 Qc4+ 64. Kb7 Qb5+ 65. Ka7 Kd7 66. f5 Kc7 67. f6 Qb8# 0-1\n7... Bd6 8. dxc5 Bxc5 9. a3 O-O 10. b4 Bb6 11. Bb2 Be6 12. Nbd2 Qe7 13. Nb3 Rfd8 14. Nbd4 Nxd4 15. Nxd4 Rac8 16. Rc1 Rxc1 17. Qxc1 Rc8 18. Qa1 Ne4 19. Rc1 Rxc1+ 20. Qxc1 Qc7 21. Qxc7 Bxc7 22. Nb5 Bb6 23. Bd4 B",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc5",
            "Bxc5",
            "a3",
            "O-O",
            "b4",
            "Bb6",
            "Bb2",
            "Be6",
            "Nbd2",
            "Qe7",
            "Nb3",
            "Rfd8",
            "Nbd4",
            "Nxd4",
            "Nxd4",
            "Rac8",
            "Rc1",
            "Rxc1",
            "Qxc1",
            "Rc8",
            "Qa1",
            "Ne4",
            "Rc1",
            "Rxc1+",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Bxc7",
            "Nb5",
            "Bb6",
            "Bd4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bd6",
          "neutral_uci": "f8d6",
          "neutral_response": "7... Bd6 8. dxc5 Bxc5 9. Nc3 O-O 10. b3 Be6 11. Bb2 Rc8 12. Rc1 Qe7 13. Nb5 Ne4 14. Nbd4 Bg4 15. h3 Bh5 16. Nf5 Qd7 17. Nxg7 Bg6 18. Nh4 d4 19. Bg4 f5 20. Nhxf5 Bxf5 21. Nxf5 Rxf5 22. Bxf5 Qxf5 23. exd4 Bd6 24. d5 Ne7 25. Rxc8+ Nxc8 26. Qd4 Qg6 27. Qh8+ Kf7 28. Qxc8 Nc5 29. Re1 Be7 30. Qc7 Qd6 31. Rxe7+ Qxe7 32. Qf4+ Ke8 33. d6 Qe1+ 34. Kh2 Nd3 35. Qa4+ Kd8 36. Bf6+ Kc8 37. d7+ Kc7 38. d8=Q# 1-0\nBf8 Qd8+ Kc7",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 284,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Ne7",
            "Rxc8+",
            "Nxc8",
            "Qd4",
            "Qg6",
            "Qh8+",
            "Kf7",
            "Qxc8",
            "Nc5",
            "Re1",
            "Be7",
            "Qc7",
            "Qd6",
            "Rxe7+",
            "Qxe7",
            "Qf4+",
            "Ke8",
            "d6",
            "Qe1+",
            "Kh2",
            "Nd3",
            "Qa4+",
            "Kd8",
            "Bf6+",
            "Kc8",
            "d7+",
            "Kc7",
            "d8=Q#",
            "Bf8",
            "Qd8+",
            "Kc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5d4",
          "positional_uci": "f8d6",
          "neutral_uci": "f8d6",
          "consensus_move": "f8d6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd4",
              "Bd6",
              "Nc3",
              "O-O",
              "Bf3",
              "Be5",
              "Nce2",
              "Ne4",
              "b3",
              "Qh4",
              "g3",
              "Qf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "Bxc5",
              "a3",
              "O-O",
              "b4",
              "Bb6",
              "Bb2",
              "Be6",
              "Nbd2",
              "Qe7",
              "Nb3",
              "Rfd8",
              "Nbd4",
              "Nxd4",
              "Nxd4",
              "Rac8",
              "Rc1",
              "Rxc1",
              "Qxc1",
              "Rc8",
              "Qa1",
              "Ne4",
              "Rc1",
              "Rxc1+",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Bxc7",
              "Nb5",
              "Bb6",
              "Bd4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Ne7",
              "Rxc8+",
              "Nxc8",
              "Qd4",
              "Qg6",
              "Qh8+",
              "Kf7",
              "Qxc8",
              "Nc5",
              "Re1",
              "Be7",
              "Qc7",
              "Qd6",
              "Rxe7+",
              "Qxe7",
              "Qf4+",
              "Ke8",
              "d6",
              "Qe1+",
              "Kh2",
              "Nd3",
              "Qa4+",
              "Kd8",
              "Bf6+",
              "Kc8",
              "d7+",
              "Kc7",
              "d8=Q#",
              "Bf8",
              "Qd8+",
              "Kc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 284,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1564,
          "total_tokens": 2046
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 284,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/pp3ppp/2n2n2/2pp4/3P4/4PN2/PP2BPPP/RNBQ1RK1 b kq - 3 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc5",
          "aggressive_uci": "d6c5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. a3 O-O 10. b4 Bb6 11. Bb2 Be6 12. Nc3 d4 13. exd4 Nxd4 14. Nxd4 Qxd4 15. Na4 Qxd1 16. Raxd1 Bb3 17. Nxb6 Bxd1 18. Nxa8 Bxe2 19. Re1 Rxa8 20. Rxe2 Re8 21. Rxe8+ Nxe8 22. f3 Nd6 23. Kf2 Nc4 24. Bc1 f6 25. Ke2 Kf7 26. Kd3 Ne5+ 27. Kd4 Ke6 28. f4 Nc6+ 29. Kc5 Kd7 30. Be3 b6+ 31. Kd5 Ne7+ 32. Ke4 Ke6 33. g4 f5+ 34. gxf5+ Nxf5 35. Bf2 Nd6+ 36. Kd4 Nb5+ 37. Kc4 Nxa3+ 38. Kb3 Nb5 39. Kc4 Nd6+ 40. Kd4 Kf5 41. Bg3 Ne4 42. Kd5 Nxg3 43. hxg3 Kg4 44. Kc6 Kxg3 45. Kb7 Kxf4 46. Kxa7 g5 47. Kxb6 g4 48. Kc7 g3 49. b5 g2 50. b6 g1=Q 51. b7 Qc5+ 52. Kd8 Qb6+ 53. Kc8 Qc6+ 54. Kb8 Ke5 55. Ka7 Qa4+ 56. Kb6 Qb4+ 57. Kc7 Qc5+ 58. Kd8 Qb6+ 59. Kc8 Qc6+ 60. Kb8 Kd6 61. Ka7 Qa4+ 62. Kb6 Qb4+ 63. Ka7 Qa5+ 64. Kb8 Kc6 65. Kc8 Qc7# e4 e5 Nf3 Nc6 d3 d4 Be3 O-O Bd6 dxc5 Bxc5 a3 O-O b4 Bb6 Bb2 Be6 Nc3 d4 exd4 Nxd4 Nxd4 Qxd4 Bxd4 Bxd4 Qxd4 Raxd1 Bb3 Nxb6 Bxd1 Nxa8 Bxe",
          "aggressive_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a3",
            "O-O",
            "b4",
            "Bb6",
            "Bb2",
            "Be6",
            "Nc3",
            "d4",
            "exd4",
            "Nxd4",
            "Nxd4",
            "Qxd4",
            "Bxd4",
            "Bxd4",
            "Qxd4",
            "Raxd1",
            "Bb3",
            "Nxb6",
            "Bxd1",
            "Nxa8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxc5",
          "positional_uci": "d6c5",
          "positional_response": "8... Bxc5 9. a3 O-O 10. b4 Bb6 11. Bb2 Be6 12. Nc3 Rc8 13. Na4 Bc7 14. Nc5\nb6 15. Nxe6 fxe6 16. Rc1 Qd6 17. g3 Ne4 18. Bb5 Ne7 19. Be5 Qd8 20. Bxc7 Rxc7\n21. Rxc7 Qxc7 22. Nd4 Qd6 23. Qg4 Nf5 24. Nxf5 exf5 25. Qe2 Nc3 26. Qd3 Nxb5\n27. Qxb5 d4 28. Rd1 Qe6 29. Rxd4 Rc8 30. Qd5 Qxd5 31. Rxd5 Rc3 32. a4 Rc4\n33. Rd4 Rc1+ 34. Kg2 Ra1 35. b5 Kf7 36. Rd7+ Kf6 37. Rxa7 h6 38. Ra6 Ke5\n39. Rxb6 Rxa4 40. Rb7 g5 41. Rb6 h5 42. Rh6 h4 43. gxh4 gxh4 44. b6 Rb4\n45. Kf3 Kd5 46. h3 Ke5 47. Ke2 Kd5 48. Kd3 Ke5 49. Kc3 Rb1 50. Kc4 Rc1+\n51. Kb5 Rb1+ 52. Kc6 Rc1+ 53. Kd7 Rd1+ 54. Kc7 Rc1+ 55. Rc6 Rb1 56. b7\n1-0\n56... Rxb7+ 57. Kxb7 Ke4 58. Rc4+ Kf3 59. Rxh4 Kxf2",
          "positional_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 435,
            "total_tokens": 604,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a3",
            "O-O",
            "b4",
            "Bb6",
            "Bb2",
            "Be6",
            "Nc3",
            "Rc8",
            "Na4",
            "Bc7",
            "Nc5",
            "b6",
            "Nxe6",
            "fxe6",
            "Rc1",
            "Qd6",
            "g3",
            "Ne4",
            "Bb5",
            "Ne7",
            "Be5",
            "Qd8",
            "Bxc7",
            "Rxc7",
            "Rxc7",
            "Qxc7",
            "Nd4",
            "Qd6",
            "Qg4",
            "Nf5",
            "Nxf5",
            "exf5",
            "Qe2",
            "Nc3",
            "Qd3",
            "Nxb5",
            "Qxb5",
            "d4",
            "Rd1",
            "Qe6",
            "Rxd4",
            "Rc8",
            "Qd5",
            "Qxd5",
            "Rxd5",
            "Rc3",
            "a4",
            "Rc4",
            "Rd4",
            "Rc1+",
            "Kg2",
            "Ra1",
            "b5",
            "Kf7",
            "Rd7+",
            "Kf6",
            "Rxa7",
            "h6",
            "Ra6",
            "Ke5",
            "Rxb6",
            "Rxa4",
            "Rb7",
            "g5",
            "Rb6",
            "h5",
            "Rh6",
            "h4",
            "gxh4",
            "gxh4",
            "b6",
            "Rb4",
            "Kf3",
            "Kd5",
            "h3",
            "Ke5",
            "Ke2",
            "Kd5",
            "Kd3",
            "Ke5",
            "Kc3",
            "Rb1",
            "Kc4",
            "Rc1+",
            "Kb5",
            "Rb1+",
            "Kc6",
            "Rc1+",
            "Kd7",
            "Rd1+",
            "Kc7",
            "Rc1+",
            "Rc6",
            "Rb1",
            "b7",
            "Rxb7+",
            "Kxb7",
            "Ke4",
            "Rc4+",
            "Kf3",
            "Rxh4",
            "Kxf2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxc5",
          "neutral_uci": "d6c5",
          "neutral_response": "8... Bxc5 9. a3 O-O 10. b4 Bb6 11. Bb2 Be6 12. Nc3 d4 13. exd4 Nxd4 14. Nxd4 Qxd4 15. Qxd4 Bxd4 16. Rfd1 Rfd8 17. Bf3 Bb3 18. Rd2 Bxc3 19. Rxd8+ Rxd8 20. Bxc3 b6 21. Rc1 h6 22. Bxf6 gxf6 23. Rc7 a5 24. bxa5 bxa5 25. Rc5 a4 26. g3 Rd3 27. Kg2 Be6 28. Ra5 Rxa3 29. Bc6 Bb3 30. Ra8+ Kg7 31. Ra7 Ra1 32. Be8 a3 33. h4 a2 34. Ra3 Rb1 35. Rxa2 Bxa2 36. Bc6 Rb6 37. Bf3 Rd6 38. Be4 Bd5 39. Bxd5 Rxd5 40. Kf3 Kg6 41. Ke4 Re5+ 42. Kf4 h5 43. f3 Rf5+ 44. Ke4 Ra5 45. Kf4 Ra4+ 46. Ke3 Kf5 47. Kf2 Ra3 48. Ke2 Ke5 49. Kf2 Kd4 50. Ke2 Ra2+ 51. Kf1 Ke3 52. g4 Kxf3 53. gxh5 Ra1# Bb6+ 55. Ke2 Ke4 56. h6 Ra2+ 57. Kd1 Kd3 58. Kc1 Kc3 59. Kb1 Rh2 60. h7 Rxh4 61. h8=Q Rxh8 62. Ka2 Ra8+ 63. Kb1 Ra7 64. Kc1 Ra1# Bb6+ 66. Ke2 Kd4 67. Kf3 Ke5 68. Kg4 Rg1+ 69. Kh5 Kf5 70. Kh6 Rg2 71. Kh7 Ke6 72. Kh6 f5 73. Kh5 f4 74. Kh4 f3 75. Kh3 Rg8 76. Kh2 f2 77. Kh3 f1=Q+ 78. Kh4 Qh1# Bb6+ 80. Kh3 Qh1# Bb6+ 82. Kh3 Qh1# Bb6+ 84. Kh3 Qh1# Bb6+ 86. Kh3 Qh1# Bb6+ 88. Kh3 Qh1# Bb6+ 90. Kh3 Qh",
          "neutral_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 640,
            "total_tokens": 808,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a3",
            "O-O",
            "b4",
            "Bb6",
            "Bb2",
            "Be6",
            "Nc3",
            "d4",
            "exd4",
            "Nxd4",
            "Nxd4",
            "Qxd4",
            "Qxd4",
            "Bxd4",
            "Rfd1",
            "Rfd8",
            "Bf3",
            "Bb3",
            "Rd2",
            "Bxc3",
            "Rxd8+",
            "Rxd8",
            "Bxc3",
            "b6",
            "Rc1",
            "h6",
            "Bxf6",
            "gxf6",
            "Rc7",
            "a5",
            "bxa5",
            "bxa5",
            "Rc5",
            "a4",
            "g3",
            "Rd3",
            "Kg2",
            "Be6",
            "Ra5",
            "Rxa3",
            "Bc6",
            "Bb3",
            "Ra8+",
            "Kg7",
            "Ra7",
            "Ra1",
            "Be8",
            "a3",
            "h4",
            "a2",
            "Ra3",
            "Rb1",
            "Rxa2",
            "Bxa2",
            "Bc6",
            "Rb6",
            "Bf3",
            "Rd6",
            "Be4",
            "Bd5",
            "Bxd5",
            "Rxd5",
            "Kf3",
            "Kg6",
            "Ke4",
            "Re5+",
            "Kf4",
            "h5",
            "f3",
            "Rf5+",
            "Ke4",
            "Ra5",
            "Kf4",
            "Ra4+",
            "Ke3",
            "Kf5",
            "Kf2",
            "Ra3",
            "Ke2",
            "Ke5",
            "Kf2",
            "Kd4",
            "Ke2",
            "Ra2+",
            "Kf1",
            "Ke3",
            "g4",
            "Kxf3",
            "gxh5",
            "Ra1#",
            "Bb6+",
            "Ke2",
            "Ke4",
            "h6",
            "Ra2+",
            "Kd1",
            "Kd3",
            "Kc1",
            "Kc3",
            "Kb1",
            "Rh2",
            "h7",
            "Rxh4",
            "h8=Q",
            "Rxh8",
            "Ka2",
            "Ra8+",
            "Kb1",
            "Ra7",
            "Kc1",
            "Ra1#",
            "Bb6+",
            "Ke2",
            "Kd4",
            "Kf3",
            "Ke5",
            "Kg4",
            "Rg1+",
            "Kh5",
            "Kf5",
            "Kh6",
            "Rg2",
            "Kh7",
            "Ke6",
            "Kh6",
            "f5",
            "Kh5",
            "f4",
            "Kh4",
            "f3",
            "Kh3",
            "Rg8",
            "Kh2",
            "f2",
            "Kh3",
            "f1=Q+",
            "Kh4",
            "Qh1#",
            "Bb6+",
            "Kh3",
            "Qh1#",
            "Bb6+",
            "Kh3",
            "Qh1#",
            "Bb6+",
            "Kh3",
            "Qh1#",
            "Bb6+",
            "Kh3",
            "Qh1#",
            "Bb6+",
            "Kh3",
            "Qh1#",
            "Bb6+",
            "Kh3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d6c5",
          "positional_uci": "d6c5",
          "neutral_uci": "d6c5",
          "consensus_move": "d6c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a3",
              "O-O",
              "b4",
              "Bb6",
              "Bb2",
              "Be6",
              "Nc3",
              "d4",
              "exd4",
              "Nxd4",
              "Nxd4",
              "Qxd4",
              "Bxd4",
              "Bxd4",
              "Qxd4",
              "Raxd1",
              "Bb3",
              "Nxb6",
              "Bxd1",
              "Nxa8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "a3",
              "O-O",
              "b4",
              "Bb6",
              "Bb2",
              "Be6",
              "Nc3",
              "Rc8",
              "Na4",
              "Bc7",
              "Nc5",
              "b6",
              "Nxe6",
              "fxe6",
              "Rc1",
              "Qd6",
              "g3",
              "Ne4",
              "Bb5",
              "Ne7",
              "Be5",
              "Qd8",
              "Bxc7",
              "Rxc7",
              "Rxc7",
              "Qxc7",
              "Nd4",
              "Qd6",
              "Qg4",
              "Nf5",
              "Nxf5",
              "exf5",
              "Qe2",
              "Nc3",
              "Qd3",
              "Nxb5",
              "Qxb5",
              "d4",
              "Rd1",
              "Qe6",
              "Rxd4",
              "Rc8",
              "Qd5",
              "Qxd5",
              "Rxd5",
              "Rc3",
              "a4",
              "Rc4",
              "Rd4",
              "Rc1+",
              "Kg2",
              "Ra1",
              "b5",
              "Kf7",
              "Rd7+",
              "Kf6",
              "Rxa7",
              "h6",
              "Ra6",
              "Ke5",
              "Rxb6",
              "Rxa4",
              "Rb7",
              "g5",
              "Rb6",
              "h5",
              "Rh6",
              "h4",
              "gxh4",
              "gxh4",
              "b6",
              "Rb4",
              "Kf3",
              "Kd5",
              "h3",
              "Ke5",
              "Ke2",
              "Kd5",
              "Kd3",
              "Ke5",
              "Kc3",
              "Rb1",
              "Kc4",
              "Rc1+",
              "Kb5",
              "Rb1+",
              "Kc6",
              "Rc1+",
              "Kd7",
              "Rd1+",
              "Kc7",
              "Rc1+",
              "Rc6",
              "Rb1",
              "b7",
              "Rxb7+",
              "Kxb7",
              "Ke4",
              "Rc4+",
              "Kf3",
              "Rxh4",
              "Kxf2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "a3",
              "O-O",
              "b4",
              "Bb6",
              "Bb2",
              "Be6",
              "Nc3",
              "d4",
              "exd4",
              "Nxd4",
              "Nxd4",
              "Qxd4",
              "Qxd4",
              "Bxd4",
              "Rfd1",
              "Rfd8",
              "Bf3",
              "Bb3",
              "Rd2",
              "Bxc3",
              "Rxd8+",
              "Rxd8",
              "Bxc3",
              "b6",
              "Rc1",
              "h6",
              "Bxf6",
              "gxf6",
              "Rc7",
              "a5",
              "bxa5",
              "bxa5",
              "Rc5",
              "a4",
              "g3",
              "Rd3",
              "Kg2",
              "Be6",
              "Ra5",
              "Rxa3",
              "Bc6",
              "Bb3",
              "Ra8+",
              "Kg7",
              "Ra7",
              "Ra1",
              "Be8",
              "a3",
              "h4",
              "a2",
              "Ra3",
              "Rb1",
              "Rxa2",
              "Bxa2",
              "Bc6",
              "Rb6",
              "Bf3",
              "Rd6",
              "Be4",
              "Bd5",
              "Bxd5",
              "Rxd5",
              "Kf3",
              "Kg6",
              "Ke4",
              "Re5+",
              "Kf4",
              "h5",
              "f3",
              "Rf5+",
              "Ke4",
              "Ra5",
              "Kf4",
              "Ra4+",
              "Ke3",
              "Kf5",
              "Kf2",
              "Ra3",
              "Ke2",
              "Ke5",
              "Kf2",
              "Kd4",
              "Ke2",
              "Ra2+",
              "Kf1",
              "Ke3",
              "g4",
              "Kxf3",
              "gxh5",
              "Ra1#",
              "Bb6+",
              "Ke2",
              "Ke4",
              "h6",
              "Ra2+",
              "Kd1",
              "Kd3",
              "Kc1",
              "Kc3",
              "Kb1",
              "Rh2",
              "h7",
              "Rxh4",
              "h8=Q",
              "Rxh8",
              "Ka2",
              "Ra8+",
              "Kb1",
              "Ra7",
              "Kc1",
              "Ra1#",
              "Bb6+",
              "Ke2",
              "Kd4",
              "Kf3",
              "Ke5",
              "Kg4",
              "Rg1+",
              "Kh5",
              "Kf5",
              "Kh6",
              "Rg2",
              "Kh7",
              "Ke6",
              "Kh6",
              "f5",
              "Kh5",
              "f4",
              "Kh4",
              "f3",
              "Kh3",
              "Rg8",
              "Kh2",
              "f2",
              "Kh3",
              "f1=Q+",
              "Kh4",
              "Qh1#",
              "Bb6+",
              "Kh3",
              "Qh1#",
              "Bb6+",
              "Kh3",
              "Qh1#",
              "Bb6+",
              "Kh3",
              "Qh1#",
              "Bb6+",
              "Kh3",
              "Qh1#",
              "Bb6+",
              "Kh3",
              "Qh1#",
              "Bb6+",
              "Kh3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 169,
            "completion_tokens": 435,
            "total_tokens": 604,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 168,
            "completion_tokens": 640,
            "total_tokens": 808,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 506,
          "total_completion_tokens": 1715,
          "total_tokens": 2221
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 169,
            "completion_tokens": 435,
            "total_tokens": 604,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 168,
            "completion_tokens": 640,
            "total_tokens": 808,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/pp3ppp/2nb1n2/2Pp4/8/4PN2/PP2BPPP/RNBQ1RK1 b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e8g8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Bd4 Nxd4 12. Nxd4 Qb6 13. Nb3 Bxe3 14.\nfxe3 Qxe3+ 15. Kh1 Nf2+ 16. Rxf2 Qxf2 17. Nc3 Be6 18. Qd4 Qxd4 19. Nxd4 Rfe8\n20. Bf3 Rad8 21. Kg1 a6 22. Kf2 Kf8 23. Rd1 Ke7 24. Nde2 Rd6 25. Nxd5+ Bxd5\n26. Rxd5 Rxd5 27. Bxd5 b6 28. Nc3 Rd8 29. Ke3 f6 30. Kd4 Kd6 31. Ne4+ Ke7\n32. b4 Rc8 33. Bc4 b5 34. Bd3 Rc1 35. Nc5 Rg1 36. Be4 Rd1+ 37. Kc3 Rd6\n38. Bb7 f5 39. Bxa6 Rb6 40. Bb7 Kd6 41. Bf3 g5 42. h3 Ke7 43. a4 bxa4\n44. Nxa4 Rb8 45. Nc5 Kd6 46. Kc4 Ke7 47. b5 Kd6 48. Na6 Rb6 49. Nb4 Ke5\n50. Kc5 Rb8 51. Nc6+ Kf4 52. Nxb8 g4 53. hxg4 fxg4 54. Bc6 h5 55. Nd7 h4\n56. b6 h3 57. gxh3 gxh3 58. b7 h2 59. b8=Q+ Ke3 60. Qxh2 Kd3 61. Qg3+ Kc2\n62. Kc4 Kd2 63. Qf2+ Kd1 64. Kc3 Kc1 65. Qc2# Qxc2+ 66. Kxc2 Kxc2 67. Nc5",
          "aggressive_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 558,
            "total_tokens": 735,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc3",
            "Ne4",
            "Bd4",
            "Nxd4",
            "Nxd4",
            "Qb6",
            "Nb3",
            "Bxe3",
            "fxe3",
            "Qxe3+",
            "Kh1",
            "Nf2+",
            "Rxf2",
            "Qxf2",
            "Nc3",
            "Be6",
            "Qd4",
            "Qxd4",
            "Nxd4",
            "Rfe8",
            "Bf3",
            "Rad8",
            "Kg1",
            "a6",
            "Kf2",
            "Kf8",
            "Rd1",
            "Ke7",
            "Nde2",
            "Rd6",
            "Nxd5+",
            "Bxd5",
            "Rxd5",
            "Rxd5",
            "Bxd5",
            "b6",
            "Nc3",
            "Rd8",
            "Ke3",
            "f6",
            "Kd4",
            "Kd6",
            "Ne4+",
            "Ke7",
            "b4",
            "Rc8",
            "Bc4",
            "b5",
            "Bd3",
            "Rc1",
            "Nc5",
            "Rg1",
            "Be4",
            "Rd1+",
            "Kc3",
            "Rd6",
            "Bb7",
            "f5",
            "Bxa6",
            "Rb6",
            "Bb7",
            "Kd6",
            "Bf3",
            "g5",
            "h3",
            "Ke7",
            "a4",
            "bxa4",
            "Nxa4",
            "Rb8",
            "Nc5",
            "Kd6",
            "Kc4",
            "Ke7",
            "b5",
            "Kd6",
            "Na6",
            "Rb6",
            "Nb4",
            "Ke5",
            "Kc5",
            "Rb8",
            "Nc6+",
            "Kf4",
            "Nxb8",
            "g4",
            "hxg4",
            "fxg4",
            "Bc6",
            "h5",
            "Nd7",
            "h4",
            "b6",
            "h3",
            "gxh3",
            "gxh3",
            "b7",
            "h2",
            "b8=Q+",
            "Ke3",
            "Qxh2",
            "Kd3",
            "Qg3+",
            "Kc2",
            "Kc4",
            "Kd2",
            "Qf2+",
            "Kd1",
            "Kc3",
            "Kc1",
            "Qc2#",
            "Qxc2+",
            "Kxc2",
            "Kxc2",
            "Nc5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "9... O-O 10. Bc3 Ne4 11. Bd4 Nxd4 12. Nxd4 Qb6 13. Nb3 Be6 14. Nxc5 Qxc5 15. Nd2 Rac8 16. Nb3 Qb6 17. Qd4 Qxd4 18. Nxd4 Bd7 19. Rfc1 Rxc1+ 20. Rxc1 Rc8 21. Rxc8+ Bxc8 22. f3 Nd6 23. Kf2 Kf8 24. Bd3 h6 25. Ke2 Ke7 26. Kd2 Bd7 27. Kc3 a5 28. b4 axb4+ 29. Kxb4 b6 30. a4 Nb7 31. Bb5 Bxb5 32. Kxb5 Nc5 33. Nf5+ Kf6 34. Nd6 Ke6 35. Nc8 Nd7 36. Nxb6 Ne5 37. a5 Kd6 38. a6 Nc6 39. Nc8+ Kc7 40. Kc5 d4 41. exd4 Nxd4 42. Kxd4 Kxc8 43. Kd5 Kb8 44. Kd6 Ka7 45. Ke7 Kxa6 46. Kxf7 Kb5 47. Kxg7 Kc4 48. Kxh6 Kd3 49. f4 Ke3 50. f5 Kf2 51. f6 Kxg2 52. f7 Kxh2 53. f8=Q Kg3 54. Qf5 Kg2 55. Qf4 Kh3 56. Qg5 Kh2 57. Kg6 Kh3 58. Kf5 Kh2 59. Kf4 Kh3 60. Qg3# 1-0\n9... O-O 10. Bc3 Ne4 11. Bd4 Nxd4 12. Nxd4 Qb6 13. Nb3 Be6 14. Nxc5 Qxc5 15. Nd2 Rac8 16. Nb3 Qb6 17. Qd4 Qxd4 18. Nxd4 Bd7 19. Rfc1 Rxc1+ 20. Rxc1 Rc8 21. Rxc8+ Bxc8 22. f3 Nd6 23. Kf2 Kf8 24. Bd3 h6 25. Ke2 Ke7 26. Kd2 Bd7 27. Kc3 a5 28. b4 axb4+ 29. Kxb4 b6 30. a4 Nb7 31. Bb5 Bxb5 32. Kxb5 Nc5 33. Nf5+ Kf6 34. Nd6",
          "positional_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bc3",
            "Ne4",
            "Bd4",
            "Nxd4",
            "Nxd4",
            "Qb6",
            "Nb3",
            "Be6",
            "Nxc5",
            "Qxc5",
            "Nd2",
            "Rac8",
            "Nb3",
            "Qb6",
            "Qd4",
            "Qxd4",
            "Nxd4",
            "Bd7",
            "Rfc1",
            "Rxc1+",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Bxc8",
            "f3",
            "Nd6",
            "Kf2",
            "Kf8",
            "Bd3",
            "h6",
            "Ke2",
            "Ke7",
            "Kd2",
            "Bd7",
            "Kc3",
            "a5",
            "b4",
            "axb4+",
            "Kxb4",
            "b6",
            "a4",
            "Nb7",
            "Bb5",
            "Bxb5",
            "Kxb5",
            "Nc5",
            "Nf5+",
            "Kf6",
            "Nd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "9... O-O 10. Bc3 Ne4 11. Bd4 Nxd4 12. Nxd4 Qb6 13. Nb3 Be6 14. Nxc5 Qxc5 15. Nd2\nNxd2 16. Qxd2 Rac8 17. Rac1 Qb6 18. b3 Rfd8 19. Rxc8 Rxc8 20. Rc1 Rxc1+ 21. Qxc1\nQc6 22. Qxc6 bxc6 23. Kf1 Kf8 24. Ke1 Ke7 25. Kd2 Kd6 26. Kc3 c5 27. a3 a5 28.\nBd3 h6 29. f4 f6 30. h3 g5 31. fxg5 fxg5 32. b4 axb4+ 33. axb4 cxb4+ 34. Kxb4 Ke5\n35. Kc3 Bf5 36. Bxf5 Kxf5 37. Kd4 Ke6 38. g4 Kd6 39. e4 dxe4 40. Kxe4 Ke6 41.\nKd4 Kd6 42. Ke4 Ke6 43. Kd4 Kd6 44. Ke4 Ke6 45. Kd4 Kd6 46. Ke4 Ke6 47. Kd4 Kd6\n48. Ke4 Ke6 49. Kd4 Kd6 50. Ke4 Ke6 51. Kd4 Kd6 52. Ke4 Ke6 53. Kd4 Kd6 54. Ke4\nKe6 55. Kd4 Kd6 56. Ke4 Ke6 57. Kd4 Kd6 58. Ke4 Ke6 59. Kd4 Kd6 60. Ke4 Ke6 61.\nKd4 Kd6 62. Ke4 Ke6 63. Kd4 Kd6 64. Ke4 Ke6 65. Kd4 Kd6 66. Ke4 Ke6 67. Kd4\nKd6 68. Ke4 Ke6 69. Kd4 Kd6 70. Ke4 Ke6 71. Kd4 Kd6 72. Ke4 Ke6 73. Kd4 Kd6 74.\nKe4 Ke6 75. Kd4 Kd6 76. Ke4 Ke6 77. Kd4 Kd6 78. Ke4 Ke6 79. Kd4 Kd6 80. Ke4\nKe6 81. Kd4 Kd6 82. Ke4 Ke6 83. Kd4 Kd6 84. Ke4 Ke6 85. Kd4 Kd6 86. Ke4 Ke6 87.\nKd",
          "neutral_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 640,
            "total_tokens": 816,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bc3",
            "Ne4",
            "Bd4",
            "Nxd4",
            "Nxd4",
            "Qb6",
            "Nb3",
            "Be6",
            "Nxc5",
            "Qxc5",
            "Nd2",
            "Nxd2",
            "Qxd2",
            "Rac8",
            "Rac1",
            "Qb6",
            "b3",
            "Rfd8",
            "Rxc8",
            "Rxc8",
            "Rc1",
            "Rxc1+",
            "Qxc1",
            "Qc6",
            "Qxc6",
            "bxc6",
            "Kf1",
            "Kf8",
            "Ke1",
            "Ke7",
            "Kd2",
            "Kd6",
            "Kc3",
            "c5",
            "a3",
            "a5",
            "Bd3",
            "h6",
            "f4",
            "f6",
            "h3",
            "g5",
            "fxg5",
            "fxg5",
            "b4",
            "axb4+",
            "axb4",
            "cxb4+",
            "Kxb4",
            "Ke5",
            "Kc3",
            "Bf5",
            "Bxf5",
            "Kxf5",
            "Kd4",
            "Ke6",
            "g4",
            "Kd6",
            "e4",
            "dxe4",
            "Kxe4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6",
            "Kd4",
            "Kd6",
            "Ke4",
            "Ke6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8g8",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc3",
              "Ne4",
              "Bd4",
              "Nxd4",
              "Nxd4",
              "Qb6",
              "Nb3",
              "Bxe3",
              "fxe3",
              "Qxe3+",
              "Kh1",
              "Nf2+",
              "Rxf2",
              "Qxf2",
              "Nc3",
              "Be6",
              "Qd4",
              "Qxd4",
              "Nxd4",
              "Rfe8",
              "Bf3",
              "Rad8",
              "Kg1",
              "a6",
              "Kf2",
              "Kf8",
              "Rd1",
              "Ke7",
              "Nde2",
              "Rd6",
              "Nxd5+",
              "Bxd5",
              "Rxd5",
              "Rxd5",
              "Bxd5",
              "b6",
              "Nc3",
              "Rd8",
              "Ke3",
              "f6",
              "Kd4",
              "Kd6",
              "Ne4+",
              "Ke7",
              "b4",
              "Rc8",
              "Bc4",
              "b5",
              "Bd3",
              "Rc1",
              "Nc5",
              "Rg1",
              "Be4",
              "Rd1+",
              "Kc3",
              "Rd6",
              "Bb7",
              "f5",
              "Bxa6",
              "Rb6",
              "Bb7",
              "Kd6",
              "Bf3",
              "g5",
              "h3",
              "Ke7",
              "a4",
              "bxa4",
              "Nxa4",
              "Rb8",
              "Nc5",
              "Kd6",
              "Kc4",
              "Ke7",
              "b5",
              "Kd6",
              "Na6",
              "Rb6",
              "Nb4",
              "Ke5",
              "Kc5",
              "Rb8",
              "Nc6+",
              "Kf4",
              "Nxb8",
              "g4",
              "hxg4",
              "fxg4",
              "Bc6",
              "h5",
              "Nd7",
              "h4",
              "b6",
              "h3",
              "gxh3",
              "gxh3",
              "b7",
              "h2",
              "b8=Q+",
              "Ke3",
              "Qxh2",
              "Kd3",
              "Qg3+",
              "Kc2",
              "Kc4",
              "Kd2",
              "Qf2+",
              "Kd1",
              "Kc3",
              "Kc1",
              "Qc2#",
              "Qxc2+",
              "Kxc2",
              "Kxc2",
              "Nc5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bc3",
              "Ne4",
              "Bd4",
              "Nxd4",
              "Nxd4",
              "Qb6",
              "Nb3",
              "Be6",
              "Nxc5",
              "Qxc5",
              "Nd2",
              "Rac8",
              "Nb3",
              "Qb6",
              "Qd4",
              "Qxd4",
              "Nxd4",
              "Bd7",
              "Rfc1",
              "Rxc1+",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Bxc8",
              "f3",
              "Nd6",
              "Kf2",
              "Kf8",
              "Bd3",
              "h6",
              "Ke2",
              "Ke7",
              "Kd2",
              "Bd7",
              "Kc3",
              "a5",
              "b4",
              "axb4+",
              "Kxb4",
              "b6",
              "a4",
              "Nb7",
              "Bb5",
              "Bxb5",
              "Kxb5",
              "Nc5",
              "Nf5+",
              "Kf6",
              "Nd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bc3",
              "Ne4",
              "Bd4",
              "Nxd4",
              "Nxd4",
              "Qb6",
              "Nb3",
              "Be6",
              "Nxc5",
              "Qxc5",
              "Nd2",
              "Nxd2",
              "Qxd2",
              "Rac8",
              "Rac1",
              "Qb6",
              "b3",
              "Rfd8",
              "Rxc8",
              "Rxc8",
              "Rc1",
              "Rxc1+",
              "Qxc1",
              "Qc6",
              "Qxc6",
              "bxc6",
              "Kf1",
              "Kf8",
              "Ke1",
              "Ke7",
              "Kd2",
              "Kd6",
              "Kc3",
              "c5",
              "a3",
              "a5",
              "Bd3",
              "h6",
              "f4",
              "f6",
              "h3",
              "g5",
              "fxg5",
              "fxg5",
              "b4",
              "axb4+",
              "axb4",
              "cxb4+",
              "Kxb4",
              "Ke5",
              "Kc3",
              "Bf5",
              "Bxf5",
              "Kxf5",
              "Kd4",
              "Ke6",
              "g4",
              "Kd6",
              "e4",
              "dxe4",
              "Kxe4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6",
              "Kd4",
              "Kd6",
              "Ke4",
              "Ke6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 177,
            "completion_tokens": 558,
            "total_tokens": 735,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 176,
            "completion_tokens": 640,
            "total_tokens": 816,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 530,
          "total_completion_tokens": 1838,
          "total_tokens": 2368
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 177,
            "completion_tokens": 558,
            "total_tokens": 735,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 176,
            "completion_tokens": 640,
            "total_tokens": 816,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/pp3ppp/2n2n2/2bp4/8/4PN2/PP1BBPPP/RN1Q1RK1 b kq - 1 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne4",
          "aggressive_uci": "f6e4",
          "aggressive_response": "10... Ne4 11. Bd4 Nxd4 12. Nxd4 Qb6 13. Nb3 Bxe3 14. fxe3 Qxe3+ 15. Kh1 Nf2+ 16.\nRxf2 Qxf2 17. Nc3 Be6 18. Qd4 Qxd4 19. Nxd4 Rfe8 20. Bf3 Rad8 21. Kg1 a6 22. Kf2\nb5 23. a3 Rd6 24. Rd1 Red8 25. Nc2 d4 26. Ne4 R6d7 27. Nc5 Rd6 28. Nb7 Bb3 29.\nRd2 Bxc2 30. Rxc2 d3 31. Rd2 R6d7 32. Nxd8 Rxd8 33. Ke3 f5 34. Rxd3 Re8+ 35.\nKf4 g6 36. Rd6 a5 37. Rd5 Rb8 38. b4 axb4 39. axb4 Kg7 40. Be2 Re8 41. Bxb5 Re4+\n42. Kf3 Rxb4 43. Be2 Rb3+ 44. Rd3 Rb4 45. g3 Kf6 46. h4 h6 47. Rd6+ Kg7 48.\nBd3 Rb3 49. Ke3 Ra3 50. Kd4 Ra4+ 51. Bc4 Ra3 52. Rd7+ Kf6 53. Rf7# Ne4 Nf6+ Nxf6",
          "aggressive_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 367,
            "total_tokens": 552,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6+",
            "Nxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne4",
          "positional_uci": "f6e4",
          "positional_response": "10... Ne4 11. Bd4 Nxd4 12. Nxd4 Qb6 13. Nb3 Be6 14. Nxc5 Qxc5 15. Nd2 Rac8 16. Nb3\nQb6 17. Qd4 Qxd4 18. Nxd4 Bd7 19. Rfc1 Rxc1+ 20. Rxc1 Rc8 21. Rxc8+ Bxc8 22.\nf3 Nd6 23. Kf2 Kf8 24. Bd3 h6 25. Ke2 Ke7 26. Kd2 Bd7 27. Kc3 a5 28. b4 axb4+\n29. Kxb4 b6 30. a4 Nb7 31. Bb5 Nc5 32. Bxd7 Kxd7 33. Kb5 Kc7 34. Nf5 g6 35.\nNxh6 f5 36. Nf7 Nd3 37. Nh8 Ne5 38. f4 Ng4 39. Nxg6 Nxe3 40. Ne7 Kd6 41. Nc8+\nKc7 42. Nxb6 d4 43. Nc4 Nxg2 44. Kc5 Nxf4 45. Kxd4 Ne6+ 46. Ke5 Nc5 47. a5\nKc6 48. Kxf5 Kb5 49. h4 Kxc4 50. h5 Kb5 51. h6 Kxa5 52. h7 Kb5 53. h8=Q Kc4\n54. Qc8 Kd4 55. Qd8+ Kc4 56. Ke5 Nd3+ 57. Ke4 Nc5+ 58. Ke3 Kb5 59. Qd5 Kb6\n60. Kd4 Nb7 61. Qe6+ Kc7 62. Kd5 Nd8 63. Qe7+ Kc8 64. Kd6 Nb7+ 65. Kc6 Nd8+\n66. Kb6 1-0\nBb5+ Kd8 Qd7#",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 484,
            "total_tokens": 669,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd4",
            "Nxd4",
            "Nxd4",
            "Qb6",
            "Nb3",
            "Be6",
            "Nxc5",
            "Qxc5",
            "Nd2",
            "Rac8",
            "Nb3",
            "Qb6",
            "Qd4",
            "Qxd4",
            "Nxd4",
            "Bd7",
            "Rfc1",
            "Rxc1+",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Bxc8",
            "f3",
            "Nd6",
            "Kf2",
            "Kf8",
            "Bd3",
            "h6",
            "Ke2",
            "Ke7",
            "Kd2",
            "Bd7",
            "Kc3",
            "a5",
            "b4",
            "axb4+",
            "Kxb4",
            "b6",
            "a4",
            "Nb7",
            "Bb5",
            "Nc5",
            "Bxd7",
            "Kxd7",
            "Kb5",
            "Kc7",
            "Nf5",
            "g6",
            "Nxh6",
            "f5",
            "Nf7",
            "Nd3",
            "Nh8",
            "Ne5",
            "f4",
            "Ng4",
            "Nxg6",
            "Nxe3",
            "Ne7",
            "Kd6",
            "Nc8+",
            "Kc7",
            "Nxb6",
            "d4",
            "Nc4",
            "Nxg2",
            "Kc5",
            "Nxf4",
            "Kxd4",
            "Ne6+",
            "Ke5",
            "Nc5",
            "a5",
            "Kc6",
            "Kxf5",
            "Kb5",
            "h4",
            "Kxc4",
            "h5",
            "Kb5",
            "h6",
            "Kxa5",
            "h7",
            "Kb5",
            "h8=Q",
            "Kc4",
            "Qc8",
            "Kd4",
            "Qd8+",
            "Kc4",
            "Ke5",
            "Nd3+",
            "Ke4",
            "Nc5+",
            "Ke3",
            "Kb5",
            "Qd5",
            "Kb6",
            "Kd4",
            "Nb7",
            "Qe6+",
            "Kc7",
            "Kd5",
            "Nd8",
            "Qe7+",
            "Kc8",
            "Kd6",
            "Nb7+",
            "Kc6",
            "Nd8+",
            "Kb6",
            "Bb5+",
            "Kd8",
            "Qd7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne4",
          "neutral_uci": "f6e4",
          "neutral_response": "10... Ne4 11. Bd4 Nxd4 12. Nxd4 Qb6 13. Nb3 Bxe3 14. fxe3 Qxe3+ 15. Kh1 Nf2+ 16.\nRxf2 Qxf2 17. Nc3 Be6 18. Qd4 Qxd4 19. Nxd4 Rfe8 20. Bf3 Rad8 21. Kg1 a6 22. Kf2\nb5 23. a3 g5 24. h3 Kg7 25. Rd1 Kf6 26. Nc6 Rd6 27. Nb4 d4 28. Ne4+ Ke5 29. Nxd6\nKxd6 30. Rxd4+ Kc5 31. Rd2 a5 32. Nd3+ Kc4 33. Ne5+ Kb3 34. Bd1+ Ka2 35. b4+ Kxa3\n36. bxa5 b4 37. a6 b3 38. Nd3 Rd8 39. Ke3 Bc4 40. Nb2 Re8+ 41. Kd4 Bxa6 42. Kc3\nRc8+ 43. Kd4 Rd8+ 44. Kc3 Rc8+ 45. Kd4 Rd8+ 46. Kc3 Rc8+ 47. Kd4 Rd8+ 48. Kc3\nRc8+ 49. Kd4 Rd8+ 50. Kc3 Rc8+ 51. Kd4 Rd8+ 52. Kc3 Rc8+ 53. Kd4 Rd8+ 54. Kc3\nRc8+ 55. Kd4 Rd8+ 56. Kc3 Rc8+ 57. Kd4 Rd8+ 58. Kc3 Rc8+ 59. Kd4 Rd8+ 60. Kc3\nRc8+ 61. Kd4 Rd8+ 62. Kc3 Rc8+ 63. Kd4 Rd8+ 64. Kc3 Rc8+ 65. Kd4 Rd8+ 66. Kc3\nRc8+ 67. Kd4 Rd8+ 68. Kc3 Rc8+ 69. Kd4 Rd8+ 70. Kc3 Rc8+ 71. Kd4 Rd8+ 72. Kc3\nRc8+ 73. Kd4 Rd8+ 74. Kc3 Rc8+ 75. Kd4 Rd8+ 76. Kc3 Rc8+ 77. Kd4 Rd8+ 78. Kc3\nRc8+ 79. Kd4 Rd8+ 80. Kc3 Rc8+ 81. Kd4 Rd8+ 82. Kc",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 640,
            "total_tokens": 824,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke5",
            "Nxd6",
            "Kxd6",
            "Rxd4+",
            "Kc5",
            "Rd2",
            "a5",
            "Nd3+",
            "Kc4",
            "Ne5+",
            "Kb3",
            "Bd1+",
            "Ka2",
            "b4+",
            "Kxa3",
            "bxa5",
            "b4",
            "a6",
            "b3",
            "Nd3",
            "Rd8",
            "Ke3",
            "Bc4",
            "Nb2",
            "Re8+",
            "Kd4",
            "Bxa6",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd4",
            "Rd8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6e4",
          "positional_uci": "f6e4",
          "neutral_uci": "f6e4",
          "consensus_move": "f6e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6+",
              "Nxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd4",
              "Nxd4",
              "Nxd4",
              "Qb6",
              "Nb3",
              "Be6",
              "Nxc5",
              "Qxc5",
              "Nd2",
              "Rac8",
              "Nb3",
              "Qb6",
              "Qd4",
              "Qxd4",
              "Nxd4",
              "Bd7",
              "Rfc1",
              "Rxc1+",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Bxc8",
              "f3",
              "Nd6",
              "Kf2",
              "Kf8",
              "Bd3",
              "h6",
              "Ke2",
              "Ke7",
              "Kd2",
              "Bd7",
              "Kc3",
              "a5",
              "b4",
              "axb4+",
              "Kxb4",
              "b6",
              "a4",
              "Nb7",
              "Bb5",
              "Nc5",
              "Bxd7",
              "Kxd7",
              "Kb5",
              "Kc7",
              "Nf5",
              "g6",
              "Nxh6",
              "f5",
              "Nf7",
              "Nd3",
              "Nh8",
              "Ne5",
              "f4",
              "Ng4",
              "Nxg6",
              "Nxe3",
              "Ne7",
              "Kd6",
              "Nc8+",
              "Kc7",
              "Nxb6",
              "d4",
              "Nc4",
              "Nxg2",
              "Kc5",
              "Nxf4",
              "Kxd4",
              "Ne6+",
              "Ke5",
              "Nc5",
              "a5",
              "Kc6",
              "Kxf5",
              "Kb5",
              "h4",
              "Kxc4",
              "h5",
              "Kb5",
              "h6",
              "Kxa5",
              "h7",
              "Kb5",
              "h8=Q",
              "Kc4",
              "Qc8",
              "Kd4",
              "Qd8+",
              "Kc4",
              "Ke5",
              "Nd3+",
              "Ke4",
              "Nc5+",
              "Ke3",
              "Kb5",
              "Qd5",
              "Kb6",
              "Kd4",
              "Nb7",
              "Qe6+",
              "Kc7",
              "Kd5",
              "Nd8",
              "Qe7+",
              "Kc8",
              "Kd6",
              "Nb7+",
              "Kc6",
              "Nd8+",
              "Kb6",
              "Bb5+",
              "Kd8",
              "Qd7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke5",
              "Nxd6",
              "Kxd6",
              "Rxd4+",
              "Kc5",
              "Rd2",
              "a5",
              "Nd3+",
              "Kc4",
              "Ne5+",
              "Kb3",
              "Bd1+",
              "Ka2",
              "b4+",
              "Kxa3",
              "bxa5",
              "b4",
              "a6",
              "b3",
              "Nd3",
              "Rd8",
              "Ke3",
              "Bc4",
              "Nb2",
              "Re8+",
              "Kd4",
              "Bxa6",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd4",
              "Rd8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 185,
            "completion_tokens": 367,
            "total_tokens": 552,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 484,
            "total_tokens": 669,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 640,
            "total_tokens": 824,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 554,
          "total_completion_tokens": 1491,
          "total_tokens": 2045
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 185,
            "completion_tokens": 367,
            "total_tokens": 552,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 484,
            "total_tokens": 669,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 640,
            "total_tokens": 824,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bq1rk1/pp3ppp/2n2n2/2bp4/8/2B1PN2/PP2BPPP/RN1Q1RK1 b - - 3 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxc3",
          "aggressive_uci": "e4c3",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Nxc3 12. Nxc3 d4 13. Rad1 Qb6 14. Qxb6\nBxb6 15. Nxd4 Nxd4 16. exd4 Rd8 17. d5 Bf5 18. Bd3 Bxd3 19. Rxd3 Rac8 20. Rfd1\nRc4 21. Kf1 Kf8 22. d6 Rc6 23. Ne4 f5 24. Ng5 Kg8 25. Ne6 Rd7 26. b4 Rc2 27.\nR3d2 Rxd2 28. Rxd2 Kf7 29. Nc5 Bxc5 30. bxc5 Ke6 31. Ke2 b6 32. cxb6 axb6 33.\n+ Kd3 Rxd6+ 34. Kc3 Rxd2 35. Kxd2 Kd5 36. Kd3 b5 37. a3 g5 38. Kc3 Kc5 39.\nKd3 Kd5 40. Kc3 Kc5 41. Kd3 Kd5 42. Kc3 Kc5 43. Kd3 Kd5 44. Kc3 Kc5 45.\nKd3 Kd5 46. Kc3 Kc5 47. Kd3 Kd5 48. Kc3 Kc5 49. Kd3 Kd5 50. Kc3 Kc5 51.\nKd3 Kd5 52. Kc3 Kc5 53. Kd3 Kd5 54. Kc3 Kc5 55. Kd3 Kd5 56. Kc3 Kc5 57.\nKd3 Kd5 58. Kc3 Kc5 59. Kd3 Kd5 60. Kc3 Kc5 61. Kd3 Kd5 62. Kc3 Kc5 63.\nKd3 Kd5 64. Kc3 Kc5 65. Kd3 Kd5 66. Kc3 Kc5 67. Kd3 Kd5 68. Kc3 Kc5 69.\nKd3 Kd5 70. Kc3 Kc5 71. Kd3 Kd5 72. Kc3 Kc5 73. Kd3 Kd5 74. Kc3 Kc5 75.",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Rad1",
            "Qb6",
            "Qxb6",
            "Bxb6",
            "Nxd4",
            "Nxd4",
            "exd4",
            "Rd8",
            "d5",
            "Bf5",
            "Bd3",
            "Bxd3",
            "Rxd3",
            "Rac8",
            "Rfd1",
            "Rc4",
            "Kf1",
            "Kf8",
            "d6",
            "Rc6",
            "Ne4",
            "f5",
            "Ng5",
            "Kg8",
            "Ne6",
            "Rd7",
            "b4",
            "Rc2",
            "R3d2",
            "Rxd2",
            "Rxd2",
            "Kf7",
            "Nc5",
            "Bxc5",
            "bxc5",
            "Ke6",
            "Ke2",
            "b6",
            "cxb6",
            "axb6",
            "Kd3",
            "Rxd6+",
            "Kc3",
            "Rxd2",
            "Kxd2",
            "Kd5",
            "Kd3",
            "b5",
            "a3",
            "g5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be6",
          "positional_uci": "c8e6",
          "positional_response": "11... Be6 12. Qxb7 Qd6 13. Qa6 Rab8 14. Qd3 Bf5 15. Qd1 Rfe8 16. Nd4 Nxd4 17.\nBxd4 Bxd4 18. Qxd4 Rb4 19. Qxa7 Rxb2 20. Bf3 Ng5 21. Qd4 Nxf3+ 22. gxf3 Rb4\n23. Qd2 Bh3 24. Rd1 Qg6+ 25. Kh1 Qg2# 26. Ke2 Bf5 27. Qxb4 Rxe3+ 28. Kxe3\nQg5+ 29. Qf4 Qe7+ 30. Kd2 Qb4+ 31. Qxb4 Bc2 32. Qb8# Bb1 33. Qe8# Qxe8\n34. Rxb1 Qa4 35. Rb8# Qxa2+ 36. Kc1# Qc4+ 37. Kb2# Qe2+ 38. Ka1# Qa6+ 39.\nKb2# Qe2+ 40. Ka1# Qa6+ 41. Kb2# Qe2+ 42. Ka1# Qa6+ 43. Kb2# Qe2+ 44.\nKa1# Qa6+ 45. Kb2# Qe2+ 46. Ka1# Qa6+ 47. Kb2# Qe2+ 48. Ka1# Qa6+ 49.\nKb2# Qe2+ 50. Ka1# Qa6+ 51. Kb2# Qe2+ 52. Ka1# Qa6+ 53. Kb2# Qe2+ 54.\nKa1# Qa6+ 55. Kb2# Qe2+ 56. Ka1# Qa6+ 57. Kb2# Qe2+ 58. Ka1# Qa6+ 59.\nKb2# Qe2+ 60. Ka1# Qa6+ 61. Kb2# Qe2+ 62. Ka1# Qa6+ 63. Kb2# Qe2+ 64.\nKa1# Qa6+ 65. Kb2# Qe2+ 66. Ka1# Qa6+ 67. Kb2# Qe2+ 68. Ka1# Qa6+ 69.\nKb2# Qe2+ 70. Ka1# Qa6+ 71. Kb2# Qe2+ 72. Ka1# Qa6+ 73. Kb2# Qe2+ 74.\nKa1# Qa6+ 75. Kb2# Qe2+ 76. Ka1# Qa6",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxb7",
            "Qd6",
            "Qa6",
            "Rab8",
            "Qd3",
            "Bf5",
            "Qd1",
            "Rfe8",
            "Nd4",
            "Nxd4",
            "Bxd4",
            "Bxd4",
            "Qxd4",
            "Rb4",
            "Qxa7",
            "Rxb2",
            "Bf3",
            "Ng5",
            "Qd4",
            "Nxf3+",
            "gxf3",
            "Rb4",
            "Qd2",
            "Bh3",
            "Rd1",
            "Qg6+",
            "Kh1",
            "Qg2#",
            "Ke2",
            "Bf5",
            "Qxb4",
            "Rxe3+",
            "Kxe3",
            "Qg5+",
            "Qf4",
            "Qe7+",
            "Kd2",
            "Qb4+",
            "Qxb4",
            "Bc2",
            "Qb8#",
            "Bb1",
            "Qe8#",
            "Qxe8",
            "Rxb1",
            "Qa4",
            "Rb8#",
            "Qxa2+",
            "Kc1#",
            "Qc4+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6+",
            "Kb2#",
            "Qe2+",
            "Ka1#",
            "Qa6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": "f8e8",
          "neutral_response": "Re8 12. Rd1 Nxf2 13. Kxf2 Rxe3 14.\nKf1 d4 15. Qc4 Qe7 16. Bd2 Be6 17. Qb5 a6 18. Qa4 Rxe2 19. Kxe2 Bb3+ 20. Kd3\nBxa4 21. Re1 Bb5+ 22. Kc2 Nb4+ 23. Kd1 Qd7 24. Bxb4 Bxb4 25. Nbd2 Re8 26.\nRxe8+ Qxe8 27. Nxd4 Qe3 28. N4f3 Qe2+ 29. Kc2 Qd3+ 30. Kd1 Bxd2 31. Nxd2 Qe2+\n32. Kc2 Qxg2 33. Re1 Qxh2 34. Re3 Qc7+ 35. Rc3 Qd7 36. b3 h5 37. a4 Bc6 38.\nNc4 h4 39. Ne5 Qf5+ 40. Nd3 Be4 41. Kd2 Bxd3 42. Rxd3 Qxd3+ 43. Kxd3 h3 44.\nKc4 h2 45. Kc5 h1=Q 46. Kb6 Qc6+ 47. Ka7 b5 48. axb5 axb5 49. b4 Qc7+ 50.\nKa6 Qb8 51. Ka5 Kf8 52. Ka6 Ke7 53. Ka5 Kd6 54. Ka6 Kc6 55. Ka5 Qa8# 0-1 Qb8+ Kc6 Qa8#",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 399,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe8+",
            "Qxe8",
            "Nxd4",
            "Qe3",
            "N4f3",
            "Qe2+",
            "Kc2",
            "Qd3+",
            "Kd1",
            "Bxd2",
            "Nxd2",
            "Qe2+",
            "Kc2",
            "Qxg2",
            "Re1",
            "Qxh2",
            "Re3",
            "Qc7+",
            "Rc3",
            "Qd7",
            "b3",
            "h5",
            "a4",
            "Bc6",
            "Nc4",
            "h4",
            "Ne5",
            "Qf5+",
            "Nd3",
            "Be4",
            "Kd2",
            "Bxd3",
            "Rxd3",
            "Qxd3+",
            "Kxd3",
            "h3",
            "Kc4",
            "h2",
            "Kc5",
            "h1=Q",
            "Kb6",
            "Qc6+",
            "Ka7",
            "b5",
            "axb5",
            "axb5",
            "b4",
            "Qc7+",
            "Ka6",
            "Qb8",
            "Ka5",
            "Kf8",
            "Ka6",
            "Ke7",
            "Ka5",
            "Kd6",
            "Ka6",
            "Kc6",
            "Ka5",
            "Qa8#",
            "Qb8+",
            "Kc6",
            "Qa8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4c3",
          "positional_uci": "c8e6",
          "neutral_uci": "f8e8",
          "consensus_move": "f8e8",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d4",
              "Rad1",
              "Qb6",
              "Qxb6",
              "Bxb6",
              "Nxd4",
              "Nxd4",
              "exd4",
              "Rd8",
              "d5",
              "Bf5",
              "Bd3",
              "Bxd3",
              "Rxd3",
              "Rac8",
              "Rfd1",
              "Rc4",
              "Kf1",
              "Kf8",
              "d6",
              "Rc6",
              "Ne4",
              "f5",
              "Ng5",
              "Kg8",
              "Ne6",
              "Rd7",
              "b4",
              "Rc2",
              "R3d2",
              "Rxd2",
              "Rxd2",
              "Kf7",
              "Nc5",
              "Bxc5",
              "bxc5",
              "Ke6",
              "Ke2",
              "b6",
              "cxb6",
              "axb6",
              "Kd3",
              "Rxd6+",
              "Kc3",
              "Rxd2",
              "Kxd2",
              "Kd5",
              "Kd3",
              "b5",
              "a3",
              "g5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxb7",
              "Qd6",
              "Qa6",
              "Rab8",
              "Qd3",
              "Bf5",
              "Qd1",
              "Rfe8",
              "Nd4",
              "Nxd4",
              "Bxd4",
              "Bxd4",
              "Qxd4",
              "Rb4",
              "Qxa7",
              "Rxb2",
              "Bf3",
              "Ng5",
              "Qd4",
              "Nxf3+",
              "gxf3",
              "Rb4",
              "Qd2",
              "Bh3",
              "Rd1",
              "Qg6+",
              "Kh1",
              "Qg2#",
              "Ke2",
              "Bf5",
              "Qxb4",
              "Rxe3+",
              "Kxe3",
              "Qg5+",
              "Qf4",
              "Qe7+",
              "Kd2",
              "Qb4+",
              "Qxb4",
              "Bc2",
              "Qb8#",
              "Bb1",
              "Qe8#",
              "Qxe8",
              "Rxb1",
              "Qa4",
              "Rb8#",
              "Qxa2+",
              "Kc1#",
              "Qc4+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6+",
              "Kb2#",
              "Qe2+",
              "Ka1#",
              "Qa6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe8+",
              "Qxe8",
              "Nxd4",
              "Qe3",
              "N4f3",
              "Qe2+",
              "Kc2",
              "Qd3+",
              "Kd1",
              "Bxd2",
              "Nxd2",
              "Qe2+",
              "Kc2",
              "Qxg2",
              "Re1",
              "Qxh2",
              "Re3",
              "Qc7+",
              "Rc3",
              "Qd7",
              "b3",
              "h5",
              "a4",
              "Bc6",
              "Nc4",
              "h4",
              "Ne5",
              "Qf5+",
              "Nd3",
              "Be4",
              "Kd2",
              "Bxd3",
              "Rxd3",
              "Qxd3+",
              "Kxd3",
              "h3",
              "Kc4",
              "h2",
              "Kc5",
              "h1=Q",
              "Kb6",
              "Qc6+",
              "Ka7",
              "b5",
              "axb5",
              "axb5",
              "b4",
              "Qc7+",
              "Ka6",
              "Qb8",
              "Ka5",
              "Kf8",
              "Ka6",
              "Ke7",
              "Ka5",
              "Kd6",
              "Ka6",
              "Kc6",
              "Ka5",
              "Qa8#",
              "Qb8+",
              "Kc6",
              "Qa8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 399,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 1679,
          "total_tokens": 2257
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 399,
            "total_tokens": 591,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/pp3ppp/2n5/2bp4/4n3/1QB1PN2/PP2BPPP/RN3RK1 b - - 5 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf2",
          "aggressive_uci": "e4f2",
          "aggressive_response": "12... Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Nxd4 Nxd4 16. Qxf7+ Kh8 17. Bxd4 Bxd4 18. Kh1 Bxf2 19. Rxf2 Be6 20. Qf4 Rf8 21. Qxf8+ Qxf8 22. Rxf8+ Rxf8 23. Nf3 Bxa2 24. Kg1 Bd5 25. Kf2 Bxf3 26. Bxf3 b5 27. Ke3 a5 28. Kd4 Rc8 29. Be4 Rc4+ 30. Kd3 Rxe4 31. Kxe4 Kg8 32. Kd5 Kf7 33. Kc5 b4 34. Kb5 Ke6 35. Kxa5 b3 36. Kb4 Kd5 37. Kxb3 Kc5 38. Kc3 Kb5 39. b4 Kc6 40. Kc4 Kb6 41. b5 Kc7 42. Kc5 Kb7 43. b6 Kc8 44. Kc6 Kb8 45. b7 Ka7 46. Kc7 Ka6 47. b8=Q Ka5 48. Kc6 Ka4 49. Kc5 Ka3 50. Kc4 Ka2 51. Kc3 Ka1 52. Qb2# Nf6 g5 Kf2 g4 Kf3 g3 Kf4 g2 Kf5 g1=Q Kf6 Qg4+ Kf7 Qf5+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6+ Kg8 Qg5+ Kh8 Qf6",
          "aggressive_tokens": {
            "prompt_tokens": 201,
            "completion_tokens": 640,
            "total_tokens": 841,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxf2",
            "Bxe3",
            "Rf1",
            "d4",
            "Nxd4",
            "Nxd4",
            "Qxf7+",
            "Kh8",
            "Bxd4",
            "Bxd4",
            "Kh1",
            "Bxf2",
            "Rxf2",
            "Be6",
            "Qf4",
            "Rf8",
            "Qxf8+",
            "Qxf8",
            "Rxf8+",
            "Rxf8",
            "Nf3",
            "Bxa2",
            "Kg1",
            "Bd5",
            "Kf2",
            "Bxf3",
            "Bxf3",
            "b5",
            "Ke3",
            "a5",
            "Kd4",
            "Rc8",
            "Be4",
            "Rc4+",
            "Kd3",
            "Rxe4",
            "Kxe4",
            "Kg8",
            "Kd5",
            "Kf7",
            "Kc5",
            "b4",
            "Kb5",
            "Ke6",
            "Kxa5",
            "b3",
            "Kb4",
            "Kd5",
            "Kxb3",
            "Kc5",
            "Kc3",
            "Kb5",
            "b4",
            "Kc6",
            "Kc4",
            "Kb6",
            "b5",
            "Kc7",
            "Kc5",
            "Kb7",
            "b6",
            "Kc8",
            "Kc6",
            "Kb8",
            "b7",
            "Ka7",
            "Kc7",
            "Ka6",
            "b8=Q",
            "Ka5",
            "Kc6",
            "Ka4",
            "Kc5",
            "Ka3",
            "Kc4",
            "Ka2",
            "Kc3",
            "Ka1",
            "Qb2#",
            "Nf6",
            "g5",
            "Kf2",
            "g4",
            "Kf3",
            "g3",
            "Kf4",
            "g2",
            "Kf5",
            "g1=Q",
            "Kf6",
            "Qg4+",
            "Kf7",
            "Qf5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxf2",
          "positional_uci": "e4f2",
          "positional_response": "12... Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Nxd4 Nxd4 16. Qxf7+ Kh8 17. Bxd4 Bxd4\n18. Kh1 Bxf2 19. Rxf2 Be6 20. Qf4 Rf8 21. Qe3 Rxf2 22. Qxf2 Qxd2 23. h3 Bc4\n24. Qf3 Qxe2 25. Qxb7 Rf8 26. Qxa7 Bd5 27. Qg1 Rf1 28. Kh2 Rxg1 29. Kxg1 Qxg2#\n30. Kh1 Qxh3+ 31. Kg1 Qg2#",
          "positional_tokens": {
            "prompt_tokens": 201,
            "completion_tokens": 175,
            "total_tokens": 376,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "Bxe3",
            "Rf1",
            "d4",
            "Nxd4",
            "Nxd4",
            "Qxf7+",
            "Kh8",
            "Bxd4",
            "Bxd4",
            "Kh1",
            "Bxf2",
            "Rxf2",
            "Be6",
            "Qf4",
            "Rf8",
            "Qe3",
            "Rxf2",
            "Qxf2",
            "Qxd2",
            "h3",
            "Bc4",
            "Qf3",
            "Qxe2",
            "Qxb7",
            "Rf8",
            "Qxa7",
            "Bd5",
            "Qg1",
            "Rf1",
            "Kh2",
            "Rxg1",
            "Kxg1",
            "Qxg2#",
            "Kh1",
            "Qxh3+",
            "Kg1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxf2",
          "neutral_uci": "e4f2",
          "neutral_response": "12... Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Nxd4 Nxd4 16. Qxf7+ Kh8 17. Bxd4 Bxd4\n18. Kh1 Bxf2 19. Rxf2 Be6 20. Qf4 Rf8 21. Qe3 Rxf2 22. Qxf2 Qxd2 23. h3 Bc4\n24. Qf3 Qxe2 25. Qxb7 Rf8 26. Qxa7 Bd5 27. Qg1 Rf1 28. Kh2 Rxg1 29. Kxg1 Qxg2#\n12... Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Nxd4 Nxd4 16. Qxf7+ Kh8 17. Bxd4 Bxd4\n18. Kh1 Bxf2 19. Rxf2 Be6 20. Qf4 Rf8 21. Qe3 Rxf2 22. Qxf2 Qxd2 23. h3 Bc4\n24. Qf3 Qxe2 25. Qxb7 Rf8 26. Qxa7 Bd5 27. Qg1 Rf1 28. Kh2 Rxg1 29. Kxg1 Qxg2# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 200,
            "completion_tokens": 316,
            "total_tokens": 516,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "Bxe3",
            "Rf1",
            "d4",
            "Nxd4",
            "Nxd4",
            "Qxf7+",
            "Kh8",
            "Bxd4",
            "Bxd4",
            "Kh1",
            "Bxf2",
            "Rxf2",
            "Be6",
            "Qf4",
            "Rf8",
            "Qe3",
            "Rxf2",
            "Qxf2",
            "Qxd2",
            "h3",
            "Bc4",
            "Qf3",
            "Qxe2",
            "Qxb7",
            "Rf8",
            "Qxa7",
            "Bd5",
            "Qg1",
            "Rf1",
            "Kh2",
            "Rxg1",
            "Kxg1",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f2",
          "positional_uci": "e4f2",
          "neutral_uci": "e4f2",
          "consensus_move": "e4f2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf2",
              "Bxe3",
              "Rf1",
              "d4",
              "Nxd4",
              "Nxd4",
              "Qxf7+",
              "Kh8",
              "Bxd4",
              "Bxd4",
              "Kh1",
              "Bxf2",
              "Rxf2",
              "Be6",
              "Qf4",
              "Rf8",
              "Qxf8+",
              "Qxf8",
              "Rxf8+",
              "Rxf8",
              "Nf3",
              "Bxa2",
              "Kg1",
              "Bd5",
              "Kf2",
              "Bxf3",
              "Bxf3",
              "b5",
              "Ke3",
              "a5",
              "Kd4",
              "Rc8",
              "Be4",
              "Rc4+",
              "Kd3",
              "Rxe4",
              "Kxe4",
              "Kg8",
              "Kd5",
              "Kf7",
              "Kc5",
              "b4",
              "Kb5",
              "Ke6",
              "Kxa5",
              "b3",
              "Kb4",
              "Kd5",
              "Kxb3",
              "Kc5",
              "Kc3",
              "Kb5",
              "b4",
              "Kc6",
              "Kc4",
              "Kb6",
              "b5",
              "Kc7",
              "Kc5",
              "Kb7",
              "b6",
              "Kc8",
              "Kc6",
              "Kb8",
              "b7",
              "Ka7",
              "Kc7",
              "Ka6",
              "b8=Q",
              "Ka5",
              "Kc6",
              "Ka4",
              "Kc5",
              "Ka3",
              "Kc4",
              "Ka2",
              "Kc3",
              "Ka1",
              "Qb2#",
              "Nf6",
              "g5",
              "Kf2",
              "g4",
              "Kf3",
              "g3",
              "Kf4",
              "g2",
              "Kf5",
              "g1=Q",
              "Kf6",
              "Qg4+",
              "Kf7",
              "Qf5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf2",
              "Bxe3",
              "Rf1",
              "d4",
              "Nxd4",
              "Nxd4",
              "Qxf7+",
              "Kh8",
              "Bxd4",
              "Bxd4",
              "Kh1",
              "Bxf2",
              "Rxf2",
              "Be6",
              "Qf4",
              "Rf8",
              "Qe3",
              "Rxf2",
              "Qxf2",
              "Qxd2",
              "h3",
              "Bc4",
              "Qf3",
              "Qxe2",
              "Qxb7",
              "Rf8",
              "Qxa7",
              "Bd5",
              "Qg1",
              "Rf1",
              "Kh2",
              "Rxg1",
              "Kxg1",
              "Qxg2#",
              "Kh1",
              "Qxh3+",
              "Kg1",
              "Qg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxf2",
              "Bxe3",
              "Rf1",
              "d4",
              "Nxd4",
              "Nxd4",
              "Qxf7+",
              "Kh8",
              "Bxd4",
              "Bxd4",
              "Kh1",
              "Bxf2",
              "Rxf2",
              "Be6",
              "Qf4",
              "Rf8",
              "Qe3",
              "Rxf2",
              "Qxf2",
              "Qxd2",
              "h3",
              "Bc4",
              "Qf3",
              "Qxe2",
              "Qxb7",
              "Rf8",
              "Qxa7",
              "Bd5",
              "Qg1",
              "Rf1",
              "Kh2",
              "Rxg1",
              "Kxg1",
              "Qxg2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 201,
            "completion_tokens": 640,
            "total_tokens": 841,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 201,
            "completion_tokens": 175,
            "total_tokens": 376,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 200,
            "completion_tokens": 316,
            "total_tokens": 516,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 602,
          "total_completion_tokens": 1131,
          "total_tokens": 1733
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 201,
            "completion_tokens": 640,
            "total_tokens": 841,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 201,
            "completion_tokens": 175,
            "total_tokens": 376,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 200,
            "completion_tokens": 316,
            "total_tokens": 516,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqr1k1/pp3ppp/2n5/2bp4/4n3/1QB1PN2/PP1NBPPP/R4RK1 b - - 7 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxe3",
          "aggressive_uci": "c5e3",
          "aggressive_response": "Repeating the game\n13... Bxe3 14. Rff1 d4 15. Bb4 Be6 16. Qa3 a5 17. Bc5 b6 18. Bb5 bxc5 19. Bxc6\nRc8 20. Bxe8 Qxe8 21. Qxa5 c4 22. Kh1 c3 23. bxc3 dxc3 24. Nb3 c2 25. Nfd2 Qd7\n26. Rac1 Qd3 27. Rf3 Qe2 28. Qe5 Bxd2 29. Qxe2 Bxc1 30. Nxc1 Bg4 31. Qa6 Rd8\n32. Rd3 Re8 33. Re3 Rd8 34. Nd3 Bf5 35. Qb5 Bd7 36. Qb6 Rc8 37. Nc1 Be6 38.\nRxe6 * Repeating the game\n38... fxe6 39. Qxe6+ Kf8 40. Qxc8+ Kf7 41. Qxc2 Kf6 42. Qxh7 g6 43. Qh8+ Kf5\n44. Qf8+ Kg5 45. Qe7+ Kh6 46. Qf6 Kh5 47. h4 Kh6 48. Qh8# * Repeating the game\n48... Qh7 49. Qf8+ Kh5 50. Qf4 Qe7 51. g4+ Kxh4 52. g5+ Kh5 53. Qh2+ Kxg5\n54. Qg3+ Kf6 55. Qh4+ Kf7 56. Qxe7+ Kxe7 57. Kg2 Kd6 58. Kf3 Kc5 59. Ke3 Kb4\n60. Kd2 Ka3 61. Kxc2 g5 62. Kb1 g4 63. Ne2 Kb4 64. Kb2 Ka4 65. a3 Ka5 66. Kb3\nKb5 67. a4+ Ka5 68. Ka3 Ka6 69. Kb4 Kb6 70. a5+ Ka6 71. Ka4 Ka7 72. Kb5 Kb7\n73. a6+ Ka7 74. Ka5 Ka8 75. Kb6 Kb8 76. a7+ Ka8 77. Ka6 g3 78. Nc3 g2 79.\nNb5 g1=Q 80. Nc7# * Repeating the game\n80... Qg6+ 81. Ka5 Qf5+ 82. Ka6 Qf6+ 83. Ka5 Qe5+ 84. Ka6 Qd6+ 85. Ka5 Qc5+",
          "aggressive_tokens": {
            "prompt_tokens": 210,
            "completion_tokens": 640,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rff1",
            "d4",
            "Bb4",
            "Be6",
            "Qa3",
            "a5",
            "Bc5",
            "b6",
            "Bb5",
            "bxc5",
            "Bxc6",
            "Rc8",
            "Bxe8",
            "Qxe8",
            "Qxa5",
            "c4",
            "Kh1",
            "c3",
            "bxc3",
            "dxc3",
            "Nb3",
            "c2",
            "Nfd2",
            "Qd7",
            "Rac1",
            "Qd3",
            "Rf3",
            "Qe2",
            "Qe5",
            "Bxd2",
            "Qxe2",
            "Bxc1",
            "Nxc1",
            "Bg4",
            "Qa6",
            "Rd8",
            "Rd3",
            "Re8",
            "Re3",
            "Rd8",
            "Nd3",
            "Bf5",
            "Qb5",
            "Bd7",
            "Qb6",
            "Rc8",
            "Nc1",
            "Be6",
            "Rxe6",
            "fxe6",
            "Qxe6+",
            "Kf8",
            "Qxc8+",
            "Kf7",
            "Qxc2",
            "Kf6",
            "Qxh7",
            "g6",
            "Qh8+",
            "Kf5",
            "Qf8+",
            "Kg5",
            "Qe7+",
            "Kh6",
            "Qf6",
            "Kh5",
            "h4",
            "Kh6",
            "Qh8#",
            "Qh7",
            "Qf8+",
            "Kh5",
            "Qf4",
            "Qe7",
            "g4+",
            "Kxh4",
            "g5+",
            "Kh5",
            "Qh2+",
            "Kxg5",
            "Qg3+",
            "Kf6",
            "Qh4+",
            "Kf7",
            "Qxe7+",
            "Kxe7",
            "Kg2",
            "Kd6",
            "Kf3",
            "Kc5",
            "Ke3",
            "Kb4",
            "Kd2",
            "Ka3",
            "Kxc2",
            "g5",
            "Kb1",
            "g4",
            "Ne2",
            "Kb4",
            "Kb2",
            "Ka4",
            "a3",
            "Ka5",
            "Kb3",
            "Kb5",
            "a4+",
            "Ka5",
            "Ka3",
            "Ka6",
            "Kb4",
            "Kb6",
            "a5+",
            "Ka6",
            "Ka4",
            "Ka7",
            "Kb5",
            "Kb7",
            "a6+",
            "Ka7",
            "Ka5",
            "Ka8",
            "Kb6",
            "Kb8",
            "a7+",
            "Ka8",
            "Ka6",
            "g3",
            "Nc3",
            "g2",
            "Nb5",
            "g1=Q",
            "Nc7#",
            "Qg6+",
            "Ka5",
            "Qf5+",
            "Ka6",
            "Qf6+",
            "Ka5",
            "Qe5+",
            "Ka6",
            "Qd6+",
            "Ka5",
            "Qc5+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxe3",
          "positional_uci": "c5e3",
          "positional_response": "13...Bxe3 14. Rff1 d4 15. Bb4 Be6 16. Qa3 a5 17. Bc5 b6 18. Bd6 Nb4 19. Bxb4 axb4\n20. Qxb4 d3 21. Bd1 Bc5 22. Qc3 Rc8 23. Kh1 Be3 24. Qb4 Bc5 25. Qc3 Be3 26.\nQb4 Bc5 27. Qc3 Be3 28. Qb4 Bc5 29. Qc3 Be3 30. Qb4 Bc5 31. Qc3 Be3 32. Qb4\nBc5 33. Qc3 Be3 34. Qb4 Bc5 35. Qc3 Be3 36. Qb4 Bc5 37. Qc3 Be3 38. Qb4 Bc5\n39. Qc3 Be3 40. Qb4 Bc5 41. Qc3 Be3 42. Qb4 Bc5 43. Qc3 Be3 44. Qb4 Bc5 45.\nQc3 Be3 46. Qb4 Bc5 47. Qc3 Be3 48. Qb4 Bc5 49. Qc3 Be3 50. Qb4 Bc5 51.\nQc3 Be3 52. Qb4 Bc5 53. Qc3 Be3 54. Qb4 Bc5 55. Qc3 Be3 56. Qb4 Bc5 57.\nQc3 Be3 58. Qb4 Bc5 59. Qc3 Be3 60. Qb4 Bc5 61. Qc3 Be3 62. Qb4 Bc5 63.\nQc3 Be3 64. Qb4 Bc5 65. Qc3 Be3 66. Qb4 Bc5 67. Qc3 Be3 68. Qb4 Bc5 69.\nQc3 Be3 70. Qb4 Bc5 71. Qc3 Be3 72. Qb4 Bc5 73. Qc3 Be3 74. Qb4 Bc5 75.\nQc3 Be3 76. Qb4 Bc5 77. Qc3 Be3 78. Qb4 Bc5 79. Qc3 Be3 80. Qb4 Bc5 81.\nQc3 Be3 82. Qb4 Bc5 83. Qc3 Be3 84. Qb4 Bc5 85. Qc3 Be3 86. Qb4 Bc5 87.\nQc3 Be3 88. Qb4 Bc5",
          "positional_tokens": {
            "prompt_tokens": 210,
            "completion_tokens": 640,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rff1",
            "d4",
            "Bb4",
            "Be6",
            "Qa3",
            "a5",
            "Bc5",
            "b6",
            "Bd6",
            "Nb4",
            "Bxb4",
            "axb4",
            "Qxb4",
            "d3",
            "Bd1",
            "Bc5",
            "Qc3",
            "Rc8",
            "Kh1",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5",
            "Qc3",
            "Be3",
            "Qb4",
            "Bc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxe3",
          "neutral_uci": "c5e3",
          "neutral_response": "Repeating the game\n13... Bxe3 14. Rff1 d4 15. Bb4 Be6 16. Qa3 a5 17. Bc5 b6 18. Bb5 bxc5 19. Bxc6\nRc8 20. Bxe8 Qxe8 21. Qxa5 c4 22. Kh1 c3 23. bxc3 dxc3 24. Nb3 c2 25. Nfd2 Qd7\n26. Rac1 Qd3 27. Rf3 Qe2 28. Qe5 Bxd2 29. Qxe2 Bxc1 30. Nxc1 Bg4 31. Qa6 Rd8\n32. Rd3 Re8 33. h3 Re1+ 34. Kh2 h6 35. hxg4 Rxc1 36. Qc8+ Kh7 37. Qf5+ g6 38.\nQxf7+ Kh8 39. Rd8# Bg8 40. Qxg8# Bg8 41. Qxg8# Bg8",
          "neutral_tokens": {
            "prompt_tokens": 209,
            "completion_tokens": 251,
            "total_tokens": 460,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rff1",
            "d4",
            "Bb4",
            "Be6",
            "Qa3",
            "a5",
            "Bc5",
            "b6",
            "Bb5",
            "bxc5",
            "Bxc6",
            "Rc8",
            "Bxe8",
            "Qxe8",
            "Qxa5",
            "c4",
            "Kh1",
            "c3",
            "bxc3",
            "dxc3",
            "Nb3",
            "c2",
            "Nfd2",
            "Qd7",
            "Rac1",
            "Qd3",
            "Rf3",
            "Qe2",
            "Qe5",
            "Bxd2",
            "Qxe2",
            "Bxc1",
            "Nxc1",
            "Bg4",
            "Qa6",
            "Rd8",
            "Rd3",
            "Re8",
            "h3",
            "Re1+",
            "Kh2",
            "h6",
            "hxg4",
            "Rxc1",
            "Qc8+",
            "Kh7",
            "Qf5+",
            "g6",
            "Qxf7+",
            "Kh8",
            "Rd8#",
            "Bg8",
            "Qxg8#",
            "Bg8",
            "Qxg8#",
            "Bg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5e3",
          "positional_uci": "c5e3",
          "neutral_uci": "c5e3",
          "consensus_move": "c5e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rff1",
              "d4",
              "Bb4",
              "Be6",
              "Qa3",
              "a5",
              "Bc5",
              "b6",
              "Bb5",
              "bxc5",
              "Bxc6",
              "Rc8",
              "Bxe8",
              "Qxe8",
              "Qxa5",
              "c4",
              "Kh1",
              "c3",
              "bxc3",
              "dxc3",
              "Nb3",
              "c2",
              "Nfd2",
              "Qd7",
              "Rac1",
              "Qd3",
              "Rf3",
              "Qe2",
              "Qe5",
              "Bxd2",
              "Qxe2",
              "Bxc1",
              "Nxc1",
              "Bg4",
              "Qa6",
              "Rd8",
              "Rd3",
              "Re8",
              "Re3",
              "Rd8",
              "Nd3",
              "Bf5",
              "Qb5",
              "Bd7",
              "Qb6",
              "Rc8",
              "Nc1",
              "Be6",
              "Rxe6",
              "fxe6",
              "Qxe6+",
              "Kf8",
              "Qxc8+",
              "Kf7",
              "Qxc2",
              "Kf6",
              "Qxh7",
              "g6",
              "Qh8+",
              "Kf5",
              "Qf8+",
              "Kg5",
              "Qe7+",
              "Kh6",
              "Qf6",
              "Kh5",
              "h4",
              "Kh6",
              "Qh8#",
              "Qh7",
              "Qf8+",
              "Kh5",
              "Qf4",
              "Qe7",
              "g4+",
              "Kxh4",
              "g5+",
              "Kh5",
              "Qh2+",
              "Kxg5",
              "Qg3+",
              "Kf6",
              "Qh4+",
              "Kf7",
              "Qxe7+",
              "Kxe7",
              "Kg2",
              "Kd6",
              "Kf3",
              "Kc5",
              "Ke3",
              "Kb4",
              "Kd2",
              "Ka3",
              "Kxc2",
              "g5",
              "Kb1",
              "g4",
              "Ne2",
              "Kb4",
              "Kb2",
              "Ka4",
              "a3",
              "Ka5",
              "Kb3",
              "Kb5",
              "a4+",
              "Ka5",
              "Ka3",
              "Ka6",
              "Kb4",
              "Kb6",
              "a5+",
              "Ka6",
              "Ka4",
              "Ka7",
              "Kb5",
              "Kb7",
              "a6+",
              "Ka7",
              "Ka5",
              "Ka8",
              "Kb6",
              "Kb8",
              "a7+",
              "Ka8",
              "Ka6",
              "g3",
              "Nc3",
              "g2",
              "Nb5",
              "g1=Q",
              "Nc7#",
              "Qg6+",
              "Ka5",
              "Qf5+",
              "Ka6",
              "Qf6+",
              "Ka5",
              "Qe5+",
              "Ka6",
              "Qd6+",
              "Ka5",
              "Qc5+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rff1",
              "d4",
              "Bb4",
              "Be6",
              "Qa3",
              "a5",
              "Bc5",
              "b6",
              "Bd6",
              "Nb4",
              "Bxb4",
              "axb4",
              "Qxb4",
              "d3",
              "Bd1",
              "Bc5",
              "Qc3",
              "Rc8",
              "Kh1",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5",
              "Qc3",
              "Be3",
              "Qb4",
              "Bc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rff1",
              "d4",
              "Bb4",
              "Be6",
              "Qa3",
              "a5",
              "Bc5",
              "b6",
              "Bb5",
              "bxc5",
              "Bxc6",
              "Rc8",
              "Bxe8",
              "Qxe8",
              "Qxa5",
              "c4",
              "Kh1",
              "c3",
              "bxc3",
              "dxc3",
              "Nb3",
              "c2",
              "Nfd2",
              "Qd7",
              "Rac1",
              "Qd3",
              "Rf3",
              "Qe2",
              "Qe5",
              "Bxd2",
              "Qxe2",
              "Bxc1",
              "Nxc1",
              "Bg4",
              "Qa6",
              "Rd8",
              "Rd3",
              "Re8",
              "h3",
              "Re1+",
              "Kh2",
              "h6",
              "hxg4",
              "Rxc1",
              "Qc8+",
              "Kh7",
              "Qf5+",
              "g6",
              "Qxf7+",
              "Kh8",
              "Rd8#",
              "Bg8",
              "Qxg8#",
              "Bg8",
              "Qxg8#",
              "Bg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 210,
            "completion_tokens": 640,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 210,
            "completion_tokens": 640,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 209,
            "completion_tokens": 251,
            "total_tokens": 460,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 629,
          "total_completion_tokens": 1531,
          "total_tokens": 2160
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 210,
            "completion_tokens": 640,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 210,
            "completion_tokens": 640,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 209,
            "completion_tokens": 251,
            "total_tokens": 460,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqr1k1/pp3ppp/2n5/2bp4/8/1QB1PN2/PP1NBRPP/R5K1 b - - 0 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d5d4",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Nxd4 Nxd4 16. Bxd4 Bxd4 17. Bc4 Be6 18. Bxe6 Rxe6 19. Nf3 Bb6 20.\na4 Rc8 21. Qb5 Rc2 22. b4 Rxf2 23. Rxf2 Qd1+ 24. Qf1 Bxf2+ 25. Kxf2 Qxf1+ 26.\nKxf1 Re4 27. b5 Rxa4 28. Ke2 Rb4 29. Kd3 Rxb5 30. Kc4 Rb2 31. g3 Rf2 32. Nd4\nRxh2 33. Nb5 a6 34. Nd6 b5+ 35. Kb4 Rg2 36. Ka5 Rxg3 37. Kxa6 b4 38. Nc4 b3\n39. Kb5 Rc3 40. Nb2 Rc2 41. Na4 b2 42. Nxb2 Rxb2+ 43. Kc4 h5 44. Kd3 h4 45.\nKe3 h3 46. Kf3 h2 47. Kg3 h1=Q 48. Kg4 Qe4+ 49. Kg3 Rg2+ 50. Kh3 Qg4# Qb3 Qb2 Qb1",
          "aggressive_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 422,
            "total_tokens": 641,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Bxd4",
            "Bc4",
            "Be6",
            "Bxe6",
            "Rxe6",
            "Nf3",
            "Bb6",
            "a4",
            "Rc8",
            "Qb5",
            "Rc2",
            "b4",
            "Rxf2",
            "Rxf2",
            "Qd1+",
            "Qf1",
            "Bxf2+",
            "Kxf2",
            "Qxf1+",
            "Kxf1",
            "Re4",
            "b5",
            "Rxa4",
            "Ke2",
            "Rb4",
            "Kd3",
            "Rxb5",
            "Kc4",
            "Rb2",
            "g3",
            "Rf2",
            "Nd4",
            "Rxh2",
            "Nb5",
            "a6",
            "Nd6",
            "b5+",
            "Kb4",
            "Rg2",
            "Ka5",
            "Rxg3",
            "Kxa6",
            "b4",
            "Nc4",
            "b3",
            "Kb5",
            "Rc3",
            "Nb2",
            "Rc2",
            "Na4",
            "b2",
            "Nxb2",
            "Rxb2+",
            "Kc4",
            "h5",
            "Kd3",
            "h4",
            "Ke3",
            "h3",
            "Kf3",
            "h2",
            "Kg3",
            "h1=Q",
            "Kg4",
            "Qe4+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Qg4#",
            "Qb3",
            "Qb2",
            "Qb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 15. Kh1 Bxf2 16. Rxf2 d4 17. Nxd4 Nxd4 18. Qxf7+ Kh8 19. Bxd4 Rg8\n20. Bc4 Be6 21. Bxe6 Qxd4 22. Nf1 Qd6 23. Bb3 Rgf8 24. Qxb7 Rxf2 25. Qxa8+\nRf8 26. Qxf8+ Qxf8 27. Kg1 Qc5+ 28. Kh1 Qf2 29. Bc4 Qxb2 30. h3 Qc1 31. Ba6\nQa1 32. Bc4 Qc3 33. Bb3 Qe1 34. Kg1 Qe2 35. Ng3 Qe3+ 36. Kh2 Qf4 37. Bd5 h5\n38. Bf3 h4 39. Kg1 hxg3 40. Kf1 Qe3 41. Be2 Qf2# 0-1\nRe8 Qxe2 Qxe2",
          "positional_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 249,
            "total_tokens": 468,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe2",
            "Qxe2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Nxf2 Rxf2 Bxf2+ Kxf2 Kxf2 Kxf2",
          "neutral_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 21,
            "total_tokens": 239,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxf2",
            "Rxf2",
            "Bxf2+",
            "Kxf2",
            "Kxf2",
            "Kxf2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d5d4",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "d5d4",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Bxd4",
              "Bc4",
              "Be6",
              "Bxe6",
              "Rxe6",
              "Nf3",
              "Bb6",
              "a4",
              "Rc8",
              "Qb5",
              "Rc2",
              "b4",
              "Rxf2",
              "Rxf2",
              "Qd1+",
              "Qf1",
              "Bxf2+",
              "Kxf2",
              "Qxf1+",
              "Kxf1",
              "Re4",
              "b5",
              "Rxa4",
              "Ke2",
              "Rb4",
              "Kd3",
              "Rxb5",
              "Kc4",
              "Rb2",
              "g3",
              "Rf2",
              "Nd4",
              "Rxh2",
              "Nb5",
              "a6",
              "Nd6",
              "b5+",
              "Kb4",
              "Rg2",
              "Ka5",
              "Rxg3",
              "Kxa6",
              "b4",
              "Nc4",
              "b3",
              "Kb5",
              "Rc3",
              "Nb2",
              "Rc2",
              "Na4",
              "b2",
              "Nxb2",
              "Rxb2+",
              "Kc4",
              "h5",
              "Kd3",
              "h4",
              "Ke3",
              "h3",
              "Kf3",
              "h2",
              "Kg3",
              "h1=Q",
              "Kg4",
              "Qe4+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Qg4#",
              "Qb3",
              "Qb2",
              "Qb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe2",
              "Qxe2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxf2",
              "Rxf2",
              "Bxf2+",
              "Kxf2",
              "Kxf2",
              "Kxf2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 219,
            "completion_tokens": 422,
            "total_tokens": 641,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 219,
            "completion_tokens": 249,
            "total_tokens": 468,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 218,
            "completion_tokens": 21,
            "total_tokens": 239,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 656,
          "total_completion_tokens": 692,
          "total_tokens": 1348
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 219,
            "completion_tokens": 422,
            "total_tokens": 641,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 219,
            "completion_tokens": 249,
            "total_tokens": 468,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 218,
            "completion_tokens": 21,
            "total_tokens": 239,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqr1k1/pp3ppp/2n5/3p4/8/1QB1bN2/PP1NBRPP/5RK1 b - - 1 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxc3",
          "aggressive_uci": "d4c3",
          "aggressive_response": "15... dxc3 16. Bxf7+ Kh8 17. Bxe8 cxd2 18. Qxe3 d1=Q 19. Rxd1 Qxd1+ 20. Rf1 Qd6 21. Ng5 Qd4 22. Rf8# Bg4 23. Nf7# Kg8 24. Nh6# Kh8 25. Nf7# Kg8 26. Nh6# Kh8 27. Nf7# Kg8 28. Nh6# Kh8 29. Nf7# Kg8 30. Nh6# Kh8 31. Nf7# Kg8 32. Nh6# Kh8 33. Nf7# Kg8 34. Nh6# Kh8 35. Nf7# Kg8 36. Nh6# Kh8 37. Nf7# Kg8 38. Nh6# Kh8 39. Nf7# Kg8 40. Nh6# Kh8 41. Nf7# Kg8 42. Nh6# Kh8 43. Nf7# Kg8 44. Nh6# Kh8 45. Nf7# Kg8 46. Nh6# Kh8 47. Nf7# Kg8 48. Nh6# Kh8 49. Nf7# Kg8 50. Nh6# Kh8 51. Nf7# Kg8 52. Nh6# Kh8 53. Nf7# Kg8 54. Nh6# Kh8 55. Nf7# Kg8 56. Nh6# Kh8 57. Nf7# Kg8 58. Nh6# Kh8 59. Nf7# Kg8 60. Nh6# Kh8 61. Nf7# Kg8 62. Nh6# Kh8 63. Nf7# Kg8 64. Nh6# Kh8 65. Nf7# Kg8 66. Nh6# Kh8 67. Nf7# Kg8 68. Nh6# Kh8 69. Nf7# Kg8 70. Nh6# Kh8 71. Nf7# Kg8 72. Nh6# Kh8 73. Nf7# Kg8 74. Nh6# Kh8 75. Nf7# Kg8 76. Nh6# Kh8 77. Nf7# Kg8 78. Nh6# Kh8 79. Nf7# Kg8 80. Nh6# Kh8 81. Nf7# Kg8 82. Nh6# Kh8 83. Nf7# Kg8 84. Nh6# Kh8 85. Nf7# Kg8 86. Nh6# Kh8 87. Nf7# Kg8 88. Nh6# Kh8 89. Nf7# Kg",
          "aggressive_tokens": {
            "prompt_tokens": 227,
            "completion_tokens": 640,
            "total_tokens": 867,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxf7+",
            "Kh8",
            "Bxe8",
            "cxd2",
            "Qxe3",
            "d1=Q",
            "Rxd1",
            "Qxd1+",
            "Rf1",
            "Qd6",
            "Ng5",
            "Qd4",
            "Rf8#",
            "Bg4",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#",
            "Kg8",
            "Nh6#",
            "Kh8",
            "Nf7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be6",
          "positional_uci": "c8e6",
          "positional_response": "15... Be6 16. Bxe6 Rxe6 17. Bb4 Qb6 18. Ba3 Qxb3 19. Nxb3 Bxf2+ 20. Kxf2 Rd8 21. Rd1 d3 22. Rd2 b6 23. Nc1 Ne5 24. Nxe5 Rxe5 25. Rxd3 Rxd3 26. Nxd3 Rd5 27. Ke3 f6 28. Bb4 Kf7 29. Bc3 g5 30. Nb4 Rd6 31. Ke4 Ke6 32. Nd3 f5+ 33. Ke3 f4+ 34. Ke4 h5 35. h4 gxh4 36. Nxf4+ Kf7 37. Nxh5 Rg6 38. Nf4 Rg4 39. Kf5 Rg3 40. Be1 Re3 41. Bxh4 a5 42. Bf2 Re8 43. Bxb6 Rb8 44. Bd4 Rb4 45. Bc3 Rb5+ 46. Ke4 a4 47. a3 Rb8 48. g4 Re8+ 49. Kf5 Rd8 50. g5 Rd1 51. g6+ Kg8 52. g7 Rf1 53. Ke4 Rg1 54. Nd5 Rg4+ 55. Kf5 Rg1 56. Ne7+ Kf7 57. g8=Q+ Rxg8 58. Nxg8 Kxg8 59. Ke5 Kf7 60. Kd5 Ke7 61. Kc5 Kd7 62. Kb5 Kc7 63. Kxa4 Kb6 64. Kb4 Ka6 65. Kc5 Kb7 66. b4 Ka6 67. a4 Kb7 68. b5 Ka7 69. a5 Kb7 70. a6+ Ka7 71. Kc6 Kb8 72. b6 Ka8 73. b7+ Kb8 74. Be5+ Ka7 75. b8=Q+ Kxa6 76. Qb6#",
          "positional_tokens": {
            "prompt_tokens": 227,
            "completion_tokens": 505,
            "total_tokens": 732,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe6",
            "Rxe6",
            "Bb4",
            "Qb6",
            "Ba3",
            "Qxb3",
            "Nxb3",
            "Bxf2+",
            "Kxf2",
            "Rd8",
            "Rd1",
            "d3",
            "Rd2",
            "b6",
            "Nc1",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rxd3",
            "Rxd3",
            "Nxd3",
            "Rd5",
            "Ke3",
            "f6",
            "Bb4",
            "Kf7",
            "Bc3",
            "g5",
            "Nb4",
            "Rd6",
            "Ke4",
            "Ke6",
            "Nd3",
            "f5+",
            "Ke3",
            "f4+",
            "Ke4",
            "h5",
            "h4",
            "gxh4",
            "Nxf4+",
            "Kf7",
            "Nxh5",
            "Rg6",
            "Nf4",
            "Rg4",
            "Kf5",
            "Rg3",
            "Be1",
            "Re3",
            "Bxh4",
            "a5",
            "Bf2",
            "Re8",
            "Bxb6",
            "Rb8",
            "Bd4",
            "Rb4",
            "Bc3",
            "Rb5+",
            "Ke4",
            "a4",
            "a3",
            "Rb8",
            "g4",
            "Re8+",
            "Kf5",
            "Rd8",
            "g5",
            "Rd1",
            "g6+",
            "Kg8",
            "g7",
            "Rf1",
            "Ke4",
            "Rg1",
            "Nd5",
            "Rg4+",
            "Kf5",
            "Rg1",
            "Ne7+",
            "Kf7",
            "g8=Q+",
            "Rxg8",
            "Nxg8",
            "Kxg8",
            "Ke5",
            "Kf7",
            "Kd5",
            "Ke7",
            "Kc5",
            "Kd7",
            "Kb5",
            "Kc7",
            "Kxa4",
            "Kb6",
            "Kb4",
            "Ka6",
            "Kc5",
            "Kb7",
            "b4",
            "Ka6",
            "a4",
            "Kb7",
            "b5",
            "Ka7",
            "a5",
            "Kb7",
            "a6+",
            "Ka7",
            "Kc6",
            "Kb8",
            "b6",
            "Ka8",
            "b7+",
            "Kb8",
            "Be5+",
            "Ka7",
            "b8=Q+",
            "Kxa6",
            "Qb6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxc3",
          "neutral_uci": "d4c3",
          "neutral_response": "15... dxc3 16. Bxf7+ Kh8 17. Bxe8 cxd2 18. Qxe3 d1=Q 19. Rxd1 Qxd1+ 20. Rf1 Qd6 21. Ng5 Qd4 22. Rf8#",
          "neutral_tokens": {
            "prompt_tokens": 226,
            "completion_tokens": 68,
            "total_tokens": 294,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf7+",
            "Kh8",
            "Bxe8",
            "cxd2",
            "Qxe3",
            "d1=Q",
            "Rxd1",
            "Qxd1+",
            "Rf1",
            "Qd6",
            "Ng5",
            "Qd4",
            "Rf8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4c3",
          "positional_uci": "c8e6",
          "neutral_uci": "d4c3",
          "consensus_move": "d4c3",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf7+",
              "Kh8",
              "Bxe8",
              "cxd2",
              "Qxe3",
              "d1=Q",
              "Rxd1",
              "Qxd1+",
              "Rf1",
              "Qd6",
              "Ng5",
              "Qd4",
              "Rf8#",
              "Bg4",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#",
              "Kg8",
              "Nh6#",
              "Kh8",
              "Nf7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxe6",
              "Rxe6",
              "Bb4",
              "Qb6",
              "Ba3",
              "Qxb3",
              "Nxb3",
              "Bxf2+",
              "Kxf2",
              "Rd8",
              "Rd1",
              "d3",
              "Rd2",
              "b6",
              "Nc1",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rxd3",
              "Rxd3",
              "Nxd3",
              "Rd5",
              "Ke3",
              "f6",
              "Bb4",
              "Kf7",
              "Bc3",
              "g5",
              "Nb4",
              "Rd6",
              "Ke4",
              "Ke6",
              "Nd3",
              "f5+",
              "Ke3",
              "f4+",
              "Ke4",
              "h5",
              "h4",
              "gxh4",
              "Nxf4+",
              "Kf7",
              "Nxh5",
              "Rg6",
              "Nf4",
              "Rg4",
              "Kf5",
              "Rg3",
              "Be1",
              "Re3",
              "Bxh4",
              "a5",
              "Bf2",
              "Re8",
              "Bxb6",
              "Rb8",
              "Bd4",
              "Rb4",
              "Bc3",
              "Rb5+",
              "Ke4",
              "a4",
              "a3",
              "Rb8",
              "g4",
              "Re8+",
              "Kf5",
              "Rd8",
              "g5",
              "Rd1",
              "g6+",
              "Kg8",
              "g7",
              "Rf1",
              "Ke4",
              "Rg1",
              "Nd5",
              "Rg4+",
              "Kf5",
              "Rg1",
              "Ne7+",
              "Kf7",
              "g8=Q+",
              "Rxg8",
              "Nxg8",
              "Kxg8",
              "Ke5",
              "Kf7",
              "Kd5",
              "Ke7",
              "Kc5",
              "Kd7",
              "Kb5",
              "Kc7",
              "Kxa4",
              "Kb6",
              "Kb4",
              "Ka6",
              "Kc5",
              "Kb7",
              "b4",
              "Ka6",
              "a4",
              "Kb7",
              "b5",
              "Ka7",
              "a5",
              "Kb7",
              "a6+",
              "Ka7",
              "Kc6",
              "Kb8",
              "b6",
              "Ka8",
              "b7+",
              "Kb8",
              "Be5+",
              "Ka7",
              "b8=Q+",
              "Kxa6",
              "Qb6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxf7+",
              "Kh8",
              "Bxe8",
              "cxd2",
              "Qxe3",
              "d1=Q",
              "Rxd1",
              "Qxd1+",
              "Rf1",
              "Qd6",
              "Ng5",
              "Qd4",
              "Rf8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 227,
            "completion_tokens": 640,
            "total_tokens": 867,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 227,
            "completion_tokens": 505,
            "total_tokens": 732,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 226,
            "completion_tokens": 68,
            "total_tokens": 294,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 680,
          "total_completion_tokens": 1213,
          "total_tokens": 1893
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 227,
            "completion_tokens": 640,
            "total_tokens": 867,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 227,
            "completion_tokens": 505,
            "total_tokens": 732,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 226,
            "completion_tokens": 68,
            "total_tokens": 294,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqr1k1/pp3ppp/2n5/8/2Bp4/1QB1bN2/PP1N1RPP/5RK1 b - - 1 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kh8",
          "aggressive_uci": "g8h8",
          "aggressive_response": "16... Kh8 17. Bxe8 cxd2 18. Qxe3 d1=Q 19. Rxd1 Qxd1+ 20. Rf1 Qd6 21. Ng5 Qe7 22. Qxe7 Nxe7 23. Rf8+ Ng8 24. Nf7# d2 Qxd2 Qe1#",
          "aggressive_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 85,
            "total_tokens": 322,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe8",
            "cxd2",
            "Qxe3",
            "d1=Q",
            "Rxd1",
            "Qxd1+",
            "Rf1",
            "Qd6",
            "Ng5",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rf8+",
            "Ng8",
            "Nf7#",
            "d2",
            "Qxd2",
            "Qe1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh8",
          "positional_uci": "g8h8",
          "positional_response": "16... Kh8 17. Bxe8 cxd2 18. Bxc6 Bxf2+ 19. Kxf2 bxc6 20. Rd1 Bg4 21. Rxd2 Qf6 22.\nQc3 Qxc3 23. bxc3 Bxf3 24. Kxf3 Kg8 25. Rd7 a5 26. Rc7 Ra6 27. Ke4 Rb6 28. Ra7 Rb2\n29. Rxa5 Rxg2 30. h4 Rg4+ 31. Ke5 Rxh4 32. Kd6 Rc4 33. Rc5 Ra4 34. Rxc6 Rxa2 35.\nc4 h5 36. c5 h4 37. Rc8+ Kh7 38. c6 h3 39. c7 Rc2 40. Rb8 h2 41. Rb1 g5 42. Rh1\nKg6 43. Rxh2 Rxh2 44. c8=Q Rd2+ 45. Ke5 Re2+ 46. Kd4 Rd2+ 47. Ke3 Rd6 48. Qe8+\nKf6 49. Qf8+ Ke6 50. Ke4 Kd7 51. Qf5+ Kc6 52. Qxg5 Re6+ 53. Kd4 Rd6+ 54. Kc4\nKd7 55. Qg7+ Kc6 56. Qa7 Rd7 57. Qa6+ Kc7 58. Kc5 Kd8 59. Qf6+ Kc7 60. Qe5+\nKd8 61. Kc6 Re7 62. Qb8# Kd7 63. Qd6+ Ke8 64. Qg6+ Kd8 65. Qg8+ Re8 66. Qd5+\nKe7 67. Qd6+ Kf7 68. Kd7 Rg8 69. Qe6+ Kg7 70. Ke7 Kh7 71. Kf7 Rg7+ 72. Kf8\nRg6 73. Qf5 Kh6 74. Kf7 Rg7+ 75. Kf6 Rg8 76. Qh3# g4 77. Qh4# g3 78. Qh3# g2\n79. Qh4# g1=Q 80. Qh3# g5 81. Qh4# g4 82. Qh3# g3 83. Qh4# g2 84. Qh3# g1=Q\n85. Qh4# g5 86. Qh3# g4 87. Qh4# g3 88. Qh3# g",
          "positional_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxe8",
            "cxd2",
            "Bxc6",
            "Bxf2+",
            "Kxf2",
            "bxc6",
            "Rd1",
            "Bg4",
            "Rxd2",
            "Qf6",
            "Qc3",
            "Qxc3",
            "bxc3",
            "Bxf3",
            "Kxf3",
            "Kg8",
            "Rd7",
            "a5",
            "Rc7",
            "Ra6",
            "Ke4",
            "Rb6",
            "Ra7",
            "Rb2",
            "Rxa5",
            "Rxg2",
            "h4",
            "Rg4+",
            "Ke5",
            "Rxh4",
            "Kd6",
            "Rc4",
            "Rc5",
            "Ra4",
            "Rxc6",
            "Rxa2",
            "c4",
            "h5",
            "c5",
            "h4",
            "Rc8+",
            "Kh7",
            "c6",
            "h3",
            "c7",
            "Rc2",
            "Rb8",
            "h2",
            "Rb1",
            "g5",
            "Rh1",
            "Kg6",
            "Rxh2",
            "Rxh2",
            "c8=Q",
            "Rd2+",
            "Ke5",
            "Re2+",
            "Kd4",
            "Rd2+",
            "Ke3",
            "Rd6",
            "Qe8+",
            "Kf6",
            "Qf8+",
            "Ke6",
            "Ke4",
            "Kd7",
            "Qf5+",
            "Kc6",
            "Qxg5",
            "Re6+",
            "Kd4",
            "Rd6+",
            "Kc4",
            "Kd7",
            "Qg7+",
            "Kc6",
            "Qa7",
            "Rd7",
            "Qa6+",
            "Kc7",
            "Kc5",
            "Kd8",
            "Qf6+",
            "Kc7",
            "Qe5+",
            "Kd8",
            "Kc6",
            "Re7",
            "Qb8#",
            "Kd7",
            "Qd6+",
            "Ke8",
            "Qg6+",
            "Kd8",
            "Qg8+",
            "Re8",
            "Qd5+",
            "Ke7",
            "Qd6+",
            "Kf7",
            "Kd7",
            "Rg8",
            "Qe6+",
            "Kg7",
            "Ke7",
            "Kh7",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg6",
            "Qf5",
            "Kh6",
            "Kf7",
            "Rg7+",
            "Kf6",
            "Rg8",
            "Qh3#",
            "g4",
            "Qh4#",
            "g3",
            "Qh3#",
            "g2",
            "Qh4#",
            "g1=Q",
            "Qh3#",
            "g5",
            "Qh4#",
            "g4",
            "Qh3#",
            "g3",
            "Qh4#",
            "g2",
            "Qh3#",
            "g1=Q",
            "Qh4#",
            "g5",
            "Qh3#",
            "g4",
            "Qh4#",
            "g3",
            "Qh3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kh8",
          "neutral_uci": "g8h8",
          "neutral_response": "16... Kh8 17. Bxe8 cxd2 18. Qxe3 d1=Q 19. Rxd1 Qxd1+ 20. Rf1 Qd6 21. Ng5 Qd4 22.\nQxd4 Nxd4 23. Rf8# Kh1 g6 25. Nf7+ Kg7 26. Nd6+ Kh6 27. Nf7+ Kg7 28. Nd6+ Kh6 29.\nNf7+ Kg7 30. Nd6+ Kh6 31. Nf7+ Kg7 32. Nd6+ Kh6 33. Nf7+ Kg7 34. Nd6+ Kh6 35.\nNf7+ Kg7 36. Nd6+ Kh6 37. Nf7+ Kg7 38. Nd6+ Kh6 39. Nf7+ Kg7 40. Nd6+ Kh6 41.\nNf7+ Kg7 42. Nd6+ Kh6 43. Nf7+ Kg7 44. Nd6+ Kh6 45. Nf7+ Kg7 46. Nd6+ Kh6 47.\nNf7+ Kg7 48. Nd6+ Kh6 49. Nf7+ Kg7 50. Nd6+ Kh6 51. Nf7+ Kg7 52. Nd6+ Kh6 53.\nNf7+ Kg7 54. Nd6+ Kh6 55. Nf7+ Kg7 56. Nd6+ Kh6 57. Nf7+ Kg7 58. Nd6+ Kh6 59.\nNf7+ Kg7 60. Nd6+ Kh6 61. Nf7+ Kg7 62. Nd6+ Kh6 63. Nf7+ Kg7 64. Nd6+ Kh6 65.\nNf7+ Kg7 66. Nd6+ Kh6 67. Nf7+ Kg7 68. Nd6+ Kh6 69. Nf7+ Kg7 70. Nd6+ Kh6 71.\nNf7+ Kg7 72. Nd6+ Kh6 73. Nf7+ Kg7 74. Nd6+ Kh6 75. Nf7+ Kg7 76. Nd6+ Kh6 77.\nNf7+ Kg7 78. Nd6+ Kh6 79. Nf7+ Kg7 80. Nd6+ Kh6 81. Nf7+ Kg7 82. Nd6+ Kh6 83.\nNf7+ Kg7 84. Nd6+ Kh6 85. Nf7+ Kg7 86. Nd6+ Kh6 87. Nf7+ Kg7 88. Nd6+ Kh6 89.\nNf7+ Kg7 90. Nd6+ Kh6 91. Nf7+ Kg",
          "neutral_tokens": {
            "prompt_tokens": 236,
            "completion_tokens": 640,
            "total_tokens": 876,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxe8",
            "cxd2",
            "Qxe3",
            "d1=Q",
            "Rxd1",
            "Qxd1+",
            "Rf1",
            "Qd6",
            "Ng5",
            "Qd4",
            "Qxd4",
            "Nxd4",
            "Rf8#",
            "Kh1",
            "g6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Nd6+",
            "Kh6",
            "Nf7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8h8",
          "positional_uci": "g8h8",
          "neutral_uci": "g8h8",
          "consensus_move": "g8h8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe8",
              "cxd2",
              "Qxe3",
              "d1=Q",
              "Rxd1",
              "Qxd1+",
              "Rf1",
              "Qd6",
              "Ng5",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rf8+",
              "Ng8",
              "Nf7#",
              "d2",
              "Qxd2",
              "Qe1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxe8",
              "cxd2",
              "Bxc6",
              "Bxf2+",
              "Kxf2",
              "bxc6",
              "Rd1",
              "Bg4",
              "Rxd2",
              "Qf6",
              "Qc3",
              "Qxc3",
              "bxc3",
              "Bxf3",
              "Kxf3",
              "Kg8",
              "Rd7",
              "a5",
              "Rc7",
              "Ra6",
              "Ke4",
              "Rb6",
              "Ra7",
              "Rb2",
              "Rxa5",
              "Rxg2",
              "h4",
              "Rg4+",
              "Ke5",
              "Rxh4",
              "Kd6",
              "Rc4",
              "Rc5",
              "Ra4",
              "Rxc6",
              "Rxa2",
              "c4",
              "h5",
              "c5",
              "h4",
              "Rc8+",
              "Kh7",
              "c6",
              "h3",
              "c7",
              "Rc2",
              "Rb8",
              "h2",
              "Rb1",
              "g5",
              "Rh1",
              "Kg6",
              "Rxh2",
              "Rxh2",
              "c8=Q",
              "Rd2+",
              "Ke5",
              "Re2+",
              "Kd4",
              "Rd2+",
              "Ke3",
              "Rd6",
              "Qe8+",
              "Kf6",
              "Qf8+",
              "Ke6",
              "Ke4",
              "Kd7",
              "Qf5+",
              "Kc6",
              "Qxg5",
              "Re6+",
              "Kd4",
              "Rd6+",
              "Kc4",
              "Kd7",
              "Qg7+",
              "Kc6",
              "Qa7",
              "Rd7",
              "Qa6+",
              "Kc7",
              "Kc5",
              "Kd8",
              "Qf6+",
              "Kc7",
              "Qe5+",
              "Kd8",
              "Kc6",
              "Re7",
              "Qb8#",
              "Kd7",
              "Qd6+",
              "Ke8",
              "Qg6+",
              "Kd8",
              "Qg8+",
              "Re8",
              "Qd5+",
              "Ke7",
              "Qd6+",
              "Kf7",
              "Kd7",
              "Rg8",
              "Qe6+",
              "Kg7",
              "Ke7",
              "Kh7",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg6",
              "Qf5",
              "Kh6",
              "Kf7",
              "Rg7+",
              "Kf6",
              "Rg8",
              "Qh3#",
              "g4",
              "Qh4#",
              "g3",
              "Qh3#",
              "g2",
              "Qh4#",
              "g1=Q",
              "Qh3#",
              "g5",
              "Qh4#",
              "g4",
              "Qh3#",
              "g3",
              "Qh4#",
              "g2",
              "Qh3#",
              "g1=Q",
              "Qh4#",
              "g5",
              "Qh3#",
              "g4",
              "Qh4#",
              "g3",
              "Qh3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxe8",
              "cxd2",
              "Qxe3",
              "d1=Q",
              "Rxd1",
              "Qxd1+",
              "Rf1",
              "Qd6",
              "Ng5",
              "Qd4",
              "Qxd4",
              "Nxd4",
              "Rf8#",
              "Kh1",
              "g6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Nd6+",
              "Kh6",
              "Nf7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 237,
            "completion_tokens": 85,
            "total_tokens": 322,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 236,
            "completion_tokens": 640,
            "total_tokens": 876,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 710,
          "total_completion_tokens": 1365,
          "total_tokens": 2075
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 237,
            "completion_tokens": 85,
            "total_tokens": 322,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 236,
            "completion_tokens": 640,
            "total_tokens": 876,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqr1k1/pp3Bpp/2n5/8/8/1Qp1bN2/PP1N1RPP/5RK1 b - - 0 16"
    },
    {
      "turn": 34,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "Repeating the entire game so far:\n1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 * d4 18. Bxc6 bxc6 19. Nc4 Be6 20.\nQa4 Bxc4 21. Qxc4 cxb2 22. Qxc6 Rc8 23. Qb5 Rb8 24. Qd3 Qd5 25. Rb1 Qxa2 26.\nNxd4 Bxd4+ 27. Qxd4 Qxb1+ 28. Kf2 Qc2+ 29. Kg3 b1=Q 30. Qxa7 Qbb3+ 31. Kh4 Qcc4+ 32.\ng4 Qbb4 33. h3 Qe1+ 34. Kh5 Qd5+ 35. g5 Qe2+ 36. Kh4 Rb4+ 37. Kg3 Qdf3#",
          "aggressive_tokens": {
            "prompt_tokens": 245,
            "completion_tokens": 327,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc6",
            "bxc6",
            "Nc4",
            "Be6",
            "Qa4",
            "Bxc4",
            "Qxc4",
            "cxb2",
            "Qxc6",
            "Rc8",
            "Qb5",
            "Rb8",
            "Qd3",
            "Qd5",
            "Rb1",
            "Qxa2",
            "Nxd4",
            "Bxd4+",
            "Qxd4",
            "Qxb1+",
            "Kf2",
            "Qc2+",
            "Kg3",
            "b1=Q",
            "Qxa7",
            "Qbb3+",
            "Kh4",
            "Qcc4+",
            "g4",
            "Qbb4",
            "h3",
            "Qe1+",
            "Kh5",
            "Qd5+",
            "g5",
            "Qe2+",
            "Kh4",
            "Rb4+",
            "Kg3",
            "Qdf3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxc5",
          "positional_uci": "e3c5",
          "positional_response": "Repeated moves: 1. d4 d5 2. Nf3\nNf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8. dxc5 Bxc5 9.\nBd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15.\nBc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 * Repeated moves: 1. d4 d5 2. Nf3 Nf6 3.\ne3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd2 O-O\n10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Bc4 dxc3\n16. Bxf7+ Kh8 17. Bxe8 * Repeated moves: 1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4\nc5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4\n11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Bc4 dxc3 16. Bxf7+\nKh8 17. Bxe8 * Repeated moves: 1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5\nexd5 6. Be2 Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8\n12. Nbd2 Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 *\nRepeated moves: 1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2\nNc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd",
          "positional_tokens": {
            "prompt_tokens": 245,
            "completion_tokens": 640,
            "total_tokens": 885,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exf2+",
          "neutral_uci": null,
          "neutral_response": "Repeated moves: 1. d4 d5 2. Nf3\nNf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd2\nO-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Bc4\ndxc3 16. Bxf7+ Kh8 17. Bxe8 * 17... exf2+ 18. Kh1 Bxd2 19. Bxc6 bxc6 20. Ne5\nQd5 21. Qxd5 cxd5 22. Rxf2 Be6 23. Rxd2 * Repeated moves: 1. d4 d5 2. Nf3 Nf6\n3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd2\nO-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Bc4\ndxc3 16. Bxf7+ Kh8 17. Bxe8 * 17... exf2+ 18. Kh1 Bxd2 19. Bxc6 bxc6 20. Ne5\nQd5 21. Qxd5 cxd5 22. Rxf2 Be6 23. Rxd2 * 23... Rc8 24. h3 Kg8 25. Nf3 h6\n26. Nd4 Bd7 27. Nf3 Be6 28. Nd4 Bd7 29. Nf3 * Repeated moves: 1. d4 d5 2. Nf3\nNf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd2\nO-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14. Rf1 d4 15. Bc4\ndxc3 16. Bxf7+ Kh8 17. Bxe8 * 17... exf2+ 18. Kh1 Bxd2 19. Bxc6 bxc6 20. Ne5\nQd5 21. Qxd5 cxd5 22. R",
          "neutral_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 640,
            "total_tokens": 884,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh1",
            "Bxd2",
            "Bxc6",
            "bxc6",
            "Ne5",
            "Qd5",
            "Qxd5",
            "cxd5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e3c5",
          "neutral_uci": null,
          "consensus_move": "e3c5",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxc6",
              "bxc6",
              "Nc4",
              "Be6",
              "Qa4",
              "Bxc4",
              "Qxc4",
              "cxb2",
              "Qxc6",
              "Rc8",
              "Qb5",
              "Rb8",
              "Qd3",
              "Qd5",
              "Rb1",
              "Qxa2",
              "Nxd4",
              "Bxd4+",
              "Qxd4",
              "Qxb1+",
              "Kf2",
              "Qc2+",
              "Kg3",
              "b1=Q",
              "Qxa7",
              "Qbb3+",
              "Kh4",
              "Qcc4+",
              "g4",
              "Qbb4",
              "h3",
              "Qe1+",
              "Kh5",
              "Qd5+",
              "g5",
              "Qe2+",
              "Kh4",
              "Rb4+",
              "Kg3",
              "Qdf3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh1",
              "Bxd2",
              "Bxc6",
              "bxc6",
              "Ne5",
              "Qd5",
              "Qxd5",
              "cxd5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 245,
            "completion_tokens": 327,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 245,
            "completion_tokens": 640,
            "total_tokens": 885,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 244,
            "completion_tokens": 640,
            "total_tokens": 884,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 734,
          "total_completion_tokens": 1607,
          "total_tokens": 2341
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 245,
            "completion_tokens": 327,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 245,
            "completion_tokens": 640,
            "total_tokens": 885,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 244,
            "completion_tokens": 640,
            "total_tokens": 884,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqB2k/pp4pp/2n5/8/8/1Qp1bN2/PP1N1RPP/5RK1 b - - 0 17"
    },
    {
      "turn": 36,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe8",
          "aggressive_uci": "d8e8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Re1 Qf8 20.\nNe4 Bb6 21. Neg5 h6 22. Nf7+ Kh7 23. Qc2+ Kg8 24. Nxh6+ gxh6 25. Qg6+ Kh8 26.\nRe8 Qxe8 27. Qxe8+ Kg7 28. Nh4 Bd8 29. Qg6+ Kf8 30. Qxh6+ Ke8 31. Qh8+ Kd7\n32. Nf5 Kc7 33. Qh7+ Kb6 34. Nd6 Bc7 35. Nc4+ Kc5 36. Qxc7 Kxc4 37. h4 Kxc3\n38. h5 Bg4 39. Qxb7 Rc8 40. h6 Bf5 41. h7 Bxh7 42. Qxc8 Be4 43. g4 Kd4\n44. g5 Ne5 45. Qd8+ Ke3 46. Qf6 Nf3+ 47. Kf1 Bd3+ 48. Kg2 Be4 49. Kg3 Nd4\n50. Qf2+ Kd3 51. Qf1+ Ke3 52. Qe1+ Ne2+ 53. Kg4 Bf3+ 54. Kf5 Be4+ 55. Kf6\nKf3 56. g6 Nf4 57. g7 Nh5+ 58. Kf7 Bd5+ 59. Kf8 Nxg7 60. Kxg7 Bxa2 61. Qa5\nBc4 62. Qxa7 Ke4 63. Kf6 Bd3 64. Qc5 Be2 65. Qe5+ Kd3 66. Kf5 Kd2 67. Kf4\nBd3 68. Qe3+ Kc3 69. Ke5 Kc4 70. Qd4+ Kb5 71. Qxd3+ Kc6 72. Qd5+ Kc7 73.\nQd6+ Kb7 74. Kd5 K",
          "aggressive_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 640,
            "total_tokens": 894,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Nh4",
            "Bd8",
            "Qg6+",
            "Kf8",
            "Qxh6+",
            "Ke8",
            "Qh8+",
            "Kd7",
            "Nf5",
            "Kc7",
            "Qh7+",
            "Kb6",
            "Nd6",
            "Bc7",
            "Nc4+",
            "Kc5",
            "Qxc7",
            "Kxc4",
            "h4",
            "Kxc3",
            "h5",
            "Bg4",
            "Qxb7",
            "Rc8",
            "h6",
            "Bf5",
            "h7",
            "Bxh7",
            "Qxc8",
            "Be4",
            "g4",
            "Kd4",
            "g5",
            "Ne5",
            "Qd8+",
            "Ke3",
            "Qf6",
            "Nf3+",
            "Kf1",
            "Bd3+",
            "Kg2",
            "Be4",
            "Kg3",
            "Nd4",
            "Qf2+",
            "Kd3",
            "Qf1+",
            "Ke3",
            "Qe1+",
            "Ne2+",
            "Kg4",
            "Bf3+",
            "Kf5",
            "Be4+",
            "Kf6",
            "Kf3",
            "g6",
            "Nf4",
            "g7",
            "Nh5+",
            "Kf7",
            "Bd5+",
            "Kf8",
            "Nxg7",
            "Kxg7",
            "Bxa2",
            "Qa5",
            "Bc4",
            "Qxa7",
            "Ke4",
            "Kf6",
            "Bd3",
            "Qc5",
            "Be2",
            "Qe5+",
            "Kd3",
            "Kf5",
            "Kd2",
            "Kf4",
            "Bd3",
            "Qe3+",
            "Kc3",
            "Ke5",
            "Kc4",
            "Qd4+",
            "Kb5",
            "Qxd3+",
            "Kc6",
            "Qd5+",
            "Kc7",
            "Qd6+",
            "Kb7",
            "Kd5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe8",
          "positional_uci": "d8e8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Re1 Qf8 20.\nNe4 Bb6 21. Neg5 h6 22. Nf7+ Kh7 23. N3g5+ hxg5 24. Nxg5+ Kg6 25. Nf3 Bg4 26.\nQc2+ Kh6 27. Qd2+ Kh7 28. Ng5+ Kh8 29. h3 Rd8 30. Qc2 Bf5 31. Qe2 Bg6 32. Ne6\nQe7 33. Nxd8 Qxe2 34. Rxe2 Nxd8 35. Re7 Kg8 36. Rd7 Bf5 37. Rd5 Be6 38. Rd2\nNc6 39. Kh2 Kf7 40. g4 Bc7+ 41. Kg2 Ne5 42. Rf2+ Ke7 43. Re2 Bd5+ 44. Kf2\nKd6 45. Rd2 Bb6+ 46. Kg3 Nc4 47. Re2 Ne3 48. Kf4 Ng2+ 49. Kg5 Bd8+ 50. Kg6\nNf4+ 51. Kxg7 Nxe2 52. Kg6 Nxc3 53. Kf5 Nxa2 54. g5 Be6+ 55. Kg6 Bxh3 56. Kh6\nBxg5+ 57. Kxg5 b5 58. Kf4 b4 59. Ke3 b3 60. Kd2 b2 61. Kc2 b1=Q+ 62. Kxb1\nNb4 63. Kb2 Kc5 64. Kb3 Be6+ 65. Ka4 Nc6 66. Ka3 Kc4 67. Ka4 Bd7 68. Ka3 Nd4\n69. Kb2 Kd3 70. Ka3 Kc3 71. Ka2 Nc2 72. Kb1 Be6 73. Kc1 Ba2 74. Kd1 Nd4 75.\nKc1 Ne2+ 76. Kd1 Kd3 77",
          "positional_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 640,
            "total_tokens": 894,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re1",
            "Qf8",
            "Ne4",
            "Bb6",
            "Neg5",
            "h6",
            "Nf7+",
            "Kh7",
            "N3g5+",
            "hxg5",
            "Nxg5+",
            "Kg6",
            "Nf3",
            "Bg4",
            "Qc2+",
            "Kh6",
            "Qd2+",
            "Kh7",
            "Ng5+",
            "Kh8",
            "h3",
            "Rd8",
            "Qc2",
            "Bf5",
            "Qe2",
            "Bg6",
            "Ne6",
            "Qe7",
            "Nxd8",
            "Qxe2",
            "Rxe2",
            "Nxd8",
            "Re7",
            "Kg8",
            "Rd7",
            "Bf5",
            "Rd5",
            "Be6",
            "Rd2",
            "Nc6",
            "Kh2",
            "Kf7",
            "g4",
            "Bc7+",
            "Kg2",
            "Ne5",
            "Rf2+",
            "Ke7",
            "Re2",
            "Bd5+",
            "Kf2",
            "Kd6",
            "Rd2",
            "Bb6+",
            "Kg3",
            "Nc4",
            "Re2",
            "Ne3",
            "Kf4",
            "Ng2+",
            "Kg5",
            "Bd8+",
            "Kg6",
            "Nf4+",
            "Kxg7",
            "Nxe2",
            "Kg6",
            "Nxc3",
            "Kf5",
            "Nxa2",
            "g5",
            "Be6+",
            "Kg6",
            "Bxh3",
            "Kh6",
            "Bxg5+",
            "Kxg5",
            "b5",
            "Kf4",
            "b4",
            "Ke3",
            "b3",
            "Kd2",
            "b2",
            "Kc2",
            "b1=Q+",
            "Kxb1",
            "Nb4",
            "Kb2",
            "Kc5",
            "Kb3",
            "Be6+",
            "Ka4",
            "Nc6",
            "Ka3",
            "Kc4",
            "Ka4",
            "Bd7",
            "Ka3",
            "Nd4",
            "Kb2",
            "Kd3",
            "Ka3",
            "Kc3",
            "Ka2",
            "Nc2",
            "Kb1",
            "Be6",
            "Kc1",
            "Ba2",
            "Kd1",
            "Nd4",
            "Kc1",
            "Ne2+",
            "Kd1",
            "Kd3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe8",
          "neutral_uci": "d8e8",
          "neutral_response": "Repeating the entire game\n18... Qxe8 19. Nd4 Nxd4 20. cxd4 Bxd4 21. Qd5 Bxf2+ 22. Rxf2 Be6 23. Qxb7 Bxa2\n24. Ne4 Qb8 25. Qe7 Qb1+ 26. Rf1 Qb6+ 27. Kh1 Bc4 28. Rf8+ Rxf8 29. Qxf8+ Bg8\n30. h3 Qb1+ 31. Kh2 Qxe4 32. Qa3 Qe5+ 33. Kh1 a5 34. Qa4 Qe1+ 35. Kh2 Qb4\n36. Qe8 a4 37. Qe2 a3 38. Qc2 a2 39. Qc1 Qb1 40. Qc8 a1=Q 41. Qxg8+ Kxg8\n42. h4 Qe5+ 43. Kh3 Qbf5+ 44. g4 Qf3# Qb1 Qb8 Qc1",
          "neutral_tokens": {
            "prompt_tokens": 253,
            "completion_tokens": 254,
            "total_tokens": 507,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Nxd4",
            "cxd4",
            "Bxd4",
            "Qd5",
            "Bxf2+",
            "Rxf2",
            "Be6",
            "Qxb7",
            "Bxa2",
            "Ne4",
            "Qb8",
            "Qe7",
            "Qb1+",
            "Rf1",
            "Qb6+",
            "Kh1",
            "Bc4",
            "Rf8+",
            "Rxf8",
            "Qxf8+",
            "Bg8",
            "h3",
            "Qb1+",
            "Kh2",
            "Qxe4",
            "Qa3",
            "Qe5+",
            "Kh1",
            "a5",
            "Qa4",
            "Qe1+",
            "Kh2",
            "Qb4",
            "Qe8",
            "a4",
            "Qe2",
            "a3",
            "Qc2",
            "a2",
            "Qc1",
            "Qb1",
            "Qc8",
            "a1=Q",
            "Qxg8+",
            "Kxg8",
            "h4",
            "Qe5+",
            "Kh3",
            "Qbf5+",
            "g4",
            "Qf3#",
            "Qb1",
            "Qb8",
            "Qc1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8e8",
          "positional_uci": "d8e8",
          "neutral_uci": "d8e8",
          "consensus_move": "d8e8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg7",
              "Nh4",
              "Bd8",
              "Qg6+",
              "Kf8",
              "Qxh6+",
              "Ke8",
              "Qh8+",
              "Kd7",
              "Nf5",
              "Kc7",
              "Qh7+",
              "Kb6",
              "Nd6",
              "Bc7",
              "Nc4+",
              "Kc5",
              "Qxc7",
              "Kxc4",
              "h4",
              "Kxc3",
              "h5",
              "Bg4",
              "Qxb7",
              "Rc8",
              "h6",
              "Bf5",
              "h7",
              "Bxh7",
              "Qxc8",
              "Be4",
              "g4",
              "Kd4",
              "g5",
              "Ne5",
              "Qd8+",
              "Ke3",
              "Qf6",
              "Nf3+",
              "Kf1",
              "Bd3+",
              "Kg2",
              "Be4",
              "Kg3",
              "Nd4",
              "Qf2+",
              "Kd3",
              "Qf1+",
              "Ke3",
              "Qe1+",
              "Ne2+",
              "Kg4",
              "Bf3+",
              "Kf5",
              "Be4+",
              "Kf6",
              "Kf3",
              "g6",
              "Nf4",
              "g7",
              "Nh5+",
              "Kf7",
              "Bd5+",
              "Kf8",
              "Nxg7",
              "Kxg7",
              "Bxa2",
              "Qa5",
              "Bc4",
              "Qxa7",
              "Ke4",
              "Kf6",
              "Bd3",
              "Qc5",
              "Be2",
              "Qe5+",
              "Kd3",
              "Kf5",
              "Kd2",
              "Kf4",
              "Bd3",
              "Qe3+",
              "Kc3",
              "Ke5",
              "Kc4",
              "Qd4+",
              "Kb5",
              "Qxd3+",
              "Kc6",
              "Qd5+",
              "Kc7",
              "Qd6+",
              "Kb7",
              "Kd5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re1",
              "Qf8",
              "Ne4",
              "Bb6",
              "Neg5",
              "h6",
              "Nf7+",
              "Kh7",
              "N3g5+",
              "hxg5",
              "Nxg5+",
              "Kg6",
              "Nf3",
              "Bg4",
              "Qc2+",
              "Kh6",
              "Qd2+",
              "Kh7",
              "Ng5+",
              "Kh8",
              "h3",
              "Rd8",
              "Qc2",
              "Bf5",
              "Qe2",
              "Bg6",
              "Ne6",
              "Qe7",
              "Nxd8",
              "Qxe2",
              "Rxe2",
              "Nxd8",
              "Re7",
              "Kg8",
              "Rd7",
              "Bf5",
              "Rd5",
              "Be6",
              "Rd2",
              "Nc6",
              "Kh2",
              "Kf7",
              "g4",
              "Bc7+",
              "Kg2",
              "Ne5",
              "Rf2+",
              "Ke7",
              "Re2",
              "Bd5+",
              "Kf2",
              "Kd6",
              "Rd2",
              "Bb6+",
              "Kg3",
              "Nc4",
              "Re2",
              "Ne3",
              "Kf4",
              "Ng2+",
              "Kg5",
              "Bd8+",
              "Kg6",
              "Nf4+",
              "Kxg7",
              "Nxe2",
              "Kg6",
              "Nxc3",
              "Kf5",
              "Nxa2",
              "g5",
              "Be6+",
              "Kg6",
              "Bxh3",
              "Kh6",
              "Bxg5+",
              "Kxg5",
              "b5",
              "Kf4",
              "b4",
              "Ke3",
              "b3",
              "Kd2",
              "b2",
              "Kc2",
              "b1=Q+",
              "Kxb1",
              "Nb4",
              "Kb2",
              "Kc5",
              "Kb3",
              "Be6+",
              "Ka4",
              "Nc6",
              "Ka3",
              "Kc4",
              "Ka4",
              "Bd7",
              "Ka3",
              "Nd4",
              "Kb2",
              "Kd3",
              "Ka3",
              "Kc3",
              "Ka2",
              "Nc2",
              "Kb1",
              "Be6",
              "Kc1",
              "Ba2",
              "Kd1",
              "Nd4",
              "Kc1",
              "Ne2+",
              "Kd1",
              "Kd3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nd4",
              "Nxd4",
              "cxd4",
              "Bxd4",
              "Qd5",
              "Bxf2+",
              "Rxf2",
              "Be6",
              "Qxb7",
              "Bxa2",
              "Ne4",
              "Qb8",
              "Qe7",
              "Qb1+",
              "Rf1",
              "Qb6+",
              "Kh1",
              "Bc4",
              "Rf8+",
              "Rxf8",
              "Qxf8+",
              "Bg8",
              "h3",
              "Qb1+",
              "Kh2",
              "Qxe4",
              "Qa3",
              "Qe5+",
              "Kh1",
              "a5",
              "Qa4",
              "Qe1+",
              "Kh2",
              "Qb4",
              "Qe8",
              "a4",
              "Qe2",
              "a3",
              "Qc2",
              "a2",
              "Qc1",
              "Qb1",
              "Qc8",
              "a1=Q",
              "Qxg8+",
              "Kxg8",
              "h4",
              "Qe5+",
              "Kh3",
              "Qbf5+",
              "g4",
              "Qf3#",
              "Qb1",
              "Qb8",
              "Qc1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 254,
            "completion_tokens": 640,
            "total_tokens": 894,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 254,
            "completion_tokens": 640,
            "total_tokens": 894,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 253,
            "completion_tokens": 254,
            "total_tokens": 507,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 761,
          "total_completion_tokens": 1534,
          "total_tokens": 2295
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 254,
            "completion_tokens": 640,
            "total_tokens": 894,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 254,
            "completion_tokens": 640,
            "total_tokens": 894,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 253,
            "completion_tokens": 254,
            "total_tokens": 507,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqB2k/pp4pp/2n5/2b5/8/1QP2N2/P2N1RPP/5RK1 b - - 0 18"
    },
    {
      "turn": 38,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb6",
          "aggressive_uci": "c5b6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bb6 20.\nNc4 Bc7 21. Re1 Qf8 22. Qh5 Bf5 23. Nh4 g6 24. Qg5 Bd8 25. Qf4 Bxh4 26. Qxh4\nRe8 27. Rxe8 Qxe8 28. Qf6+ Kg8 29. h3 Qe1+ 30. Kh2 Qe6 31. Qh4 b5 32. Nd2 Qd6+\n33. Kg1 Qxd2 34. Qf6 Qe1+ 35. Kh2 Qe5+ 36. Qxe5 Nxe5 37. g4 Be6 38. a3 Nc4\n39. Kg3 Nxa3 40. Kf4 Nb1 41. Ke5 Bc4 42. Kd4 a5 43. Kc5 a4 44. Kb4 a3 45.\nh4 a2 46. h5 a1=Q 47. hxg6 Qa3#",
          "aggressive_tokens": {
            "prompt_tokens": 263,
            "completion_tokens": 393,
            "total_tokens": 656,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Bc7",
            "Re1",
            "Qf8",
            "Qh5",
            "Bf5",
            "Nh4",
            "g6",
            "Qg5",
            "Bd8",
            "Qf4",
            "Bxh4",
            "Qxh4",
            "Re8",
            "Rxe8",
            "Qxe8",
            "Qf6+",
            "Kg8",
            "h3",
            "Qe1+",
            "Kh2",
            "Qe6",
            "Qh4",
            "b5",
            "Nd2",
            "Qd6+",
            "Kg1",
            "Qxd2",
            "Qf6",
            "Qe1+",
            "Kh2",
            "Qe5+",
            "Qxe5",
            "Nxe5",
            "g4",
            "Be6",
            "a3",
            "Nc4",
            "Kg3",
            "Nxa3",
            "Kf4",
            "Nb1",
            "Ke5",
            "Bc4",
            "Kd4",
            "a5",
            "Kc5",
            "a4",
            "Kb4",
            "a3",
            "h4",
            "a2",
            "h5",
            "a1=Q",
            "hxg6",
            "Qa3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe7",
          "positional_uci": "e8e7",
          "positional_response": "19... Qe7 20. Nd4 Nxd4 21. cxd4 Bxd4 22. Qb4 Bc5 23. Qe4 Be6 24. Kh1 Bxf2 25.\nRxf2 Rd8 26. h3 Qd6 27. Qxb7 Bxa2 28. Qxa7 Bd5 29. Qe3 h6 30. Nf3 Qg3 31. Qe2\nRf8 32. Kg1 Bxf3 33. Rxf3 Rxf3 34. Qxf3 Qxf3 35. gxf3 g5 36. Kg2 Kg7 37. Kg3 Kg6\n38. h4 Kf5 39. hxg5 hxg5 40. Kg2 Kf4 41. Kf2 g4 42. fxg4 Kxg4 43. Kg2 *",
          "positional_tokens": {
            "prompt_tokens": 263,
            "completion_tokens": 205,
            "total_tokens": 468,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Nxd4",
            "cxd4",
            "Bxd4",
            "Qb4",
            "Bc5",
            "Qe4",
            "Be6",
            "Kh1",
            "Bxf2",
            "Rxf2",
            "Rd8",
            "h3",
            "Qd6",
            "Qxb7",
            "Bxa2",
            "Qxa7",
            "Bd5",
            "Qe3",
            "h6",
            "Nf3",
            "Qg3",
            "Qe2",
            "Rf8",
            "Kg1",
            "Bxf3",
            "Rxf3",
            "Rxf3",
            "Qxf3",
            "Qxf3",
            "gxf3",
            "g5",
            "Kg2",
            "Kg7",
            "Kg3",
            "Kg6",
            "h4",
            "Kf5",
            "hxg5",
            "hxg5",
            "Kg2",
            "Kf4",
            "Kf2",
            "g4",
            "fxg4",
            "Kxg4",
            "Kg2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf2+",
          "neutral_uci": "c5f2",
          "neutral_response": "19... Bxf2+ 20. Rxf2 Qe7 21. Ng5 h6 22. Nf7+ Kg8 23. Qh5 Be6 24. Nxh6+ gxh6\n25. Qg6+ Kh8 26. Qxh6+ Kg8 27. Qg6+ Kh8 28. Qh6+ Kg8 29. Qg6+ Kh8 30. Qh6+ Kg8\n31. Qg6+ Kh8 32. Qh6+ Kg8 33. Qg6+ Kh8 34. Qh6+ Kg8 35. Qg6+ Kh8 36. Qh6+ Kg8\n37. Qg6+ Kh8 38. Qh6+ Kg8 39. Qg6+ Kh8 40. Qh6+ Kg8 41. Qg6+ Kh8 42. Qh6+ Kg8\n43. Qg6+ Kh8 44. Qh6+ Kg8 45. Qg6+ Kh8 46. Qh6+ Kg8 47. Qg6+ Kh8 48. Qh6+ Kg8\n49. Qg6+ Kh8 50. Qh6+ Kg8 51. Qg6+ Kh8 52. Qh6+ Kg8 53. Qg6+ Kh8 54. Qh6+ Kg8\n55. Qg6+ Kh8 56. Qh6+ Kg8 57. Qg6+ Kh8 58. Qh6+ Kg8 59. Qg6+ Kh8 60. Qh6+ Kg8\n61. Qg6+ Kh8 62. Qh6+ Kg8 63. Qg6+ Kh8 64. Qh6+ Kg8 65. Qg6+ Kh8 66. Qh6+ Kg8\n67. Qg6+ Kh8 68. Qh6+ Kg8 69. Qg6+ Kh8 70. Qh6+ Kg8 71. Qg6+ Kh8 72. Qh6+ Kg8\n73. Qg6+ Kh8 74. Qh6+ Kg8 75. Qg6+ Kh8 76. Qh6+ Kg8 77. Qg6+ Kh8 78. Qh6+ Kg8\n79. Qg6+ Kh8 80. Qh6+ Kg8 81. Qg6+ Kh8 82. Qh6+ Kg8 83. Qg6+ Kh8 84. Qh6+ Kg8\n85. Qg6+ Kh8 86. Qh6+ Kg8 87. Qg6+ Kh8 88. Qh6+ Kg8 89. Qg6+ Kh8 90. Q",
          "neutral_tokens": {
            "prompt_tokens": 262,
            "completion_tokens": 640,
            "total_tokens": 902,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxf2",
            "Qe7",
            "Ng5",
            "h6",
            "Nf7+",
            "Kg8",
            "Qh5",
            "Be6",
            "Nxh6+",
            "gxh6",
            "Qg6+",
            "Kh8",
            "Qxh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5b6",
          "positional_uci": "e8e7",
          "neutral_uci": "c5f2",
          "consensus_move": "c5f2",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Bc7",
              "Re1",
              "Qf8",
              "Qh5",
              "Bf5",
              "Nh4",
              "g6",
              "Qg5",
              "Bd8",
              "Qf4",
              "Bxh4",
              "Qxh4",
              "Re8",
              "Rxe8",
              "Qxe8",
              "Qf6+",
              "Kg8",
              "h3",
              "Qe1+",
              "Kh2",
              "Qe6",
              "Qh4",
              "b5",
              "Nd2",
              "Qd6+",
              "Kg1",
              "Qxd2",
              "Qf6",
              "Qe1+",
              "Kh2",
              "Qe5+",
              "Qxe5",
              "Nxe5",
              "g4",
              "Be6",
              "a3",
              "Nc4",
              "Kg3",
              "Nxa3",
              "Kf4",
              "Nb1",
              "Ke5",
              "Bc4",
              "Kd4",
              "a5",
              "Kc5",
              "a4",
              "Kb4",
              "a3",
              "h4",
              "a2",
              "h5",
              "a1=Q",
              "hxg6",
              "Qa3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nd4",
              "Nxd4",
              "cxd4",
              "Bxd4",
              "Qb4",
              "Bc5",
              "Qe4",
              "Be6",
              "Kh1",
              "Bxf2",
              "Rxf2",
              "Rd8",
              "h3",
              "Qd6",
              "Qxb7",
              "Bxa2",
              "Qxa7",
              "Bd5",
              "Qe3",
              "h6",
              "Nf3",
              "Qg3",
              "Qe2",
              "Rf8",
              "Kg1",
              "Bxf3",
              "Rxf3",
              "Rxf3",
              "Qxf3",
              "Qxf3",
              "gxf3",
              "g5",
              "Kg2",
              "Kg7",
              "Kg3",
              "Kg6",
              "h4",
              "Kf5",
              "hxg5",
              "hxg5",
              "Kg2",
              "Kf4",
              "Kf2",
              "g4",
              "fxg4",
              "Kxg4",
              "Kg2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxf2",
              "Qe7",
              "Ng5",
              "h6",
              "Nf7+",
              "Kg8",
              "Qh5",
              "Be6",
              "Nxh6+",
              "gxh6",
              "Qg6+",
              "Kh8",
              "Qxh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 263,
            "completion_tokens": 393,
            "total_tokens": 656,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 263,
            "completion_tokens": 205,
            "total_tokens": 468,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 262,
            "completion_tokens": 640,
            "total_tokens": 902,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 788,
          "total_completion_tokens": 1238,
          "total_tokens": 2026
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 263,
            "completion_tokens": 393,
            "total_tokens": 656,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 263,
            "completion_tokens": 205,
            "total_tokens": 468,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 262,
            "completion_tokens": 640,
            "total_tokens": 902,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1q2k/pp4pp/2n5/1Qb5/8/2P2N2/P2N1RPP/5RK1 b - - 1 19"
    },
    {
      "turn": 40,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe3#",
          "aggressive_uci": "e8e3",
          "aggressive_response": "20... Qe3# 21. Kg3 Bd7 22. Qxb7 Rd8 23. Re1 Qxc3 24. Ne4 Qa5 25. Nd6 Kg8 26. Qb3+ Kh8 27. Nf7+ Kg8 28. Nh6+ Kh8 29. Qg8+ Rxg8 30. Nf7#",
          "aggressive_tokens": {
            "prompt_tokens": 273,
            "completion_tokens": 88,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg3",
            "Bd7",
            "Qxb7",
            "Rd8",
            "Re1",
            "Qxc3",
            "Ne4",
            "Qa5",
            "Nd6",
            "Kg8",
            "Qb3+",
            "Kh8",
            "Nf7+",
            "Kg8",
            "Nh6+",
            "Kh8",
            "Qg8+",
            "Rxg8",
            "Nf7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe3+",
          "positional_uci": "e8e3",
          "positional_response": "Re8 Qe3+ 22. Kg3 Qg6+ 23. Kf2 Qe3+ 24. Kg3 Qg6+ 25. Kf2 Qe3+ 26. Kg3 Qg6+ 27. Kf2 Qe3+ 28. Kg3 Qg6+ 29. Kf2 Qe3+ 30. Kg3 Qg6+ 31. Kf2 Qe3+ 32. Kg3 Qg6+ 33. Kf2 Qe3+ 34. Kg3 Qg6+ 35. Kf2 Qe3+ 36. Kg3 Qg6+ 37. Kf2 Qe3+ 38. Kg3 Qg6+ 39. Kf2 Qe3+ 40. Kg3 Qg6+ 41. Kf2 Qe3+ 42. Kg3 Qg6+ 43. Kf2 Qe3+ 44. Kg3 Qg6+ 45. Kf2 Qe3+ 46. Kg3 Qg6+ 47. Kf2 Qe3+ 48. Kg3 Qg6+ 49. Kf2 Qe3+ 50. Kg3 Qg6+ 51. Kf2 Qe3+ 52. Kg3 Qg6+ 53. Kf2 Qe3+ 54. Kg3 Qg6+ 55. Kf2 Qe3+ 56. Kg3 Qg6+ 57. Kf2 Qe3+ 58. Kg3 Qg6+ 59. Kf2 Qe3+ 60. Kg3 Qg6+ 61. Kf2 Qe3+ 62. Kg3 Qg6+ 63. Kf2 Qe3+ 64. Kg3 Qg6+ 65. Kf2 Qe3+ 66. Kg3 Qg6+ 67. Kf2 Qe3+ 68. Kg3 Qg6+ 69. Kf2 Qe3+ 70. Kg3 Qg6+ 71. Kf2 Qe3+ 72. Kg3 Qg6+ 73. Kf2 Qe3+ 74. Kg3 Qg6+ 75. Kf2 Qe3+ 76. Kg3 Qg6+ 77. Kf2 Qe3+ 78. Kg3 Qg6+ 79. Kf2 Qe3+ 80. Kg3 Qg6+ 81. Kf2 Qe3+ 82. Kg3 Qg6+ 83. Kf2 Qe3+ 84. Kg3 Qg6+ 85. Kf2 Qe3+ 86. Kg3 Qg6+ 87. Kf2 Qe3+ 88. Kg3 Qg",
          "positional_tokens": {
            "prompt_tokens": 273,
            "completion_tokens": 640,
            "total_tokens": 913,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bg4",
          "neutral_uci": "c8g4",
          "neutral_response": "Repeated moves: 1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2\nNc6 7. O-O Bd6 8. dxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2\n13. Rxf2 Bxe3 14. Rf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8\n19. Qb5 Bxf2+ 20. Kxf2 * 20... Bg4 21. Qxb7 Rb8 22. Qa6 Rb2 23. Kg1 Qe3+ 24.\nKh1 Qe6 25. Ng5 Qe8 26. Qd3 g6 27. Nf7+ Kg7 28. Nd6 Qe2 29. Qxe2 Bxe2 30. Rf7+\nKg8 31. N2e4 Rb1+ 32. Rf1 Rxf1# 20... Bg4 21. Qxb7 Rb8 22. Qa6 Rb2 23. Kg1 Qe3+\n24. Kh1 Qe6 25. Ng5 Qe8 26. Qd3 g6 27. Nf7+ Kg7 28. Nd6 Qe2 29. Qxe2 Bxe2 30.\nRf7+ Kg8 31. N2e4 Rb1+ 32. Rf1 Rxf1# 33. Nxf1 Bxf1 34. Kg1 Bd3 35. Nc5 Bc4\n36. a3 Kf7 37. Kf2 Ke7 38. Ke3 Kd6 39. Ne4+ Ke5 40. Nd2 Bd5 41. g3 Na5 42. Kd3\nNb3 43. Nf1 Nc5+ 44. Ke3 Bc4 45. Nd2 Kd5 46. h4 Na4 47. Ne4 Ke5 48. Nd2 Bd5\n49. c4 Bc6 50. Nb3 Nb2 51. Nd2 a5 52. g4 a4 53. h5 g5 54. h6 Bd7 55. Nf3+ Kf6\n56. Kd4 Bxg4 57. Ne5 Be6 58. c5 g4 59. c6 g3 60. Nf3 g2 61. c7 Nc4 62. Ng1 Nxa3\n63. Kc3 Nb5+",
          "neutral_tokens": {
            "prompt_tokens": 272,
            "completion_tokens": 640,
            "total_tokens": 912,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxb7",
            "Rb8",
            "Qa6",
            "Rb2",
            "Kg1",
            "Qe3+",
            "Kh1",
            "Qe6",
            "Ng5",
            "Qe8",
            "Qd3",
            "g6",
            "Nf7+",
            "Kg7",
            "Nd6",
            "Qe2",
            "Qxe2",
            "Bxe2",
            "Rf7+",
            "Kg8",
            "N2e4",
            "Rb1+",
            "Rf1",
            "Rxf1#",
            "Nxf1",
            "Bxf1",
            "Kg1",
            "Bd3",
            "Nc5",
            "Bc4",
            "a3",
            "Kf7",
            "Kf2",
            "Ke7",
            "Ke3",
            "Kd6",
            "Ne4+",
            "Ke5",
            "Nd2",
            "Bd5",
            "g3",
            "Na5",
            "Kd3",
            "Nb3",
            "Nf1",
            "Nc5+",
            "Ke3",
            "Bc4",
            "Nd2",
            "Kd5",
            "h4",
            "Na4",
            "Ne4",
            "Ke5",
            "Nd2",
            "Bd5",
            "c4",
            "Bc6",
            "Nb3",
            "Nb2",
            "Nd2",
            "a5",
            "g4",
            "a4",
            "h5",
            "g5",
            "h6",
            "Bd7",
            "Nf3+",
            "Kf6",
            "Kd4",
            "Bxg4",
            "Ne5",
            "Be6",
            "c5",
            "g4",
            "c6",
            "g3",
            "Nf3",
            "g2",
            "c7",
            "Nc4",
            "Ng1",
            "Nxa3",
            "Kc3",
            "Nb5+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8e3",
          "positional_uci": "e8e3",
          "neutral_uci": "c8g4",
          "consensus_move": "e8e3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg3",
              "Bd7",
              "Qxb7",
              "Rd8",
              "Re1",
              "Qxc3",
              "Ne4",
              "Qa5",
              "Nd6",
              "Kg8",
              "Qb3+",
              "Kh8",
              "Nf7+",
              "Kg8",
              "Nh6+",
              "Kh8",
              "Qg8+",
              "Rxg8",
              "Nf7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxb7",
              "Rb8",
              "Qa6",
              "Rb2",
              "Kg1",
              "Qe3+",
              "Kh1",
              "Qe6",
              "Ng5",
              "Qe8",
              "Qd3",
              "g6",
              "Nf7+",
              "Kg7",
              "Nd6",
              "Qe2",
              "Qxe2",
              "Bxe2",
              "Rf7+",
              "Kg8",
              "N2e4",
              "Rb1+",
              "Rf1",
              "Rxf1#",
              "Nxf1",
              "Bxf1",
              "Kg1",
              "Bd3",
              "Nc5",
              "Bc4",
              "a3",
              "Kf7",
              "Kf2",
              "Ke7",
              "Ke3",
              "Kd6",
              "Ne4+",
              "Ke5",
              "Nd2",
              "Bd5",
              "g3",
              "Na5",
              "Kd3",
              "Nb3",
              "Nf1",
              "Nc5+",
              "Ke3",
              "Bc4",
              "Nd2",
              "Kd5",
              "h4",
              "Na4",
              "Ne4",
              "Ke5",
              "Nd2",
              "Bd5",
              "c4",
              "Bc6",
              "Nb3",
              "Nb2",
              "Nd2",
              "a5",
              "g4",
              "a4",
              "h5",
              "g5",
              "h6",
              "Bd7",
              "Nf3+",
              "Kf6",
              "Kd4",
              "Bxg4",
              "Ne5",
              "Be6",
              "c5",
              "g4",
              "c6",
              "g3",
              "Nf3",
              "g2",
              "c7",
              "Nc4",
              "Ng1",
              "Nxa3",
              "Kc3",
              "Nb5+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 273,
            "completion_tokens": 88,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 273,
            "completion_tokens": 640,
            "total_tokens": 913,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 272,
            "completion_tokens": 640,
            "total_tokens": 912,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 818,
          "total_completion_tokens": 1368,
          "total_tokens": 2186
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 273,
            "completion_tokens": 88,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 273,
            "completion_tokens": 640,
            "total_tokens": 913,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 272,
            "completion_tokens": 640,
            "total_tokens": 912,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1q2k/pp4pp/2n5/1Q6/8/2P2N2/P2N1KPP/5R2 b - - 0 20"
    },
    {
      "turn": 42,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxc3+",
          "aggressive_uci": null,
          "aggressive_response": "21... Qxc3+ 22. Kf2 Bg4 23. Qxb7 Rf8 24. Kg1 Nd4 25. Qe4 Bxf3 26. Nxf3 Nxf3+ 27. gxf3 h6 28. Rf2 Qc1+ 29. Kg2 Qg5+ 30. Qg4 Qd5 31. Qe4 Qg5+ 32. Qg4 Qd5 33. Qe4 Qg5+ 34. Qg4 Qd5 35. Qe4 Qg5+ 36. Qg4 Qd5 37. Qe4 Qg5+ 38. Qg4 Qd5 39. Qe4 Qg5+ 40. Qg4 Qd5 41. Qe4 Qg5+ 42. Qg4 Qd5 43. Qe4 Qg5+ 44. Qg4 Qd5 45. Qe4 Qg5+ 46. Qg4 Qd5 47. Qe4 Qg5+ 48. Qg4 Qd5 49. Qe4 Qg5+ 50. Qg4 Qd5 51. Qe4 Qg5+ 52. Qg4 Qd5 53. Qe4 Qg5+ 54. Qg4 Qd5 55. Qe4 Qg5+ 56. Qg4 Qd5 57. Qe4 Qg5+ 58. Qg4 Qd5 59. Qe4 Qg5+ 60. Qg4 Qd5 61. Qe4 Qg5+ 62. Qg4 Qd5 63. Qe4 Qg5+ 64. Qg4 Qd5 65. Qe4 Qg5+ 66. Qg4 Qd5 67. Qe4 Qg5+ 68. Qg4 Qd5 69. Qe4 Qg5+ 70. Qg4 Qd5 71. Qe4 Qg5+ 72. Qg4 Qd5 73. Qe4 Qg5+ 74. Qg4 Qd5 75. Qe4 Qg5+ 76. Qg4 Qd5 77. Qe4 Qg5+ 78. Qg4 Qd5 79. Qe4 Qg5+ 80. Qg4 Qd5 81. Qe4 Qg5+ 82. Qg4 Qd5 83. Qe4 Qg5+ 84. Qg4 Qd5 85. Qe4 Qg5+ 86. Qg4 Qd5 87. Qe4 Qg5+ 88. Qg4 Qd5 89",
          "aggressive_tokens": {
            "prompt_tokens": 283,
            "completion_tokens": 640,
            "total_tokens": 923,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf2",
            "Bg4",
            "Qxb7",
            "Rf8",
            "Kg1",
            "Nd4",
            "Qe4",
            "Bxf3",
            "Nxf3",
            "Nxf3+",
            "gxf3",
            "h6",
            "Rf2",
            "Qc1+",
            "Kg2",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5",
            "Qe4",
            "Qg5+",
            "Qg4",
            "Qd5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxc3+",
          "positional_uci": null,
          "positional_response": "21... Qxc3+ 22. Kf2 Bg4 23. Qxb7 Rf8 24. Kg1 Nd4 25. Qe7 Kg8 26. Qe4 Bxf3\n27. Nxf3 Nxf3+ 28. gxf3 Qc5+ 29. Kh1 Qb5 30. Rb1 Qa6 31. Qd5+ Kh8 32. Qf7 Qd6\n33. Qxa7 Qd3 34. Rb8 Qxf3+ 35. Kg1 Qf1#",
          "positional_tokens": {
            "prompt_tokens": 283,
            "completion_tokens": 132,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf2",
            "Bg4",
            "Qxb7",
            "Rf8",
            "Kg1",
            "Nd4",
            "Qe7",
            "Kg8",
            "Qe4",
            "Bxf3",
            "Nxf3",
            "Nxf3+",
            "gxf3",
            "Qc5+",
            "Kh1",
            "Qb5",
            "Rb1",
            "Qa6",
            "Qd5+",
            "Kh8",
            "Qf7",
            "Qd6",
            "Qxa7",
            "Qd3",
            "Rb8",
            "Qxf3+",
            "Kg1",
            "Qf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bd7",
          "neutral_uci": "c8d7",
          "neutral_response": "21... Bd7 22. Qxb7 Re8+ 23. Kf2 Ne5 24. Nxe5 Rxe5 25. Qxd7 Rf5+ 26. Qxf5 g6\n27. Qf8#",
          "neutral_tokens": {
            "prompt_tokens": 282,
            "completion_tokens": 56,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxb7",
            "Re8+",
            "Kf2",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Qxd7",
            "Rf5+",
            "Qxf5",
            "g6",
            "Qf8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "c8d7",
          "consensus_move": "c8d7",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf2",
              "Bg4",
              "Qxb7",
              "Rf8",
              "Kg1",
              "Nd4",
              "Qe4",
              "Bxf3",
              "Nxf3",
              "Nxf3+",
              "gxf3",
              "h6",
              "Rf2",
              "Qc1+",
              "Kg2",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5",
              "Qe4",
              "Qg5+",
              "Qg4",
              "Qd5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf2",
              "Bg4",
              "Qxb7",
              "Rf8",
              "Kg1",
              "Nd4",
              "Qe7",
              "Kg8",
              "Qe4",
              "Bxf3",
              "Nxf3",
              "Nxf3+",
              "gxf3",
              "Qc5+",
              "Kh1",
              "Qb5",
              "Rb1",
              "Qa6",
              "Qd5+",
              "Kh8",
              "Qf7",
              "Qd6",
              "Qxa7",
              "Qd3",
              "Rb8",
              "Qxf3+",
              "Kg1",
              "Qf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxb7",
              "Re8+",
              "Kf2",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Qxd7",
              "Rf5+",
              "Qxf5",
              "g6",
              "Qf8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 283,
            "completion_tokens": 640,
            "total_tokens": 923,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 283,
            "completion_tokens": 132,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 282,
            "completion_tokens": 56,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 848,
          "total_completion_tokens": 828,
          "total_tokens": 1676
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 283,
            "completion_tokens": 640,
            "total_tokens": 923,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 283,
            "completion_tokens": 132,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 282,
            "completion_tokens": 56,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b4k/pp4pp/2n5/1Q6/8/2P1KN2/P2N2PP/5R2 b - - 0 21"
    },
    {
      "turn": 44,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg4",
          "aggressive_uci": "d7g4",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Bg4 23. Ng5 Re8+ 24. Kf4 g6 25. Kxg4 Ne5+ 26. Kg3\nNxd3 27. Rf7 Re3+ 28. Ndf3 h6 29. Rh7+ Kg8 30. Rxh6 Kg7 31. Rh7+ Kf6 32. Rf7# d4\n33. cxd4 Re2 34. Rxb7 Rxa2 35. Rf7# d3 36. Ne4+ Ke6 37. Rf6+ Kd5 38. Nc3+ Kc4\n39. Nxa2 Kb3 40. Ra6 Kc2 41. Rxa7 d2 42. Nxd2 Kxd2 43. Ra6 Ke3 44. Rxg6 Ke4 45.\nh4 Kf5 46. h5 Ke5 47. h6 Kf5 48. Rg4 Kf6 49. h7 Kf7 50. h8=Q Ke6 51. Qh5 Kf6\n52. Rg6+ Kf7 53. Qh7+ Kf8 54. Rg8# d2 55. Nc3 d1=Q 56. Nxd1 Ke8 57. Ne3 Kf8\n58. Nd5 Ke8 59. Nf6+ Kf8 60. Nd7+ Ke8 61. Nf6+ Kf8 62. Nd5 Ke8 63. Qe7# d1=Q\n64. Nf6# d2 65. Qe8# d1=Q 66. Qe7# d2 67. Qe8# d1=Q 68. Qe7# d2 69. Qe8# d1=Q\n70. Qe7# d2 71. Qe8# d1=Q 72. Qe7# d2 73. Qe8# d1=Q",
          "aggressive_tokens": {
            "prompt_tokens": 291,
            "completion_tokens": 640,
            "total_tokens": 931,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ng5",
            "Re8+",
            "Kf4",
            "g6",
            "Kxg4",
            "Ne5+",
            "Kg3",
            "Nxd3",
            "Rf7",
            "Re3+",
            "Ndf3",
            "h6",
            "Rh7+",
            "Kg8",
            "Rxh6",
            "Kg7",
            "Rh7+",
            "Kf6",
            "Rf7#",
            "d4",
            "cxd4",
            "Re2",
            "Rxb7",
            "Rxa2",
            "Rf7#",
            "d3",
            "Ne4+",
            "Ke6",
            "Rf6+",
            "Kd5",
            "Nc3+",
            "Kc4",
            "Nxa2",
            "Kb3",
            "Ra6",
            "Kc2",
            "Rxa7",
            "d2",
            "Nxd2",
            "Kxd2",
            "Ra6",
            "Ke3",
            "Rxg6",
            "Ke4",
            "h4",
            "Kf5",
            "h5",
            "Ke5",
            "h6",
            "Kf5",
            "Rg4",
            "Kf6",
            "h7",
            "Kf7",
            "h8=Q",
            "Ke6",
            "Qh5",
            "Kf6",
            "Rg6+",
            "Kf7",
            "Qh7+",
            "Kf8",
            "Rg8#",
            "d2",
            "Nc3",
            "d1=Q",
            "Nxd1",
            "Ke8",
            "Ne3",
            "Kf8",
            "Nd5",
            "Ke8",
            "Nf6+",
            "Kf8",
            "Nd7+",
            "Ke8",
            "Nf6+",
            "Kf8",
            "Nd5",
            "Ke8",
            "Qe7#",
            "d1=Q",
            "Nf6#",
            "d2",
            "Qe8#",
            "d1=Q",
            "Qe7#",
            "d2",
            "Qe8#",
            "d1=Q",
            "Qe7#",
            "d2",
            "Qe8#",
            "d1=Q",
            "Qe7#",
            "d2",
            "Qe8#",
            "d1=Q",
            "Qe7#",
            "d2",
            "Qe8#",
            "d1=Q"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8+",
          "positional_uci": "a8e8",
          "positional_response": "22... Re8+ 23. Kf2 Ne5 24. Nxe5 Rxe5 25. Qxd7 h6 26. Qd8+ Kh7 27. Qd3+ Kg8 28. Qd8+ Kh7 29. Qd3+ Kg8 30. Qd8+ Kh7 31. Qd3+ Kg8 32. Qd8+ Kh7 33. Qd3+ Kg8 34. Qd8+ Kh7 35. Qd3+ Kg8 36. Qd8+ Kh7 37. Qd3+ Kg8 38. Qd8+ Kh7 39. Qd3+ Kg8 40. Qd8+ Kh7 41. Qd3+ Kg8 42. Qd8+ Kh7 43. Qd3+ Kg8 44. Qd8+ Kh7 45. Qd3+ Kg8 46. Qd8+ Kh7 47. Qd3+ Kg8 48. Qd8+ Kh7 49. Qd3+ Kg8 50. Qd8+ Kh7 51. Qd3+ Kg8 52. Qd8+ Kh7 53. Qd3+ Kg8 54. Qd8+ Kh7 55. Qd3+ Kg8 56. Qd8+ Kh7 57. Qd3+ Kg8 58. Qd8+ Kh7 59. Qd3+ Kg8 60. Qd8+ Kh7 61. Qd3+ Kg8 62. Qd8+ Kh7 63. Qd3+ Kg8 64. Qd8+ Kh7 65. Qd3+ Kg8 66. Qd8+ Kh7 67. Qd3+ Kg8 68. Qd8+ Kh7 69. Qd3+ Kg8 70. Qd8+ Kh7 71. Qd3+ Kg8 72. Qd8+ Kh7 73. Qd3+ Kg8 74. Qd8+ Kh7 75. Qd3+ Kg8 76. Qd8+ Kh7 77. Qd3+ Kg8 78. Qd8+ Kh7 79. Qd3+ Kg8 80. Qd8+ Kh7 81. Qd3+ Kg8 82. Qd8+ Kh7 83. Qd3+ Kg8 84. Qd8+ Kh7 85. Qd3+ Kg8 86. Qd8+ Kh7 87. Qd3+ Kg8 88. Qd8+ Kh7 89. Qd3+ Kg8 90. Qd8+ Kh7 91. Qd3+ Kg8 92. Qd8+ Kh7 93. Qd3",
          "positional_tokens": {
            "prompt_tokens": 291,
            "completion_tokens": 640,
            "total_tokens": 931,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf2",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Qxd7",
            "h6",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": "a8e8",
          "neutral_response": "Re8+ 23. Kf2 Bg4 24. Re1 Rf8 25. Qd6 Kg8 26.\nQd5+ Kh8 27. Qd6 Kg8 28. Qd5+ Kh8 29. Qd6 Kg8 30. Qd5+ Kh8 31. Qd6 Kg8 32. Qd5+ Kh8\n33. Qd6 Kg8 34. Qd5+ Kh8 35. Qd6 Kg8 36. Qd5+ Kh8 37. Qd6 Kg8 38. Qd5+ Kh8 39.\nQd6 Kg8 40. Qd5+ Kh8 41. Qd6 Kg8 42. Qd5+ Kh8 43. Qd6 Kg8 44. Qd5+ Kh8 45. Qd6 Kg8\n46. Qd5+ Kh8 47. Qd6 Kg8 48. Qd5+ Kh8 49. Qd6 Kg8 50. Qd5+ Kh8 51. Qd6 Kg8 52.\nQd5+ Kh8 53. Qd6 Kg8 54. Qd5+ Kh8 55. Qd6 Kg8 56. Qd5+ Kh8 57. Qd6 Kg8 58. Qd5+ Kh8\n59. Qd6 Kg8 60. Qd5+ Kh8 61. Qd6 Kg8 62. Qd5+ Kh8 63. Qd6 Kg8 64. Qd5+ Kh8 65.\nQd6 Kg8 66. Qd5+ Kh8 67. Qd6 Kg8 68. Qd5+ Kh8 69. Qd6 Kg8 70. Qd5+ Kh8 71. Qd6 Kg8\n72. Qd5+ Kh8 73. Qd6 Kg8 74. Qd5+ Kh8 75. Qd6 Kg8 76. Qd5+ Kh8 77. Qd6 Kg8 78.\nQd5+ Kh8 79. Qd6 Kg8 80. Qd5+ Kh8 81. Qd6 Kg8 82. Qd5+ Kh8 83. Qd6 Kg8 84. Qd5+ Kh8\n85. Qd6 Kg8 86. Qd5+ Kh8 87. Qd6 Kg8 88. Qd5+ Kh8 89. Qd6 Kg8 90. Qd5+ Kh8 91.\nQd6 Kg8 92. Qd5+ Kh8 93. Qd6 Kg8 94. Qd5+ Kh8 95. Qd6 Kg8 96. Qd5+ Kh8 97. Qd6 Kg8",
          "neutral_tokens": {
            "prompt_tokens": 290,
            "completion_tokens": 640,
            "total_tokens": 930,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf2",
            "Bg4",
            "Re1",
            "Rf8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8",
            "Qd5+",
            "Kh8",
            "Qd6",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7g4",
          "positional_uci": "a8e8",
          "neutral_uci": "a8e8",
          "consensus_move": "a8e8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ng5",
              "Re8+",
              "Kf4",
              "g6",
              "Kxg4",
              "Ne5+",
              "Kg3",
              "Nxd3",
              "Rf7",
              "Re3+",
              "Ndf3",
              "h6",
              "Rh7+",
              "Kg8",
              "Rxh6",
              "Kg7",
              "Rh7+",
              "Kf6",
              "Rf7#",
              "d4",
              "cxd4",
              "Re2",
              "Rxb7",
              "Rxa2",
              "Rf7#",
              "d3",
              "Ne4+",
              "Ke6",
              "Rf6+",
              "Kd5",
              "Nc3+",
              "Kc4",
              "Nxa2",
              "Kb3",
              "Ra6",
              "Kc2",
              "Rxa7",
              "d2",
              "Nxd2",
              "Kxd2",
              "Ra6",
              "Ke3",
              "Rxg6",
              "Ke4",
              "h4",
              "Kf5",
              "h5",
              "Ke5",
              "h6",
              "Kf5",
              "Rg4",
              "Kf6",
              "h7",
              "Kf7",
              "h8=Q",
              "Ke6",
              "Qh5",
              "Kf6",
              "Rg6+",
              "Kf7",
              "Qh7+",
              "Kf8",
              "Rg8#",
              "d2",
              "Nc3",
              "d1=Q",
              "Nxd1",
              "Ke8",
              "Ne3",
              "Kf8",
              "Nd5",
              "Ke8",
              "Nf6+",
              "Kf8",
              "Nd7+",
              "Ke8",
              "Nf6+",
              "Kf8",
              "Nd5",
              "Ke8",
              "Qe7#",
              "d1=Q",
              "Nf6#",
              "d2",
              "Qe8#",
              "d1=Q",
              "Qe7#",
              "d2",
              "Qe8#",
              "d1=Q",
              "Qe7#",
              "d2",
              "Qe8#",
              "d1=Q",
              "Qe7#",
              "d2",
              "Qe8#",
              "d1=Q",
              "Qe7#",
              "d2",
              "Qe8#",
              "d1=Q"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf2",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Qxd7",
              "h6",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf2",
              "Bg4",
              "Re1",
              "Rf8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8",
              "Qd5+",
              "Kh8",
              "Qd6",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 291,
            "completion_tokens": 640,
            "total_tokens": 931,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 291,
            "completion_tokens": 640,
            "total_tokens": 931,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 290,
            "completion_tokens": 640,
            "total_tokens": 930,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 872,
          "total_completion_tokens": 1920,
          "total_tokens": 2792
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 291,
            "completion_tokens": 640,
            "total_tokens": 931,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 291,
            "completion_tokens": 640,
            "total_tokens": 931,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 290,
            "completion_tokens": 640,
            "total_tokens": 930,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r6k/pp1b2pp/2n5/8/8/2PQKN2/P2N2PP/5R2 b - - 2 22"
    },
    {
      "turn": 46,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "c6e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Nxe5 Rxe5 25. Qxd7 h6 26.\nQd8+ Kh7 27. Qd3+ Kg8 28. Qd8+ Kh7 29. Qd3+ Kg8 30. Qd8+ Kh7 31. Qd3+ Kg8 32.\nQd8+ Kh7 33. Qd3+ Kg8 34. Qd8+ Kh7 35. Qd3+ Kg8 36. Qd8+ Kh7 37. Qd3+ Kg8 38.\nQd8+ Kh7 39. Qd3+ Kg8 40. Qd8+ Kh7 41. Qd3+ Kg8 42. Qd8+ Kh7 43. Qd3+ Kg8 44.\nQd8+ Kh7 45. Qd3+ Kg8 46. Qd8+ Kh7 47. Qd3+ Kg8 48. Qd8+ Kh7 49. Qd3+ Kg8 50.\nQd8+ Kh7 51. Qd3+ Kg8 52. Qd8+ Kh7 53. Qd3+ Kg8 54. Qd8+ Kh7 55. Qd3+ Kg8 56.\nQd8+ Kh7 57. Qd3+ Kg8 58. Qd8+ Kh7 59. Qd3+ Kg8 60. Qd8+ Kh7 61. Qd3+ Kg8 62.\nQd8+ Kh7 63. Qd3+ Kg8 64. Qd8+ Kh7 65. Qd3+ Kg8 66. Qd8+ Kh7 67. Qd3+ Kg8 68.\nQd8+ Kh7 69. Qd3+ Kg8 70. Qd8+ Kh7 71. Qd3+ Kg8 72. Qd8+ Kh7 73. Qd3+",
          "aggressive_tokens": {
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "Rxe5",
            "Qxd7",
            "h6",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "c6e5",
          "positional_response": "23... Ne5 24. Nxe5 Rxe5 25. Qxd7 h6 26. Qd8+ Kh7 27. Qd3+ Kg8 28. Qd8+ Kh7 29. Qd3+ Kg8 30. Qd8+ Kh7 31. Qd3+ Kg8 32. Qd8+ Kh7 33. Qd3+ Kg8 34. Qd8+ Kh7 35. Qd3+ Kg8 36. Qd8+ Kh7 37. Qd3+ Kg8 38. Qd8+ Kh7 39. Qd3+ Kg8 40. Qd8+ Kh7 41. Qd3+ Kg8 42. Qd8+ Kh7 43. Qd3+ Kg8 44. Qd8+ Kh7 45. Qd3+ Kg8 46. Qd8+ Kh7 47. Qd3+ Kg8 48. Qd8+ Kh7 49. Qd3+ Kg8 50. Qd8+ Kh7 51. Qd3+ Kg8 52. Qd8+ Kh7 53. Qd3+ Kg8 54. Qd8+ Kh7 55. Qd3+ Kg8 56. Qd8+ Kh7 57. Qd3+ Kg8 58. Qd8+ Kh7 59. Qd3+ Kg8 60. Qd8+ Kh7 61. Qd3+ Kg8 62. Qd8+ Kh7 63. Qd3+ Kg8 64. Qd8+ Kh7 65. Qd3+ Kg8 66. Qd8+ Kh7 67. Qd3+ Kg8 68. Qd8+ Kh7 69. Qd3+ Kg8 70. Qd8+ Kh7 71. Qd3+ Kg8 72. Qd8+ Kh7 73. Qd3+ Kg8 74. Qd8+ Kh7 75. Qd3+ Kg8 76. Qd8+ Kh7 77. Qd3+ Kg8 78. Qd8+ Kh7 79. Qd3+ Kg8 80. Qd8+ Kh7 81. Qd3+ Kg8 82. Qd8+ Kh7 83. Qd3+ Kg8 84. Qd8+ Kh7 85. Qd3+ Kg8 86. Qd8+ Kh7 87. Qd3+ Kg8 88. Qd8+ Kh7 89. Qd3+ Kg8 90. Qd8+ Kh7 91. Qd3+ Kg8 92. Qd8+ Kh7 93. Qd3+ Kg8 94. Qd8",
          "positional_tokens": {
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "Rxe5",
            "Qxd7",
            "h6",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": "c6e5",
          "neutral_response": "23... Ne5 24. Nxe5 Rxe5 25. Qxd7 h6 26. Qd8+ Kh7 27. Qd3+ Kg8 28. Qd8+ Kh7 29. Qd3+ Kg8 30. Qd8+ Kh7 31. Qd3+ Kg8 32. Qd8+ Kh7 33. Qd3+ Kg8 34. Qd8+ Kh7 35. Qd3+ Kg8 36. Qd8+ Kh7 37. Qd3+ Kg8 38. Qd8+ Kh7 39. Qd3+ Kg8 40. Qd8+ Kh7 41. Qd3+ Kg8 42. Qd8+ Kh7 43. Qd3+ Kg8 44. Qd8+ Kh7 45. Qd3+ Kg8 46. Qd8+ Kh7 47. Qd3+ Kg8 48. Qd8+ Kh7 49. Qd3+ Kg8 50. Qd8+ Kh7 51. Qd3+ Kg8 52. Qd8+ Kh7 53. Qd3+ Kg8 54. Qd8+ Kh7 55. Qd3+ Kg8 56. Qd8+ Kh7 57. Qd3+ Kg8 58. Qd8+ Kh7 59. Qd3+ Kg8 60. Qd8+ Kh7 61. Qd3+ Kg8 62. Qd8+ Kh7 63. Qd3+ Kg8 64. Qd8+ Kh7 65. Qd3+ Kg8 66. Qd8+ Kh7 67. Qd3+ Kg8 68. Qd8+ Kh7 69. Qd3+ Kg8 70. Qd8+ Kh7 71. Qd3+ Kg8 72. Qd8+ Kh7 73. Qd3+ Kg8 74. Qd8+ Kh7 75. Qd3+ Kg8 76. Qd8+ Kh7 77. Qd3+ Kg8 78. Qd8+ Kh7 79. Qd3+ Kg8 80. Qd8+ Kh7 81. Qd3+ Kg8 82. Qd8+ Kh7 83. Qd3+ Kg8 84. Qd8+ Kh7 85. Qd3+ Kg8 86. Qd8+ Kh7 87. Qd3+ Kg8 88. Qd8+ Kh7 89. Qd3+ Kg8 90. Qd8+ Kh7 91. Qd3+ Kg8 92. Qd8+ Kh7 93. Qd3+ Kg8 94. Qd8",
          "neutral_tokens": {
            "prompt_tokens": 299,
            "completion_tokens": 640,
            "total_tokens": 939,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "Rxe5",
            "Qxd7",
            "h6",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6e5",
          "positional_uci": "c6e5",
          "neutral_uci": "c6e5",
          "consensus_move": "c6e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe5",
              "Rxe5",
              "Qxd7",
              "h6",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxe5",
              "Rxe5",
              "Qxd7",
              "h6",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxe5",
              "Rxe5",
              "Qxd7",
              "h6",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 299,
            "completion_tokens": 640,
            "total_tokens": 939,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 899,
          "total_completion_tokens": 1920,
          "total_tokens": 2819
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 299,
            "completion_tokens": 640,
            "total_tokens": 939,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "4r2k/pp1b2pp/2n5/8/8/2PQ1N2/P2N1KPP/5R2 b - - 4 23"
    },
    {
      "turn": 48,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ng4+",
          "aggressive_uci": "e5g4",
          "aggressive_response": "24... Ng4+ 25. Kg1 Ne3 26. Re1 Bc6 27. Qd3 Ng4 28. Rxe8+ Bxe8 29. Qd8 Nf6 30. Ne4 Kg8 31. Nxf6+ gxf6 32. Qxe8+ Kg7 33. Qe7+ Kg6 34. Qxb7 Kf5 35. Qxa7 Ke4 36. Qxh7+ Ke3 37. Qf5 Ke2 38. Qxf6 Kd1 39. c4 Kc2 40. c5 Kb1 41. c6 Kxa2 42. c7 Kb3 43. c8=Q Ka4 44. Qb6 Ka3 45. Qa8#",
          "aggressive_tokens": {
            "prompt_tokens": 308,
            "completion_tokens": 181,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe8+",
            "Bxe8",
            "Qd8",
            "Nf6",
            "Ne4",
            "Kg8",
            "Nxf6+",
            "gxf6",
            "Qxe8+",
            "Kg7",
            "Qe7+",
            "Kg6",
            "Qxb7",
            "Kf5",
            "Qxa7",
            "Ke4",
            "Qxh7+",
            "Ke3",
            "Qf5",
            "Ke2",
            "Qxf6",
            "Kd1",
            "c4",
            "Kc2",
            "c5",
            "Kb1",
            "c6",
            "Kxa2",
            "c7",
            "Kb3",
            "c8=Q",
            "Ka4",
            "Qb6",
            "Ka3",
            "Qa8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ng4+",
          "positional_uci": "e5g4",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26. Re1 Bc6 27. Qd3 Ng4 28. Rxe8+ Bxe8 29. Qd8 Nf6 30. Ne4 Kg8 31. Nxf6+ gxf6 32. Qxe8+ Kg7 33. Qe7+ Kg6 34. Qxb7 Kf5 35. Qxa7 Ke4 36. Qxh7+ Ke3 37. Qf5 Ke2 38. Qxf6 Kd1 39. c4 Kc2 40. c5 Kb1 41. c6 Kxa2 42. c7 Kb3 43. c8=Q Ka4 44. Qb6 Ka3 45. Qa8#",
          "positional_tokens": {
            "prompt_tokens": 308,
            "completion_tokens": 377,
            "total_tokens": 685,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe8+",
            "Bxe8",
            "Qd8",
            "Nf6",
            "Ne4",
            "Kg8",
            "Nxf6+",
            "gxf6",
            "Qxe8+",
            "Kg7",
            "Qe7+",
            "Kg6",
            "Qxb7",
            "Kf5",
            "Qxa7",
            "Ke4",
            "Qxh7+",
            "Ke3",
            "Qf5",
            "Ke2",
            "Qxf6",
            "Kd1",
            "c4",
            "Kc2",
            "c5",
            "Kb1",
            "c6",
            "Kxa2",
            "c7",
            "Kb3",
            "c8=Q",
            "Ka4",
            "Qb6",
            "Ka3",
            "Qa8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ng4+",
          "neutral_uci": "e5g4",
          "neutral_response": "24... Ng4+ 25. Kg1 Ne3 26. Re1 Bc6 27. Qd3 Ng4 28. Rxe8+ Bxe8 29. Qd8 Nf6 30. Ne4 Kg8 31. Nxf6+ gxf6 32. Qxe8+ Kg7 33. Qe7+ Kg6 34. Qxb7 Kf5 35. Qxa7 Ke4 36. Qxh7+ Ke3 37. Qf5 Ke2 38. Qxf6 Kd1 39. c4 Kc2 40. c5 Kb1 41. c6 Kxa2 42. c7 Kb3 43. c8=Q Ka4 44. Qb6 Ka3 45. Qa8#",
          "neutral_tokens": {
            "prompt_tokens": 307,
            "completion_tokens": 181,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe8+",
            "Bxe8",
            "Qd8",
            "Nf6",
            "Ne4",
            "Kg8",
            "Nxf6+",
            "gxf6",
            "Qxe8+",
            "Kg7",
            "Qe7+",
            "Kg6",
            "Qxb7",
            "Kf5",
            "Qxa7",
            "Ke4",
            "Qxh7+",
            "Ke3",
            "Qf5",
            "Ke2",
            "Qxf6",
            "Kd1",
            "c4",
            "Kc2",
            "c5",
            "Kb1",
            "c6",
            "Kxa2",
            "c7",
            "Kb3",
            "c8=Q",
            "Ka4",
            "Qb6",
            "Ka3",
            "Qa8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5g4",
          "positional_uci": "e5g4",
          "neutral_uci": "e5g4",
          "consensus_move": "e5g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxe8+",
              "Bxe8",
              "Qd8",
              "Nf6",
              "Ne4",
              "Kg8",
              "Nxf6+",
              "gxf6",
              "Qxe8+",
              "Kg7",
              "Qe7+",
              "Kg6",
              "Qxb7",
              "Kf5",
              "Qxa7",
              "Ke4",
              "Qxh7+",
              "Ke3",
              "Qf5",
              "Ke2",
              "Qxf6",
              "Kd1",
              "c4",
              "Kc2",
              "c5",
              "Kb1",
              "c6",
              "Kxa2",
              "c7",
              "Kb3",
              "c8=Q",
              "Ka4",
              "Qb6",
              "Ka3",
              "Qa8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxe8+",
              "Bxe8",
              "Qd8",
              "Nf6",
              "Ne4",
              "Kg8",
              "Nxf6+",
              "gxf6",
              "Qxe8+",
              "Kg7",
              "Qe7+",
              "Kg6",
              "Qxb7",
              "Kf5",
              "Qxa7",
              "Ke4",
              "Qxh7+",
              "Ke3",
              "Qf5",
              "Ke2",
              "Qxf6",
              "Kd1",
              "c4",
              "Kc2",
              "c5",
              "Kb1",
              "c6",
              "Kxa2",
              "c7",
              "Kb3",
              "c8=Q",
              "Ka4",
              "Qb6",
              "Ka3",
              "Qa8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe8+",
              "Bxe8",
              "Qd8",
              "Nf6",
              "Ne4",
              "Kg8",
              "Nxf6+",
              "gxf6",
              "Qxe8+",
              "Kg7",
              "Qe7+",
              "Kg6",
              "Qxb7",
              "Kf5",
              "Qxa7",
              "Ke4",
              "Qxh7+",
              "Ke3",
              "Qf5",
              "Ke2",
              "Qxf6",
              "Kd1",
              "c4",
              "Kc2",
              "c5",
              "Kb1",
              "c6",
              "Kxa2",
              "c7",
              "Kb3",
              "c8=Q",
              "Ka4",
              "Qb6",
              "Ka3",
              "Qa8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 308,
            "completion_tokens": 181,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 308,
            "completion_tokens": 377,
            "total_tokens": 685,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 307,
            "completion_tokens": 181,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 923,
          "total_completion_tokens": 739,
          "total_tokens": 1662
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 308,
            "completion_tokens": 181,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 308,
            "completion_tokens": 377,
            "total_tokens": 685,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 307,
            "completion_tokens": 181,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r2k/pp1b2pp/8/4n3/8/2P2N2/P2N1KPP/1Q3R2 b - - 6 24"
    },
    {
      "turn": 50,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne3",
          "aggressive_uci": "g4e3",
          "aggressive_response": "25... Ne3 26. Re1 Bf5 27. Qxb7 Ng4 28. Rxe8#",
          "aggressive_tokens": {
            "prompt_tokens": 316,
            "completion_tokens": 28,
            "total_tokens": 344,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1",
            "Bf5",
            "Qxb7",
            "Ng4",
            "Rxe8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne3",
          "positional_uci": "g4e3",
          "positional_response": "25... Ne3 26. Re1 Bf5 27. Qxb7 Ng4 28. Rxe8#",
          "positional_tokens": {
            "prompt_tokens": 316,
            "completion_tokens": 28,
            "total_tokens": 344,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1",
            "Bf5",
            "Qxb7",
            "Ng4",
            "Rxe8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne3",
          "neutral_uci": "g4e3",
          "neutral_response": "25... Ne3 26. Re1 Bf5 27. Qxb7 Ng4 28. Rxe8#",
          "neutral_tokens": {
            "prompt_tokens": 315,
            "completion_tokens": 28,
            "total_tokens": 343,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1",
            "Bf5",
            "Qxb7",
            "Ng4",
            "Rxe8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4e3",
          "positional_uci": "g4e3",
          "neutral_uci": "g4e3",
          "consensus_move": "g4e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re1",
              "Bf5",
              "Qxb7",
              "Ng4",
              "Rxe8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re1",
              "Bf5",
              "Qxb7",
              "Ng4",
              "Rxe8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re1",
              "Bf5",
              "Qxb7",
              "Ng4",
              "Rxe8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 316,
            "completion_tokens": 28,
            "total_tokens": 344,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 316,
            "completion_tokens": 28,
            "total_tokens": 344,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 315,
            "completion_tokens": 28,
            "total_tokens": 343,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 947,
          "total_completion_tokens": 84,
          "total_tokens": 1031
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 316,
            "completion_tokens": 28,
            "total_tokens": 344,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 316,
            "completion_tokens": 28,
            "total_tokens": 344,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 315,
            "completion_tokens": 28,
            "total_tokens": 343,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r2k/pp1b2pp/8/8/6n1/2P2N2/P2N2PP/1Q3RK1 b - - 8 25"
    },
    {
      "turn": 52,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc6",
          "aggressive_uci": "d7c6",
          "aggressive_response": "26... Bc6 27. Re1 h6 28. Qd3 Ng4 29. Rxe8+ Bxe8 30. Qd8 Nf6 31. Ne4 Nxe4 32. Qxe8+ Kh7 33. Qxe4+ Kg8 34. Qxb7 Kh7 35. Qxa7 Kg6 36. c4 Kf5 37. c5 Ke4 38. c6 Kd3 39. c7 Ke2 40. c8=Q Kd1 41. Qad7+ Ke2 42. Qce8#",
          "aggressive_tokens": {
            "prompt_tokens": 324,
            "completion_tokens": 138,
            "total_tokens": 462,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1",
            "h6",
            "Qd3",
            "Ng4",
            "Rxe8+",
            "Bxe8",
            "Qd8",
            "Nf6",
            "Ne4",
            "Nxe4",
            "Qxe8+",
            "Kh7",
            "Qxe4+",
            "Kg8",
            "Qxb7",
            "Kh7",
            "Qxa7",
            "Kg6",
            "c4",
            "Kf5",
            "c5",
            "Ke4",
            "c6",
            "Kd3",
            "c7",
            "Ke2",
            "c8=Q",
            "Kd1",
            "Qad7+",
            "Ke2",
            "Qce8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bc6",
          "positional_uci": "d7c6",
          "positional_response": "26... Bc6 27. Re1 h6 28. Qd3 Ng4 29. Rxe8+ Bxe8 30. Qd8 Nf6 31. Ne4 Nxe4 32. Qxe8+ Kh7 33. Qxe4+ Kg8 34. Qxb7 Kh7 35. Qxa7 Kg6 36. c4 Kf5 37. c5 Ke4 38. c6 Kd3 39. c7 Ke2 40. c8=Q Kd1 41. Qad7+ Ke2 42. Qce8#",
          "positional_tokens": {
            "prompt_tokens": 324,
            "completion_tokens": 138,
            "total_tokens": 462,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1",
            "h6",
            "Qd3",
            "Ng4",
            "Rxe8+",
            "Bxe8",
            "Qd8",
            "Nf6",
            "Ne4",
            "Nxe4",
            "Qxe8+",
            "Kh7",
            "Qxe4+",
            "Kg8",
            "Qxb7",
            "Kh7",
            "Qxa7",
            "Kg6",
            "c4",
            "Kf5",
            "c5",
            "Ke4",
            "c6",
            "Kd3",
            "c7",
            "Ke2",
            "c8=Q",
            "Kd1",
            "Qad7+",
            "Ke2",
            "Qce8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rf8 Rxf2",
          "neutral_tokens": {
            "prompt_tokens": 323,
            "completion_tokens": 8,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rf8",
            "Rxf2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7c6",
          "positional_uci": "d7c6",
          "neutral_uci": null,
          "consensus_move": "d7c6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re1",
              "h6",
              "Qd3",
              "Ng4",
              "Rxe8+",
              "Bxe8",
              "Qd8",
              "Nf6",
              "Ne4",
              "Nxe4",
              "Qxe8+",
              "Kh7",
              "Qxe4+",
              "Kg8",
              "Qxb7",
              "Kh7",
              "Qxa7",
              "Kg6",
              "c4",
              "Kf5",
              "c5",
              "Ke4",
              "c6",
              "Kd3",
              "c7",
              "Ke2",
              "c8=Q",
              "Kd1",
              "Qad7+",
              "Ke2",
              "Qce8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re1",
              "h6",
              "Qd3",
              "Ng4",
              "Rxe8+",
              "Bxe8",
              "Qd8",
              "Nf6",
              "Ne4",
              "Nxe4",
              "Qxe8+",
              "Kh7",
              "Qxe4+",
              "Kg8",
              "Qxb7",
              "Kh7",
              "Qxa7",
              "Kg6",
              "c4",
              "Kf5",
              "c5",
              "Ke4",
              "c6",
              "Kd3",
              "c7",
              "Ke2",
              "c8=Q",
              "Kd1",
              "Qad7+",
              "Ke2",
              "Qce8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rf8",
              "Rxf2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 324,
            "completion_tokens": 138,
            "total_tokens": 462,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 324,
            "completion_tokens": 138,
            "total_tokens": 462,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 323,
            "completion_tokens": 8,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 971,
          "total_completion_tokens": 284,
          "total_tokens": 1255
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 324,
            "completion_tokens": 138,
            "total_tokens": 462,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 324,
            "completion_tokens": 138,
            "total_tokens": 462,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 323,
            "completion_tokens": 8,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r2k/pp1b2pp/8/8/8/2P1nN2/P2N2PP/1QR3K1 b - - 10 26"
    },
    {
      "turn": 54,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ng4",
          "aggressive_uci": "e3g4",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Ng5 Re2 29. Qxh7#",
          "aggressive_tokens": {
            "prompt_tokens": 332,
            "completion_tokens": 240,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ng5",
            "Re2",
            "Qxh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re6",
          "positional_uci": "e8e6",
          "positional_response": "27... Re6 28. Ng5 Rg6 29. Ndf3 h6 30. Qxg6 hxg5 31. Nxg5 Kg8 32. Qf7+ Kh8 33. Qf8#",
          "positional_tokens": {
            "prompt_tokens": 332,
            "completion_tokens": 55,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ng5",
            "Rg6",
            "Ndf3",
            "h6",
            "Qxg6",
            "hxg5",
            "Nxg5",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ng4",
          "neutral_uci": "e3g4",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Ng5 Re2 29. Qxh7#",
          "neutral_tokens": {
            "prompt_tokens": 331,
            "completion_tokens": 240,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ng5",
            "Re2",
            "Qxh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e3g4",
          "positional_uci": "e8e6",
          "neutral_uci": "e3g4",
          "consensus_move": "e3g4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ng5",
              "Re2",
              "Qxh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ng5",
              "Rg6",
              "Ndf3",
              "h6",
              "Qxg6",
              "hxg5",
              "Nxg5",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ng5",
              "Re2",
              "Qxh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 332,
            "completion_tokens": 240,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 332,
            "completion_tokens": 55,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 331,
            "completion_tokens": 240,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 995,
          "total_completion_tokens": 535,
          "total_tokens": 1530
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 332,
            "completion_tokens": 240,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 332,
            "completion_tokens": 55,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 331,
            "completion_tokens": 240,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r2k/pp4pp/2b5/8/7P/2P1nN2/P2N2P1/1QR3K1 b - - 0 27"
    },
    {
      "turn": 56,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf8",
          "aggressive_uci": "e8f8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Re1 Rf8 29. Ng5 g6 30. Re7 Nf6 31. Nde4 Nxe4 32. Nxe4\nKg8 33. Qb3+ Kh8 34. Ng5 Bd5 35. Qxd5 Rf1+ 36. Kxf1 h6 37. Rh7#",
          "aggressive_tokens": {
            "prompt_tokens": 339,
            "completion_tokens": 307,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ng5",
            "g6",
            "Re7",
            "Nf6",
            "Nde4",
            "Nxe4",
            "Nxe4",
            "Kg8",
            "Qb3+",
            "Kh8",
            "Ng5",
            "Bd5",
            "Qxd5",
            "Rf1+",
            "Kxf1",
            "h6",
            "Rh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd8",
          "positional_uci": "e8d8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Re1 Rd8 29. Ng5 Rxd2 30. Qxh7#",
          "positional_tokens": {
            "prompt_tokens": 339,
            "completion_tokens": 248,
            "total_tokens": 587,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ng5",
            "Rxd2",
            "Qxh7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd8",
          "neutral_uci": "e8d8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Re1 Rd8 29. Ng5 Rxd2 30. Qxh7#",
          "neutral_tokens": {
            "prompt_tokens": 338,
            "completion_tokens": 248,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ng5",
            "Rxd2",
            "Qxh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8f8",
          "positional_uci": "e8d8",
          "neutral_uci": "e8d8",
          "consensus_move": "e8d8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ng5",
              "g6",
              "Re7",
              "Nf6",
              "Nde4",
              "Nxe4",
              "Nxe4",
              "Kg8",
              "Qb3+",
              "Kh8",
              "Ng5",
              "Bd5",
              "Qxd5",
              "Rf1+",
              "Kxf1",
              "h6",
              "Rh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ng5",
              "Rxd2",
              "Qxh7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ng5",
              "Rxd2",
              "Qxh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 339,
            "completion_tokens": 307,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 339,
            "completion_tokens": 248,
            "total_tokens": 587,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 338,
            "completion_tokens": 248,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1016,
          "total_completion_tokens": 803,
          "total_tokens": 1819
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 339,
            "completion_tokens": 307,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 339,
            "completion_tokens": 248,
            "total_tokens": 587,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 338,
            "completion_tokens": 248,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4r2k/pp4pp/2b5/8/6nP/2P2N2/P2N2P1/1Q2R1K1 b - - 2 28"
    },
    {
      "turn": 58,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd3",
          "aggressive_uci": "d8d3",
          "aggressive_response": "29... Rd3 30. Qxd3 Bxf3 31. Qd8#",
          "aggressive_tokens": {
            "prompt_tokens": 346,
            "completion_tokens": 21,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd3",
            "Bxf3",
            "Qd8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd3",
          "positional_uci": "d8d3",
          "positional_response": "29... Rd3 30. Qxd3 Bxf3 31. Qd8#",
          "positional_tokens": {
            "prompt_tokens": 346,
            "completion_tokens": 21,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd3",
            "Bxf3",
            "Qd8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": "d8e8",
          "neutral_response": "Re8 30. Rxe8+ Bxe8 31. Qe4 Bc6 32.\nQxg4 h6 33. Qc8+ Kh7 34. Qf5+ Kh8 35. Qf8+ Kh7 36. Qf5+ Kh8 37. Qf8+ Kh7\n38. Qf5+ Kh8 39. Qf8+ Kh7 40. Qf5+ Kh8 41. Qf8+ Kh7 42. Qf5+ Kh8 43. Qf8+ Kh7\n44. Qf5+ Kh8 45. Qf8+ Kh7 46. Qf5+ Kh8 47. Qf8+ Kh7 48. Qf5+ Kh8 49. Qf8+ Kh7\n50. Qf5+ Kh8 51. Qf8+ Kh7 52. Qf5+ Kh8 53. Qf8+ Kh7 54. Qf5+ Kh8 55. Qf8+ Kh7\n56. Qf5+ Kh8 57. Qf8+ Kh7 58. Qf5+ Kh8 59. Qf8+ Kh7 60. Qf5+ Kh8 61. Qf8+ Kh7\n62. Qf5+ Kh8 63. Qf8+ Kh7 64. Qf5+ Kh8 65. Qf8+ Kh7 66. Qf5+ Kh8 67. Qf8+ Kh7\n68. Qf5+ Kh8 69. Qf8+ Kh7 70. Qf5+ Kh8 71. Qf8+ Kh7 72. Qf5+ Kh8 73. Qf8+ Kh7\n74. Qf5+ Kh8 75. Qf8+ Kh7 76. Qf5+ Kh8 77. Qf8+ Kh7 78. Qf5+ Kh8 79. Qf8+ Kh7\n80. Qf5+ Kh8 81. Qf8+ Kh7 82. Qf5+ Kh8 83. Qf8+ Kh7 84. Qf5+ Kh8 85. Qf8+ Kh7\n86. Qf5+ Kh8 87. Qf8+ Kh7 88. Qf5+ Kh8 89. Qf8+ Kh7 90. Qf5+ Kh8 91. Qf8+ Kh7\n92. Qf5+ Kh8 93. Qf8+ Kh7 94. Qf5+ Kh8 95. Qf8+ Kh7 96. Qf5+ Kh8 97. Qf8+ Kh7\n98. Qf5+ Kh8 99. Qf8+ Kh7 100. Qf5+",
          "neutral_tokens": {
            "prompt_tokens": 345,
            "completion_tokens": 640,
            "total_tokens": 985,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxe8+",
            "Bxe8",
            "Qe4",
            "Bc6",
            "Qxg4",
            "h6",
            "Qc8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf5+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8d3",
          "positional_uci": "d8d3",
          "neutral_uci": "d8e8",
          "consensus_move": "d8d3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxd3",
              "Bxf3",
              "Qd8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxd3",
              "Bxf3",
              "Qd8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe8+",
              "Bxe8",
              "Qe4",
              "Bc6",
              "Qxg4",
              "h6",
              "Qc8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf5+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 346,
            "completion_tokens": 21,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 346,
            "completion_tokens": 21,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 345,
            "completion_tokens": 640,
            "total_tokens": 985,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1037,
          "total_completion_tokens": 682,
          "total_tokens": 1719
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 57,
            "turn_number": 29,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 346,
            "completion_tokens": 21,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 57,
            "turn_number": 29,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 346,
            "completion_tokens": 21,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 57,
            "turn_number": 29,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 345,
            "completion_tokens": 640,
            "total_tokens": 985,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3r3k/pp4pp/2b5/8/6nP/1NP2N2/P5P1/1Q2R1K1 b - - 4 29"
    },
    {
      "turn": 60,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne3",
          "aggressive_uci": "g4e3",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Re1 Rd8 29. Nb3 Rd3 30. Qxd3 Ne3 31. Qd8+ Be8 32. Qxe8#",
          "aggressive_tokens": {
            "prompt_tokens": 354,
            "completion_tokens": 263,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8+",
            "Be8",
            "Qxe8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne3",
          "positional_uci": "g4e3",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Re1 Rd8 29. Nb3 Rd3 30. Qxd3 Ne3 31. Qd8+ Be8 32. Qxe8#",
          "positional_tokens": {
            "prompt_tokens": 354,
            "completion_tokens": 263,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8+",
            "Be8",
            "Qxe8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne3",
          "neutral_uci": "g4e3",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Re1 Rd8 29. Nb3 Rd3 30. Qxd3 Ne3 31. Qd8+ Be8 32. Qxe8#",
          "neutral_tokens": {
            "prompt_tokens": 353,
            "completion_tokens": 263,
            "total_tokens": 616,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8+",
            "Be8",
            "Qxe8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4e3",
          "positional_uci": "g4e3",
          "neutral_uci": "g4e3",
          "consensus_move": "g4e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd8+",
              "Be8",
              "Qxe8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd8+",
              "Be8",
              "Qxe8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd8+",
              "Be8",
              "Qxe8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 354,
            "completion_tokens": 263,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 354,
            "completion_tokens": 263,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 353,
            "completion_tokens": 263,
            "total_tokens": 616,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1061,
          "total_completion_tokens": 789,
          "total_tokens": 1850
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 59,
            "turn_number": 30,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 354,
            "completion_tokens": 263,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 59,
            "turn_number": 30,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 354,
            "completion_tokens": 263,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 59,
            "turn_number": 30,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 353,
            "completion_tokens": 263,
            "total_tokens": 616,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "7k/pp4pp/2b5/8/6nP/1NPQ1N2/P5P1/4R1K1 b - - 0 30"
    },
    {
      "turn": 62,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be8",
          "aggressive_uci": "c6e8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. e3 e6 4. c4 c5 5. cxd5 exd5 6. Be2 Nc6 7. O-O Bd6 8.\ndxc5 Bxc5 9. Bd2 O-O 10. Bc3 Ne4 11. Qb3 Re8 12. Nbd2 Nxf2 13. Rxf2 Bxe3 14.\nRf1 d4 15. Bc4 dxc3 16. Bxf7+ Kh8 17. Bxe8 Bc5 18. bxc3 Qxe8 19. Qb5 Bxf2+ 20.\nKxf2 Qe3+ 21. Kxe3 Bd7 22. Qd3 Re8+ 23. Kf2 Ne5 24. Qb1 Ng4+ 25. Kg1 Ne3 26.\nRc1 Bc6 27. h4 Ng4 28. Re1 Rd8 29. Nb3 Rd3 30. Qxd3 Ne3 31. Qd8+ Be8 32. Qxe8# dxe1=Q+ 33. Nxe1 *",
          "aggressive_tokens": {
            "prompt_tokens": 363,
            "completion_tokens": 276,
            "total_tokens": 639,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe8#",
            "dxe1=Q+",
            "Nxe1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be8",
          "positional_uci": "c6e8",
          "positional_response": "31...Be8 32. Qxe8#",
          "positional_tokens": {
            "prompt_tokens": 363,
            "completion_tokens": 12,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 32. Qxe8+ Bxe8 33. Rxe3 Bf7 34. Re7 Bg8 35. Rxb7 h6 36. Rxa7 Kh7 37. Nbd4 Kg6 38. a4 Kf6 39. a5 Bc4 40. a6 Bxa6 41. Rxa6+ Kf7 42. c4 Ke7 43. c5 Kd7 44. c6+ Kc7 45. Ne5 Kd6 46. Nf7+ Kc7 47. Ne6+ Kc8 48. Ra8# Kd7 49. c7 Kxe6 50. c8=Q+ Kxf7 51. Qf5+ Ke7 52. Ra7+ Kd6 53. Ra6+ Kc7 54. Qf7+ Kb8 55. Re6 Kc8 56. Re8# Kd7 57. Qxe7+ Kc6 58. Qe5 Kd7 59. Re6 Kd8 60. Qd6+ Kc8 61. Re7 g5 62. Qc7# Kd8 63. Qd7# Kc8 64. Re8# Kd7 65. Qe6+ Kc7 66. Re7+ Kd8 67. Qd7# Kc8 68. Re8# Kd7 69. Qe6+ Kc7 70. Re7+ Kd8 71. Qd7# Kc8 72. Re8# Kd7 73. Qe6+ Kc7 74. Re7+ Kd8 75. Qd7# Kc8 76. Re8# Kd7 77. Qe6+ Kc7 78. Re7+ Kd8 79. Qd7# Kc8 80. Re8# Kd7 81. Qe6+ Kc7 82. Re7+ Kd8 83. Qd7# Kc8 84. Re8# Kd7 85. Qe6+ Kc7 86. Re7+ Kd8 87. Qd7# Kc8 88. Re8# Kd7 89. Qe6+ Kc7 90. Re7+ Kd8 91. Qd7# Kc8 92. Re8# Kd7 93. Qe6+ Kc7 94. Re7+ Kd8 95. Qd7# Kc8 96. Re8# Kd7 97. Qe6+ Kc7 98. Re7+ Kd8 99. Qd7# Kc8 100. Re8# Kd7 101. Qe6",
          "neutral_tokens": {
            "prompt_tokens": 362,
            "completion_tokens": 640,
            "total_tokens": 1002,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kd7",
            "Qe6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6e8",
          "positional_uci": "c6e8",
          "neutral_uci": null,
          "consensus_move": "c6e8",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe8#",
              "dxe1=Q+",
              "Nxe1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd7",
              "Qe6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 363,
            "completion_tokens": 276,
            "total_tokens": 639,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 363,
            "completion_tokens": 12,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 362,
            "completion_tokens": 640,
            "total_tokens": 1002,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1088,
          "total_completion_tokens": 928,
          "total_tokens": 2016
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 61,
            "turn_number": 31,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 363,
            "completion_tokens": 276,
            "total_tokens": 639,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 61,
            "turn_number": 31,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 363,
            "completion_tokens": 12,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 61,
            "turn_number": 31,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 362,
            "completion_tokens": 640,
            "total_tokens": 1002,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3Q3k/pp4pp/2b5/8/7P/1NP1nN2/P5P1/4R1K1 b - - 2 31"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 Nf6\nd4 Nf6 Nc3 d5 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Re1 Qd6 Re3 Bf5 Qe2 Bxd3 Qe1 Bb5 a4 Bc6 b4 Re8 b5 Rxe3 Qxe3 Bd7 Re1 h6 c4 Re8 Qc1 Rxe1+ Qxe1 Qe6 Qc1 Qe4 h3 Be6 c5 Qxa4 b6 axb6 cxb6 cxb6 Qxb6 Qc6 Qd8+ Kh7 Qd3+ g6 Qd8 b5 Qb8 Qc4 Qb7 Qc3 b4 Qb2 b3 Kh2 Qc7+ g3 Qc2 Qf6 b2 h4 b1=Q h5 Qf5 hxg6+ Qxg6 Qxg6+ fxg6 Kg2 Bd5+ Kh2 Qh5+ Kg1 Qh1#",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 264,
            "total_tokens": 374,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "d5",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8",
            "c3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Re1",
            "Qd6",
            "Re3",
            "Bf5",
            "Qe2",
            "Bxd3",
            "Qe1",
            "Bb5",
            "a4",
            "Bc6",
            "b4",
            "Re8",
            "b5",
            "Rxe3",
            "Qxe3",
            "Bd7",
            "Re1",
            "h6",
            "c4",
            "Re8",
            "Qc1",
            "Rxe1+",
            "Qxe1",
            "Qe6",
            "Qc1",
            "Qe4",
            "h3",
            "Be6",
            "c5",
            "Qxa4",
            "b6",
            "axb6",
            "cxb6",
            "cxb6",
            "Qxb6",
            "Qc6",
            "Qd8+",
            "Kh7",
            "Qd3+",
            "g6",
            "Qd8",
            "b5",
            "Qb8",
            "Qc4",
            "Qb7",
            "Qc3",
            "b4",
            "Qb2",
            "b3",
            "Kh2",
            "Qc7+",
            "g3",
            "Qc2",
            "Qf6",
            "b2",
            "h4",
            "b1=Q",
            "h5",
            "Qf5",
            "hxg6+",
            "Qxg6",
            "Qxg6+",
            "fxg6",
            "Kg2",
            "Bd5+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qh1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6 19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8 22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8 25. Qe7+ Kg8 26. Qg7# 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6 19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8 22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8 25. Qe7+ Kg8 26. Qg7# 1-0 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Bh6 Qe6 Nf6 Qxf6 Bxf6 Be6 Qxb7 Rc8 Rad1 Bd7 Rxd6 Nb8 Rfd1 Rc7 Qxb8+ Ke7 Qxc7 Kf7 Qxd7+ Kg8 Qe7 Kh8 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 600,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Be6",
            "Qxb7",
            "Rc8",
            "Rad1",
            "Bd7",
            "Rxd6",
            "Nb8",
            "Rfd1",
            "Rxc2",
            "Rxd7",
            "Nxd7",
            "Qxd7+",
            "Kf8",
            "Qe7+",
            "Kg8",
            "Qg7#",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Bh6",
            "Qe6",
            "Nf6",
            "Qxf6",
            "Bxf6",
            "Be6",
            "Qxb7",
            "Rc8",
            "Rad1",
            "Bd7",
            "Rxd6",
            "Nb8",
            "Rfd1",
            "Rc7",
            "Qxb8+",
            "Ke7",
            "Qxc7",
            "Kf7",
            "Qxd7+",
            "Kg8",
            "Qe7",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 Nf6\nd4 Nf6 Nc3 d5 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Re1 Qd6 Re3 Bf5 Qe2 Bxd3 Qe1 Bb5 a4 Bc6 b4 Qd5 f3 Re8 b5 Rxe3 Qxe3 Re8 Qxa7 Bd7 Qf2 Qd3 Rc1 Re2 Qg3 Qe3+ Kf1 Qxc1+ Kxe2 Qxc3 Qf4 Qc2+ Ke3 Qc1+ Ke4 Qxf4+ Kxf4 Kf8 Ke5 Ke7 Kd5 Be6+ Kc5 Kd7 a5 Kc8 a6 bxa6 bxa6 Kb8 Kc6 Bc8 a7+ Kxa7 Kxc7 Be6 Kd6 Kb6 Ke5 Kc5 g4 Kd4 f4 Ke4 f5 Bxf5 gxf5 Kxf5 Ke7 f5 Kf7 f4 Kf6 Kf8 g5 Kg7 f4 Kf6 Kf8 g4 Kg7 f3 Kf8 g2 Kg7 f1=Q+ Kg8 Qf2# Kf8 g1=Q#\nd4 Nf6 Nc3 d5 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 c3 e5 dxe5 Nxe5 Nxe5 Qxe5+ Qe2 Qxe2+ Bxe2 Re8 f3 Bf5 Kf2 Rad8 Rad1 Rxd1 Rxd1 h6 g4 Be6 b3 c6 c4 a6 h3 b5 cxb5 axb5 Rd6 Bd5 Bxb5 Bxf3 Bxc6 Bxc6 Rxc6 Ra8 a4 Rb8 Rc3 Kf8 Ke3 Ke7 Kd4 Kd6 Kc4 Rc8 Kb5 Rb8+ Ka6 Kc5 Rb7 b4 Rc7+ Kb6 Rc5 Rc8+ Kd6 Rd8+ Ke7 Rd5 Rc3 b5 Rxh3 b6 Rc3+ Kb5 Rc8 b7 Rb8+ Kc6 Rc8+ Kd6 Rd8+ Ke7 Rd5 Rc3+ Kb6 Rb3+ Kc7 Rc3+ Kd6 Rd3+ Ke7 Rd5 Rc3+ Kb6 Rb3+ Kc7 Rc3+ Kd6 Rd3+ Ke7 Rd5 Rc3+ Kb6 Rb3+ Kc7 Rc3+ Kd6 Rd3+ Ke7 Rd5 Rc3+ Kb6 Rb3",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "d5",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "c3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5+",
            "Qe2",
            "Qxe2+",
            "Bxe2",
            "Re8",
            "f3",
            "Bf5",
            "Kf2",
            "Rad8",
            "Rad1",
            "Rxd1",
            "Rxd1",
            "h6",
            "g4",
            "Be6",
            "b3",
            "c6",
            "c4",
            "a6",
            "h3",
            "b5",
            "cxb5",
            "axb5",
            "Rd6",
            "Bd5",
            "Bxb5",
            "Bxf3",
            "Bxc6",
            "Bxc6",
            "Rxc6",
            "Ra8",
            "a4",
            "Rb8",
            "Rc3",
            "Kf8",
            "Ke3",
            "Ke7",
            "Kd4",
            "Kd6",
            "Kc4",
            "Rc8",
            "Kb5",
            "Rb8+",
            "Ka6",
            "Kc5",
            "Rb7",
            "b4",
            "Rc7+",
            "Kb6",
            "Rc5",
            "Rc8+",
            "Kd6",
            "Rd8+",
            "Ke7",
            "Rd5",
            "Rc3",
            "b5",
            "Rxh3",
            "b6",
            "Rc3+",
            "Kb5",
            "Rc8",
            "b7",
            "Rb8+",
            "Kc6",
            "Rc8+",
            "Kd6",
            "Rd8+",
            "Ke7",
            "Rd5",
            "Rc3+",
            "Kb6",
            "Rb3+",
            "Kc7",
            "Rc3+",
            "Kd6",
            "Rd3+",
            "Ke7",
            "Rd5",
            "Rc3+",
            "Kb6",
            "Rb3+",
            "Kc7",
            "Rc3+",
            "Kd6",
            "Rd3+",
            "Ke7",
            "Rd5",
            "Rc3+",
            "Kb6",
            "Rb3+",
            "Kc7",
            "Rc3+",
            "Kd6",
            "Rd3+",
            "Ke7",
            "Rd5",
            "Rc3+",
            "Kb6",
            "Rb3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Nc3",
              "d5",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8",
              "c3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Re1",
              "Qd6",
              "Re3",
              "Bf5",
              "Qe2",
              "Bxd3",
              "Qe1",
              "Bb5",
              "a4",
              "Bc6",
              "b4",
              "Re8",
              "b5",
              "Rxe3",
              "Qxe3",
              "Bd7",
              "Re1",
              "h6",
              "c4",
              "Re8",
              "Qc1",
              "Rxe1+",
              "Qxe1",
              "Qe6",
              "Qc1",
              "Qe4",
              "h3",
              "Be6",
              "c5",
              "Qxa4",
              "b6",
              "axb6",
              "cxb6",
              "cxb6",
              "Qxb6",
              "Qc6",
              "Qd8+",
              "Kh7",
              "Qd3+",
              "g6",
              "Qd8",
              "b5",
              "Qb8",
              "Qc4",
              "Qb7",
              "Qc3",
              "b4",
              "Qb2",
              "b3",
              "Kh2",
              "Qc7+",
              "g3",
              "Qc2",
              "Qf6",
              "b2",
              "h4",
              "b1=Q",
              "h5",
              "Qf5",
              "hxg6+",
              "Qxg6",
              "Qxg6+",
              "fxg6",
              "Kg2",
              "Bd5+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qh1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Be6",
              "Qxb7",
              "Rc8",
              "Rad1",
              "Bd7",
              "Rxd6",
              "Nb8",
              "Rfd1",
              "Rxc2",
              "Rxd7",
              "Nxd7",
              "Qxd7+",
              "Kf8",
              "Qe7+",
              "Kg8",
              "Qg7#",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Bh6",
              "Qe6",
              "Nf6",
              "Qxf6",
              "Bxf6",
              "Be6",
              "Qxb7",
              "Rc8",
              "Rad1",
              "Bd7",
              "Rxd6",
              "Nb8",
              "Rfd1",
              "Rc7",
              "Qxb8+",
              "Ke7",
              "Qxc7",
              "Kf7",
              "Qxd7+",
              "Kg8",
              "Qe7",
              "Kh8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Nc3",
              "d5",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "c3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5+",
              "Qe2",
              "Qxe2+",
              "Bxe2",
              "Re8",
              "f3",
              "Bf5",
              "Kf2",
              "Rad8",
              "Rad1",
              "Rxd1",
              "Rxd1",
              "h6",
              "g4",
              "Be6",
              "b3",
              "c6",
              "c4",
              "a6",
              "h3",
              "b5",
              "cxb5",
              "axb5",
              "Rd6",
              "Bd5",
              "Bxb5",
              "Bxf3",
              "Bxc6",
              "Bxc6",
              "Rxc6",
              "Ra8",
              "a4",
              "Rb8",
              "Rc3",
              "Kf8",
              "Ke3",
              "Ke7",
              "Kd4",
              "Kd6",
              "Kc4",
              "Rc8",
              "Kb5",
              "Rb8+",
              "Ka6",
              "Kc5",
              "Rb7",
              "b4",
              "Rc7+",
              "Kb6",
              "Rc5",
              "Rc8+",
              "Kd6",
              "Rd8+",
              "Ke7",
              "Rd5",
              "Rc3",
              "b5",
              "Rxh3",
              "b6",
              "Rc3+",
              "Kb5",
              "Rc8",
              "b7",
              "Rb8+",
              "Kc6",
              "Rc8+",
              "Kd6",
              "Rd8+",
              "Ke7",
              "Rd5",
              "Rc3+",
              "Kb6",
              "Rb3+",
              "Kc7",
              "Rc3+",
              "Kd6",
              "Rd3+",
              "Ke7",
              "Rd5",
              "Rc3+",
              "Kb6",
              "Rb3+",
              "Kc7",
              "Rc3+",
              "Kd6",
              "Rd3+",
              "Ke7",
              "Rd5",
              "Rc3+",
              "Kb6",
              "Rb3+",
              "Kc7",
              "Rc3+",
              "Kd6",
              "Rd3+",
              "Ke7",
              "Rd5",
              "Rc3+",
              "Kb6",
              "Rb3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 264,
            "total_tokens": 374,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 600,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1504,
          "total_tokens": 1833
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 264,
            "total_tokens": 374,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 600,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 O-O 7. Bd3 d6 8. c3 Nc6 9. Qc2 g6 10. O-O-O a6 11. h4 b5 12. h5 b4 13. hxg6 hxg6 14. exf5 exf5 15. g4 bxc3 16. bxc3 Ne7 17. gxf5 Bxf5 18. Rdg1 Bg7 19. Nh4 Bxd3 20. Qxd3 Rxf2 21. Nxg6 Nxg6 22. Qxg6 Qf6 23. Qh7+ Kf8 24. Rg6 Qf7 25. Rhg1 Qxa2 26. Qxg7+ Ke8 27. Re1+ Kd8 28. Qg8+ Qxg8 29. Rxg8+ Kd7 30. Rxa8 Kc6 31. Rxa6+ Kb5 32. Ra7 c5 33. dxc5 dxc5 34. Re5 Kb6 35. Rae7 Kb5 36. Rc7 Ka4 37. Rexc5 Rf4 38. Rb7 Rf1+ 39. Kc2 Rf2 40. Rc8 Rf5 41. Ra8+ Ra5 42. Rxa5+ Kxa5 43. c4 Ka6 44. Rb1 Ka5 45. c5 Ka4 46. c6 Ka3 47. c7 Ka2 48. c8=Q Ka3 49. Qa8# e4 Nc3 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "O-O",
            "Bd3",
            "d6",
            "c3",
            "Nc6",
            "Qc2",
            "g6",
            "O-O-O",
            "a6",
            "h4",
            "b5",
            "h5",
            "b4",
            "hxg6",
            "hxg6",
            "exf5",
            "exf5",
            "g4",
            "bxc3",
            "bxc3",
            "Ne7",
            "gxf5",
            "Bxf5",
            "Rdg1",
            "Bg7",
            "Nh4",
            "Bxd3",
            "Qxd3",
            "Rxf2",
            "Nxg6",
            "Nxg6",
            "Qxg6",
            "Qf6",
            "Qh7+",
            "Kf8",
            "Rg6",
            "Qf7",
            "Rhg1",
            "Qxa2",
            "Qxg7+",
            "Ke8",
            "Re1+",
            "Kd8",
            "Qg8+",
            "Qxg8",
            "Rxg8+",
            "Kd7",
            "Rxa8",
            "Kc6",
            "Rxa6+",
            "Kb5",
            "Ra7",
            "c5",
            "dxc5",
            "dxc5",
            "Re5",
            "Kb6",
            "Rae7",
            "Kb5",
            "Rc7",
            "Ka4",
            "Rexc5",
            "Rf4",
            "Rb7",
            "Rf1+",
            "Kc2",
            "Rf2",
            "Rc8",
            "Rf5",
            "Ra8+",
            "Ra5",
            "Rxa5+",
            "Kxa5",
            "c4",
            "Ka6",
            "Rb1",
            "Ka5",
            "c5",
            "Ka4",
            "c6",
            "Ka3",
            "c7",
            "Ka2",
            "c8=Q",
            "Ka3",
            "Qa8#",
            "e4",
            "Nc3",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nf6 3. c4 e6 4. g3 d5 5. Bg2 c6 6. O-O Bd6 7. b3 Qe7 8. Bb2 O-O 9. Qc1 b6 10. Ba3 Bxa3 11. Qxa3 Qxa3 12. Nxa3 Bb7 13. Rac1 Nbd7 14. cxd5 exd5 15. Nc2 Ne4 16. Nb4 Rac8 17. Nd3 Rfe8 18. Rfd1 g6 19. Nfe5 Nxe5 20. Nxe5 c5 21. e3 cxd4 22. exd4 Nc3 23. Rxc3 Rxc3 24. Rd2 Rc1+ 25. Bf1 Ba6 26. Nd3 Ra1 27. Kg2 Ree1 28. Nxe1 Bxf1+ 29. Kxf1 Kf7 30. Ke2 Ke6 31. Nd3 g5 32. Rc2 Kd6 33. Ne5 f4 34. gxf4 gxf4 35. Kf3 Rd1 36. Rc6+ Ke7 37. Rc7+ Ke6 38. Rxa7 Rxd4 39. Nc6 Rd2 40. Rxh7 Kd6 41. Rh6+ Kc5 42. b4+ Kb5 43. a3 Ka4 44. Rd6 Kxa3 45. h4 Kb3 46. h5 Kc4 47. h6 Rd3+ 48. Kxf4 Rh3 49. Kg4 Rh1 50. Ne5+ Kxb4 51. Rxb6+ Kc5 52. Rc6+ Kd4 53. Nf3+ Ke4 54. Re6+ Kd3 55. Re3+ Kc4 56. Nh4 d4 57. Rh3 Rg1+ 58. Kf3 Rg8 59. h7 Rh8 60. Ng6 Rxh7 61. Rxh7 d3 62. Rd7 Kc3 63. Ke3 d2 64. Rxd2 Kc4 65. f4 Kc5 66. f5 Kc6 67. f6 Kc7 68. f7 Kc6 69. f8=Q Kc7 70. Qd6+ Kb7 71. Rb2+ Ka7 72. Qb6+ Ka8 73. Qb7# d4 e5 Qd5",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 596,
            "total_tokens": 712,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke4",
            "Re6+",
            "Kd3",
            "Re3+",
            "Kc4",
            "Nh4",
            "d4",
            "Rh3",
            "Rg1+",
            "Kf3",
            "Rg8",
            "h7",
            "Rh8",
            "Ng6",
            "Rxh7",
            "Rxh7",
            "d3",
            "Rd7",
            "Kc3",
            "Ke3",
            "d2",
            "Rxd2",
            "Kc4",
            "f4",
            "Kc5",
            "f5",
            "Kc6",
            "f6",
            "Kc7",
            "f7",
            "Kc6",
            "f8=Q",
            "Kc7",
            "Qd6+",
            "Kb7",
            "Rb2+",
            "Ka7",
            "Qb6+",
            "Ka8",
            "Qb7#",
            "d4",
            "e5",
            "Qd5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nf6 3. c4 e6 4. Nc3 Bb4 5. Qc2 O-O 6. g3 b6 7. Bg2 Bb7 8. O-O Bxc3 9. Qxc3 d6 10. b3 Nbd7 11. Bb2 Qe7 12. Rad1 Rae8 13. Rfe1 Ne4 14. Qc2 Ndf6 15. Nd2 Nxf2 16. Kxf2 Ng4+ 17. Kg1 Ne3 18. Qd3 Nxg2 19. Rf1 f4 20. Nf3 Ne3 21. gxf4 Nxd1 22. Rxd1 Rxf4 23. d5 exd5 24. cxd5 Qxe2 25. Qxe2 Rxe2 26. Bc1 Rxf3 27. Bg5 Rff2 28. Bh4 Rg2+ 29. Kf1 Ba6 30. Rc1 Ref2+ 31. Ke1 Rf1# 0-1\n\n32. Kxf1 Rxa2+ 33. Kg1 Rb2 34. Rxc7 Rxb3",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 282,
            "total_tokens": 397,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ne3",
            "gxf4",
            "Nxd1",
            "Rxd1",
            "Rxf4",
            "d5",
            "exd5",
            "cxd5",
            "Qxe2",
            "Qxe2",
            "Rxe2",
            "Bc1",
            "Rxf3",
            "Bg5",
            "Rff2",
            "Bh4",
            "Rg2+",
            "Kf1",
            "Ba6",
            "Rc1",
            "Ref2+",
            "Ke1",
            "Rf1#",
            "Kxf1",
            "Rxa2+",
            "Kg1",
            "Rb2",
            "Rxc7",
            "Rxb3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "O-O",
              "Bd3",
              "d6",
              "c3",
              "Nc6",
              "Qc2",
              "g6",
              "O-O-O",
              "a6",
              "h4",
              "b5",
              "h5",
              "b4",
              "hxg6",
              "hxg6",
              "exf5",
              "exf5",
              "g4",
              "bxc3",
              "bxc3",
              "Ne7",
              "gxf5",
              "Bxf5",
              "Rdg1",
              "Bg7",
              "Nh4",
              "Bxd3",
              "Qxd3",
              "Rxf2",
              "Nxg6",
              "Nxg6",
              "Qxg6",
              "Qf6",
              "Qh7+",
              "Kf8",
              "Rg6",
              "Qf7",
              "Rhg1",
              "Qxa2",
              "Qxg7+",
              "Ke8",
              "Re1+",
              "Kd8",
              "Qg8+",
              "Qxg8",
              "Rxg8+",
              "Kd7",
              "Rxa8",
              "Kc6",
              "Rxa6+",
              "Kb5",
              "Ra7",
              "c5",
              "dxc5",
              "dxc5",
              "Re5",
              "Kb6",
              "Rae7",
              "Kb5",
              "Rc7",
              "Ka4",
              "Rexc5",
              "Rf4",
              "Rb7",
              "Rf1+",
              "Kc2",
              "Rf2",
              "Rc8",
              "Rf5",
              "Ra8+",
              "Ra5",
              "Rxa5+",
              "Kxa5",
              "c4",
              "Ka6",
              "Rb1",
              "Ka5",
              "c5",
              "Ka4",
              "c6",
              "Ka3",
              "c7",
              "Ka2",
              "c8=Q",
              "Ka3",
              "Qa8#",
              "e4",
              "Nc3",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke4",
              "Re6+",
              "Kd3",
              "Re3+",
              "Kc4",
              "Nh4",
              "d4",
              "Rh3",
              "Rg1+",
              "Kf3",
              "Rg8",
              "h7",
              "Rh8",
              "Ng6",
              "Rxh7",
              "Rxh7",
              "d3",
              "Rd7",
              "Kc3",
              "Ke3",
              "d2",
              "Rxd2",
              "Kc4",
              "f4",
              "Kc5",
              "f5",
              "Kc6",
              "f6",
              "Kc7",
              "f7",
              "Kc6",
              "f8=Q",
              "Kc7",
              "Qd6+",
              "Kb7",
              "Rb2+",
              "Ka7",
              "Qb6+",
              "Ka8",
              "Qb7#",
              "d4",
              "e5",
              "Qd5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ne3",
              "gxf4",
              "Nxd1",
              "Rxd1",
              "Rxf4",
              "d5",
              "exd5",
              "cxd5",
              "Qxe2",
              "Qxe2",
              "Rxe2",
              "Bc1",
              "Rxf3",
              "Bg5",
              "Rff2",
              "Bh4",
              "Rg2+",
              "Kf1",
              "Ba6",
              "Rc1",
              "Ref2+",
              "Ke1",
              "Rf1#",
              "Kxf1",
              "Rxa2+",
              "Kg1",
              "Rb2",
              "Rxc7",
              "Rxb3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 596,
            "total_tokens": 712,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 282,
            "total_tokens": 397,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1289,
          "total_tokens": 1636
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 596,
            "total_tokens": 712,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 282,
            "total_tokens": 397,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppppp1pp/8/5p2/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 e5 12. dxe5 Nxe5 13. Nxe5 Qxe5 14. Qc2 Bf5 15. Rae1 Bxd3 16. Qxd3 Qd6 17. Re3 Rae8 18. Rfe1 Rxe3 19. Qxe3 c5 20. Qe7 Qxe7 21. Rxe7 Rf7 22. Re8+ Rf8 23. Re7 Rf7 24. Re8+ Rf8 25. Re7 Rf7 26. Re8+ Rf8 27. Re7 Rf7 28. Re8+ Rf8 29. Re7 Rf7 30. Re8+ Rf8 31. Re7 Rf7 32. Re8+ Rf8 33. Re7 Rf7 34. Re8+ Rf8 35. Re7 Rf7 36. Re8+ Rf8 37. Re7 Rf7 38. Re8+ Rf8 39. Re7 Rf7 40. Re8+ Rf8 41. Re7 Rf7 42. Re8+ Rf8 43. Re7 Rf7 44. Re8+ Rf8 45. Re7 Rf7 46. Re8+ Rf8 47. Re7 Rf7 48. Re8+ Rf8 49. Re7 Rf7 50. Re8+ Rf8 51. Re7 Rf7 52. Re8+ Rf8 53. Re7 Rf7 54. Re8+ Rf8 55. Re7 Rf7 56. Re8+ Rf8 57. Re7 Rf7 58. Re8+ Rf8 59. Re7 Rf7 60. Re8+ Rf8 61. Re7 Rf7 62. Re8+ Rf8 63. Re7 Rf7 64. Re8+ Rf8 65. Re7 Rf7 66. Re8+ Rf8 67. Re7 Rf7 68. Re8+ Rf8 69. Re7 Rf7 70. Re8+ Rf8 71. Re7 Rf7 72. Re8+ Rf8 73. Re7 Rf7 74. Re8+ Rf8 75. Re7 Rf7 76. Re8+ Rf8 77. Re7 Rf7 78. Re8",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Qc2",
            "Bf5",
            "Rae1",
            "Bxd3",
            "Qxd3",
            "Qd6",
            "Re3",
            "Rae8",
            "Rfe1",
            "Rxe3",
            "Qxe3",
            "c5",
            "Qe7",
            "Qxe7",
            "Rxe7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. O-O Ne4 8. Bxe7 Qxe7 9. Ne5 Nd7 10. Ndf3 Nxe5 11. Nxe5 Bd7 12. c4 c6 13. c5 Be8 14. f3 Nf6 15. b4 Nd7 16. f4 Nxe5 17. fxe5 Qg5 18. Qd2 Bh5 19. a4 Rf7 20. b5 Raf8 21. bxc6 bxc6 22. Rab1 f4 23. exf4 Rxf4 24. Rxf4 Rxf4 25. Rb8+ Kf7 26. Rb7+ Kg8 27. Rxa7 Qg4 28. Ra8+ Kf7 29. Ra7+ Kg8 30. Ra8+ Kf7 31. Ra7+ Kg8 32. Ra8+ Kf7 33. Ra7+ Kg8 34. Ra8+ Kf7 35. Ra7+ Kg8 36. Ra8+ Kf7 37. Ra7+ Kg8 38. Ra8+ Kf7 39. Ra7+ Kg8 40. Ra8+ Kf7 41. Ra7+ Kg8 42. Ra8+ Kf7 43. Ra7+ Kg8 44. Ra8+ Kf7 45. Ra7+ Kg8 46. Ra8+ Kf7 47. Ra7+ Kg8 48. Ra8+ Kf7 49. Ra7+ Kg8 50. Ra8+ Kf7 51. Ra7+ Kg8 52. Ra8+ Kf7 53. Ra7+ Kg8 54. Ra8+ Kf7 55. Ra7+ Kg8 56. Ra8+ Kf7 57. Ra7+ Kg8 58. Ra8+ Kf7 59. Ra7+ Kg8 60. Ra8+ Kf7 61. Ra7+ Kg8 62. Ra8+ Kf7 63. Ra7+ Kg8 64. Ra8+ Kf7 65. Ra7+ Kg8 66. Ra8+ Kf7 67. Ra7+ Kg8 68. Ra8+ Kf7 69. Ra7+ Kg8 70. Ra8+ Kf7 71. Ra7+ Kg8 72. Ra8+ Kf7 73. Ra7+ Kg8 74. Ra8+ Kf7 75. Ra7+ Kg8 76. Ra8+ Kf7 77. Ra7+ Kg8 78. Ra8+ Kf7 79. Ra7",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "O-O",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Ne5",
            "Nd7",
            "Ndf3",
            "Nxe5",
            "Nxe5",
            "Bd7",
            "c4",
            "c6",
            "c5",
            "Be8",
            "f3",
            "Nf6",
            "b4",
            "Nd7",
            "f4",
            "Nxe5",
            "fxe5",
            "Qg5",
            "Qd2",
            "Bh5",
            "a4",
            "Rf7",
            "b5",
            "Raf8",
            "bxc6",
            "bxc6",
            "Rab1",
            "f4",
            "exf4",
            "Rxf4",
            "Rxf4",
            "Rxf4",
            "Rb8+",
            "Kf7",
            "Rb7+",
            "Kg8",
            "Rxa7",
            "Qg4",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Ra8+",
            "Kf7",
            "Ra7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bg5",
          "neutral_uci": "c1g5",
          "neutral_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. Ne5 Nbd7 8. f4 Nxe5 9. fxe5 Ne4 10. Bxe7 Qxe7 11. O-O Bd7 12. c4 c6 13. c5 b6 14. b4 bxc5 15. bxc5 Rab8 16. Bxe4 fxe4 17. Rxf8+ Qxf8 18. Rb1 Rxb1 19. Qxb1 Qc8 20. Qb4 Qa6 21. Qb8+ Kf7 22. Qd6 Ke8 23. Qb8+ Ke7 24. Qd6+ Ke8 25. Qb8+ Ke7 26. Qd6+ Ke8 27. Qb8+ Ke7 28. Qd6+ Ke8 29. Qb8+ Ke7 30. Qd6+ Ke8 31. Qb8+ Ke7 32. Qd6+ Ke8 33. Qb8+ Ke7 34. Qd6+ Ke8 35. Qb8+ Ke7 36. Qd6+ Ke8 37. Qb8+ Ke7 38. Qd6+ Ke8 39. Qb8+ Ke7 40. Qd6+ Ke8 41. Qb8+ Ke7 42. Qd6+ Ke8 43. Qb8+ Ke7 44. Qd6+ Ke8 45. Qb8+ Ke7 46. Qd6+ Ke8 47. Qb8+ Ke7 48. Qd6+ Ke8 49. Qb8+ Ke7 50. Qd6+ Ke8 51. Qb8+ Ke7 52. Qd6+ Ke8 53. Qb8+ Ke7 54. Qd6+ Ke8 55. Qb8+ Ke7 56. Qd6+ Ke8 57. Qb8+ Ke7 58. Qd6+ Ke8 59. Qb8+ Ke7 60. Qd6+ Ke8 61. Qb8+ Ke7 62. Qd6+ Ke8 63. Qb8+ Ke7 64. Qd6+ Ke8 65. Qb8+ Ke7 66. Qd6+ Ke8 67. Qb8+ Ke7 68. Qd6+ Ke8 69. Qb8+ Ke7 70. Qd6+ Ke8 71. Qb8+ Ke7 72. Qd6+ Ke8 73. Qb8+ Ke7 74. Qd6+ Ke8 75. Qb8+ Ke",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "Ne5",
            "Nbd7",
            "f4",
            "Nxe5",
            "fxe5",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Bd7",
            "c4",
            "c6",
            "c5",
            "b6",
            "b4",
            "bxc5",
            "bxc5",
            "Rab8",
            "Bxe4",
            "fxe4",
            "Rxf8+",
            "Qxf8",
            "Rb1",
            "Rxb1",
            "Qxb1",
            "Qc8",
            "Qb4",
            "Qa6",
            "Qb8+",
            "Kf7",
            "Qd6",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Ke7",
            "Qd6+",
            "Ke8",
            "Qb8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": "c1g5",
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Qc2",
              "Bf5",
              "Rae1",
              "Bxd3",
              "Qxd3",
              "Qd6",
              "Re3",
              "Rae8",
              "Rfe1",
              "Rxe3",
              "Qxe3",
              "c5",
              "Qe7",
              "Qxe7",
              "Rxe7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "O-O",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Ne5",
              "Nd7",
              "Ndf3",
              "Nxe5",
              "Nxe5",
              "Bd7",
              "c4",
              "c6",
              "c5",
              "Be8",
              "f3",
              "Nf6",
              "b4",
              "Nd7",
              "f4",
              "Nxe5",
              "fxe5",
              "Qg5",
              "Qd2",
              "Bh5",
              "a4",
              "Rf7",
              "b5",
              "Raf8",
              "bxc6",
              "bxc6",
              "Rab1",
              "f4",
              "exf4",
              "Rxf4",
              "Rxf4",
              "Rxf4",
              "Rb8+",
              "Kf7",
              "Rb7+",
              "Kg8",
              "Rxa7",
              "Qg4",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Ra8+",
              "Kf7",
              "Ra7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "Ne5",
              "Nbd7",
              "f4",
              "Nxe5",
              "fxe5",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "O-O",
              "Bd7",
              "c4",
              "c6",
              "c5",
              "b6",
              "b4",
              "bxc5",
              "bxc5",
              "Rab8",
              "Bxe4",
              "fxe4",
              "Rxf8+",
              "Qxf8",
              "Rb1",
              "Rxb1",
              "Qxb1",
              "Qc8",
              "Qb4",
              "Qa6",
              "Qb8+",
              "Kf7",
              "Qd6",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Ke7",
              "Qd6+",
              "Ke8",
              "Qb8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1920,
          "total_tokens": 2294
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppppp1pp/5n2/5p2/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "g5f6",
          "aggressive_response": "4. Bxf6 exf6 5. e3 d5 6. c4 Be6 7. Qb3 b6 8. Nc3 c6 9. cxd5 Bxd5 10. Nxd5 Qxd5 11. Bc4 Qa5+ 12. Ke2 Nd7 13. Bf7+ Kd8 14. Rac1 Rc8 15. Rhd1 Bd6 16. d5 c5 17. Nd2 Qa6+ 18. Ke1 Ne5 19. Be6 Nd3+ 20. Kf1 Nxc1+ 21. Kg1 Nxb3 22. Nxb3 Qxa2 23. Bxc8 Qxb3 24. Ra1 Kxc8 25. g3 Kb7 26. Kg2 Qxb2 27. Rd1 Re8 28. h4 Rxe3 29. Rf1 Rxg3+ 30. Kh1 Rh3+ 31. Kg2 Rh2+ 32. Kg1 Qd4 33. h5 Qg4# g6 h5 Qh6#",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 255,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exf6",
            "e3",
            "d5",
            "c4",
            "Be6",
            "Qb3",
            "b6",
            "Nc3",
            "c6",
            "cxd5",
            "Bxd5",
            "Nxd5",
            "Qxd5",
            "Bc4",
            "Qa5+",
            "Ke2",
            "Nd7",
            "Bf7+",
            "Kd8",
            "Rac1",
            "Rc8",
            "Rhd1",
            "Bd6",
            "d5",
            "c5",
            "Nd2",
            "Qa6+",
            "Ke1",
            "Ne5",
            "Be6",
            "Nd3+",
            "Kf1",
            "Nxc1+",
            "Kg1",
            "Nxb3",
            "Nxb3",
            "Qxa2",
            "Bxc8",
            "Qxb3",
            "Ra1",
            "Kxc8",
            "g3",
            "Kb7",
            "Kg2",
            "Qxb2",
            "Rd1",
            "Re8",
            "h4",
            "Rxe3",
            "Rf1",
            "Rxg3+",
            "Kh1",
            "Rh3+",
            "Kg2",
            "Rh2+",
            "Kg1",
            "Qd4",
            "h5",
            "Qg4#",
            "g6",
            "h5",
            "Qh6#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "g5f6",
          "positional_response": "4. Bxf6 exf6 5. e3 d5 6. c4 Be6 7. Qb3 b6 8. Nc3 c6 9. cxd5 Bxd5 10. Nxd5 Qxd5 11. Bc4 Qa5+ 12. Ke2 Nd7 13. Bf7+ Kd8 14. Rac1 Rc8 15. Rhd1 Bd6 16. d5 c5 17. Nd2 Qa6+ 18. Ke1 Ne5 19. Be6 Nd3+ 20. Kf1 Nxc1+ 21. Kg1 Nxb3 22. Nxb3 Rc7 23. a3 Qe2 24. Rb1 Qc2 25. Rf1 Qxb3 26. g3 Qxb2 27. a4 Qb3 28. Ra1 Be5 29. Rc1 Qxa4 30. Kg2 Qe4+ 31. Kg1 Ke7 32. Rd1 Rd8 33. h4 Qf3 34. Rd2 Bxg3 35. fxg3 Qxe3+ 36. Rf2 Qxg3+ 37. Rg2 Qe1+ 38. Kh2 Qxh4+ 39. Kg1 Qd4+ 40. Kh2 Rxd5 41. Bxd5 Qxd5 42. Re2+ Kf7 43. Kg3 Qd3+ 44. Kf2 Re7 45. Rxe7+ Kxe7 46. Kg2 c4 47. Kf2 c3 48. Kg2 c2 49. Kf2 c1=Q 50. Kg2 Qcc2+ 51. Kg1 Qdd1# c3 Kf3 Kf2",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 414,
            "total_tokens": 547,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exf6",
            "e3",
            "d5",
            "c4",
            "Be6",
            "Qb3",
            "b6",
            "Nc3",
            "c6",
            "cxd5",
            "Bxd5",
            "Nxd5",
            "Qxd5",
            "Bc4",
            "Qa5+",
            "Ke2",
            "Nd7",
            "Bf7+",
            "Kd8",
            "Rac1",
            "Rc8",
            "Rhd1",
            "Bd6",
            "d5",
            "c5",
            "Nd2",
            "Qa6+",
            "Ke1",
            "Ne5",
            "Be6",
            "Nd3+",
            "Kf1",
            "Nxc1+",
            "Kg1",
            "Nxb3",
            "Nxb3",
            "Rc7",
            "a3",
            "Qe2",
            "Rb1",
            "Qc2",
            "Rf1",
            "Qxb3",
            "g3",
            "Qxb2",
            "a4",
            "Qb3",
            "Ra1",
            "Be5",
            "Rc1",
            "Qxa4",
            "Kg2",
            "Qe4+",
            "Kg1",
            "Ke7",
            "Rd1",
            "Rd8",
            "h4",
            "Qf3",
            "Rd2",
            "Bxg3",
            "fxg3",
            "Qxe3+",
            "Rf2",
            "Qxg3+",
            "Rg2",
            "Qe1+",
            "Kh2",
            "Qxh4+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Rxd5",
            "Bxd5",
            "Qxd5",
            "Re2+",
            "Kf7",
            "Kg3",
            "Qd3+",
            "Kf2",
            "Re7",
            "Rxe7+",
            "Kxe7",
            "Kg2",
            "c4",
            "Kf2",
            "c3",
            "Kg2",
            "c2",
            "Kf2",
            "c1=Q",
            "Kg2",
            "Qcc2+",
            "Kg1",
            "Qdd1#",
            "c3",
            "Kf3",
            "Kf2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "g5f6",
          "neutral_response": "4. Bxf6 exf6 5. e3 d5 6. c4 Be6 7. Qb3 b6 8. Nc3 c6 9. cxd5 Bxd5 10. Nxd5 Qxd5 11. Bc4 Qa5+ 12. Ke2 Nd7 13. Bf7+ Kd8 14. Rac1 Rc8 15. Rhd1 Bd6 16. d5 c5 17. Nd2 Ne5 18. Be6 Rc7 19. f4 Qa6+ 20. Nc4 Nxc4 21. Qxc4 Qxc4+ 22. Rxc4 b5 23. Rc2 Ke7 24. Kf3 Rb8 25. g4 fxg4+ 26. Kxg4 c4 27. e4 b4 28. Re1 b3 29. axb3 cxb3 30. Rxc7+ Bxc7 31. e5 fxe5 32. fxe5 Rb4+ 33. Kf3 Rd4 34. Bg8 Kf8 35. Bxh7 Kg7 36. e6 Bd6 37. e7 Bxe7 38. Rxe7+ Kh6 39. Bg8 Rd2 40. h4 g5 41. hxg5+ Kxg5 42. Re2 Rd3+ 43. Ke4 Rh3 44. d6 Kf6 45. Kd5 Rh5+ 46. Kc6 Rh3 47. d7 Rd3 48. Bd5 1-0 49. d8=Q+ Rxd8 50. Kxd8 a5 51. Re3 a4 52. Re4 a3 53. bxa3 b2 54. Rb4 Ke5 55. Rxb2 Kxd5 56. a4 Kc5 57. a5 Kc4 58. a6 Kc3 59. Rb7 Kc4 60. a7 Kc5 61. a8=Q Kc6 62. Qa6+ Kc5 63. Rb5+ Kc4 64. Qa4+ Kc3 65. Rb3+ Kc2 66. Qa2+ Kc1 67. Rb1# b3 68. Qb2# bxb2 69. Rxb2 Kxb2 70. h4 Kc3 71. h5 Kd4 72. h6 Ke5 73. h7 Kf6 74. h8=Q+ Kf7 75. Qh6 Kg8 76. Qf6 Kh7 77. Qg5 Kh8 78. Ke7 Kh7 79. Kf7 Kh",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "exf6",
            "e3",
            "d5",
            "c4",
            "Be6",
            "Qb3",
            "b6",
            "Nc3",
            "c6",
            "cxd5",
            "Bxd5",
            "Nxd5",
            "Qxd5",
            "Bc4",
            "Qa5+",
            "Ke2",
            "Nd7",
            "Bf7+",
            "Kd8",
            "Rac1",
            "Rc8",
            "Rhd1",
            "Bd6",
            "d5",
            "c5",
            "Nd2",
            "Ne5",
            "Be6",
            "Rc7",
            "f4",
            "Qa6+",
            "Nc4",
            "Nxc4",
            "Qxc4",
            "Qxc4+",
            "Rxc4",
            "b5",
            "Rc2",
            "Ke7",
            "Kf3",
            "Rb8",
            "g4",
            "fxg4+",
            "Kxg4",
            "c4",
            "e4",
            "b4",
            "Re1",
            "b3",
            "axb3",
            "cxb3",
            "Rxc7+",
            "Bxc7",
            "e5",
            "fxe5",
            "fxe5",
            "Rb4+",
            "Kf3",
            "Rd4",
            "Bg8",
            "Kf8",
            "Bxh7",
            "Kg7",
            "e6",
            "Bd6",
            "e7",
            "Bxe7",
            "Rxe7+",
            "Kh6",
            "Bg8",
            "Rd2",
            "h4",
            "g5",
            "hxg5+",
            "Kxg5",
            "Re2",
            "Rd3+",
            "Ke4",
            "Rh3",
            "d6",
            "Kf6",
            "Kd5",
            "Rh5+",
            "Kc6",
            "Rh3",
            "d7",
            "Rd3",
            "Bd5",
            "d8=Q+",
            "Rxd8",
            "Kxd8",
            "a5",
            "Re3",
            "a4",
            "Re4",
            "a3",
            "bxa3",
            "b2",
            "Rb4",
            "Ke5",
            "Rxb2",
            "Kxd5",
            "a4",
            "Kc5",
            "a5",
            "Kc4",
            "a6",
            "Kc3",
            "Rb7",
            "Kc4",
            "a7",
            "Kc5",
            "a8=Q",
            "Kc6",
            "Qa6+",
            "Kc5",
            "Rb5+",
            "Kc4",
            "Qa4+",
            "Kc3",
            "Rb3+",
            "Kc2",
            "Qa2+",
            "Kc1",
            "Rb1#",
            "b3",
            "Qb2#",
            "bxb2",
            "Rxb2",
            "Kxb2",
            "h4",
            "Kc3",
            "h5",
            "Kd4",
            "h6",
            "Ke5",
            "h7",
            "Kf6",
            "h8=Q+",
            "Kf7",
            "Qh6",
            "Kg8",
            "Qf6",
            "Kh7",
            "Qg5",
            "Kh8",
            "Ke7",
            "Kh7",
            "Kf7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5f6",
          "positional_uci": "g5f6",
          "neutral_uci": "g5f6",
          "consensus_move": "g5f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "exf6",
              "e3",
              "d5",
              "c4",
              "Be6",
              "Qb3",
              "b6",
              "Nc3",
              "c6",
              "cxd5",
              "Bxd5",
              "Nxd5",
              "Qxd5",
              "Bc4",
              "Qa5+",
              "Ke2",
              "Nd7",
              "Bf7+",
              "Kd8",
              "Rac1",
              "Rc8",
              "Rhd1",
              "Bd6",
              "d5",
              "c5",
              "Nd2",
              "Qa6+",
              "Ke1",
              "Ne5",
              "Be6",
              "Nd3+",
              "Kf1",
              "Nxc1+",
              "Kg1",
              "Nxb3",
              "Nxb3",
              "Qxa2",
              "Bxc8",
              "Qxb3",
              "Ra1",
              "Kxc8",
              "g3",
              "Kb7",
              "Kg2",
              "Qxb2",
              "Rd1",
              "Re8",
              "h4",
              "Rxe3",
              "Rf1",
              "Rxg3+",
              "Kh1",
              "Rh3+",
              "Kg2",
              "Rh2+",
              "Kg1",
              "Qd4",
              "h5",
              "Qg4#",
              "g6",
              "h5",
              "Qh6#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "exf6",
              "e3",
              "d5",
              "c4",
              "Be6",
              "Qb3",
              "b6",
              "Nc3",
              "c6",
              "cxd5",
              "Bxd5",
              "Nxd5",
              "Qxd5",
              "Bc4",
              "Qa5+",
              "Ke2",
              "Nd7",
              "Bf7+",
              "Kd8",
              "Rac1",
              "Rc8",
              "Rhd1",
              "Bd6",
              "d5",
              "c5",
              "Nd2",
              "Qa6+",
              "Ke1",
              "Ne5",
              "Be6",
              "Nd3+",
              "Kf1",
              "Nxc1+",
              "Kg1",
              "Nxb3",
              "Nxb3",
              "Rc7",
              "a3",
              "Qe2",
              "Rb1",
              "Qc2",
              "Rf1",
              "Qxb3",
              "g3",
              "Qxb2",
              "a4",
              "Qb3",
              "Ra1",
              "Be5",
              "Rc1",
              "Qxa4",
              "Kg2",
              "Qe4+",
              "Kg1",
              "Ke7",
              "Rd1",
              "Rd8",
              "h4",
              "Qf3",
              "Rd2",
              "Bxg3",
              "fxg3",
              "Qxe3+",
              "Rf2",
              "Qxg3+",
              "Rg2",
              "Qe1+",
              "Kh2",
              "Qxh4+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Rxd5",
              "Bxd5",
              "Qxd5",
              "Re2+",
              "Kf7",
              "Kg3",
              "Qd3+",
              "Kf2",
              "Re7",
              "Rxe7+",
              "Kxe7",
              "Kg2",
              "c4",
              "Kf2",
              "c3",
              "Kg2",
              "c2",
              "Kf2",
              "c1=Q",
              "Kg2",
              "Qcc2+",
              "Kg1",
              "Qdd1#",
              "c3",
              "Kf3",
              "Kf2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "exf6",
              "e3",
              "d5",
              "c4",
              "Be6",
              "Qb3",
              "b6",
              "Nc3",
              "c6",
              "cxd5",
              "Bxd5",
              "Nxd5",
              "Qxd5",
              "Bc4",
              "Qa5+",
              "Ke2",
              "Nd7",
              "Bf7+",
              "Kd8",
              "Rac1",
              "Rc8",
              "Rhd1",
              "Bd6",
              "d5",
              "c5",
              "Nd2",
              "Ne5",
              "Be6",
              "Rc7",
              "f4",
              "Qa6+",
              "Nc4",
              "Nxc4",
              "Qxc4",
              "Qxc4+",
              "Rxc4",
              "b5",
              "Rc2",
              "Ke7",
              "Kf3",
              "Rb8",
              "g4",
              "fxg4+",
              "Kxg4",
              "c4",
              "e4",
              "b4",
              "Re1",
              "b3",
              "axb3",
              "cxb3",
              "Rxc7+",
              "Bxc7",
              "e5",
              "fxe5",
              "fxe5",
              "Rb4+",
              "Kf3",
              "Rd4",
              "Bg8",
              "Kf8",
              "Bxh7",
              "Kg7",
              "e6",
              "Bd6",
              "e7",
              "Bxe7",
              "Rxe7+",
              "Kh6",
              "Bg8",
              "Rd2",
              "h4",
              "g5",
              "hxg5+",
              "Kxg5",
              "Re2",
              "Rd3+",
              "Ke4",
              "Rh3",
              "d6",
              "Kf6",
              "Kd5",
              "Rh5+",
              "Kc6",
              "Rh3",
              "d7",
              "Rd3",
              "Bd5",
              "d8=Q+",
              "Rxd8",
              "Kxd8",
              "a5",
              "Re3",
              "a4",
              "Re4",
              "a3",
              "bxa3",
              "b2",
              "Rb4",
              "Ke5",
              "Rxb2",
              "Kxd5",
              "a4",
              "Kc5",
              "a5",
              "Kc4",
              "a6",
              "Kc3",
              "Rb7",
              "Kc4",
              "a7",
              "Kc5",
              "a8=Q",
              "Kc6",
              "Qa6+",
              "Kc5",
              "Rb5+",
              "Kc4",
              "Qa4+",
              "Kc3",
              "Rb3+",
              "Kc2",
              "Qa2+",
              "Kc1",
              "Rb1#",
              "b3",
              "Qb2#",
              "bxb2",
              "Rxb2",
              "Kxb2",
              "h4",
              "Kc3",
              "h5",
              "Kd4",
              "h6",
              "Ke5",
              "h7",
              "Kf6",
              "h8=Q+",
              "Kf7",
              "Qh6",
              "Kg8",
              "Qf6",
              "Kh7",
              "Qg5",
              "Kh8",
              "Ke7",
              "Kh7",
              "Kf7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 255,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 414,
            "total_tokens": 547,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1309,
          "total_tokens": 1707
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 255,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 414,
            "total_tokens": 547,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppppp2p/5np1/5pB1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e3",
          "aggressive_uci": "e2e3",
          "aggressive_response": "5. e3 d5 6. c4 c6 7. Nc3 Be6 8. Qb3 Qd7 9. cxd5 cxd5 10. Bb5 Nc6 11. O-O Bd6 12. Rac1 O-O 13. Na4 Rac8 14. Nc5 Bxc5 15. Rxc5 a6 16. Bxc6 Rxc6 17. Rfc1 Rfc8 18. Rxc6 Rxc6 19. Rxc6 Qxc6 20. Qc3 Qxc3 21. bxc3 Kf7 22. Kf1 Ke7 23. Ke2 Kd6 24. Kd3 Kc6 25. Nd2 Kb5 26. Kc2 Ka4 27. Kb2 b6 28. Nb1 Kb5 29. Na3+ Kc6 30. Kb3 g5 31. g3 h5 32. h4 f4 33. exf4 gxf4 34. gxf4 Bf5 35. c4 Bd3 36. Kc3 Be2 37. cxd5+ Kxd5 38. Nc2 Ke4 39. Kd2 Bc4 40. a3 Kxf4 41. Ne3 Be6 42. d5 Bd7 43. Kd3 Ke5 44. Kc4 f5 45. f3 f4 46. Nc2 Bb5+ 47. Kb4 Kxd5 48. a4 Be2 49. Ne1 Kd4 50. a5 bxa5+ 51. Kxa5 Ke3 52. Kb4 Bxf3 53. Kc3 Be2 54. Nc2+ Kf2 55. Kd2 Bb5 56. Nd4 Kg3 57. Nf5+ Kg4 58. Nd4 Kxh4 59. Ke1 Kg3 60. Nf5+ Kg2 61. Nh4+ Kg3 62. Nf5+ Kg4 63. Nd4 h4 64. Kf2 h3 65. Kg1 Kg3 66. Nf5+ Kf3 67. Kh2 Bd7 68. Nd4+ Ke3 69. Nc2+ Kd2 70. Nd4 a5 71. Nb3+ Ke2 72. Nxa5 f3 73. Nc4 f2 74. Ne5 f1=Q 75. Nxd7 Qg2# e4 d5 f4",
          "aggressive_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 586,
            "total_tokens": 728,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "c4",
            "c6",
            "Nc3",
            "Be6",
            "Qb3",
            "Qd7",
            "cxd5",
            "cxd5",
            "Bb5",
            "Nc6",
            "O-O",
            "Bd6",
            "Rac1",
            "O-O",
            "Na4",
            "Rac8",
            "Nc5",
            "Bxc5",
            "Rxc5",
            "a6",
            "Bxc6",
            "Rxc6",
            "Rfc1",
            "Rfc8",
            "Rxc6",
            "Rxc6",
            "Rxc6",
            "Qxc6",
            "Qc3",
            "Qxc3",
            "bxc3",
            "Kf7",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd6",
            "Kd3",
            "Kc6",
            "Nd2",
            "Kb5",
            "Kc2",
            "Ka4",
            "Kb2",
            "b6",
            "Nb1",
            "Kb5",
            "Na3+",
            "Kc6",
            "Kb3",
            "g5",
            "g3",
            "h5",
            "h4",
            "f4",
            "exf4",
            "gxf4",
            "gxf4",
            "Bf5",
            "c4",
            "Bd3",
            "Kc3",
            "Be2",
            "cxd5+",
            "Kxd5",
            "Nc2",
            "Ke4",
            "Kd2",
            "Bc4",
            "a3",
            "Kxf4",
            "Ne3",
            "Be6",
            "d5",
            "Bd7",
            "Kd3",
            "Ke5",
            "Kc4",
            "f5",
            "f3",
            "f4",
            "Nc2",
            "Bb5+",
            "Kb4",
            "Kxd5",
            "a4",
            "Be2",
            "Ne1",
            "Kd4",
            "a5",
            "bxa5+",
            "Kxa5",
            "Ke3",
            "Kb4",
            "Bxf3",
            "Kc3",
            "Be2",
            "Nc2+",
            "Kf2",
            "Kd2",
            "Bb5",
            "Nd4",
            "Kg3",
            "Nf5+",
            "Kg4",
            "Nd4",
            "Kxh4",
            "Ke1",
            "Kg3",
            "Nf5+",
            "Kg2",
            "Nh4+",
            "Kg3",
            "Nf5+",
            "Kg4",
            "Nd4",
            "h4",
            "Kf2",
            "h3",
            "Kg1",
            "Kg3",
            "Nf5+",
            "Kf3",
            "Kh2",
            "Bd7",
            "Nd4+",
            "Ke3",
            "Nc2+",
            "Kd2",
            "Nd4",
            "a5",
            "Nb3+",
            "Ke2",
            "Nxa5",
            "f3",
            "Nc4",
            "f2",
            "Ne5",
            "f1=Q",
            "Nxd7",
            "Qg2#",
            "e4",
            "d5",
            "f4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": "e2e3",
          "positional_response": "5. e3 d5 6. c4 c6 7. Nc3 Be6 8. Qb3 Qd7 9. cxd5 cxd5 10. Bb5 Nc6 11. O-O Bd6 12. Rac1 O-O 13. Na4 Rac8 14. Nc5 Bxc5 15. Rxc5 a6 16. Bxc6 Rxc6 17. Rfc1 Rfc8 18. Rxc6 Rxc6 19. Rxc6 Qxc6 20. Qc3 Qxc3 21. bxc3 Kf7 22. Kf1 Ke7 23. Ke2 Kd6 24. Kd3 Kc6 25. Nd2 Kb5 26. Kc2 Ka4 27. Kb2 b6 28. Nb1 Kb5 29. Nd2 Ka4 30. Nb1 Kb5 31. Nd2 Ka4 32. Nb1 Kb5 33. Nd2 Ka4 34. Nb1 Kb5 35. Nd2 Ka4 36. Nb1 Kb5 37. Nd2 Ka4 38. Nb1 Kb5 39. Nd2 Ka4 40. Nb1 Kb5 41. Nd2 Ka4 42. Nb1 Kb5 43. Nd2 Ka4 44. Nb1 Kb5 45. Nd2 Ka4 46. Nb1 Kb5 47. Nd2 Ka4 48. Nb1 Kb5 49. Nd2 Ka4 50. Nb1 Kb5 51. Nd2 Ka4 52. Nb1 Kb5 53. Nd2 Ka4 54. Nb1 Kb5 55. Nd2 Ka4 56. Nb1 Kb5 57. Nd2 Ka4 58. Nb1 Kb5 59. Nd2 Ka4 60. Nb1 Kb5 61. Nd2 Ka4 62. Nb1 Kb5 63. Nd2 Ka4 64. Nb1 Kb5 65. Nd2 Ka4 66. Nb1 Kb5 67. Nd2 Ka4 68. Nb1 Kb5 69. Nd2 Ka4 70. Nb1 Kb5 71. Nd2 Ka4 72. Nb1 Kb5 73. Nd2 Ka4 74. Nb1 Kb5 75. Nd2 Ka4 76. Nb1 Kb5 77. Nd2 Ka4 78. Nb1 Kb5 79. Nd2 Ka4 80. Nb1 Kb5 81. Nd2 Ka4 82. Nb1 Kb5 83. Nd2 Ka4 84. Nb1 Kb5 85. Nd2 Ka4 86. Nb1 Kb5 87. Nd2 Ka4 88. Nb1 Kb5 89. Nd2 Ka4 90. Nb1 Kb5 91. Nd2 Ka4 92. Nb",
          "positional_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "c4",
            "c6",
            "Nc3",
            "Be6",
            "Qb3",
            "Qd7",
            "cxd5",
            "cxd5",
            "Bb5",
            "Nc6",
            "O-O",
            "Bd6",
            "Rac1",
            "O-O",
            "Na4",
            "Rac8",
            "Nc5",
            "Bxc5",
            "Rxc5",
            "a6",
            "Bxc6",
            "Rxc6",
            "Rfc1",
            "Rfc8",
            "Rxc6",
            "Rxc6",
            "Rxc6",
            "Qxc6",
            "Qc3",
            "Qxc3",
            "bxc3",
            "Kf7",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd6",
            "Kd3",
            "Kc6",
            "Nd2",
            "Kb5",
            "Kc2",
            "Ka4",
            "Kb2",
            "b6",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4",
            "Nb1",
            "Kb5",
            "Nd2",
            "Ka4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e3",
          "neutral_uci": "e2e3",
          "neutral_response": "5. e3 d5 6. c4 c6 7. Nc3 Be6 8. Qb3 Qd7 9. cxd5 cxd5 10. Bb5 Nc6 11. O-O Bd6 12. Rac1 O-O 13. Na4 Rac8 14. Nc5 Bxc5 15. Rxc5 a6 16. Bxc6 Rxc6 17. Rfc1 Rfc8 18. Rxc6 Rxc6 19. Rxc6 Qxc6 20. Qc3 Qxc3 21. bxc3 Kf7 22. Kf1 Ke7 23. Ke2 Kd6 24. Kd3 Kc6 25. Nd2 Kb5 26. Kc2 Ka4 27. Kb2 b6 28. Nb1 Kb5 29. Na3+ Kc6 30. Kb3 g5 31. g3 h5 32. h4 f4 33. exf4 gxf4 34. gxf4 Bf5 35. c4 Bd3 36. Kc3 Be2 37. cxd5+ Kxd5 38. Nc2 Ke4 39. Kd2 Bc4 40. a3 Kxf4 41. Ne3 Bb5 42. Nd5+ Kg4 43. Nxf6+ Kxh4 44. d5 Kg5 45. Ne4+ Kf4 46. Nf6 h4 47. d6 h3 48. d7 Bxd7 49. Nxd7 h2 50. Nxb6 h1=Q 51. Nc4 Qd5+ 52. Kc3 Kf3 53. Nd2+ Kxf2 54. Nb3 Ke3 55. Kb4 Qb5+ 56. Kc3 Qd3+ 57. Kb4 Qb5+ 58. Kc3 Qa4 59. Kb2 Kd3 60. Nc5+ Kc4 61. Nxa4 Kb5 62. Nc3+ Kc4 63. Kc2 Kd4 64. Kb3 Kc5 65. Ka4 Kc4 66. Ne4 Kd4 67. Nd6 Kc5 68. Nb7+ Kb6 69. Nd8 Kc7 70. Ne6+ Kb6 71. Kb4 Kc6 72. Ka5 Kb7 73. Nc5+ Ka7 74. Nxa6 Kb7 75. Nc5+ Ka7 76. Kb5 Kb8 77. Kb6 Ka8 78. a4 Kb8 79. a5 Ka8 80. a6 Kb8 81. Ne6 Ka8 82. Nc7+",
          "neutral_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "c4",
            "c6",
            "Nc3",
            "Be6",
            "Qb3",
            "Qd7",
            "cxd5",
            "cxd5",
            "Bb5",
            "Nc6",
            "O-O",
            "Bd6",
            "Rac1",
            "O-O",
            "Na4",
            "Rac8",
            "Nc5",
            "Bxc5",
            "Rxc5",
            "a6",
            "Bxc6",
            "Rxc6",
            "Rfc1",
            "Rfc8",
            "Rxc6",
            "Rxc6",
            "Rxc6",
            "Qxc6",
            "Qc3",
            "Qxc3",
            "bxc3",
            "Kf7",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd6",
            "Kd3",
            "Kc6",
            "Nd2",
            "Kb5",
            "Kc2",
            "Ka4",
            "Kb2",
            "b6",
            "Nb1",
            "Kb5",
            "Na3+",
            "Kc6",
            "Kb3",
            "g5",
            "g3",
            "h5",
            "h4",
            "f4",
            "exf4",
            "gxf4",
            "gxf4",
            "Bf5",
            "c4",
            "Bd3",
            "Kc3",
            "Be2",
            "cxd5+",
            "Kxd5",
            "Nc2",
            "Ke4",
            "Kd2",
            "Bc4",
            "a3",
            "Kxf4",
            "Ne3",
            "Bb5",
            "Nd5+",
            "Kg4",
            "Nxf6+",
            "Kxh4",
            "d5",
            "Kg5",
            "Ne4+",
            "Kf4",
            "Nf6",
            "h4",
            "d6",
            "h3",
            "d7",
            "Bxd7",
            "Nxd7",
            "h2",
            "Nxb6",
            "h1=Q",
            "Nc4",
            "Qd5+",
            "Kc3",
            "Kf3",
            "Nd2+",
            "Kxf2",
            "Nb3",
            "Ke3",
            "Kb4",
            "Qb5+",
            "Kc3",
            "Qd3+",
            "Kb4",
            "Qb5+",
            "Kc3",
            "Qa4",
            "Kb2",
            "Kd3",
            "Nc5+",
            "Kc4",
            "Nxa4",
            "Kb5",
            "Nc3+",
            "Kc4",
            "Kc2",
            "Kd4",
            "Kb3",
            "Kc5",
            "Ka4",
            "Kc4",
            "Ne4",
            "Kd4",
            "Nd6",
            "Kc5",
            "Nb7+",
            "Kb6",
            "Nd8",
            "Kc7",
            "Ne6+",
            "Kb6",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Nc5+",
            "Ka7",
            "Nxa6",
            "Kb7",
            "Nc5+",
            "Ka7",
            "Kb5",
            "Kb8",
            "Kb6",
            "Ka8",
            "a4",
            "Kb8",
            "a5",
            "Ka8",
            "a6",
            "Kb8",
            "Ne6",
            "Ka8",
            "Nc7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e3",
          "positional_uci": "e2e3",
          "neutral_uci": "e2e3",
          "consensus_move": "e2e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "c4",
              "c6",
              "Nc3",
              "Be6",
              "Qb3",
              "Qd7",
              "cxd5",
              "cxd5",
              "Bb5",
              "Nc6",
              "O-O",
              "Bd6",
              "Rac1",
              "O-O",
              "Na4",
              "Rac8",
              "Nc5",
              "Bxc5",
              "Rxc5",
              "a6",
              "Bxc6",
              "Rxc6",
              "Rfc1",
              "Rfc8",
              "Rxc6",
              "Rxc6",
              "Rxc6",
              "Qxc6",
              "Qc3",
              "Qxc3",
              "bxc3",
              "Kf7",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd6",
              "Kd3",
              "Kc6",
              "Nd2",
              "Kb5",
              "Kc2",
              "Ka4",
              "Kb2",
              "b6",
              "Nb1",
              "Kb5",
              "Na3+",
              "Kc6",
              "Kb3",
              "g5",
              "g3",
              "h5",
              "h4",
              "f4",
              "exf4",
              "gxf4",
              "gxf4",
              "Bf5",
              "c4",
              "Bd3",
              "Kc3",
              "Be2",
              "cxd5+",
              "Kxd5",
              "Nc2",
              "Ke4",
              "Kd2",
              "Bc4",
              "a3",
              "Kxf4",
              "Ne3",
              "Be6",
              "d5",
              "Bd7",
              "Kd3",
              "Ke5",
              "Kc4",
              "f5",
              "f3",
              "f4",
              "Nc2",
              "Bb5+",
              "Kb4",
              "Kxd5",
              "a4",
              "Be2",
              "Ne1",
              "Kd4",
              "a5",
              "bxa5+",
              "Kxa5",
              "Ke3",
              "Kb4",
              "Bxf3",
              "Kc3",
              "Be2",
              "Nc2+",
              "Kf2",
              "Kd2",
              "Bb5",
              "Nd4",
              "Kg3",
              "Nf5+",
              "Kg4",
              "Nd4",
              "Kxh4",
              "Ke1",
              "Kg3",
              "Nf5+",
              "Kg2",
              "Nh4+",
              "Kg3",
              "Nf5+",
              "Kg4",
              "Nd4",
              "h4",
              "Kf2",
              "h3",
              "Kg1",
              "Kg3",
              "Nf5+",
              "Kf3",
              "Kh2",
              "Bd7",
              "Nd4+",
              "Ke3",
              "Nc2+",
              "Kd2",
              "Nd4",
              "a5",
              "Nb3+",
              "Ke2",
              "Nxa5",
              "f3",
              "Nc4",
              "f2",
              "Ne5",
              "f1=Q",
              "Nxd7",
              "Qg2#",
              "e4",
              "d5",
              "f4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d5",
              "c4",
              "c6",
              "Nc3",
              "Be6",
              "Qb3",
              "Qd7",
              "cxd5",
              "cxd5",
              "Bb5",
              "Nc6",
              "O-O",
              "Bd6",
              "Rac1",
              "O-O",
              "Na4",
              "Rac8",
              "Nc5",
              "Bxc5",
              "Rxc5",
              "a6",
              "Bxc6",
              "Rxc6",
              "Rfc1",
              "Rfc8",
              "Rxc6",
              "Rxc6",
              "Rxc6",
              "Qxc6",
              "Qc3",
              "Qxc3",
              "bxc3",
              "Kf7",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd6",
              "Kd3",
              "Kc6",
              "Nd2",
              "Kb5",
              "Kc2",
              "Ka4",
              "Kb2",
              "b6",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4",
              "Nb1",
              "Kb5",
              "Nd2",
              "Ka4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "c4",
              "c6",
              "Nc3",
              "Be6",
              "Qb3",
              "Qd7",
              "cxd5",
              "cxd5",
              "Bb5",
              "Nc6",
              "O-O",
              "Bd6",
              "Rac1",
              "O-O",
              "Na4",
              "Rac8",
              "Nc5",
              "Bxc5",
              "Rxc5",
              "a6",
              "Bxc6",
              "Rxc6",
              "Rfc1",
              "Rfc8",
              "Rxc6",
              "Rxc6",
              "Rxc6",
              "Qxc6",
              "Qc3",
              "Qxc3",
              "bxc3",
              "Kf7",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd6",
              "Kd3",
              "Kc6",
              "Nd2",
              "Kb5",
              "Kc2",
              "Ka4",
              "Kb2",
              "b6",
              "Nb1",
              "Kb5",
              "Na3+",
              "Kc6",
              "Kb3",
              "g5",
              "g3",
              "h5",
              "h4",
              "f4",
              "exf4",
              "gxf4",
              "gxf4",
              "Bf5",
              "c4",
              "Bd3",
              "Kc3",
              "Be2",
              "cxd5+",
              "Kxd5",
              "Nc2",
              "Ke4",
              "Kd2",
              "Bc4",
              "a3",
              "Kxf4",
              "Ne3",
              "Bb5",
              "Nd5+",
              "Kg4",
              "Nxf6+",
              "Kxh4",
              "d5",
              "Kg5",
              "Ne4+",
              "Kf4",
              "Nf6",
              "h4",
              "d6",
              "h3",
              "d7",
              "Bxd7",
              "Nxd7",
              "h2",
              "Nxb6",
              "h1=Q",
              "Nc4",
              "Qd5+",
              "Kc3",
              "Kf3",
              "Nd2+",
              "Kxf2",
              "Nb3",
              "Ke3",
              "Kb4",
              "Qb5+",
              "Kc3",
              "Qd3+",
              "Kb4",
              "Qb5+",
              "Kc3",
              "Qa4",
              "Kb2",
              "Kd3",
              "Nc5+",
              "Kc4",
              "Nxa4",
              "Kb5",
              "Nc3+",
              "Kc4",
              "Kc2",
              "Kd4",
              "Kb3",
              "Kc5",
              "Ka4",
              "Kc4",
              "Ne4",
              "Kd4",
              "Nd6",
              "Kc5",
              "Nb7+",
              "Kb6",
              "Nd8",
              "Kc7",
              "Ne6+",
              "Kb6",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Nc5+",
              "Ka7",
              "Nxa6",
              "Kb7",
              "Nc5+",
              "Ka7",
              "Kb5",
              "Kb8",
              "Kb6",
              "Ka8",
              "a4",
              "Kb8",
              "a5",
              "Ka8",
              "a6",
              "Kb8",
              "Ne6",
              "Ka8",
              "Nc7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 142,
            "completion_tokens": 586,
            "total_tokens": 728,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 425,
          "total_completion_tokens": 1866,
          "total_tokens": 2291
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 142,
            "completion_tokens": 586,
            "total_tokens": 728,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pppp3p/5pp1/5p2/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c4",
          "aggressive_uci": "c2c4",
          "aggressive_response": "6. c4 d6 7. Nc3 Be6 8. d5 Bf7 9. Nd4 c5 10. Ne6 Bxe6 11. dxe6 Nc6 12. Nd5 Bg7 13. h4 O-O 14. h5 Re8 15. hxg6 hxg6 16. Nf4 g5 17. Qh5 Qe7 18. Qh7+ Kf8 19. Ng6# d5 cxd4 Qh8#",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 120,
            "total_tokens": 269,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d6",
            "Nc3",
            "Be6",
            "d5",
            "Bf7",
            "Nd4",
            "c5",
            "Ne6",
            "Bxe6",
            "dxe6",
            "Nc6",
            "Nd5",
            "Bg7",
            "h4",
            "O-O",
            "h5",
            "Re8",
            "hxg6",
            "hxg6",
            "Nf4",
            "g5",
            "Qh5",
            "Qe7",
            "Qh7+",
            "Kf8",
            "Ng6#",
            "d5",
            "cxd4",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c4",
          "positional_uci": "c2c4",
          "positional_response": "6. c4 d6 7. Nc3 Be6 8. d5 Bf7 9. Nd4 c5 10. Ne6 Bxe6 11. dxe6 Nc6 12. Nd5 Bg7 13. h4 O-O 14. h5 Re8 15. hxg6 hxg6 16. Nf4 g5 17. Qh5 Qa5+ 18. Kd1 Ne5 19. Qh7+ Kf8 20. Nh5 Re7 21. Nxg7 Rxg7 22. Qh8+ Rg8 23. Qxf6+ Ke8 24. Rh7 Qd8 25. Qxf5 Rf8 26. Qe4 Rxf2 27. Be2 Qf6 28. Qxb7 Rd8 29. Bh5+ Kf8 30. e7+ Kg8 31. exd8=Q+ Qxd8 32. Qg7# d5 e4 dxc4+ Ke1 Qd2#",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 241,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d6",
            "Nc3",
            "Be6",
            "d5",
            "Bf7",
            "Nd4",
            "c5",
            "Ne6",
            "Bxe6",
            "dxe6",
            "Nc6",
            "Nd5",
            "Bg7",
            "h4",
            "O-O",
            "h5",
            "Re8",
            "hxg6",
            "hxg6",
            "Nf4",
            "g5",
            "Qh5",
            "Qa5+",
            "Kd1",
            "Ne5",
            "Qh7+",
            "Kf8",
            "Nh5",
            "Re7",
            "Nxg7",
            "Rxg7",
            "Qh8+",
            "Rg8",
            "Qxf6+",
            "Ke8",
            "Rh7",
            "Qd8",
            "Qxf5",
            "Rf8",
            "Qe4",
            "Rxf2",
            "Be2",
            "Qf6",
            "Qxb7",
            "Rd8",
            "Bh5+",
            "Kf8",
            "e7+",
            "Kg8",
            "exd8=Q+",
            "Qxd8",
            "Qg7#",
            "d5",
            "e4",
            "dxc4+",
            "Ke1",
            "Qd2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c4",
          "neutral_uci": "c2c4",
          "neutral_response": "6. c4 d6 7. Nc3 Be6 8. d5 Bf7 9. Nd4 c5 10. Ne6 Bxe6 11. dxe6 Nc6 12. Nd5 Bg7 13. h4 O-O 14. h5 Re8 15. hxg6 hxg6 16. Nf4 g5 17. Qh5 Qa5+ 18. Kd1 Ne5 19. Qh7+ Kf8 20. Nh5 Re7 21. Nxg7 Rxg7 22. Qh8+ Rg8 23. Qxf6+ Ke8 24. Rh7 Qd8 25. Qxf5 Rf8 26. Qe4 Rxf2 27. Be2 Qf6 28. Qxb7 Rd8 29. Bh5+ Kf8 30. e7+ Kg8 31. exd8=Q+ Qxd8 32. Qg7# d4 e5 Qxd8",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 234,
            "total_tokens": 382,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d6",
            "Nc3",
            "Be6",
            "d5",
            "Bf7",
            "Nd4",
            "c5",
            "Ne6",
            "Bxe6",
            "dxe6",
            "Nc6",
            "Nd5",
            "Bg7",
            "h4",
            "O-O",
            "h5",
            "Re8",
            "hxg6",
            "hxg6",
            "Nf4",
            "g5",
            "Qh5",
            "Qa5+",
            "Kd1",
            "Ne5",
            "Qh7+",
            "Kf8",
            "Nh5",
            "Re7",
            "Nxg7",
            "Rxg7",
            "Qh8+",
            "Rg8",
            "Qxf6+",
            "Ke8",
            "Rh7",
            "Qd8",
            "Qxf5",
            "Rf8",
            "Qe4",
            "Rxf2",
            "Be2",
            "Qf6",
            "Qxb7",
            "Rd8",
            "Bh5+",
            "Kf8",
            "e7+",
            "Kg8",
            "exd8=Q+",
            "Qxd8",
            "Qg7#",
            "d4",
            "e5",
            "Qxd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c4",
          "positional_uci": "c2c4",
          "neutral_uci": "c2c4",
          "consensus_move": "c2c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d6",
              "Nc3",
              "Be6",
              "d5",
              "Bf7",
              "Nd4",
              "c5",
              "Ne6",
              "Bxe6",
              "dxe6",
              "Nc6",
              "Nd5",
              "Bg7",
              "h4",
              "O-O",
              "h5",
              "Re8",
              "hxg6",
              "hxg6",
              "Nf4",
              "g5",
              "Qh5",
              "Qe7",
              "Qh7+",
              "Kf8",
              "Ng6#",
              "d5",
              "cxd4",
              "Qh8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d6",
              "Nc3",
              "Be6",
              "d5",
              "Bf7",
              "Nd4",
              "c5",
              "Ne6",
              "Bxe6",
              "dxe6",
              "Nc6",
              "Nd5",
              "Bg7",
              "h4",
              "O-O",
              "h5",
              "Re8",
              "hxg6",
              "hxg6",
              "Nf4",
              "g5",
              "Qh5",
              "Qa5+",
              "Kd1",
              "Ne5",
              "Qh7+",
              "Kf8",
              "Nh5",
              "Re7",
              "Nxg7",
              "Rxg7",
              "Qh8+",
              "Rg8",
              "Qxf6+",
              "Ke8",
              "Rh7",
              "Qd8",
              "Qxf5",
              "Rf8",
              "Qe4",
              "Rxf2",
              "Be2",
              "Qf6",
              "Qxb7",
              "Rd8",
              "Bh5+",
              "Kf8",
              "e7+",
              "Kg8",
              "exd8=Q+",
              "Qxd8",
              "Qg7#",
              "d5",
              "e4",
              "dxc4+",
              "Ke1",
              "Qd2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d6",
              "Nc3",
              "Be6",
              "d5",
              "Bf7",
              "Nd4",
              "c5",
              "Ne6",
              "Bxe6",
              "dxe6",
              "Nc6",
              "Nd5",
              "Bg7",
              "h4",
              "O-O",
              "h5",
              "Re8",
              "hxg6",
              "hxg6",
              "Nf4",
              "g5",
              "Qh5",
              "Qa5+",
              "Kd1",
              "Ne5",
              "Qh7+",
              "Kf8",
              "Nh5",
              "Re7",
              "Nxg7",
              "Rxg7",
              "Qh8+",
              "Rg8",
              "Qxf6+",
              "Ke8",
              "Rh7",
              "Qd8",
              "Qxf5",
              "Rf8",
              "Qe4",
              "Rxf2",
              "Be2",
              "Qf6",
              "Qxb7",
              "Rd8",
              "Bh5+",
              "Kf8",
              "e7+",
              "Kg8",
              "exd8=Q+",
              "Qxd8",
              "Qg7#",
              "d4",
              "e5",
              "Qxd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 120,
            "total_tokens": 269,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 241,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 234,
            "total_tokens": 382,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 595,
          "total_tokens": 1041
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 120,
            "total_tokens": 269,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 241,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 234,
            "total_tokens": 382,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pp1p3p/2p2pp1/5p2/3P4/4PN2/PPP2PPP/RN1QKB1R w KQkq - 0 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "7. Nc3 Qa5 8. Qb3 d6 9. a3 Bxc3+ 10. Qxc3 Qxc3+ 11. bxc3 Be6 12. Rb1 b6 13. Bd3 Nd7 14. O-O O-O 15. Rfe1 Rfe8 16. Nd2 d5 17. cxd5 Bxd5 18. c4 Bf7 19. e4 fxe4 20. Nxe4 Kg7 21. Nd6 Rxe1+ 22. Rxe1 Kf8 23. Be4 Rd8 24. Bxc6 Nb8 25. Nxf7 Nxc6 26. Nxd8 Nxd8 27. d5 Kf7 28. f4 Nb7 29. Kf2 Nd6 30. Rc1 Ne4+ 31. Ke3 Nc5 32. Kd4 Ke7 33. Re1+ Kd6 34. Re8 Nb3+ 35. Kc3 Nc5 36. Rh8 h5 37. Rh6 Ne4+ 38. Kd4 Nd2 39. Rxg6 Ke7 40. Rg7+ Kd6 41. Rxa7 Nb3+ 42. Kc3 Nc5 43. Rh7 Ne4+ 44. Kd4 Nd2 45. Rxh5 Nb3+ 46. Kc3 Nc5 47. Rh6 Ke7 48. g4 Ne4+ 49. Kd4 Nf2 50. g5 fxg5 51. fxg5 Ng4 52. Rxb6 Nxh2 53. g6 Nf3+ 54. Kc5 Ne5 55. Re6+ Kd7 56. Rxe5 Kc7 57. g7 Kd7 58. g8=Q Kc7 59. Re7# Qa5+ 60. Kd4+ Kd6 61. Qe6# Qd2+ 62. Ke4 Qe2+ 63. Kf5 Qf3+ 64. Kg6 Qg3+ 65. Kf7 Qf4+ 66. Ke8 Kc5 67. Qc6+ Kd4 68. Qxb6+ Kxc4 69. Qb4+ Kxd5 70. Qxf4 Kc5 71. Re5+ Kd6 72. Qf6+ Kc7 73. Re7+ Kc8 74. Qc6+ Kb8 75. Qb7# Qa5+ 76. Kf7# Qf5+ 77. Kg8# Qg6+ 78. Rg7# Qe8+ 79. Kh7# Qh5+",
          "aggressive_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 640,
            "total_tokens": 798,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qa5",
            "Qb3",
            "d6",
            "a3",
            "Bxc3+",
            "Qxc3",
            "Qxc3+",
            "bxc3",
            "Be6",
            "Rb1",
            "b6",
            "Bd3",
            "Nd7",
            "O-O",
            "O-O",
            "Rfe1",
            "Rfe8",
            "Nd2",
            "d5",
            "cxd5",
            "Bxd5",
            "c4",
            "Bf7",
            "e4",
            "fxe4",
            "Nxe4",
            "Kg7",
            "Nd6",
            "Rxe1+",
            "Rxe1",
            "Kf8",
            "Be4",
            "Rd8",
            "Bxc6",
            "Nb8",
            "Nxf7",
            "Nxc6",
            "Nxd8",
            "Nxd8",
            "d5",
            "Kf7",
            "f4",
            "Nb7",
            "Kf2",
            "Nd6",
            "Rc1",
            "Ne4+",
            "Ke3",
            "Nc5",
            "Kd4",
            "Ke7",
            "Re1+",
            "Kd6",
            "Re8",
            "Nb3+",
            "Kc3",
            "Nc5",
            "Rh8",
            "h5",
            "Rh6",
            "Ne4+",
            "Kd4",
            "Nd2",
            "Rxg6",
            "Ke7",
            "Rg7+",
            "Kd6",
            "Rxa7",
            "Nb3+",
            "Kc3",
            "Nc5",
            "Rh7",
            "Ne4+",
            "Kd4",
            "Nd2",
            "Rxh5",
            "Nb3+",
            "Kc3",
            "Nc5",
            "Rh6",
            "Ke7",
            "g4",
            "Ne4+",
            "Kd4",
            "Nf2",
            "g5",
            "fxg5",
            "fxg5",
            "Ng4",
            "Rxb6",
            "Nxh2",
            "g6",
            "Nf3+",
            "Kc5",
            "Ne5",
            "Re6+",
            "Kd7",
            "Rxe5",
            "Kc7",
            "g7",
            "Kd7",
            "g8=Q",
            "Kc7",
            "Re7#",
            "Qa5+",
            "Kd4+",
            "Kd6",
            "Qe6#",
            "Qd2+",
            "Ke4",
            "Qe2+",
            "Kf5",
            "Qf3+",
            "Kg6",
            "Qg3+",
            "Kf7",
            "Qf4+",
            "Ke8",
            "Kc5",
            "Qc6+",
            "Kd4",
            "Qxb6+",
            "Kxc4",
            "Qb4+",
            "Kxd5",
            "Qxf4",
            "Kc5",
            "Re5+",
            "Kd6",
            "Qf6+",
            "Kc7",
            "Re7+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb7#",
            "Qa5+",
            "Kf7#",
            "Qf5+",
            "Kg8#",
            "Qg6+",
            "Rg7#",
            "Qe8+",
            "Kh7#",
            "Qh5+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "7. Nc3 Qa5 8. Qb3 d6 9. Bd3 Be6 10. O-O Nd7 11. a3 Bxc3 12. bxc3 b5 13. d5 bxc4 14. Bxc4 cxd5 15. Bb5 Rb8 16. Bxd7+ Kxd7 17. Qc2 Rhc8 18. Rfc1 Rc4 19. Nd4 Rbc8 20. Qb3 Rxc3 21. Rxc3 Qxc3 22. Qb5+ Ke7 23. Rb1 Qc1+ 24. Rxc1 Rxc1+ 25. Qf1 Rxf1+ 26. Kxf1 Bd7 27. Ke2 Kd8 28. Kd3 Kc7 29. Kc3 Kb6 30. Kb4 a5+ 31. Kc3 Kc5 32. Nb3+ Kb5 33. Nd4+ Ka4 34. Kb2 g5 35. Ne2 Kb5 36. Kc3 Kc5 37. Nd4 a4 38. g3 h5 39. h4 f4 40. exf4 gxf4 41. gxf4 Bg4 42. f3 Bh3 43. f5 Bf1 44. Ne6+ Kb5 45. Nf4 Kc5 46. Nxh5 d4+ 47. Kd2 Kc4 48. Nxf6 Kb3 49. h5 Kxa3 50. h6 Kb2 51. h7 a3 52. h8=Q a2 53. Qb8+ Ka3 54. Qxd6+ Kb2 55. Qxd4+ Kb1 56. Qb4+ Ka1 57. Kc1 Bd3 58. Qb2# d3 e5 d2+ Kxd2 d4 Kc3 d3 Qb3#",
          "positional_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 454,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qa5",
            "Qb3",
            "d6",
            "Bd3",
            "Be6",
            "O-O",
            "Nd7",
            "a3",
            "Bxc3",
            "bxc3",
            "b5",
            "d5",
            "bxc4",
            "Bxc4",
            "cxd5",
            "Bb5",
            "Rb8",
            "Bxd7+",
            "Kxd7",
            "Qc2",
            "Rhc8",
            "Rfc1",
            "Rc4",
            "Nd4",
            "Rbc8",
            "Qb3",
            "Rxc3",
            "Rxc3",
            "Qxc3",
            "Qb5+",
            "Ke7",
            "Rb1",
            "Qc1+",
            "Rxc1",
            "Rxc1+",
            "Qf1",
            "Rxf1+",
            "Kxf1",
            "Bd7",
            "Ke2",
            "Kd8",
            "Kd3",
            "Kc7",
            "Kc3",
            "Kb6",
            "Kb4",
            "a5+",
            "Kc3",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Ka4",
            "Kb2",
            "g5",
            "Ne2",
            "Kb5",
            "Kc3",
            "Kc5",
            "Nd4",
            "a4",
            "g3",
            "h5",
            "h4",
            "f4",
            "exf4",
            "gxf4",
            "gxf4",
            "Bg4",
            "f3",
            "Bh3",
            "f5",
            "Bf1",
            "Ne6+",
            "Kb5",
            "Nf4",
            "Kc5",
            "Nxh5",
            "d4+",
            "Kd2",
            "Kc4",
            "Nxf6",
            "Kb3",
            "h5",
            "Kxa3",
            "h6",
            "Kb2",
            "h7",
            "a3",
            "h8=Q",
            "a2",
            "Qb8+",
            "Ka3",
            "Qxd6+",
            "Kb2",
            "Qxd4+",
            "Kb1",
            "Qb4+",
            "Ka1",
            "Kc1",
            "Bd3",
            "Qb2#",
            "d3",
            "e5",
            "d2+",
            "Kxd2",
            "d4",
            "Kc3",
            "d3",
            "Qb3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "7. Nc3 Qa5 8. Qb3 d6 9. Bd3 Be6 10. O-O Nd7 11. a3 Bxc3 12. bxc3 Qc7 13. Rab1 b6 14. e4 fxe4 15. Bxe4 O-O 16. Rfe1 Rae8 17. Qa4 Nb8 18. d5 Bd7 19. Qc2 c5 20. Bd3 Bg4 21. Nd2 Qf7 22. f3 Bc8 23. Ne4 Qc7 24. Nxf6+ Rxf6 25. Rxe8+ Kf7 26. Rbe1 Nd7 27. R1e7# d5 28. Qe2 Qd6 29. Rxh7# Kg8 30. Qe7 Qxe7 31. Rhxe7 Nf8 32. Rxa7 Bf5 33. Bxf5 Rxf5 34. cxd5 Rxd5 35. Raa8 Rf5 36. Kf2 Kg7 37. Rxf8 Rxf8 38. Rxf8 Kxf8 39. Ke3 Ke7 40. Ke4 Ke6 41. c4 Kd6 42. f4 Ke6 43. g4 Kd6 44. f5 gxf5+ 45. gxf5 Ke7 46. Ke5 Kf7 47. f6 Kf8 48. Ke6 Ke8 49. f7+ Kf8 50. Kf6 b5 51. cxb5 c4 52. b6 c3 53. b7 c2 54. b8=Q# c1=Q 55. Qd6# Kg8 56. f8=Q+ Kh7 57. Qg7# Kg8 58. Qdf8# c3 59. Qff7#",
          "neutral_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 442,
            "total_tokens": 599,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qa5",
            "Qb3",
            "d6",
            "Bd3",
            "Be6",
            "O-O",
            "Nd7",
            "a3",
            "Bxc3",
            "bxc3",
            "Qc7",
            "Rab1",
            "b6",
            "e4",
            "fxe4",
            "Bxe4",
            "O-O",
            "Rfe1",
            "Rae8",
            "Qa4",
            "Nb8",
            "d5",
            "Bd7",
            "Qc2",
            "c5",
            "Bd3",
            "Bg4",
            "Nd2",
            "Qf7",
            "f3",
            "Bc8",
            "Ne4",
            "Qc7",
            "Nxf6+",
            "Rxf6",
            "Rxe8+",
            "Kf7",
            "Rbe1",
            "Nd7",
            "R1e7#",
            "d5",
            "Qe2",
            "Qd6",
            "Rxh7#",
            "Kg8",
            "Qe7",
            "Qxe7",
            "Rhxe7",
            "Nf8",
            "Rxa7",
            "Bf5",
            "Bxf5",
            "Rxf5",
            "cxd5",
            "Rxd5",
            "Raa8",
            "Rf5",
            "Kf2",
            "Kg7",
            "Rxf8",
            "Rxf8",
            "Rxf8",
            "Kxf8",
            "Ke3",
            "Ke7",
            "Ke4",
            "Ke6",
            "c4",
            "Kd6",
            "f4",
            "Ke6",
            "g4",
            "Kd6",
            "f5",
            "gxf5+",
            "gxf5",
            "Ke7",
            "Ke5",
            "Kf7",
            "f6",
            "Kf8",
            "Ke6",
            "Ke8",
            "f7+",
            "Kf8",
            "Kf6",
            "b5",
            "cxb5",
            "c4",
            "b6",
            "c3",
            "b7",
            "c2",
            "b8=Q#",
            "c1=Q",
            "Qd6#",
            "Kg8",
            "f8=Q+",
            "Kh7",
            "Qg7#",
            "Kg8",
            "Qdf8#",
            "c3",
            "Qff7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "b1c3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qa5",
              "Qb3",
              "d6",
              "a3",
              "Bxc3+",
              "Qxc3",
              "Qxc3+",
              "bxc3",
              "Be6",
              "Rb1",
              "b6",
              "Bd3",
              "Nd7",
              "O-O",
              "O-O",
              "Rfe1",
              "Rfe8",
              "Nd2",
              "d5",
              "cxd5",
              "Bxd5",
              "c4",
              "Bf7",
              "e4",
              "fxe4",
              "Nxe4",
              "Kg7",
              "Nd6",
              "Rxe1+",
              "Rxe1",
              "Kf8",
              "Be4",
              "Rd8",
              "Bxc6",
              "Nb8",
              "Nxf7",
              "Nxc6",
              "Nxd8",
              "Nxd8",
              "d5",
              "Kf7",
              "f4",
              "Nb7",
              "Kf2",
              "Nd6",
              "Rc1",
              "Ne4+",
              "Ke3",
              "Nc5",
              "Kd4",
              "Ke7",
              "Re1+",
              "Kd6",
              "Re8",
              "Nb3+",
              "Kc3",
              "Nc5",
              "Rh8",
              "h5",
              "Rh6",
              "Ne4+",
              "Kd4",
              "Nd2",
              "Rxg6",
              "Ke7",
              "Rg7+",
              "Kd6",
              "Rxa7",
              "Nb3+",
              "Kc3",
              "Nc5",
              "Rh7",
              "Ne4+",
              "Kd4",
              "Nd2",
              "Rxh5",
              "Nb3+",
              "Kc3",
              "Nc5",
              "Rh6",
              "Ke7",
              "g4",
              "Ne4+",
              "Kd4",
              "Nf2",
              "g5",
              "fxg5",
              "fxg5",
              "Ng4",
              "Rxb6",
              "Nxh2",
              "g6",
              "Nf3+",
              "Kc5",
              "Ne5",
              "Re6+",
              "Kd7",
              "Rxe5",
              "Kc7",
              "g7",
              "Kd7",
              "g8=Q",
              "Kc7",
              "Re7#",
              "Qa5+",
              "Kd4+",
              "Kd6",
              "Qe6#",
              "Qd2+",
              "Ke4",
              "Qe2+",
              "Kf5",
              "Qf3+",
              "Kg6",
              "Qg3+",
              "Kf7",
              "Qf4+",
              "Ke8",
              "Kc5",
              "Qc6+",
              "Kd4",
              "Qxb6+",
              "Kxc4",
              "Qb4+",
              "Kxd5",
              "Qxf4",
              "Kc5",
              "Re5+",
              "Kd6",
              "Qf6+",
              "Kc7",
              "Re7+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb7#",
              "Qa5+",
              "Kf7#",
              "Qf5+",
              "Kg8#",
              "Qg6+",
              "Rg7#",
              "Qe8+",
              "Kh7#",
              "Qh5+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qa5",
              "Qb3",
              "d6",
              "Bd3",
              "Be6",
              "O-O",
              "Nd7",
              "a3",
              "Bxc3",
              "bxc3",
              "b5",
              "d5",
              "bxc4",
              "Bxc4",
              "cxd5",
              "Bb5",
              "Rb8",
              "Bxd7+",
              "Kxd7",
              "Qc2",
              "Rhc8",
              "Rfc1",
              "Rc4",
              "Nd4",
              "Rbc8",
              "Qb3",
              "Rxc3",
              "Rxc3",
              "Qxc3",
              "Qb5+",
              "Ke7",
              "Rb1",
              "Qc1+",
              "Rxc1",
              "Rxc1+",
              "Qf1",
              "Rxf1+",
              "Kxf1",
              "Bd7",
              "Ke2",
              "Kd8",
              "Kd3",
              "Kc7",
              "Kc3",
              "Kb6",
              "Kb4",
              "a5+",
              "Kc3",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Ka4",
              "Kb2",
              "g5",
              "Ne2",
              "Kb5",
              "Kc3",
              "Kc5",
              "Nd4",
              "a4",
              "g3",
              "h5",
              "h4",
              "f4",
              "exf4",
              "gxf4",
              "gxf4",
              "Bg4",
              "f3",
              "Bh3",
              "f5",
              "Bf1",
              "Ne6+",
              "Kb5",
              "Nf4",
              "Kc5",
              "Nxh5",
              "d4+",
              "Kd2",
              "Kc4",
              "Nxf6",
              "Kb3",
              "h5",
              "Kxa3",
              "h6",
              "Kb2",
              "h7",
              "a3",
              "h8=Q",
              "a2",
              "Qb8+",
              "Ka3",
              "Qxd6+",
              "Kb2",
              "Qxd4+",
              "Kb1",
              "Qb4+",
              "Ka1",
              "Kc1",
              "Bd3",
              "Qb2#",
              "d3",
              "e5",
              "d2+",
              "Kxd2",
              "d4",
              "Kc3",
              "d3",
              "Qb3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qa5",
              "Qb3",
              "d6",
              "Bd3",
              "Be6",
              "O-O",
              "Nd7",
              "a3",
              "Bxc3",
              "bxc3",
              "Qc7",
              "Rab1",
              "b6",
              "e4",
              "fxe4",
              "Bxe4",
              "O-O",
              "Rfe1",
              "Rae8",
              "Qa4",
              "Nb8",
              "d5",
              "Bd7",
              "Qc2",
              "c5",
              "Bd3",
              "Bg4",
              "Nd2",
              "Qf7",
              "f3",
              "Bc8",
              "Ne4",
              "Qc7",
              "Nxf6+",
              "Rxf6",
              "Rxe8+",
              "Kf7",
              "Rbe1",
              "Nd7",
              "R1e7#",
              "d5",
              "Qe2",
              "Qd6",
              "Rxh7#",
              "Kg8",
              "Qe7",
              "Qxe7",
              "Rhxe7",
              "Nf8",
              "Rxa7",
              "Bf5",
              "Bxf5",
              "Rxf5",
              "cxd5",
              "Rxd5",
              "Raa8",
              "Rf5",
              "Kf2",
              "Kg7",
              "Rxf8",
              "Rxf8",
              "Rxf8",
              "Kxf8",
              "Ke3",
              "Ke7",
              "Ke4",
              "Ke6",
              "c4",
              "Kd6",
              "f4",
              "Ke6",
              "g4",
              "Kd6",
              "f5",
              "gxf5+",
              "gxf5",
              "Ke7",
              "Ke5",
              "Kf7",
              "f6",
              "Kf8",
              "Ke6",
              "Ke8",
              "f7+",
              "Kf8",
              "Kf6",
              "b5",
              "cxb5",
              "c4",
              "b6",
              "c3",
              "b7",
              "c2",
              "b8=Q#",
              "c1=Q",
              "Qd6#",
              "Kg8",
              "f8=Q+",
              "Kh7",
              "Qg7#",
              "Kg8",
              "Qdf8#",
              "c3",
              "Qff7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 158,
            "completion_tokens": 640,
            "total_tokens": 798,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 158,
            "completion_tokens": 454,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 157,
            "completion_tokens": 442,
            "total_tokens": 599,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 473,
          "total_completion_tokens": 1536,
          "total_tokens": 2009
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 158,
            "completion_tokens": 640,
            "total_tokens": 798,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 158,
            "completion_tokens": 454,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 157,
            "completion_tokens": 442,
            "total_tokens": 599,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/pp1p3p/2p2pp1/5p2/1bPP4/4PN2/PP3PPP/RN1QKB1R w KQkq - 1 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qb3",
          "aggressive_uci": "d1b3",
          "aggressive_response": "8. Qb3 Qa5 9. Rc1 d6 10. a3 Bxc3+ 11. Rxc3 c5 12. d5 O-O 13. Bd3 Re8 14. O-O Qc7 15. Qc2 Qe7 16. Re1 Nc7 17. e4 fxe4 18. Rxe4 Qf7 19. Rxe8+ Nxe8 20. b4 b6 21. bxc5 bxc5 22. Rb3 Ng7 23. Qb2 Qc7 24. Qxf6 Bf5 25. Bxf5 Nxf5 26. Ng5 Re8 27. Ne6 Qa5 28. g4 Qe1+ 29. Kg2 Qe4+ 30. Kh3 Qxc4 31. Rb7 Qd3+ 32. Kg2 Qxd5+ 33. Kh3 Qf3# Qg2#",
          "aggressive_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 223,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qa5",
            "Rc1",
            "d6",
            "a3",
            "Bxc3+",
            "Rxc3",
            "c5",
            "d5",
            "O-O",
            "Bd3",
            "Re8",
            "O-O",
            "Qc7",
            "Qc2",
            "Qe7",
            "Re1",
            "Nc7",
            "e4",
            "fxe4",
            "Rxe4",
            "Qf7",
            "Rxe8+",
            "Nxe8",
            "b4",
            "b6",
            "bxc5",
            "bxc5",
            "Rb3",
            "Ng7",
            "Qb2",
            "Qc7",
            "Qxf6",
            "Bf5",
            "Bxf5",
            "Nxf5",
            "Ng5",
            "Re8",
            "Ne6",
            "Qa5",
            "g4",
            "Qe1+",
            "Kg2",
            "Qe4+",
            "Kh3",
            "Qxc4",
            "Rb7",
            "Qd3+",
            "Kg2",
            "Qxd5+",
            "Kh3",
            "Qf3#",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qb3",
          "positional_uci": "d1b3",
          "positional_response": "8. Qb3 Qa5 9. Rc1 d6 10. a3 Bxc3+ 11. Rxc3 c5 12. d5 O-O 13. Bd3 Re8 14. O-O Qc7 15. Qc2 Qe7 16. Re1 Nc7 17. e4 fxe4 18. Rxe4 Qf7 19. Rxe8+ Nxe8 20. b4 b6 21. bxc5 bxc5 22. Rb3 Ng7 23. Qb2 Qc7 24. Qxf6 Bf5 25. Bxf5 Nxf5 26. Ng5 Rf8 27. Qe6+ Kg7 28. Qe1 Nd4 29. Re3 Qb6 30. Re7+ Kg8 31. Rxh7 Qb2 32. h3 Ne2+ 33. Kh2 Qe5+ 34. g3 Qxg5 35. Rxa7 Nd4 36. Qe7 Rxf2+ 37. Kh1 Qc1+ 38. Qe1 Qxe1# Qc1+ Qe1# Qc1+ Qe1#",
          "positional_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 279,
            "total_tokens": 445,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qa5",
            "Rc1",
            "d6",
            "a3",
            "Bxc3+",
            "Rxc3",
            "c5",
            "d5",
            "O-O",
            "Bd3",
            "Re8",
            "O-O",
            "Qc7",
            "Qc2",
            "Qe7",
            "Re1",
            "Nc7",
            "e4",
            "fxe4",
            "Rxe4",
            "Qf7",
            "Rxe8+",
            "Nxe8",
            "b4",
            "b6",
            "bxc5",
            "bxc5",
            "Rb3",
            "Ng7",
            "Qb2",
            "Qc7",
            "Qxf6",
            "Bf5",
            "Bxf5",
            "Nxf5",
            "Ng5",
            "Rf8",
            "Qe6+",
            "Kg7",
            "Qe1",
            "Nd4",
            "Re3",
            "Qb6",
            "Re7+",
            "Kg8",
            "Rxh7",
            "Qb2",
            "h3",
            "Ne2+",
            "Kh2",
            "Qe5+",
            "g3",
            "Qxg5",
            "Rxa7",
            "Nd4",
            "Qe7",
            "Rxf2+",
            "Kh1",
            "Qc1+",
            "Qe1",
            "Qxe1#",
            "Qc1+",
            "Qe1#",
            "Qc1+",
            "Qe1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qb3",
          "neutral_uci": "d1b3",
          "neutral_response": "8. Qb3 Qa5 9. Rc1 d6 10. a3 Bxc3+ 11. Rxc3 c5 12. d5 O-O 13. Be2 Nc7 14. O-O Ne8 15. Qc2 Ng7 16. Rb1 Qc7 17. b4 b6 18. bxc5 bxc5 19. Rcb3 Re8 20. Bd3 Re7 21. Qc3 Kf7 22. Nd2 Ba6 23. e4 fxe4 24. Nxe4 Ne8 25. Qd2 Kg7 26. Qf4 Rd8 27. h4 Re5 28. g4 Qe7 29. f3 f5 30. gxf5 Rxf5 31. Qg3 Nf6 32. Ng5 Re5 33. Ne6+ Rxe6 34. dxe6 Qxe6 35. Re1 Qf7 36. Rb2 Nh5 37. Qg5 Rd7 38. Rbe2 Nf6 39. Re6 Bb7 40. h5 Bxf3 41. hxg6 hxg6 42. Rf1 Qxe6 43. Qxg6+ Kf8 44. Rxf3 Rf7 45. Bf5 Qe1+ 46. Kg2 Qe2+ 47. Rf2 Qe5 48. Qh6+ Ke7 49. Qh4 Rg7+ 50. Kf1 Qa1+ 51. Ke2 Qb2+ 52. Kf1 Qc1+ 53. Ke2 Qb2+ 54. Kf1 Qc1+ 55. Ke2 Qb2+ 56. Kf1 Qc1+ 57. Ke2 Qb2+ 58. Kf1 Qc1+ 59. Ke2 Qb2+ 60. Kf1 Qc1+ 61. Ke2 Qb2+ 62. Kf1 Qc1+ 63. Ke2 Qb2+ 64. Kf1 Qc1+ 65. Ke2 Qb2+ 66. Kf1 Qc1+ 67. Ke2 Qb2+ 68. Kf1 Qc1+ 69. Ke2 Qb2+ 70. Kf1 Qc1+ 71. Ke2 Qb2+ 72. Kf1 Qc1+ 73. Ke2 Qb2+ 74. Kf1 Qc1+ 75. Ke2 Qb2+ 76. Kf1 Qc1+ 77. Ke2 Qb2+ 78. Kf1 Qc1+ 79. Ke2 Qb2+ 80. Kf",
          "neutral_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 640,
            "total_tokens": 805,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qa5",
            "Rc1",
            "d6",
            "a3",
            "Bxc3+",
            "Rxc3",
            "c5",
            "d5",
            "O-O",
            "Be2",
            "Nc7",
            "O-O",
            "Ne8",
            "Qc2",
            "Ng7",
            "Rb1",
            "Qc7",
            "b4",
            "b6",
            "bxc5",
            "bxc5",
            "Rcb3",
            "Re8",
            "Bd3",
            "Re7",
            "Qc3",
            "Kf7",
            "Nd2",
            "Ba6",
            "e4",
            "fxe4",
            "Nxe4",
            "Ne8",
            "Qd2",
            "Kg7",
            "Qf4",
            "Rd8",
            "h4",
            "Re5",
            "g4",
            "Qe7",
            "f3",
            "f5",
            "gxf5",
            "Rxf5",
            "Qg3",
            "Nf6",
            "Ng5",
            "Re5",
            "Ne6+",
            "Rxe6",
            "dxe6",
            "Qxe6",
            "Re1",
            "Qf7",
            "Rb2",
            "Nh5",
            "Qg5",
            "Rd7",
            "Rbe2",
            "Nf6",
            "Re6",
            "Bb7",
            "h5",
            "Bxf3",
            "hxg6",
            "hxg6",
            "Rf1",
            "Qxe6",
            "Qxg6+",
            "Kf8",
            "Rxf3",
            "Rf7",
            "Bf5",
            "Qe1+",
            "Kg2",
            "Qe2+",
            "Rf2",
            "Qe5",
            "Qh6+",
            "Ke7",
            "Qh4",
            "Rg7+",
            "Kf1",
            "Qa1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Qc1+",
            "Ke2",
            "Qb2+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1b3",
          "positional_uci": "d1b3",
          "neutral_uci": "d1b3",
          "consensus_move": "d1b3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qa5",
              "Rc1",
              "d6",
              "a3",
              "Bxc3+",
              "Rxc3",
              "c5",
              "d5",
              "O-O",
              "Bd3",
              "Re8",
              "O-O",
              "Qc7",
              "Qc2",
              "Qe7",
              "Re1",
              "Nc7",
              "e4",
              "fxe4",
              "Rxe4",
              "Qf7",
              "Rxe8+",
              "Nxe8",
              "b4",
              "b6",
              "bxc5",
              "bxc5",
              "Rb3",
              "Ng7",
              "Qb2",
              "Qc7",
              "Qxf6",
              "Bf5",
              "Bxf5",
              "Nxf5",
              "Ng5",
              "Re8",
              "Ne6",
              "Qa5",
              "g4",
              "Qe1+",
              "Kg2",
              "Qe4+",
              "Kh3",
              "Qxc4",
              "Rb7",
              "Qd3+",
              "Kg2",
              "Qxd5+",
              "Kh3",
              "Qf3#",
              "Qg2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qa5",
              "Rc1",
              "d6",
              "a3",
              "Bxc3+",
              "Rxc3",
              "c5",
              "d5",
              "O-O",
              "Bd3",
              "Re8",
              "O-O",
              "Qc7",
              "Qc2",
              "Qe7",
              "Re1",
              "Nc7",
              "e4",
              "fxe4",
              "Rxe4",
              "Qf7",
              "Rxe8+",
              "Nxe8",
              "b4",
              "b6",
              "bxc5",
              "bxc5",
              "Rb3",
              "Ng7",
              "Qb2",
              "Qc7",
              "Qxf6",
              "Bf5",
              "Bxf5",
              "Nxf5",
              "Ng5",
              "Rf8",
              "Qe6+",
              "Kg7",
              "Qe1",
              "Nd4",
              "Re3",
              "Qb6",
              "Re7+",
              "Kg8",
              "Rxh7",
              "Qb2",
              "h3",
              "Ne2+",
              "Kh2",
              "Qe5+",
              "g3",
              "Qxg5",
              "Rxa7",
              "Nd4",
              "Qe7",
              "Rxf2+",
              "Kh1",
              "Qc1+",
              "Qe1",
              "Qxe1#",
              "Qc1+",
              "Qe1#",
              "Qc1+",
              "Qe1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qa5",
              "Rc1",
              "d6",
              "a3",
              "Bxc3+",
              "Rxc3",
              "c5",
              "d5",
              "O-O",
              "Be2",
              "Nc7",
              "O-O",
              "Ne8",
              "Qc2",
              "Ng7",
              "Rb1",
              "Qc7",
              "b4",
              "b6",
              "bxc5",
              "bxc5",
              "Rcb3",
              "Re8",
              "Bd3",
              "Re7",
              "Qc3",
              "Kf7",
              "Nd2",
              "Ba6",
              "e4",
              "fxe4",
              "Nxe4",
              "Ne8",
              "Qd2",
              "Kg7",
              "Qf4",
              "Rd8",
              "h4",
              "Re5",
              "g4",
              "Qe7",
              "f3",
              "f5",
              "gxf5",
              "Rxf5",
              "Qg3",
              "Nf6",
              "Ng5",
              "Re5",
              "Ne6+",
              "Rxe6",
              "dxe6",
              "Qxe6",
              "Re1",
              "Qf7",
              "Rb2",
              "Nh5",
              "Qg5",
              "Rd7",
              "Rbe2",
              "Nf6",
              "Re6",
              "Bb7",
              "h5",
              "Bxf3",
              "hxg6",
              "hxg6",
              "Rf1",
              "Qxe6",
              "Qxg6+",
              "Kf8",
              "Rxf3",
              "Rf7",
              "Bf5",
              "Qe1+",
              "Kg2",
              "Qe2+",
              "Rf2",
              "Qe5",
              "Qh6+",
              "Ke7",
              "Qh4",
              "Rg7+",
              "Kf1",
              "Qa1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Qc1+",
              "Ke2",
              "Qb2+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 166,
            "completion_tokens": 223,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 166,
            "completion_tokens": 279,
            "total_tokens": 445,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 165,
            "completion_tokens": 640,
            "total_tokens": 805,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 497,
          "total_completion_tokens": 1142,
          "total_tokens": 1639
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 166,
            "completion_tokens": 223,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 166,
            "completion_tokens": 279,
            "total_tokens": 445,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 165,
            "completion_tokens": 640,
            "total_tokens": 805,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/pp1p3p/n1p2pp1/5p2/1bPP4/2N1PN2/PP3PPP/R2QKB1R w KQkq - 3 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxc3",
          "aggressive_uci": "b3c3",
          "aggressive_response": "9. Qxc3 O-O 10. c5 d5 11. cxd6 Qxd6 12. Bxa6 bxa6 13. O-O Be6 14. Rfc1 Bd5\n15. Nd2 Rab8 16. b3 Rfe8 17. Qc5 Qd7 18. Nc4 f4 19. exf4 Qg4 20. Ne3 Rxe3\n21. Qxd5+ cxd5 22. fxe3 Re8 23. Rc3 Qe2 24. Rac1 Rxe3 25. Rc8+ Kg7 26. R1c7+\nKh6 27. h3 Qe1+ 28. Kh2 Qg3+ 29. Kg1 Re1# e4 dxe4 Nxe4 Qd5 Nc3 Qd6 Nxd6",
          "aggressive_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 195,
            "total_tokens": 371,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c5",
            "d5",
            "cxd6",
            "Qxd6",
            "Bxa6",
            "bxa6",
            "O-O",
            "Be6",
            "Rfc1",
            "Bd5",
            "Nd2",
            "Rab8",
            "b3",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "f4",
            "exf4",
            "Qg4",
            "Ne3",
            "Rxe3",
            "Qxd5+",
            "cxd5",
            "fxe3",
            "Re8",
            "Rc3",
            "Qe2",
            "Rac1",
            "Rxe3",
            "Rc8+",
            "Kg7",
            "R1c7+",
            "Kh6",
            "h3",
            "Qe1+",
            "Kh2",
            "Qg3+",
            "Kg1",
            "Re1#",
            "e4",
            "dxe4",
            "Nxe4",
            "Qd5",
            "Nc3",
            "Qd6",
            "Nxd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxc3",
          "positional_uci": "b3c3",
          "positional_response": "9. Qxc3 O-O 10. c5 d5 11. cxd6 Qxd6 12. Bxa6 bxa6 13. O-O Be6 14. Rfc1 Bd5 15. Nd2 Rab8 16. b3 Rfe8 17. Qc5 Qd7 18. Nc4 f4 19. exf4 Qg4 20. Ne3 Rxe3 21. Qxd5+ cxd5 22. fxe3 Re8 23. Rc3 Qe2 24. Rac1 Rxe3 25. Rc8+ Kg7 26. R8c7+ Kh6 27. R7c2 Qd3 28. Rf2 Qxd4 29. Rcf1 Re2 30. g3 Rxf2 31. Rxf2 Qe3 32. Kg2 d4 33. Rf3 Qe4 34. Kf2 d3 35. Re3 Qd4 36. Kf3 d2 37. Re4 d1=Q+ 38. Re2 Q4d3+ 39. Kg4 Q1xe2+ 40. Kh3 Qf1+ 41. Kh4 g5+ 42. fxg5+ fxg5+ 43. Kg4 Qdf5# d4 d5 d6",
          "positional_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 306,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c5",
            "d5",
            "cxd6",
            "Qxd6",
            "Bxa6",
            "bxa6",
            "O-O",
            "Be6",
            "Rfc1",
            "Bd5",
            "Nd2",
            "Rab8",
            "b3",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "f4",
            "exf4",
            "Qg4",
            "Ne3",
            "Rxe3",
            "Qxd5+",
            "cxd5",
            "fxe3",
            "Re8",
            "Rc3",
            "Qe2",
            "Rac1",
            "Rxe3",
            "Rc8+",
            "Kg7",
            "R8c7+",
            "Kh6",
            "R7c2",
            "Qd3",
            "Rf2",
            "Qxd4",
            "Rcf1",
            "Re2",
            "g3",
            "Rxf2",
            "Rxf2",
            "Qe3",
            "Kg2",
            "d4",
            "Rf3",
            "Qe4",
            "Kf2",
            "d3",
            "Re3",
            "Qd4",
            "Kf3",
            "d2",
            "Re4",
            "d1=Q+",
            "Re2",
            "Q4d3+",
            "Kg4",
            "Q1xe2+",
            "Kh3",
            "Qf1+",
            "Kh4",
            "g5+",
            "fxg5+",
            "fxg5+",
            "Kg4",
            "Qdf5#",
            "d4",
            "d5",
            "d6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxc3",
          "neutral_uci": "b3c3",
          "neutral_response": "9. Qxc3 d5 10. cxd5 cxd5 11. Bxa6 bxa6 12. Qc6+ Bd7 13. Qxd5 Rb8 14. O-O Rxb2\n15. Rfb1 Rxb1+ 16. Rxb1 Ke7 17. Rb7 Qc8 18. h3 Rd8 19. Rxa7 Ke8 20. Qg8+ Ke7\n21. Qxh7+ Ke6 22. Qxg6 Qb8 23. Rxa6+ Ke7 24. Qxf6+ Ke8 25. Ne5 Qb1+ 26. Kh2 Qb8\n27. Qf7# Qd6 28. Rxd6 Be6 29. Rxe6# Qe7 30. Qxe7# Qxe7 31. Rxe7+ Kxe7 32. Nc6+ Kd7 33. Nxd8 Kxd8",
          "neutral_tokens": {
            "prompt_tokens": 175,
            "completion_tokens": 225,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "cxd5",
            "cxd5",
            "Bxa6",
            "bxa6",
            "Qc6+",
            "Bd7",
            "Qxd5",
            "Rb8",
            "O-O",
            "Rxb2",
            "Rfb1",
            "Rxb1+",
            "Rxb1",
            "Ke7",
            "Rb7",
            "Qc8",
            "h3",
            "Rd8",
            "Rxa7",
            "Ke8",
            "Qg8+",
            "Ke7",
            "Qxh7+",
            "Ke6",
            "Qxg6",
            "Qb8",
            "Rxa6+",
            "Ke7",
            "Qxf6+",
            "Ke8",
            "Ne5",
            "Qb1+",
            "Kh2",
            "Qb8",
            "Qf7#",
            "Qd6",
            "Rxd6",
            "Be6",
            "Rxe6#",
            "Qe7",
            "Qxe7#",
            "Qxe7",
            "Rxe7+",
            "Kxe7",
            "Nc6+",
            "Kd7",
            "Nxd8",
            "Kxd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b3c3",
          "positional_uci": "b3c3",
          "neutral_uci": "b3c3",
          "consensus_move": "b3c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "c5",
              "d5",
              "cxd6",
              "Qxd6",
              "Bxa6",
              "bxa6",
              "O-O",
              "Be6",
              "Rfc1",
              "Bd5",
              "Nd2",
              "Rab8",
              "b3",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "f4",
              "exf4",
              "Qg4",
              "Ne3",
              "Rxe3",
              "Qxd5+",
              "cxd5",
              "fxe3",
              "Re8",
              "Rc3",
              "Qe2",
              "Rac1",
              "Rxe3",
              "Rc8+",
              "Kg7",
              "R1c7+",
              "Kh6",
              "h3",
              "Qe1+",
              "Kh2",
              "Qg3+",
              "Kg1",
              "Re1#",
              "e4",
              "dxe4",
              "Nxe4",
              "Qd5",
              "Nc3",
              "Qd6",
              "Nxd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "c5",
              "d5",
              "cxd6",
              "Qxd6",
              "Bxa6",
              "bxa6",
              "O-O",
              "Be6",
              "Rfc1",
              "Bd5",
              "Nd2",
              "Rab8",
              "b3",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "f4",
              "exf4",
              "Qg4",
              "Ne3",
              "Rxe3",
              "Qxd5+",
              "cxd5",
              "fxe3",
              "Re8",
              "Rc3",
              "Qe2",
              "Rac1",
              "Rxe3",
              "Rc8+",
              "Kg7",
              "R8c7+",
              "Kh6",
              "R7c2",
              "Qd3",
              "Rf2",
              "Qxd4",
              "Rcf1",
              "Re2",
              "g3",
              "Rxf2",
              "Rxf2",
              "Qe3",
              "Kg2",
              "d4",
              "Rf3",
              "Qe4",
              "Kf2",
              "d3",
              "Re3",
              "Qd4",
              "Kf3",
              "d2",
              "Re4",
              "d1=Q+",
              "Re2",
              "Q4d3+",
              "Kg4",
              "Q1xe2+",
              "Kh3",
              "Qf1+",
              "Kh4",
              "g5+",
              "fxg5+",
              "fxg5+",
              "Kg4",
              "Qdf5#",
              "d4",
              "d5",
              "d6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "cxd5",
              "cxd5",
              "Bxa6",
              "bxa6",
              "Qc6+",
              "Bd7",
              "Qxd5",
              "Rb8",
              "O-O",
              "Rxb2",
              "Rfb1",
              "Rxb1+",
              "Rxb1",
              "Ke7",
              "Rb7",
              "Qc8",
              "h3",
              "Rd8",
              "Rxa7",
              "Ke8",
              "Qg8+",
              "Ke7",
              "Qxh7+",
              "Ke6",
              "Qxg6",
              "Qb8",
              "Rxa6+",
              "Ke7",
              "Qxf6+",
              "Ke8",
              "Ne5",
              "Qb1+",
              "Kh2",
              "Qb8",
              "Qf7#",
              "Qd6",
              "Rxd6",
              "Be6",
              "Rxe6#",
              "Qe7",
              "Qxe7#",
              "Qxe7",
              "Rxe7+",
              "Kxe7",
              "Nc6+",
              "Kd7",
              "Nxd8",
              "Kxd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 176,
            "completion_tokens": 195,
            "total_tokens": 371,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 176,
            "completion_tokens": 306,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 175,
            "completion_tokens": 225,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 527,
          "total_completion_tokens": 726,
          "total_tokens": 1253
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 176,
            "completion_tokens": 195,
            "total_tokens": 371,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 176,
            "completion_tokens": 306,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 175,
            "completion_tokens": 225,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/pp1p3p/n1p2pp1/5p2/2PP4/1Qb1PN2/PP3PPP/R3KB1R w KQkq - 0 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c5",
          "aggressive_uci": "c4c5",
          "aggressive_response": "10. c5 d5 11. Bxa6 bxa6 12. O-O O-O 13. b4 Rb8 14. a3 Qc7 15. Rfb1 f4 16. exf4\nQxf4 17. Re1 Bg4 18. Re3 Rfe8 19. Rae1 Rxe3 20. Rxe3 Bxf3 21. Rxf3 Qe4 22. h3\nRe8 23. Re3 Qb1+ 24. Kh2 Rxe3 25. Qxe3 Qe4 26. Qxe4 dxe4 27. Kg3 Kf7 28. Kf4\nKe6 29. Kxe4 f5+ 30. Kd3 Kd5 31. f4 h6 32. h4 h5 33. g3 Ke6 34. Kc4 Kd7 35.\nd5 cxd5+ 36. Kxd5 Kc7 37. a4 Kd7 38. b5 axb5 39. axb5 Kc7 40. Ke6 a5 41. bxa6\nKb8 42. Kd7 Ka7 43. c6 Kxa6 44. c7 Kb5 45. c8=Q Kb4 46. Qc2 Kb5 47. Qc3 Kb6\n48. Qc4 Kb7 49. Qc5 Kb8 50. Qc6 Ka7 51. Qb5 Ka8 52. Kc7 Ka7 53. Qb7# Qd8+ Qxd8+\nKb7",
          "aggressive_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 374,
            "total_tokens": 559,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Bxa6",
            "bxa6",
            "O-O",
            "O-O",
            "b4",
            "Rb8",
            "a3",
            "Qc7",
            "Rfb1",
            "f4",
            "exf4",
            "Qxf4",
            "Re1",
            "Bg4",
            "Re3",
            "Rfe8",
            "Rae1",
            "Rxe3",
            "Rxe3",
            "Bxf3",
            "Rxf3",
            "Qe4",
            "h3",
            "Re8",
            "Re3",
            "Qb1+",
            "Kh2",
            "Rxe3",
            "Qxe3",
            "Qe4",
            "Qxe4",
            "dxe4",
            "Kg3",
            "Kf7",
            "Kf4",
            "Ke6",
            "Kxe4",
            "f5+",
            "Kd3",
            "Kd5",
            "f4",
            "h6",
            "h4",
            "h5",
            "g3",
            "Ke6",
            "Kc4",
            "Kd7",
            "d5",
            "cxd5+",
            "Kxd5",
            "Kc7",
            "a4",
            "Kd7",
            "b5",
            "axb5",
            "axb5",
            "Kc7",
            "Ke6",
            "a5",
            "bxa6",
            "Kb8",
            "Kd7",
            "Ka7",
            "c6",
            "Kxa6",
            "c7",
            "Kb5",
            "c8=Q",
            "Kb4",
            "Qc2",
            "Kb5",
            "Qc3",
            "Kb6",
            "Qc4",
            "Kb7",
            "Qc5",
            "Kb8",
            "Qc6",
            "Ka7",
            "Qb5",
            "Ka8",
            "Kc7",
            "Ka7",
            "Qb7#",
            "Qd8+",
            "Qxd8+",
            "Kb7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c5",
          "positional_uci": "c4c5",
          "positional_response": "10. c5 Nc7 11. Bc4 b5 12. Bb3 a5 13. a3 a4 14. Ba2 Ba6 15. O-O b4 16. Qxb4 Bxf1 17. Rxf1 Kf8 18. Qb7 Qd8 19. Qb4 Kg7 20. Qc4 Qe7 21. Re1 Rhb8 22. Re2 Nd5 23. Qc2 Qe4 24. Qd1 Rb7 25. Nd2 Qd3 26. Bc4 Qxe2 27. Qxe2 Rxb2 28. Bxd5 cxd5 29. Qd3 Rab8 30. g3 Ra2 31. Nf3 Rbb2 32. Qa6 Rxf2 33. Qd6 Rxf3 34. Qxd7+ Kh6 35. Qxd5 Rxe3 36. Kf1 Rxh2 37. c6 Rc3 38. Kg1 Rd2 39. Qh1+ Kg7 40. Qg2 Rxg2+ 41. Kxg2 Rxc6 42. Kf3 Rc3+ 43. Kf4 Rxa3 44. d5 Rd3 45. g4 fxg4 46. Kxg4 Rxd5 47. Kf4 a3 48. Ke4 Rd8 49. Ke3 a2 50. Ke4 a1=Q 51. Ke3 Qe1+ 52. Kf3 Rd3+ 53. Kf4 Qe3+ 54. Kg4 Rd4# Qe4+ 56. Kg3 Rd3+ 57. Kf2 Qe3+ 58. Kg2 Rd2+ 59. Kf1 Qe2+ 60. Kg1 Qg2#",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 428,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc7",
            "Bc4",
            "b5",
            "Bb3",
            "a5",
            "a3",
            "a4",
            "Ba2",
            "Ba6",
            "O-O",
            "b4",
            "Qxb4",
            "Bxf1",
            "Rxf1",
            "Kf8",
            "Qb7",
            "Qd8",
            "Qb4",
            "Kg7",
            "Qc4",
            "Qe7",
            "Re1",
            "Rhb8",
            "Re2",
            "Nd5",
            "Qc2",
            "Qe4",
            "Qd1",
            "Rb7",
            "Nd2",
            "Qd3",
            "Bc4",
            "Qxe2",
            "Qxe2",
            "Rxb2",
            "Bxd5",
            "cxd5",
            "Qd3",
            "Rab8",
            "g3",
            "Ra2",
            "Nf3",
            "Rbb2",
            "Qa6",
            "Rxf2",
            "Qd6",
            "Rxf3",
            "Qxd7+",
            "Kh6",
            "Qxd5",
            "Rxe3",
            "Kf1",
            "Rxh2",
            "c6",
            "Rc3",
            "Kg1",
            "Rd2",
            "Qh1+",
            "Kg7",
            "Qg2",
            "Rxg2+",
            "Kxg2",
            "Rxc6",
            "Kf3",
            "Rc3+",
            "Kf4",
            "Rxa3",
            "d5",
            "Rd3",
            "g4",
            "fxg4",
            "Kxg4",
            "Rxd5",
            "Kf4",
            "a3",
            "Ke4",
            "Rd8",
            "Ke3",
            "a2",
            "Ke4",
            "a1=Q",
            "Ke3",
            "Qe1+",
            "Kf3",
            "Rd3+",
            "Kf4",
            "Qe3+",
            "Kg4",
            "Rd4#",
            "Qe4+",
            "Kg3",
            "Rd3+",
            "Kf2",
            "Qe3+",
            "Kg2",
            "Rd2+",
            "Kf1",
            "Qe2+",
            "Kg1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c5",
          "neutral_uci": "c4c5",
          "neutral_response": "10. c5 Nc7 11. Bc4 b5 12. cxb6 axb6 13. O-O Ba6 14. Bxa6 Rxa6 15. a3 O-O 16.\nRfe1 Nd5 17. Qc4 b5 18. Qb3 Kg7 19. Nd2 Rfa8 20. e4 fxe4 21. Rxe4 Qd6 22. Rae1\nRa4 23. Qh3 f5 24. Rh4 h5 25. Nf3 Nf4 26. Qg3 Ne2+ 27. Rxe2 Qxg3 28. hxg3 Kf6\n29. Ne5 R8a7 30. Nd3 Rc4 31. Nc5 Rc1+ 32. Kh2 Rd1 33. Rf4 g5 34. Rf3 Rxd4\n35. Rd3 Rxd3 36. Nxd3 d6 37. Nb4 Rc7 38. Rc2 c5 39. Nd5+ Ke5 40. Nxc7 b4 41.\naxb4 cxb4 42. Rc4 b3 43. Rb4 d5 44. Rxb3 d4 45. Rd3 Ke4 46. Rd1 d3 47. b4\nKd4 48. b5 Kc5 49. Rxd3 Kb6 50. Rc3 Kb7 51. Nd5 Kb8 52. b6 Kb7 53. Rc7+ Kb8\n54. b7 f4 55. gxf4 gxf4 56. Rh7 h4 57. Nb4 h3 58. Nc6# g6 h5 g5 h4 g4 h3 g3\nh2 g2 h1=Q g8=Q#",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 417,
            "total_tokens": 601,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd5+",
            "Ke5",
            "Nxc7",
            "b4",
            "axb4",
            "cxb4",
            "Rc4",
            "b3",
            "Rb4",
            "d5",
            "Rxb3",
            "d4",
            "Rd3",
            "Ke4",
            "Rd1",
            "d3",
            "b4",
            "Kd4",
            "b5",
            "Kc5",
            "Rxd3",
            "Kb6",
            "Rc3",
            "Kb7",
            "Nd5",
            "Kb8",
            "b6",
            "Kb7",
            "Rc7+",
            "Kb8",
            "b7",
            "f4",
            "gxf4",
            "gxf4",
            "Rh7",
            "h4",
            "Nb4",
            "h3",
            "Nc6#",
            "g6",
            "h5",
            "g5",
            "h4",
            "g4",
            "h3",
            "g3",
            "h2",
            "g2",
            "h1=Q",
            "g8=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4c5",
          "positional_uci": "c4c5",
          "neutral_uci": "c4c5",
          "consensus_move": "c4c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Bxa6",
              "bxa6",
              "O-O",
              "O-O",
              "b4",
              "Rb8",
              "a3",
              "Qc7",
              "Rfb1",
              "f4",
              "exf4",
              "Qxf4",
              "Re1",
              "Bg4",
              "Re3",
              "Rfe8",
              "Rae1",
              "Rxe3",
              "Rxe3",
              "Bxf3",
              "Rxf3",
              "Qe4",
              "h3",
              "Re8",
              "Re3",
              "Qb1+",
              "Kh2",
              "Rxe3",
              "Qxe3",
              "Qe4",
              "Qxe4",
              "dxe4",
              "Kg3",
              "Kf7",
              "Kf4",
              "Ke6",
              "Kxe4",
              "f5+",
              "Kd3",
              "Kd5",
              "f4",
              "h6",
              "h4",
              "h5",
              "g3",
              "Ke6",
              "Kc4",
              "Kd7",
              "d5",
              "cxd5+",
              "Kxd5",
              "Kc7",
              "a4",
              "Kd7",
              "b5",
              "axb5",
              "axb5",
              "Kc7",
              "Ke6",
              "a5",
              "bxa6",
              "Kb8",
              "Kd7",
              "Ka7",
              "c6",
              "Kxa6",
              "c7",
              "Kb5",
              "c8=Q",
              "Kb4",
              "Qc2",
              "Kb5",
              "Qc3",
              "Kb6",
              "Qc4",
              "Kb7",
              "Qc5",
              "Kb8",
              "Qc6",
              "Ka7",
              "Qb5",
              "Ka8",
              "Kc7",
              "Ka7",
              "Qb7#",
              "Qd8+",
              "Qxd8+",
              "Kb7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc7",
              "Bc4",
              "b5",
              "Bb3",
              "a5",
              "a3",
              "a4",
              "Ba2",
              "Ba6",
              "O-O",
              "b4",
              "Qxb4",
              "Bxf1",
              "Rxf1",
              "Kf8",
              "Qb7",
              "Qd8",
              "Qb4",
              "Kg7",
              "Qc4",
              "Qe7",
              "Re1",
              "Rhb8",
              "Re2",
              "Nd5",
              "Qc2",
              "Qe4",
              "Qd1",
              "Rb7",
              "Nd2",
              "Qd3",
              "Bc4",
              "Qxe2",
              "Qxe2",
              "Rxb2",
              "Bxd5",
              "cxd5",
              "Qd3",
              "Rab8",
              "g3",
              "Ra2",
              "Nf3",
              "Rbb2",
              "Qa6",
              "Rxf2",
              "Qd6",
              "Rxf3",
              "Qxd7+",
              "Kh6",
              "Qxd5",
              "Rxe3",
              "Kf1",
              "Rxh2",
              "c6",
              "Rc3",
              "Kg1",
              "Rd2",
              "Qh1+",
              "Kg7",
              "Qg2",
              "Rxg2+",
              "Kxg2",
              "Rxc6",
              "Kf3",
              "Rc3+",
              "Kf4",
              "Rxa3",
              "d5",
              "Rd3",
              "g4",
              "fxg4",
              "Kxg4",
              "Rxd5",
              "Kf4",
              "a3",
              "Ke4",
              "Rd8",
              "Ke3",
              "a2",
              "Ke4",
              "a1=Q",
              "Ke3",
              "Qe1+",
              "Kf3",
              "Rd3+",
              "Kf4",
              "Qe3+",
              "Kg4",
              "Rd4#",
              "Qe4+",
              "Kg3",
              "Rd3+",
              "Kf2",
              "Qe3+",
              "Kg2",
              "Rd2+",
              "Kf1",
              "Qe2+",
              "Kg1",
              "Qg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nd5+",
              "Ke5",
              "Nxc7",
              "b4",
              "axb4",
              "cxb4",
              "Rc4",
              "b3",
              "Rb4",
              "d5",
              "Rxb3",
              "d4",
              "Rd3",
              "Ke4",
              "Rd1",
              "d3",
              "b4",
              "Kd4",
              "b5",
              "Kc5",
              "Rxd3",
              "Kb6",
              "Rc3",
              "Kb7",
              "Nd5",
              "Kb8",
              "b6",
              "Kb7",
              "Rc7+",
              "Kb8",
              "b7",
              "f4",
              "gxf4",
              "gxf4",
              "Rh7",
              "h4",
              "Nb4",
              "h3",
              "Nc6#",
              "g6",
              "h5",
              "g5",
              "h4",
              "g4",
              "h3",
              "g3",
              "h2",
              "g2",
              "h1=Q",
              "g8=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 185,
            "completion_tokens": 374,
            "total_tokens": 559,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 428,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 417,
            "total_tokens": 601,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 554,
          "total_completion_tokens": 1219,
          "total_tokens": 1773
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 185,
            "completion_tokens": 374,
            "total_tokens": 559,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 428,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 417,
            "total_tokens": 601,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/pp1pq2p/n1p2pp1/5p2/2PP4/2Q1PN2/PP3PPP/R3KB1R w KQkq - 1 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxa6",
          "aggressive_uci": "f1a6",
          "aggressive_response": "11. Bxa6 bxa6 12. O-O O-O 13. b4 d5 14. cxd6 Qxd6 15. a3 Be6 16. Rfc1 Bd5 17. Nd2\nRfe8 18. Qc5 Qd7 19. Nc4 Rb5 20. Qd6 Qf7 21. Na5 Re6 22. Qd8+ Re8 23. Qd6 Re6\n24. Qg3 Kg7 25. Rc5 Rxc5 26. bxc5 Re4 27. Rb1 Rg4 28. Rb7 Rxg3 29. Rxf7+ Kxf7\n30. hxg3 Ke6 31. f3 g5 32. Kf2 h5 33. Nb7 Kd7 34. Nd6 Be6 35. Ke2 Kc7 36. Kd3\nKd7 37. Kc3 Kc7 38. Kb4 Kd7 39. Ka5 Kc7 40. Kxa6 Kb8 41. Ne8 Bc4+ 42. Ka5 Bf1\n43. Nxf6 Bxg2 44. Nxh5 Bxf3 45. Ng7 Be4 46. Ne6 g4 47. Ka6 Bd5 48. Ng7 Be4 49.\nNe8 Bd5 50. Nd6 Be6 51. a4 Ka8 52. a5 Kb8 53. Ne8 Bc8# 1-0\n\nd4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O O-O 13. b4 d5 14.\ncxd6 Qxd6 15. a3 Be6 16. Rfc1 Bd5 17. Nd2 Rfe8 18. Qc5 Qd7 19. Nc4 Rb5 20.\nQd6 Qf7 21. Na5 Re6 22. Qd8+ Re8 23. Qd6 Re6 24. Qg3 Kg7 25. Rc5 Rxc5 26. bxc5\nRe4 27. Rb1 Rg4 28. Rb7 Rxg3 29. Rxf7+ Kxf7 30. hxg3 Ke6 31. f3 g5 32. Kf2 h5\n33. Nb7 Kd7 34. Nd6 Be6 35. Ke2 Kc7",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "bxa6",
            "O-O",
            "O-O",
            "b4",
            "d5",
            "cxd6",
            "Qxd6",
            "a3",
            "Be6",
            "Rfc1",
            "Bd5",
            "Nd2",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "Rb5",
            "Qd6",
            "Qf7",
            "Na5",
            "Re6",
            "Qd8+",
            "Re8",
            "Qd6",
            "Re6",
            "Qg3",
            "Kg7",
            "Rc5",
            "Rxc5",
            "bxc5",
            "Re4",
            "Rb1",
            "Rg4",
            "Rb7",
            "Rxg3",
            "Rxf7+",
            "Kxf7",
            "hxg3",
            "Ke6",
            "f3",
            "g5",
            "Kf2",
            "h5",
            "Nb7",
            "Kd7",
            "Nd6",
            "Be6",
            "Ke2",
            "Kc7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxa6",
          "positional_uci": "f1a6",
          "positional_response": "11. Bxa6 bxa6 12. O-O O-O 13. b4 d5 14. cxd6 Qxd6 15. a3 Be6 16. Rac1 Bd5 17. Nd2\nRfe8 18. Qc5 Qd7 19. Nc4 Rb5 20. Qd6 Qf7 21. Na5 Re6 22. Qd8+ Re8 23. Qd6 Re6\n24. Qg3 g5 25. Rc5 h5 26. Rfc1 h4 27. Qh3 Qh5 28. Qxf5 h3 29. Rxd5 cxd5 30.\nQxe6+ Kg7 31. Rc7+ Kg6 32. Qf7+ Kh6 33. Qh7# g4 34. Qg7# g3 35. Qxf6# Kg4 36.\nRg7+ Kh5 37. Qg5# Kg4 38. Qg6# Kg4 39. h3# Kg4 40. Qg5# Kg4 41. Qg6# Kg4 42.\nQg5# Kg4 43. Qg6# Kg4 44. Qg5# Kg4 45. Qg6# Kg4 46. Qg5# Kg4 47. Qg6# Kg4 48.\nQg5# Kg4 49. Qg6# Kg4 50. Qg5# Kg4 51. Qg6# Kg4 52. Qg5# Kg4 53. Qg6# Kg4 54.\nQg5# Kg4 55. Qg6# Kg4 56. Qg5# Kg4 57. Qg6# Kg4 58. Qg5# Kg4 59. Qg6# Kg4 60.\nQg5# Kg4 61. Qg6# Kg4 62. Qg5# Kg4 63. Qg6# Kg4 64. Qg5# Kg4 65. Qg6# Kg4 66.\nQg5# Kg4 67. Qg6# Kg4 68. Qg5# Kg4 69. Qg6# Kg4 70. Qg5# Kg4 71. Qg6# Kg4 72.\nQg5# Kg4 73. Qg6# Kg4 74. Qg5# Kg4 75. Qg6# Kg4 76. Qg5# Kg4 77. Qg6# Kg4 78.\nQg5# Kg4 79. Qg6# Kg4 80. Qg5# Kg4 81. Qg6# Kg4 82. Qg5# Kg4 83. Qg6# Kg4",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "bxa6",
            "O-O",
            "O-O",
            "b4",
            "d5",
            "cxd6",
            "Qxd6",
            "a3",
            "Be6",
            "Rac1",
            "Bd5",
            "Nd2",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "Rb5",
            "Qd6",
            "Qf7",
            "Na5",
            "Re6",
            "Qd8+",
            "Re8",
            "Qd6",
            "Re6",
            "Qg3",
            "g5",
            "Rc5",
            "h5",
            "Rfc1",
            "h4",
            "Qh3",
            "Qh5",
            "Qxf5",
            "h3",
            "Rxd5",
            "cxd5",
            "Qxe6+",
            "Kg7",
            "Rc7+",
            "Kg6",
            "Qf7+",
            "Kh6",
            "Qh7#",
            "g4",
            "Qg7#",
            "g3",
            "Qxf6#",
            "Kg4",
            "Rg7+",
            "Kh5",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "h3#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4",
            "Qg5#",
            "Kg4",
            "Qg6#",
            "Kg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxa6",
          "neutral_uci": "f1a6",
          "neutral_response": "11. Bxa6 bxa6 12. O-O O-O 13. b4 d5 14. cxd6 Qxd6 15. a3 Be6 16. Rfc1 Bd5 17.\nNd2 Rfe8 18. Qc5 Qd7 19. Nc4 Rb5 20. Qd6 Qf7 21. Na5 Re6 22. Qd8+ Re8 23. Qd6\nRe6 24. Qg3 g5 25. Rc5 Rxc5 26. bxc5 h5 27. Rb1 Re7 28. Qb8+ Kg7 29. Qd6 Rd7\n30. Qb8 f4 31. exf4 gxf4 32. Qxf4 Qg6 33. Qg3 Qxg3 34. hxg3 Be4 35. Rb7 Rxb7\n36. Nxb7 Kf7 37. Nd6+ Ke6 38. Nxe4 Kd5 39. Nxf6+ Kxd4 40. Nxh5 Kxc5 41. g4\nKd6 42. g5 Ke6 43. g6 Ke7 44. f4 c5 45. f5 c4 46. f6+ Kf8 47. Nf4 c3 48. Ne6+\nKg8 49. f7+ Kh8 50. f8=Q# Qd7 Qf7 Qd7",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 342,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxa6",
            "O-O",
            "O-O",
            "b4",
            "d5",
            "cxd6",
            "Qxd6",
            "a3",
            "Be6",
            "Rfc1",
            "Bd5",
            "Nd2",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "Rb5",
            "Qd6",
            "Qf7",
            "Na5",
            "Re6",
            "Qd8+",
            "Re8",
            "Qd6",
            "Re6",
            "Qg3",
            "g5",
            "Rc5",
            "Rxc5",
            "bxc5",
            "h5",
            "Rb1",
            "Re7",
            "Qb8+",
            "Kg7",
            "Qd6",
            "Rd7",
            "Qb8",
            "f4",
            "exf4",
            "gxf4",
            "Qxf4",
            "Qg6",
            "Qg3",
            "Qxg3",
            "hxg3",
            "Be4",
            "Rb7",
            "Rxb7",
            "Nxb7",
            "Kf7",
            "Nd6+",
            "Ke6",
            "Nxe4",
            "Kd5",
            "Nxf6+",
            "Kxd4",
            "Nxh5",
            "Kxc5",
            "g4",
            "Kd6",
            "g5",
            "Ke6",
            "g6",
            "Ke7",
            "f4",
            "c5",
            "f5",
            "c4",
            "f6+",
            "Kf8",
            "Nf4",
            "c3",
            "Ne6+",
            "Kg8",
            "f7+",
            "Kh8",
            "f8=Q#",
            "Qd7",
            "Qf7",
            "Qd7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1a6",
          "positional_uci": "f1a6",
          "neutral_uci": "f1a6",
          "consensus_move": "f1a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "bxa6",
              "O-O",
              "O-O",
              "b4",
              "d5",
              "cxd6",
              "Qxd6",
              "a3",
              "Be6",
              "Rfc1",
              "Bd5",
              "Nd2",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "Rb5",
              "Qd6",
              "Qf7",
              "Na5",
              "Re6",
              "Qd8+",
              "Re8",
              "Qd6",
              "Re6",
              "Qg3",
              "Kg7",
              "Rc5",
              "Rxc5",
              "bxc5",
              "Re4",
              "Rb1",
              "Rg4",
              "Rb7",
              "Rxg3",
              "Rxf7+",
              "Kxf7",
              "hxg3",
              "Ke6",
              "f3",
              "g5",
              "Kf2",
              "h5",
              "Nb7",
              "Kd7",
              "Nd6",
              "Be6",
              "Ke2",
              "Kc7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "bxa6",
              "O-O",
              "O-O",
              "b4",
              "d5",
              "cxd6",
              "Qxd6",
              "a3",
              "Be6",
              "Rac1",
              "Bd5",
              "Nd2",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "Rb5",
              "Qd6",
              "Qf7",
              "Na5",
              "Re6",
              "Qd8+",
              "Re8",
              "Qd6",
              "Re6",
              "Qg3",
              "g5",
              "Rc5",
              "h5",
              "Rfc1",
              "h4",
              "Qh3",
              "Qh5",
              "Qxf5",
              "h3",
              "Rxd5",
              "cxd5",
              "Qxe6+",
              "Kg7",
              "Rc7+",
              "Kg6",
              "Qf7+",
              "Kh6",
              "Qh7#",
              "g4",
              "Qg7#",
              "g3",
              "Qxf6#",
              "Kg4",
              "Rg7+",
              "Kh5",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "h3#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4",
              "Qg5#",
              "Kg4",
              "Qg6#",
              "Kg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "bxa6",
              "O-O",
              "O-O",
              "b4",
              "d5",
              "cxd6",
              "Qxd6",
              "a3",
              "Be6",
              "Rfc1",
              "Bd5",
              "Nd2",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "Rb5",
              "Qd6",
              "Qf7",
              "Na5",
              "Re6",
              "Qd8+",
              "Re8",
              "Qd6",
              "Re6",
              "Qg3",
              "g5",
              "Rc5",
              "Rxc5",
              "bxc5",
              "h5",
              "Rb1",
              "Re7",
              "Qb8+",
              "Kg7",
              "Qd6",
              "Rd7",
              "Qb8",
              "f4",
              "exf4",
              "gxf4",
              "Qxf4",
              "Qg6",
              "Qg3",
              "Qxg3",
              "hxg3",
              "Be4",
              "Rb7",
              "Rxb7",
              "Nxb7",
              "Kf7",
              "Nd6+",
              "Ke6",
              "Nxe4",
              "Kd5",
              "Nxf6+",
              "Kxd4",
              "Nxh5",
              "Kxc5",
              "g4",
              "Kd6",
              "g5",
              "Ke6",
              "g6",
              "Ke7",
              "f4",
              "c5",
              "f5",
              "c4",
              "f6+",
              "Kf8",
              "Nf4",
              "c3",
              "Ne6+",
              "Kg8",
              "f7+",
              "Kh8",
              "f8=Q#",
              "Qd7",
              "Qf7",
              "Qd7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 342,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 1622,
          "total_tokens": 2200
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 640,
            "total_tokens": 833,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 342,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1rb1k2r/pp1pq2p/n1p2pp1/2P2p2/3P4/2Q1PN2/PP3PPP/R3KB1R w KQk - 1 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "12. O-O O-O 13. b4 d5 14. cxd6 Qxd6 15. a3 Be6 16. Rfc1 Bd5 17. Nd2 Rfe8 18. Qc5 Qd7 19. Nc4 f4 20. exf4 Qg4 21. Ne3 Rxe3 22. Qxd5+ cxd5 23. fxe3 Re8 24. Rc3 Qe2 25. Rac1 Rxe3 26. Rc8+ Kg7 27. R1c7+ Kh6 28. h3 Qe1+ 29. Kh2 Qg3+ 30. Kg1 Re1# d4 d5 d6",
          "aggressive_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 164,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "d5",
            "cxd6",
            "Qxd6",
            "a3",
            "Be6",
            "Rfc1",
            "Bd5",
            "Nd2",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "f4",
            "exf4",
            "Qg4",
            "Ne3",
            "Rxe3",
            "Qxd5+",
            "cxd5",
            "fxe3",
            "Re8",
            "Rc3",
            "Qe2",
            "Rac1",
            "Rxe3",
            "Rc8+",
            "Kg7",
            "R1c7+",
            "Kh6",
            "h3",
            "Qe1+",
            "Kh2",
            "Qg3+",
            "Kg1",
            "Re1#",
            "d4",
            "d5",
            "d6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "12. O-O O-O 13. b4 d5 14. cxd6 Qxd6 15. a3 Be6 16. Rac1 Bd5 17. Nd2 Rfe8 18. Qc5 Qd7 19. Nc4 Rb5 20. Qd6 Qf7 21. Na5 Re6 22. Qd8+ Re8 23. Qd6 Re6 24. Qg3 g5 25. Rc5 h5 26. Rfc1 h4 27. Qh3 Qh5 28. Qxf5 h3 29. Rxd5 cxd5 30. Qxe6+ Kg7 31. Rc7+ Kg6 32. Qf7+ Kh6 33. Qh7# g8=Q Qxg2#",
          "positional_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 187,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "d5",
            "cxd6",
            "Qxd6",
            "a3",
            "Be6",
            "Rac1",
            "Bd5",
            "Nd2",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "Rb5",
            "Qd6",
            "Qf7",
            "Na5",
            "Re6",
            "Qd8+",
            "Re8",
            "Qd6",
            "Re6",
            "Qg3",
            "g5",
            "Rc5",
            "h5",
            "Rfc1",
            "h4",
            "Qh3",
            "Qh5",
            "Qxf5",
            "h3",
            "Rxd5",
            "cxd5",
            "Qxe6+",
            "Kg7",
            "Rc7+",
            "Kg6",
            "Qf7+",
            "Kh6",
            "Qh7#",
            "g8=Q",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "12. O-O O-O 13. b4 d5 14. cxd6 Qxd6 15. a3 Be6 16. Rfc1 Bd5 17. Nd2 Rfe8 18. Qc5 Qd7 19. Nc4 f4 20. exf4 Qg4 21. Ne3 Rxe3 22. Qxd5+ cxd5 23. fxe3 Re8 24. Rc3 Qe2 25. Rac1 Rxe3 26. Rc8+ Kg7 27. R8c7+ Kh6 28. R7c2 Qd3 29. Rf2 Qxd4 30. Rcf1 Rxa3 31. Kh1 Qxf2 32. Rxf2 Ra1+ 33. Rf1 Rxf1# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 201,
            "completion_tokens": 191,
            "total_tokens": 392,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "d5",
            "cxd6",
            "Qxd6",
            "a3",
            "Be6",
            "Rfc1",
            "Bd5",
            "Nd2",
            "Rfe8",
            "Qc5",
            "Qd7",
            "Nc4",
            "f4",
            "exf4",
            "Qg4",
            "Ne3",
            "Rxe3",
            "Qxd5+",
            "cxd5",
            "fxe3",
            "Re8",
            "Rc3",
            "Qe2",
            "Rac1",
            "Rxe3",
            "Rc8+",
            "Kg7",
            "R8c7+",
            "Kh6",
            "R7c2",
            "Qd3",
            "Rf2",
            "Qxd4",
            "Rcf1",
            "Rxa3",
            "Kh1",
            "Qxf2",
            "Rxf2",
            "Ra1+",
            "Rf1",
            "Rxf1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b4",
              "d5",
              "cxd6",
              "Qxd6",
              "a3",
              "Be6",
              "Rfc1",
              "Bd5",
              "Nd2",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "f4",
              "exf4",
              "Qg4",
              "Ne3",
              "Rxe3",
              "Qxd5+",
              "cxd5",
              "fxe3",
              "Re8",
              "Rc3",
              "Qe2",
              "Rac1",
              "Rxe3",
              "Rc8+",
              "Kg7",
              "R1c7+",
              "Kh6",
              "h3",
              "Qe1+",
              "Kh2",
              "Qg3+",
              "Kg1",
              "Re1#",
              "d4",
              "d5",
              "d6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "b4",
              "d5",
              "cxd6",
              "Qxd6",
              "a3",
              "Be6",
              "Rac1",
              "Bd5",
              "Nd2",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "Rb5",
              "Qd6",
              "Qf7",
              "Na5",
              "Re6",
              "Qd8+",
              "Re8",
              "Qd6",
              "Re6",
              "Qg3",
              "g5",
              "Rc5",
              "h5",
              "Rfc1",
              "h4",
              "Qh3",
              "Qh5",
              "Qxf5",
              "h3",
              "Rxd5",
              "cxd5",
              "Qxe6+",
              "Kg7",
              "Rc7+",
              "Kg6",
              "Qf7+",
              "Kh6",
              "Qh7#",
              "g8=Q",
              "Qxg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "b4",
              "d5",
              "cxd6",
              "Qxd6",
              "a3",
              "Be6",
              "Rfc1",
              "Bd5",
              "Nd2",
              "Rfe8",
              "Qc5",
              "Qd7",
              "Nc4",
              "f4",
              "exf4",
              "Qg4",
              "Ne3",
              "Rxe3",
              "Qxd5+",
              "cxd5",
              "fxe3",
              "Re8",
              "Rc3",
              "Qe2",
              "Rac1",
              "Rxe3",
              "Rc8+",
              "Kg7",
              "R8c7+",
              "Kh6",
              "R7c2",
              "Qd3",
              "Rf2",
              "Qxd4",
              "Rcf1",
              "Rxa3",
              "Kh1",
              "Qxf2",
              "Rxf2",
              "Ra1+",
              "Rf1",
              "Rxf1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 202,
            "completion_tokens": 164,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 202,
            "completion_tokens": 187,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 201,
            "completion_tokens": 191,
            "total_tokens": 392,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 605,
          "total_completion_tokens": 542,
          "total_tokens": 1147
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 202,
            "completion_tokens": 164,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 202,
            "completion_tokens": 187,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 201,
            "completion_tokens": 191,
            "total_tokens": 392,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1rb1k2r/p2pq2p/p1p2pp1/2P2p2/3P4/2Q1PN2/PP3PPP/R3K2R w KQk - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd6",
          "aggressive_uci": "c5d6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14. Rac1 Bd7 15. b3 O-O 16. Qc5 Qxc5 17. Rxc5 Rb5 18. Rfc1 Rfb8 19. Nd2 Rxc5 20. Rxc5 Rb5 21. Rc4 Kf7 22. Ra4 a5 23. Nc4 Ke6 24. Rxa5 Rxa5 25. Nxa5 Kd5 26. Kf1 c5 27. dxc5 Kxc5 28. Ke2 Kb4 29. Nc4 Bb5 30. Kd3 Bxc4+ 31. bxc4 Kc5 32. Kc3 a5 33. a4 g5 34. f3 h5 35. g3 g4 36. f4 Kc6 37. Kd4 Kd6 38. c5+ Kc6 39. Kc4 Kc7 40. Kb5 Kb7 41. Kxa5 Kc6 42. Kb4 Kc7 43. Kb5 Kb7 44. a5 Kc7 45. a6 Kb8 46. Kb6 Ka8 47. c6 Kb8 48. c7+ Kc8 49. a7 Kd7 50. a8=Q Kd6 51. c8=Q Ke7 52. Qab7+ Kd6 53. Qcc6# d5 cxd6 Qxd6",
          "aggressive_tokens": {
            "prompt_tokens": 209,
            "completion_tokens": 445,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "cxd6",
          "positional_uci": "c5d6",
          "positional_response": "13. cxd6 Qxd6 14. Rac1 Bd7 15. b3 O-O 16. Qc5 Qxc5 17. Rxc5 Rb5 18. Rfc1 Rfb8 19. Nd2 Kf7 20. Nc4 Ke6 21. Na5 Rxc5 22. Rxc5 Rb5 23. Nxc6 Rxc5 24. Nd8+ Kd5 25. dxc5 Kxc5 26. Kf1 Kb4 27. Ke2 Ka3 28. Kd3 Kxa2 29. Kc3 Ka3 30. Nb7 Bc6 31. Nc5 Bxg2 32. Nxa6 Bf1 33. Nc5 a5 34. Nd7 a4 35. bxa4 Kxa4 36. Nxf6 h6 37. Kd4 Kb5 38. Ke5 Kc6 39. Ng8 h5 40. Ne7+ Kd7 41. Nxg6 Bh3 42. Nf4 Bg4 43. h3 Bd1 44. Kxf5 Ke7 45. Kg5 Kf7 46. Nxh5 Bf3 47. Nf4 Kg7 48. h4 Kh7 49. h5 Kg7 50. h6+ Kh7 51. Nh5 Be4 52. Nf6+ Kh8 53. Nxe4 Kh7 54. Nf6+ Kh8 55. Nd7 Kh7 56. e4 Kh8 57. e5 Kh7 58. e6 Kh8 59. e7 Kh7 60. f3 Kh8 61. e8=Q+ Kh7 62. Qf7+ Kh8 63. Qg7# d5 e6 dxe7",
          "positional_tokens": {
            "prompt_tokens": 209,
            "completion_tokens": 421,
            "total_tokens": 630,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd6",
            "Rac1",
            "Bd7",
            "b3",
            "O-O",
            "Qc5",
            "Qxc5",
            "Rxc5",
            "Rb5",
            "Rfc1",
            "Rfb8",
            "Nd2",
            "Kf7",
            "Nc4",
            "Ke6",
            "Na5",
            "Rxc5",
            "Rxc5",
            "Rb5",
            "Nxc6",
            "Rxc5",
            "Nd8+",
            "Kd5",
            "dxc5",
            "Kxc5",
            "Kf1",
            "Kb4",
            "Ke2",
            "Ka3",
            "Kd3",
            "Kxa2",
            "Kc3",
            "Ka3",
            "Nb7",
            "Bc6",
            "Nc5",
            "Bxg2",
            "Nxa6",
            "Bf1",
            "Nc5",
            "a5",
            "Nd7",
            "a4",
            "bxa4",
            "Kxa4",
            "Nxf6",
            "h6",
            "Kd4",
            "Kb5",
            "Ke5",
            "Kc6",
            "Ng8",
            "h5",
            "Ne7+",
            "Kd7",
            "Nxg6",
            "Bh3",
            "Nf4",
            "Bg4",
            "h3",
            "Bd1",
            "Kxf5",
            "Ke7",
            "Kg5",
            "Kf7",
            "Nxh5",
            "Bf3",
            "Nf4",
            "Kg7",
            "h4",
            "Kh7",
            "h5",
            "Kg7",
            "h6+",
            "Kh7",
            "Nh5",
            "Be4",
            "Nf6+",
            "Kh8",
            "Nxe4",
            "Kh7",
            "Nf6+",
            "Kh8",
            "Nd7",
            "Kh7",
            "e4",
            "Kh8",
            "e5",
            "Kh7",
            "e6",
            "Kh8",
            "e7",
            "Kh7",
            "f3",
            "Kh8",
            "e8=Q+",
            "Kh7",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "d5",
            "e6",
            "dxe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "cxd6",
          "neutral_uci": "c5d6",
          "neutral_response": "13. cxd6 Qxd6 14. Rac1 Bd7 15. b3 O-O 16. Qc5 Qxc5 17. Rxc5 Rb5 18. Rfc1 Rfb8\n19. Nd2 Rxc5 20. Rxc5 Rb5 21. Rc4 Kf7 22. Ra4 Bc8 23. Nc4 Ke6 24. Kf1 c5\n25. dxc5 Rxc5 26. Ke2 Bb7 27. f3 g5 28. Kd3 Rd5+ 29. Kc3 Rd1 30. Rb4 Bc6\n31. Na5 Bb5 32. a4 Bf1 33. Rb7 Bxg2 34. Rxa7 Bxf3 35. Rxa6+ Kf7 36. Nc4\nRh1 37. Nd6+ Kg6 38. Ra5 f4 39. exf4 gxf4 40. Rf5 Rxh2 41. Rxf4 Rh3 42.\nKb4 Bd1 43. Ne4 Rxb3+ 44. Kc4 Rb6 45. a5 Ra6 46. Kb5 Be2+ 47. Kb4 h5 48.\nNc5 Ra8 49. Re4 Bf3 50. Re3 Bg4 51. a6 h4 52. Kb5 h3 53. Re1 Bf3 54. Rg1+\nKf5 55. Rg3 h2 56. Rxf3+ Kg4 57. Rf1 Kg3 58. Kb6 Kg2 59. Ra1 h1=Q 60. Rxh1\nKxh1 61. Kb7 Rh8 62. a7 f5 63. Ne6 Rh7+ 64. Nc7 Rh8 65. Ne6 Rh7+ 66. Nc7\nRh8 67. Ne6 Rh7+ 68. Nc7 Rh8 69. Ne6 Rh7+ 70. Nc7 Rh8 71. Ne6 Rh7+ 72. Nc7\nRh8 73. Ne6 Rh7+ 74. Nc7 Rh8 75. Ne6 Rh7+ 76. Nc7 Rh8 77. Ne6 Rh7+ 78. Nc7\nRh8 79. Ne6 Rh7+ 80. Nc7 Rh8 81. Ne6 Rh7+ 82. Nc7 Rh8 83. Ne6 Rh7+ 84. Nc7\nRh8 85. Ne6 Rh7+ 86. Nc7 Rh8 87. Ne6 Rh7+ 88. Nc7 Rh8 89. Ne6 Rh7+ 90. Nc",
          "neutral_tokens": {
            "prompt_tokens": 208,
            "completion_tokens": 640,
            "total_tokens": 848,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxd6",
            "Rac1",
            "Bd7",
            "b3",
            "O-O",
            "Qc5",
            "Qxc5",
            "Rxc5",
            "Rb5",
            "Rfc1",
            "Rfb8",
            "Nd2",
            "Rxc5",
            "Rxc5",
            "Rb5",
            "Rc4",
            "Kf7",
            "Ra4",
            "Bc8",
            "Nc4",
            "Ke6",
            "Kf1",
            "c5",
            "dxc5",
            "Rxc5",
            "Ke2",
            "Bb7",
            "f3",
            "g5",
            "Kd3",
            "Rd5+",
            "Kc3",
            "Rd1",
            "Rb4",
            "Bc6",
            "Na5",
            "Bb5",
            "a4",
            "Bf1",
            "Rb7",
            "Bxg2",
            "Rxa7",
            "Bxf3",
            "Rxa6+",
            "Kf7",
            "Nc4",
            "Rh1",
            "Nd6+",
            "Kg6",
            "Ra5",
            "f4",
            "exf4",
            "gxf4",
            "Rf5",
            "Rxh2",
            "Rxf4",
            "Rh3",
            "Kb4",
            "Bd1",
            "Ne4",
            "Rxb3+",
            "Kc4",
            "Rb6",
            "a5",
            "Ra6",
            "Kb5",
            "Be2+",
            "Kb4",
            "h5",
            "Nc5",
            "Ra8",
            "Re4",
            "Bf3",
            "Re3",
            "Bg4",
            "a6",
            "h4",
            "Kb5",
            "h3",
            "Re1",
            "Bf3",
            "Rg1+",
            "Kf5",
            "Rg3",
            "h2",
            "Rxf3+",
            "Kg4",
            "Rf1",
            "Kg3",
            "Kb6",
            "Kg2",
            "Ra1",
            "h1=Q",
            "Rxh1",
            "Kxh1",
            "Kb7",
            "Rh8",
            "a7",
            "f5",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+",
            "Nc7",
            "Rh8",
            "Ne6",
            "Rh7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5d6",
          "positional_uci": "c5d6",
          "neutral_uci": "c5d6",
          "consensus_move": "c5d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxd6",
              "Rac1",
              "Bd7",
              "b3",
              "O-O",
              "Qc5",
              "Qxc5",
              "Rxc5",
              "Rb5",
              "Rfc1",
              "Rfb8",
              "Nd2",
              "Kf7",
              "Nc4",
              "Ke6",
              "Na5",
              "Rxc5",
              "Rxc5",
              "Rb5",
              "Nxc6",
              "Rxc5",
              "Nd8+",
              "Kd5",
              "dxc5",
              "Kxc5",
              "Kf1",
              "Kb4",
              "Ke2",
              "Ka3",
              "Kd3",
              "Kxa2",
              "Kc3",
              "Ka3",
              "Nb7",
              "Bc6",
              "Nc5",
              "Bxg2",
              "Nxa6",
              "Bf1",
              "Nc5",
              "a5",
              "Nd7",
              "a4",
              "bxa4",
              "Kxa4",
              "Nxf6",
              "h6",
              "Kd4",
              "Kb5",
              "Ke5",
              "Kc6",
              "Ng8",
              "h5",
              "Ne7+",
              "Kd7",
              "Nxg6",
              "Bh3",
              "Nf4",
              "Bg4",
              "h3",
              "Bd1",
              "Kxf5",
              "Ke7",
              "Kg5",
              "Kf7",
              "Nxh5",
              "Bf3",
              "Nf4",
              "Kg7",
              "h4",
              "Kh7",
              "h5",
              "Kg7",
              "h6+",
              "Kh7",
              "Nh5",
              "Be4",
              "Nf6+",
              "Kh8",
              "Nxe4",
              "Kh7",
              "Nf6+",
              "Kh8",
              "Nd7",
              "Kh7",
              "e4",
              "Kh8",
              "e5",
              "Kh7",
              "e6",
              "Kh8",
              "e7",
              "Kh7",
              "f3",
              "Kh8",
              "e8=Q+",
              "Kh7",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "d5",
              "e6",
              "dxe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxd6",
              "Rac1",
              "Bd7",
              "b3",
              "O-O",
              "Qc5",
              "Qxc5",
              "Rxc5",
              "Rb5",
              "Rfc1",
              "Rfb8",
              "Nd2",
              "Rxc5",
              "Rxc5",
              "Rb5",
              "Rc4",
              "Kf7",
              "Ra4",
              "Bc8",
              "Nc4",
              "Ke6",
              "Kf1",
              "c5",
              "dxc5",
              "Rxc5",
              "Ke2",
              "Bb7",
              "f3",
              "g5",
              "Kd3",
              "Rd5+",
              "Kc3",
              "Rd1",
              "Rb4",
              "Bc6",
              "Na5",
              "Bb5",
              "a4",
              "Bf1",
              "Rb7",
              "Bxg2",
              "Rxa7",
              "Bxf3",
              "Rxa6+",
              "Kf7",
              "Nc4",
              "Rh1",
              "Nd6+",
              "Kg6",
              "Ra5",
              "f4",
              "exf4",
              "gxf4",
              "Rf5",
              "Rxh2",
              "Rxf4",
              "Rh3",
              "Kb4",
              "Bd1",
              "Ne4",
              "Rxb3+",
              "Kc4",
              "Rb6",
              "a5",
              "Ra6",
              "Kb5",
              "Be2+",
              "Kb4",
              "h5",
              "Nc5",
              "Ra8",
              "Re4",
              "Bf3",
              "Re3",
              "Bg4",
              "a6",
              "h4",
              "Kb5",
              "h3",
              "Re1",
              "Bf3",
              "Rg1+",
              "Kf5",
              "Rg3",
              "h2",
              "Rxf3+",
              "Kg4",
              "Rf1",
              "Kg3",
              "Kb6",
              "Kg2",
              "Ra1",
              "h1=Q",
              "Rxh1",
              "Kxh1",
              "Kb7",
              "Rh8",
              "a7",
              "f5",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+",
              "Nc7",
              "Rh8",
              "Ne6",
              "Rh7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 209,
            "completion_tokens": 445,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 209,
            "completion_tokens": 421,
            "total_tokens": 630,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 208,
            "completion_tokens": 640,
            "total_tokens": 848,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 626,
          "total_completion_tokens": 1506,
          "total_tokens": 2132
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 209,
            "completion_tokens": 445,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 209,
            "completion_tokens": 421,
            "total_tokens": 630,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 208,
            "completion_tokens": 640,
            "total_tokens": 848,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "1rb1k2r/p3q2p/p1p2pp1/2Pp1p2/3P4/2Q1PN2/PP3PPP/R4RK1 w k d6 0 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rac1",
          "aggressive_uci": "a1c1",
          "aggressive_response": "14. Rac1 Bd7 15. b3 O-O 16. Qc5 Qxc5 17. Rxc5 Rb5 18. Rfc1 Rfb8 19. Nd2 Kf7 20. Nc4 Ke6 21. Na5 Rxc5 22. Rxc5 Rb5 23. Nxc6 Rxc5 24. Nd8+ Kd5 25. dxc5 Kxc5 26. Kf1 Kb4 27. Ke2 Ka3 28. Kd3 Kxa2 29. Kc3 Ka3 30. Nb7 Bc6 31. Nc5 Bxg2 32. Nxa6 Bf1 33. Nc5 a5 34. Nd7 a4 35. bxa4 Kxa4 36. Nxf6 h6 37. Kd4 Kb5 38. Ke5 Kc6 39. Ng8 h5 40. Kf6 Kd5 41. Kxg6 Ke4 42. Kxh5 Kf3 43. Kg5 Kxf2 44. Kf4 Bh3 45. Ne7 Kg2 46. Nxf5 Kxh2 47. e4 Kg2 48. e5 Kf2 49. e6 Bf1 50. e7 Bb5 51. Nd6 Bd7 52. Ke5 Ke3 53. Kf6 Kd4 54. Kf7 Kd5 55. Ne8 Ke5 56. Nf6 Bc6 57. Ng4+ Kd6 58. Nf6 Ke5 59. Ng8 Kd6 60. Kf8 Ke6 61. Nh6 Kf6 62. Nf7 Ke6 63. Nd8+ Kd7 64. Nxc6 Kxc6 65. e8=Q+ Kd5 66. Qe7 Kd4 67. Qe6 Kd3 68. Qe5 Kc4 69. Qd6 Kc3 70. Qd5 Kb4 71. Qc6 Kb3 72. Qc5 Kb2 73. Qc4 Kb1 74. Qc3 Ka2 75. Qb4 Ka1 76. Ke7 Ka2 77. Kd6 Ka1 78. Kd5 Ka2 79. Kd4 Ka1 80. Kc3 Ka2 81. Qb2# e4 e5 e6",
          "aggressive_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 569,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "b3",
            "O-O",
            "Qc5",
            "Qxc5",
            "Rxc5",
            "Rb5",
            "Rfc1",
            "Rfb8",
            "Nd2",
            "Kf7",
            "Nc4",
            "Ke6",
            "Na5",
            "Rxc5",
            "Rxc5",
            "Rb5",
            "Nxc6",
            "Rxc5",
            "Nd8+",
            "Kd5",
            "dxc5",
            "Kxc5",
            "Kf1",
            "Kb4",
            "Ke2",
            "Ka3",
            "Kd3",
            "Kxa2",
            "Kc3",
            "Ka3",
            "Nb7",
            "Bc6",
            "Nc5",
            "Bxg2",
            "Nxa6",
            "Bf1",
            "Nc5",
            "a5",
            "Nd7",
            "a4",
            "bxa4",
            "Kxa4",
            "Nxf6",
            "h6",
            "Kd4",
            "Kb5",
            "Ke5",
            "Kc6",
            "Ng8",
            "h5",
            "Kf6",
            "Kd5",
            "Kxg6",
            "Ke4",
            "Kxh5",
            "Kf3",
            "Kg5",
            "Kxf2",
            "Kf4",
            "Bh3",
            "Ne7",
            "Kg2",
            "Nxf5",
            "Kxh2",
            "e4",
            "Kg2",
            "e5",
            "Kf2",
            "e6",
            "Bf1",
            "e7",
            "Bb5",
            "Nd6",
            "Bd7",
            "Ke5",
            "Ke3",
            "Kf6",
            "Kd4",
            "Kf7",
            "Kd5",
            "Ne8",
            "Ke5",
            "Nf6",
            "Bc6",
            "Ng4+",
            "Kd6",
            "Nf6",
            "Ke5",
            "Ng8",
            "Kd6",
            "Kf8",
            "Ke6",
            "Nh6",
            "Kf6",
            "Nf7",
            "Ke6",
            "Nd8+",
            "Kd7",
            "Nxc6",
            "Kxc6",
            "e8=Q+",
            "Kd5",
            "Qe7",
            "Kd4",
            "Qe6",
            "Kd3",
            "Qe5",
            "Kc4",
            "Qd6",
            "Kc3",
            "Qd5",
            "Kb4",
            "Qc6",
            "Kb3",
            "Qc5",
            "Kb2",
            "Qc4",
            "Kb1",
            "Qc3",
            "Ka2",
            "Qb4",
            "Ka1",
            "Ke7",
            "Ka2",
            "Kd6",
            "Ka1",
            "Kd5",
            "Ka2",
            "Kd4",
            "Ka1",
            "Kc3",
            "Ka2",
            "Qb2#",
            "e4",
            "e5",
            "e6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rac1",
          "positional_uci": "a1c1",
          "positional_response": "14. Rac1 Bd7 15. b3 O-O 16. Qc5 Qxc5 17. Rxc5 Rb5 18. Rfc1 Rfb8 19. Nd2 Kf7 20. Nc4 Ke6 21. Na5 Rxc5 22. Rxc5 Rb5 23. Nxc6 Rxc5 24. Nd8+ Kd5 25. dxc5 Kxc5 26. Kf1 Kb4 27. Ke2 Ka3 28. Kd3 Kxa2 29. Kc3 Ka3 30. Nb7 Bc6 31. Nc5 Bxg2 32. Nxa6 Bf1 33. Nc5 a5 34. Nd7 a4 35. bxa4 Kxa4 36. Nxf6 h6 37. Kd4 Kb5 38. Ke5 Kc6 39. Ng8 h5 40. Ne7+ Kd7 41. Nxg6 Bh3 42. Nf4 Bg4 43. h3 Bd1 44. Kxf5 Ke7 45. Kg5 Kf7 46. Nxh5 Bf3 47. Nf4 Kg7 48. h4 Kh7 49. h5 Kg7 50. h6+ Kh7 51. Nh5 Be4 52. Nf6+ Kh8 53. Nxe4 Kh7 54. Nf6+ Kh8 55. Nh5 Kh7 56. e4 Kh8 57. e5 Kh7 58. e6 Kh8 59. e7 Kh7 60. f4 Kh8 61. e8=Q+ Kh7 62. Qf7+ Kh8 63. Qg7# d5 d4 d3 d2 d1=Q d1=Q Qxd1#",
          "positional_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 424,
            "total_tokens": 642,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "b3",
            "O-O",
            "Qc5",
            "Qxc5",
            "Rxc5",
            "Rb5",
            "Rfc1",
            "Rfb8",
            "Nd2",
            "Kf7",
            "Nc4",
            "Ke6",
            "Na5",
            "Rxc5",
            "Rxc5",
            "Rb5",
            "Nxc6",
            "Rxc5",
            "Nd8+",
            "Kd5",
            "dxc5",
            "Kxc5",
            "Kf1",
            "Kb4",
            "Ke2",
            "Ka3",
            "Kd3",
            "Kxa2",
            "Kc3",
            "Ka3",
            "Nb7",
            "Bc6",
            "Nc5",
            "Bxg2",
            "Nxa6",
            "Bf1",
            "Nc5",
            "a5",
            "Nd7",
            "a4",
            "bxa4",
            "Kxa4",
            "Nxf6",
            "h6",
            "Kd4",
            "Kb5",
            "Ke5",
            "Kc6",
            "Ng8",
            "h5",
            "Ne7+",
            "Kd7",
            "Nxg6",
            "Bh3",
            "Nf4",
            "Bg4",
            "h3",
            "Bd1",
            "Kxf5",
            "Ke7",
            "Kg5",
            "Kf7",
            "Nxh5",
            "Bf3",
            "Nf4",
            "Kg7",
            "h4",
            "Kh7",
            "h5",
            "Kg7",
            "h6+",
            "Kh7",
            "Nh5",
            "Be4",
            "Nf6+",
            "Kh8",
            "Nxe4",
            "Kh7",
            "Nf6+",
            "Kh8",
            "Nh5",
            "Kh7",
            "e4",
            "Kh8",
            "e5",
            "Kh7",
            "e6",
            "Kh8",
            "e7",
            "Kh7",
            "f4",
            "Kh8",
            "e8=Q+",
            "Kh7",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "d5",
            "d4",
            "d3",
            "d2",
            "d1=Q",
            "d1=Q",
            "Qxd1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rac1",
          "neutral_uci": "a1c1",
          "neutral_response": "14. Rac1 Bd7 15. b3 O-O 16. Qc5 Qxc5 17. Rxc5 Rb5 18. Rfc1 Rfb8 19. Nd2 Kf7 20. Nc4 Ke6 21. Na5 Rxc5 22. Rxc5 Rb5 23. Kf1 Kd6 24. Nc4+ Ke6 25. Ke2 Rxc5 26. dxc5 Kd5 27. Kd3 Kxc5 28. Kc3 Be6 29. b4+ Kb5 30. Nd6+ Ka4 31. Ne8 Bxa2 32. Nxf6 h6 33. Nd7 Bd5 34. g3 Kb5 35. Ne5 g5 36. Nd3 a5 37. bxa5 Kxa5 38. Kd4 Kb5 39. Ke5 Be4 40. Nb2 a5 41. g4 a4 42. gxf5 a3 43. f6 Bg6 44. Nd3 a2 45. Ke6 a1=Q 46. Ne5 Qa2+ 47. Ke7 Qa7+ 48. Ke6 Qa2+ 49. Ke7 Qa3+ 50. Ke6 Qb3+ 51. Ke7 Qb4+ 52. Ke6 Qb3+ 53. Ke7 Qb4+ 54. Ke6 Qb3+ 55. Ke7 Qb4+ 56. Ke6 Qb3+ 57. Ke7 Qb4+ 58. Ke6 Qb3+ 59. Ke7 Qb4+ 60. Ke6 Qb3+ 61. Ke7 Qb4+ 62. Ke6 Qb3+ 63. Ke7 Qb4+ 64. Ke6 Qb3+ 65. Ke7 Qb4+ 66. Ke6 Qb3+ 67. Ke7 Qb4+ 68. Ke6 Qb3+ 69. Ke7 Qb4+ 70. Ke6 Qb3+ 71. Ke7 Qb4+ 72. Ke6 Qb3+ 73. Ke7 Qb4+ 74. Ke6 Qb3+ 75. Ke7 Qb4+ 76. Ke6 Qb3+ 77. Ke7 Qb4+ 78. Ke6 Qb3+ 79. Ke7 Qb4+ 80. Ke6 Qb3+ 81. Ke7 Qb4+ 82. Ke6 Qb3+ 83. Ke7 Qb4+ 84. Ke6 Qb3+ 85. Ke7 Qb4+ 86. Ke6 Qb3+ 87. Ke7 Qb4+ 88. Ke6 Q",
          "neutral_tokens": {
            "prompt_tokens": 217,
            "completion_tokens": 640,
            "total_tokens": 857,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd7",
            "b3",
            "O-O",
            "Qc5",
            "Qxc5",
            "Rxc5",
            "Rb5",
            "Rfc1",
            "Rfb8",
            "Nd2",
            "Kf7",
            "Nc4",
            "Ke6",
            "Na5",
            "Rxc5",
            "Rxc5",
            "Rb5",
            "Kf1",
            "Kd6",
            "Nc4+",
            "Ke6",
            "Ke2",
            "Rxc5",
            "dxc5",
            "Kd5",
            "Kd3",
            "Kxc5",
            "Kc3",
            "Be6",
            "b4+",
            "Kb5",
            "Nd6+",
            "Ka4",
            "Ne8",
            "Bxa2",
            "Nxf6",
            "h6",
            "Nd7",
            "Bd5",
            "g3",
            "Kb5",
            "Ne5",
            "g5",
            "Nd3",
            "a5",
            "bxa5",
            "Kxa5",
            "Kd4",
            "Kb5",
            "Ke5",
            "Be4",
            "Nb2",
            "a5",
            "g4",
            "a4",
            "gxf5",
            "a3",
            "f6",
            "Bg6",
            "Nd3",
            "a2",
            "Ke6",
            "a1=Q",
            "Ne5",
            "Qa2+",
            "Ke7",
            "Qa7+",
            "Ke6",
            "Qa2+",
            "Ke7",
            "Qa3+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6",
            "Qb3+",
            "Ke7",
            "Qb4+",
            "Ke6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a1c1",
          "positional_uci": "a1c1",
          "neutral_uci": "a1c1",
          "consensus_move": "a1c1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd7",
              "b3",
              "O-O",
              "Qc5",
              "Qxc5",
              "Rxc5",
              "Rb5",
              "Rfc1",
              "Rfb8",
              "Nd2",
              "Kf7",
              "Nc4",
              "Ke6",
              "Na5",
              "Rxc5",
              "Rxc5",
              "Rb5",
              "Nxc6",
              "Rxc5",
              "Nd8+",
              "Kd5",
              "dxc5",
              "Kxc5",
              "Kf1",
              "Kb4",
              "Ke2",
              "Ka3",
              "Kd3",
              "Kxa2",
              "Kc3",
              "Ka3",
              "Nb7",
              "Bc6",
              "Nc5",
              "Bxg2",
              "Nxa6",
              "Bf1",
              "Nc5",
              "a5",
              "Nd7",
              "a4",
              "bxa4",
              "Kxa4",
              "Nxf6",
              "h6",
              "Kd4",
              "Kb5",
              "Ke5",
              "Kc6",
              "Ng8",
              "h5",
              "Kf6",
              "Kd5",
              "Kxg6",
              "Ke4",
              "Kxh5",
              "Kf3",
              "Kg5",
              "Kxf2",
              "Kf4",
              "Bh3",
              "Ne7",
              "Kg2",
              "Nxf5",
              "Kxh2",
              "e4",
              "Kg2",
              "e5",
              "Kf2",
              "e6",
              "Bf1",
              "e7",
              "Bb5",
              "Nd6",
              "Bd7",
              "Ke5",
              "Ke3",
              "Kf6",
              "Kd4",
              "Kf7",
              "Kd5",
              "Ne8",
              "Ke5",
              "Nf6",
              "Bc6",
              "Ng4+",
              "Kd6",
              "Nf6",
              "Ke5",
              "Ng8",
              "Kd6",
              "Kf8",
              "Ke6",
              "Nh6",
              "Kf6",
              "Nf7",
              "Ke6",
              "Nd8+",
              "Kd7",
              "Nxc6",
              "Kxc6",
              "e8=Q+",
              "Kd5",
              "Qe7",
              "Kd4",
              "Qe6",
              "Kd3",
              "Qe5",
              "Kc4",
              "Qd6",
              "Kc3",
              "Qd5",
              "Kb4",
              "Qc6",
              "Kb3",
              "Qc5",
              "Kb2",
              "Qc4",
              "Kb1",
              "Qc3",
              "Ka2",
              "Qb4",
              "Ka1",
              "Ke7",
              "Ka2",
              "Kd6",
              "Ka1",
              "Kd5",
              "Ka2",
              "Kd4",
              "Ka1",
              "Kc3",
              "Ka2",
              "Qb2#",
              "e4",
              "e5",
              "e6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd7",
              "b3",
              "O-O",
              "Qc5",
              "Qxc5",
              "Rxc5",
              "Rb5",
              "Rfc1",
              "Rfb8",
              "Nd2",
              "Kf7",
              "Nc4",
              "Ke6",
              "Na5",
              "Rxc5",
              "Rxc5",
              "Rb5",
              "Nxc6",
              "Rxc5",
              "Nd8+",
              "Kd5",
              "dxc5",
              "Kxc5",
              "Kf1",
              "Kb4",
              "Ke2",
              "Ka3",
              "Kd3",
              "Kxa2",
              "Kc3",
              "Ka3",
              "Nb7",
              "Bc6",
              "Nc5",
              "Bxg2",
              "Nxa6",
              "Bf1",
              "Nc5",
              "a5",
              "Nd7",
              "a4",
              "bxa4",
              "Kxa4",
              "Nxf6",
              "h6",
              "Kd4",
              "Kb5",
              "Ke5",
              "Kc6",
              "Ng8",
              "h5",
              "Ne7+",
              "Kd7",
              "Nxg6",
              "Bh3",
              "Nf4",
              "Bg4",
              "h3",
              "Bd1",
              "Kxf5",
              "Ke7",
              "Kg5",
              "Kf7",
              "Nxh5",
              "Bf3",
              "Nf4",
              "Kg7",
              "h4",
              "Kh7",
              "h5",
              "Kg7",
              "h6+",
              "Kh7",
              "Nh5",
              "Be4",
              "Nf6+",
              "Kh8",
              "Nxe4",
              "Kh7",
              "Nf6+",
              "Kh8",
              "Nh5",
              "Kh7",
              "e4",
              "Kh8",
              "e5",
              "Kh7",
              "e6",
              "Kh8",
              "e7",
              "Kh7",
              "f4",
              "Kh8",
              "e8=Q+",
              "Kh7",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "d5",
              "d4",
              "d3",
              "d2",
              "d1=Q",
              "d1=Q",
              "Qxd1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd7",
              "b3",
              "O-O",
              "Qc5",
              "Qxc5",
              "Rxc5",
              "Rb5",
              "Rfc1",
              "Rfb8",
              "Nd2",
              "Kf7",
              "Nc4",
              "Ke6",
              "Na5",
              "Rxc5",
              "Rxc5",
              "Rb5",
              "Kf1",
              "Kd6",
              "Nc4+",
              "Ke6",
              "Ke2",
              "Rxc5",
              "dxc5",
              "Kd5",
              "Kd3",
              "Kxc5",
              "Kc3",
              "Be6",
              "b4+",
              "Kb5",
              "Nd6+",
              "Ka4",
              "Ne8",
              "Bxa2",
              "Nxf6",
              "h6",
              "Nd7",
              "Bd5",
              "g3",
              "Kb5",
              "Ne5",
              "g5",
              "Nd3",
              "a5",
              "bxa5",
              "Kxa5",
              "Kd4",
              "Kb5",
              "Ke5",
              "Be4",
              "Nb2",
              "a5",
              "g4",
              "a4",
              "gxf5",
              "a3",
              "f6",
              "Bg6",
              "Nd3",
              "a2",
              "Ke6",
              "a1=Q",
              "Ne5",
              "Qa2+",
              "Ke7",
              "Qa7+",
              "Ke6",
              "Qa2+",
              "Ke7",
              "Qa3+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6",
              "Qb3+",
              "Ke7",
              "Qb4+",
              "Ke6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 218,
            "completion_tokens": 569,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 218,
            "completion_tokens": 424,
            "total_tokens": 642,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 217,
            "completion_tokens": 640,
            "total_tokens": 857,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 653,
          "total_completion_tokens": 1633,
          "total_tokens": 2286
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 218,
            "completion_tokens": 569,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 218,
            "completion_tokens": 424,
            "total_tokens": 642,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 217,
            "completion_tokens": 640,
            "total_tokens": 857,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "1rb1k2r/p6p/p1pq1pp1/5p2/3P4/2Q1PN2/PP3PPP/R4RK1 w k - 0 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nd2",
          "aggressive_uci": "f3d2",
          "aggressive_response": "15. Nd2 O-O 16. Nc4 Qe6 17. b3 Rfc8 18. Qa5 c5 19. dxc5 Rb5 20. Qa3 Rbxc5\n21. Rfd1 Bb5 22. Rd6 Qe7 23. Rcd1 Bxc4 24. bxc4 Rxc4 25. Qxa6 Rc1 26. h3 Rxd1+\n27. Rxd1 Rc2 28. Qa4 Rc7 29. Qb3+ Kg7 30. Qd5 Qe5 31. Qd8 Re7 32. Rd7 Rxd7\n33. Qxd7+ Kh6 34. Qxa7 Qa1+ 35. Kh2 Qe5+ 36. g3 Qb2 37. Kg2 Qe5 38. Qd4 Qe6\n39. a4 Qc6+ 40. Kh2 Qf3 41. Qf4+ Qxf4 42. gxf4 Kg7 43. a5 Kf7 44. a6 Ke7\n45. a7 Kd7 46. a8=Q Kc7 47. Qa7+ Kc6 48. Qxh7 Kd5 49. Qxg6 Ke4 50. Qxf6 Kf3\n51. Qxf5 Kxf2 52. e4 Kf3 53. e5 Ke3 54. e6 Kf3 55. e7 Ke3 56. e8=Q+ Kf3\n57. Qfe4+ Kf2 58. Qe2# Qxe2 59. Qxe2+ Kxe2 60. f5 Kf3 61. f6 Kf4 62. f7 Kf5\n63. f8=Q+ Kg6 64. Kg3 Kh5 65. Qf5+ Kh6 66. Kg4 Kg7 67. Kg5 Kg8 68. Kg6 Kh8\n69. Qf8# Kg8 70. Qg7# Kg8 71. Qf7+ Kh8 72. Qh7# Kg8 73. Qg7# Kg8 74. Qf7+ Kh8\n75. Qf8# Kg8 76. Qg7# Kg8 77. Qf7+ Kh8 78. Qf8# Kg8 79. Qg7# Kg8 80. Qf7+ Kh8\n81. Qf8# Kg8 82. Qg7# Kg8 83. Qf7+ Kh8 84. Qf8# Kg8 85. Qg7# Kg8 86. Qf7+ Kh8\n87. Qf8# Kg8 88. Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 226,
            "completion_tokens": 640,
            "total_tokens": 866,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nc4",
            "Qe6",
            "b3",
            "Rfc8",
            "Qa5",
            "c5",
            "dxc5",
            "Rb5",
            "Qa3",
            "Rbxc5",
            "Rfd1",
            "Bb5",
            "Rd6",
            "Qe7",
            "Rcd1",
            "Bxc4",
            "bxc4",
            "Rxc4",
            "Qxa6",
            "Rc1",
            "h3",
            "Rxd1+",
            "Rxd1",
            "Rc2",
            "Qa4",
            "Rc7",
            "Qb3+",
            "Kg7",
            "Qd5",
            "Qe5",
            "Qd8",
            "Re7",
            "Rd7",
            "Rxd7",
            "Qxd7+",
            "Kh6",
            "Qxa7",
            "Qa1+",
            "Kh2",
            "Qe5+",
            "g3",
            "Qb2",
            "Kg2",
            "Qe5",
            "Qd4",
            "Qe6",
            "a4",
            "Qc6+",
            "Kh2",
            "Qf3",
            "Qf4+",
            "Qxf4",
            "gxf4",
            "Kg7",
            "a5",
            "Kf7",
            "a6",
            "Ke7",
            "a7",
            "Kd7",
            "a8=Q",
            "Kc7",
            "Qa7+",
            "Kc6",
            "Qxh7",
            "Kd5",
            "Qxg6",
            "Ke4",
            "Qxf6",
            "Kf3",
            "Qxf5",
            "Kxf2",
            "e4",
            "Kf3",
            "e5",
            "Ke3",
            "e6",
            "Kf3",
            "e7",
            "Ke3",
            "e8=Q+",
            "Kf3",
            "Qfe4+",
            "Kf2",
            "Qe2#",
            "Qxe2",
            "Qxe2+",
            "Kxe2",
            "f5",
            "Kf3",
            "f6",
            "Kf4",
            "f7",
            "Kf5",
            "f8=Q+",
            "Kg6",
            "Kg3",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kg5",
            "Kg8",
            "Kg6",
            "Kh8",
            "Qf8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh7#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nd2",
          "positional_uci": "f3d2",
          "positional_response": "15. Nd2 O-O 16. Nc4 Qe6 17. b3 Rfc8 18. Qa5 c5 19. dxc5 Rb5 20. Qd2 Rbxc5\n21. Rfd1 Bb5 22. Nd6 Rxc1 23. Rxc1 Rxc1+ 24. Qxc1 Qxd6 25. Qc8+ Kg7 26. Qb7+\nKh6 27. h3 Qd1+ 28. Kh2 Qd6+ 29. Kg1 Qc6 30. Qxa7 Qc1+ 31. Kh2 Qf1 32. Kg3\nBc6 33. f3 Qe1+ 34. Kh2 Qe2 35. Kg3 Qxa2 36. Qb6 Bb5 37. Qxf6 Qxb3 38. Qf8+\nKh5 39. Qg7 h6 40. Qe7 g5 41. Qf6 Qxe3 42. Qf7# Qf4+ 43. Kf2 Kh4 44. Qg6\nQd2+ 45. Kg1 Kg3 46. Qxh6 Qxg2# Qxg2#",
          "positional_tokens": {
            "prompt_tokens": 226,
            "completion_tokens": 289,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nc4",
            "Qe6",
            "b3",
            "Rfc8",
            "Qa5",
            "c5",
            "dxc5",
            "Rb5",
            "Qd2",
            "Rbxc5",
            "Rfd1",
            "Bb5",
            "Nd6",
            "Rxc1",
            "Rxc1",
            "Rxc1+",
            "Qxc1",
            "Qxd6",
            "Qc8+",
            "Kg7",
            "Qb7+",
            "Kh6",
            "h3",
            "Qd1+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qc6",
            "Qxa7",
            "Qc1+",
            "Kh2",
            "Qf1",
            "Kg3",
            "Bc6",
            "f3",
            "Qe1+",
            "Kh2",
            "Qe2",
            "Kg3",
            "Qxa2",
            "Qb6",
            "Bb5",
            "Qxf6",
            "Qxb3",
            "Qf8+",
            "Kh5",
            "Qg7",
            "h6",
            "Qe7",
            "g5",
            "Qf6",
            "Qxe3",
            "Qf7#",
            "Qf4+",
            "Kf2",
            "Kh4",
            "Qg6",
            "Qd2+",
            "Kg1",
            "Kg3",
            "Qxh6",
            "Qxg2#",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nd2",
          "neutral_uci": "f3d2",
          "neutral_response": "15. Nd2 O-O 16. Nc4 Qe6 17. b3 Rfc8 18. Qa5 c5 19. dxc5 Rb5 20. Qa3 Rbxc5\n21. Rfd1 Bb5 22. Rd6 Qe7 23. Rcd1 Bxc4 24. bxc4 Rxc4 25. Qxa6 Rc1 26. h3 Rxd1+\n27. Rxd1 Rc2 28. Qa4 Rc7 29. Qb3+ Kg7 30. Qb8 Rb7 31. Qc8 Rc7 32. Qb8 Rb7\n33. Qc8 Rc7 34. Qb8 Rb7 35. Qc8 Rc7 36. Qb8 Rb7 37. Qc8 Rc7 38. Qb8 Rb7\n39. Qc8 Rc7 40. Qb8 Rb7 41. Qc8 Rc7 42. Qb8 Rb7 43. Qc8 Rc7 44. Qb8 Rb7\n45. Qc8 Rc7 46. Qb8 Rb7 47. Qc8 Rc7 48. Qb8 Rb7 49. Qc8 Rc7 50. Qb8 Rb7\n51. Qc8 Rc7 52. Qb8 Rb7 53. Qc8 Rc7 54. Qb8 Rb7 55. Qc8 Rc7 56. Qb8 Rb7\n57. Qc8 Rc7 58. Qb8 Rb7 59. Qc8 Rc7 60. Qb8 Rb7 61. Qc8 Rc7 62. Qb8 Rb7\n63. Qc8 Rc7 64. Qb8 Rb7 65. Qc8 Rc7 66. Qb8 Rb7 67. Qc8 Rc7 68. Qb8 Rb7\n69. Qc8 Rc7 70. Qb8 Rb7 71. Qc8 Rc7 72. Qb8 Rb7 73. Qc8 Rc7 74. Qb8 Rb7\n75. Qc8 Rc7 76. Qb8 Rb7 77. Qc8 Rc7 78. Qb8 Rb7 79. Qc8 Rc7 80. Qb8 Rb7\n81. Qc8 Rc7 82. Qb8 Rb7 83. Qc8 Rc7 84. Qb8 Rb7 85. Qc8 Rc7 86. Qb8 Rb7\n87. Qc8 Rc7 88. Qb8 Rb7 89. Qc8 Rc7 90.",
          "neutral_tokens": {
            "prompt_tokens": 225,
            "completion_tokens": 640,
            "total_tokens": 865,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nc4",
            "Qe6",
            "b3",
            "Rfc8",
            "Qa5",
            "c5",
            "dxc5",
            "Rb5",
            "Qa3",
            "Rbxc5",
            "Rfd1",
            "Bb5",
            "Rd6",
            "Qe7",
            "Rcd1",
            "Bxc4",
            "bxc4",
            "Rxc4",
            "Qxa6",
            "Rc1",
            "h3",
            "Rxd1+",
            "Rxd1",
            "Rc2",
            "Qa4",
            "Rc7",
            "Qb3+",
            "Kg7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7",
            "Qb8",
            "Rb7",
            "Qc8",
            "Rc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3d2",
          "positional_uci": "f3d2",
          "neutral_uci": "f3d2",
          "consensus_move": "f3d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nc4",
              "Qe6",
              "b3",
              "Rfc8",
              "Qa5",
              "c5",
              "dxc5",
              "Rb5",
              "Qa3",
              "Rbxc5",
              "Rfd1",
              "Bb5",
              "Rd6",
              "Qe7",
              "Rcd1",
              "Bxc4",
              "bxc4",
              "Rxc4",
              "Qxa6",
              "Rc1",
              "h3",
              "Rxd1+",
              "Rxd1",
              "Rc2",
              "Qa4",
              "Rc7",
              "Qb3+",
              "Kg7",
              "Qd5",
              "Qe5",
              "Qd8",
              "Re7",
              "Rd7",
              "Rxd7",
              "Qxd7+",
              "Kh6",
              "Qxa7",
              "Qa1+",
              "Kh2",
              "Qe5+",
              "g3",
              "Qb2",
              "Kg2",
              "Qe5",
              "Qd4",
              "Qe6",
              "a4",
              "Qc6+",
              "Kh2",
              "Qf3",
              "Qf4+",
              "Qxf4",
              "gxf4",
              "Kg7",
              "a5",
              "Kf7",
              "a6",
              "Ke7",
              "a7",
              "Kd7",
              "a8=Q",
              "Kc7",
              "Qa7+",
              "Kc6",
              "Qxh7",
              "Kd5",
              "Qxg6",
              "Ke4",
              "Qxf6",
              "Kf3",
              "Qxf5",
              "Kxf2",
              "e4",
              "Kf3",
              "e5",
              "Ke3",
              "e6",
              "Kf3",
              "e7",
              "Ke3",
              "e8=Q+",
              "Kf3",
              "Qfe4+",
              "Kf2",
              "Qe2#",
              "Qxe2",
              "Qxe2+",
              "Kxe2",
              "f5",
              "Kf3",
              "f6",
              "Kf4",
              "f7",
              "Kf5",
              "f8=Q+",
              "Kg6",
              "Kg3",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kg5",
              "Kg8",
              "Kg6",
              "Kh8",
              "Qf8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh7#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Nc4",
              "Qe6",
              "b3",
              "Rfc8",
              "Qa5",
              "c5",
              "dxc5",
              "Rb5",
              "Qd2",
              "Rbxc5",
              "Rfd1",
              "Bb5",
              "Nd6",
              "Rxc1",
              "Rxc1",
              "Rxc1+",
              "Qxc1",
              "Qxd6",
              "Qc8+",
              "Kg7",
              "Qb7+",
              "Kh6",
              "h3",
              "Qd1+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qc6",
              "Qxa7",
              "Qc1+",
              "Kh2",
              "Qf1",
              "Kg3",
              "Bc6",
              "f3",
              "Qe1+",
              "Kh2",
              "Qe2",
              "Kg3",
              "Qxa2",
              "Qb6",
              "Bb5",
              "Qxf6",
              "Qxb3",
              "Qf8+",
              "Kh5",
              "Qg7",
              "h6",
              "Qe7",
              "g5",
              "Qf6",
              "Qxe3",
              "Qf7#",
              "Qf4+",
              "Kf2",
              "Kh4",
              "Qg6",
              "Qd2+",
              "Kg1",
              "Kg3",
              "Qxh6",
              "Qxg2#",
              "Qxg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Nc4",
              "Qe6",
              "b3",
              "Rfc8",
              "Qa5",
              "c5",
              "dxc5",
              "Rb5",
              "Qa3",
              "Rbxc5",
              "Rfd1",
              "Bb5",
              "Rd6",
              "Qe7",
              "Rcd1",
              "Bxc4",
              "bxc4",
              "Rxc4",
              "Qxa6",
              "Rc1",
              "h3",
              "Rxd1+",
              "Rxd1",
              "Rc2",
              "Qa4",
              "Rc7",
              "Qb3+",
              "Kg7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7",
              "Qb8",
              "Rb7",
              "Qc8",
              "Rc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 226,
            "completion_tokens": 640,
            "total_tokens": 866,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 226,
            "completion_tokens": 289,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 225,
            "completion_tokens": 640,
            "total_tokens": 865,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 677,
          "total_completion_tokens": 1569,
          "total_tokens": 2246
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 226,
            "completion_tokens": 640,
            "total_tokens": 866,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 226,
            "completion_tokens": 289,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 225,
            "completion_tokens": 640,
            "total_tokens": 865,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "1r2k2r/p2b3p/p1pq1pp1/5p2/3P4/2Q1PN2/PP3PPP/2R2RK1 w k - 2 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e3e4",
          "aggressive_response": "16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Bf5 19. Nxa6 Rb6 20. Nb4 Qb5 21. Nxc6 Qxb2\n22. Ne7+ Kh8 23. Nxf5 gxf5 24. Qc5 Rg8 25. Qxf5 Qxd4 26. Rc7 Qh4 27. Rxa7 Rb2\n28. g3 Qh6 29. a4 Rb4 30. a5 Rh4 31. Rf7 Rxh2 32. Qxf6+ Qxf6 33. Rxf6 Rh5\n34. Ra1 Ra8 35. a6 Kg7 36. Rb6 Rf5 37. a7 Rf7 38. Rba6 h5 39. Kg2 Rf5\n40. Rb1 Rf7 41. Rba1 Rf5 42. R1a5 Rxa5 43. Rxa5 Kg6 44. Kh3 Kh6 45. Kh4 Kg6\n46. Ra6+ Kf5 47. Kxh5 Rh8+ 48. Rh6 Ra8 49. Rh7 Kf6 50. g4 Ke6 51. g5 Kf5\n52. g6 Kf6 53. Rf7+ Ke6 54. Kh6 Rh8+ 55. Kg7 Ra8 56. f4 Kd6 57. f5 Ke5\n58. f6 Kf5 59. Kh7 Kg5 60. g7 Kh5 61. g8=Q Rxg8 62. Kxg8 Kg6 63. a8=Q Kh6\n64. Qh1+ Kg6 65. Qg2+ Kh6 66. Rh7# Qe7 67. Qg7+ Qxg7+ 68. fxg7+ Kg6 69. g8=Q+ Kf6 70. Rf7+ Ke6 71. Qe8+ Kd6 72. Rd7+ Kc6 73. Qc8+ Kb6 74. Rb7+ Ka6 75. Qa8# Qe7 76. Qa7# Qxg7# 77. Rxg7# Qe7 78. Qxe7# Qxg7# 79. Kxg7# Qe7 80. Qxe7# Qxg7# 81. Kxg7# Qe7 82. Qxe7# Qxg7# 83. Kxg7# Qe7 84. Qxe7# Qxg7# 85. Kxg7# Qe7 86. Qxe7# Qxg7# 87.",
          "aggressive_tokens": {
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Bf5",
            "Nxa6",
            "Rb6",
            "Nb4",
            "Qb5",
            "Nxc6",
            "Qxb2",
            "Ne7+",
            "Kh8",
            "Nxf5",
            "gxf5",
            "Qc5",
            "Rg8",
            "Qxf5",
            "Qxd4",
            "Rc7",
            "Qh4",
            "Rxa7",
            "Rb2",
            "g3",
            "Qh6",
            "a4",
            "Rb4",
            "a5",
            "Rh4",
            "Rf7",
            "Rxh2",
            "Qxf6+",
            "Qxf6",
            "Rxf6",
            "Rh5",
            "Ra1",
            "Ra8",
            "a6",
            "Kg7",
            "Rb6",
            "Rf5",
            "a7",
            "Rf7",
            "Rba6",
            "h5",
            "Kg2",
            "Rf5",
            "Rb1",
            "Rf7",
            "Rba1",
            "Rf5",
            "R1a5",
            "Rxa5",
            "Rxa5",
            "Kg6",
            "Kh3",
            "Kh6",
            "Kh4",
            "Kg6",
            "Ra6+",
            "Kf5",
            "Kxh5",
            "Rh8+",
            "Rh6",
            "Ra8",
            "Rh7",
            "Kf6",
            "g4",
            "Ke6",
            "g5",
            "Kf5",
            "g6",
            "Kf6",
            "Rf7+",
            "Ke6",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Ra8",
            "f4",
            "Kd6",
            "f5",
            "Ke5",
            "f6",
            "Kf5",
            "Kh7",
            "Kg5",
            "g7",
            "Kh5",
            "g8=Q",
            "Rxg8",
            "Kxg8",
            "Kg6",
            "a8=Q",
            "Kh6",
            "Qh1+",
            "Kg6",
            "Qg2+",
            "Kh6",
            "Rh7#",
            "Qe7",
            "Qg7+",
            "Qxg7+",
            "fxg7+",
            "Kg6",
            "g8=Q+",
            "Kf6",
            "Rf7+",
            "Ke6",
            "Qe8+",
            "Kd6",
            "Rd7+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Rb7+",
            "Ka6",
            "Qa8#",
            "Qe7",
            "Qa7#",
            "Qxg7#",
            "Rxg7#",
            "Qe7",
            "Qxe7#",
            "Qxg7#",
            "Kxg7#",
            "Qe7",
            "Qxe7#",
            "Qxg7#",
            "Kxg7#",
            "Qe7",
            "Qxe7#",
            "Qxg7#",
            "Kxg7#",
            "Qe7",
            "Qxe7#",
            "Qxg7#",
            "Kxg7#",
            "Qe7",
            "Qxe7#",
            "Qxg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e3e4",
          "positional_response": "16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Bc8 19. Rfe1 Rb6 20. Re7 Rf7 21. Re8+ Rf8\n22. Rce1 Qxa2 23. b3 Bf5 24. Qc4+ Kg7 25. R1e7+ Kh6 26. Qc1+ g5 27. Rxf8\nRxb3 28. Nxb3 Qxb3 29. Rxf6+ Bg6 30. h4 Qd5 31. Re5 Qxd4 32. Qxg5+ Kg7\n33. Re7+ Kg8 34. Rxg6+ hxg6 35. Qxg6+ Kf8 36. Qf7# d5 e6 Qd8+ Kh7 Qxd5 Qxd5\nQxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+ Kh6 Qxd5+ Kh7 Qxd5+",
          "positional_tokens": {
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Bc8",
            "Rfe1",
            "Rb6",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Rce1",
            "Qxa2",
            "b3",
            "Bf5",
            "Qc4+",
            "Kg7",
            "R1e7+",
            "Kh6",
            "Qc1+",
            "g5",
            "Rxf8",
            "Rxb3",
            "Nxb3",
            "Qxb3",
            "Rxf6+",
            "Bg6",
            "h4",
            "Qd5",
            "Re5",
            "Qxd4",
            "Qxg5+",
            "Kg7",
            "Re7+",
            "Kg8",
            "Rxg6+",
            "hxg6",
            "Qxg6+",
            "Kf8",
            "Qf7#",
            "d5",
            "e6",
            "Qd8+",
            "Kh7",
            "Qxd5",
            "Qxd5",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+",
            "Kh6",
            "Qxd5+",
            "Kh7",
            "Qxd5+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e3e4",
          "neutral_response": "16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Bc8 19. Rfe1 Rb6 20. Re7 Rf7 21. Re8+ Rf8 22.\nRce1 Qxa2 23. b3 Bf5 24. Qc4+ Kg7 25. R1e7+ Kh6 26. Qc1+ g5 27. Rxf8 Kg6 28.\nRg8+ Kh6 29. h4 Kh5 30. Rxh7+ Bxh7 31. Rxg5+ Kxh4 32. Qf4# d5 Qb8+ Qxb8",
          "neutral_tokens": {
            "prompt_tokens": 233,
            "completion_tokens": 158,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Bc8",
            "Rfe1",
            "Rb6",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Rce1",
            "Qxa2",
            "b3",
            "Bf5",
            "Qc4+",
            "Kg7",
            "R1e7+",
            "Kh6",
            "Qc1+",
            "g5",
            "Rxf8",
            "Kg6",
            "Rg8+",
            "Kh6",
            "h4",
            "Kh5",
            "Rxh7+",
            "Bxh7",
            "Rxg5+",
            "Kxh4",
            "Qf4#",
            "d5",
            "Qb8+",
            "Qxb8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e3e4",
          "positional_uci": "e3e4",
          "neutral_uci": "e3e4",
          "consensus_move": "e3e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Bf5",
              "Nxa6",
              "Rb6",
              "Nb4",
              "Qb5",
              "Nxc6",
              "Qxb2",
              "Ne7+",
              "Kh8",
              "Nxf5",
              "gxf5",
              "Qc5",
              "Rg8",
              "Qxf5",
              "Qxd4",
              "Rc7",
              "Qh4",
              "Rxa7",
              "Rb2",
              "g3",
              "Qh6",
              "a4",
              "Rb4",
              "a5",
              "Rh4",
              "Rf7",
              "Rxh2",
              "Qxf6+",
              "Qxf6",
              "Rxf6",
              "Rh5",
              "Ra1",
              "Ra8",
              "a6",
              "Kg7",
              "Rb6",
              "Rf5",
              "a7",
              "Rf7",
              "Rba6",
              "h5",
              "Kg2",
              "Rf5",
              "Rb1",
              "Rf7",
              "Rba1",
              "Rf5",
              "R1a5",
              "Rxa5",
              "Rxa5",
              "Kg6",
              "Kh3",
              "Kh6",
              "Kh4",
              "Kg6",
              "Ra6+",
              "Kf5",
              "Kxh5",
              "Rh8+",
              "Rh6",
              "Ra8",
              "Rh7",
              "Kf6",
              "g4",
              "Ke6",
              "g5",
              "Kf5",
              "g6",
              "Kf6",
              "Rf7+",
              "Ke6",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Ra8",
              "f4",
              "Kd6",
              "f5",
              "Ke5",
              "f6",
              "Kf5",
              "Kh7",
              "Kg5",
              "g7",
              "Kh5",
              "g8=Q",
              "Rxg8",
              "Kxg8",
              "Kg6",
              "a8=Q",
              "Kh6",
              "Qh1+",
              "Kg6",
              "Qg2+",
              "Kh6",
              "Rh7#",
              "Qe7",
              "Qg7+",
              "Qxg7+",
              "fxg7+",
              "Kg6",
              "g8=Q+",
              "Kf6",
              "Rf7+",
              "Ke6",
              "Qe8+",
              "Kd6",
              "Rd7+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Rb7+",
              "Ka6",
              "Qa8#",
              "Qe7",
              "Qa7#",
              "Qxg7#",
              "Rxg7#",
              "Qe7",
              "Qxe7#",
              "Qxg7#",
              "Kxg7#",
              "Qe7",
              "Qxe7#",
              "Qxg7#",
              "Kxg7#",
              "Qe7",
              "Qxe7#",
              "Qxg7#",
              "Kxg7#",
              "Qe7",
              "Qxe7#",
              "Qxg7#",
              "Kxg7#",
              "Qe7",
              "Qxe7#",
              "Qxg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Bc8",
              "Rfe1",
              "Rb6",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Rce1",
              "Qxa2",
              "b3",
              "Bf5",
              "Qc4+",
              "Kg7",
              "R1e7+",
              "Kh6",
              "Qc1+",
              "g5",
              "Rxf8",
              "Rxb3",
              "Nxb3",
              "Qxb3",
              "Rxf6+",
              "Bg6",
              "h4",
              "Qd5",
              "Re5",
              "Qxd4",
              "Qxg5+",
              "Kg7",
              "Re7+",
              "Kg8",
              "Rxg6+",
              "hxg6",
              "Qxg6+",
              "Kf8",
              "Qf7#",
              "d5",
              "e6",
              "Qd8+",
              "Kh7",
              "Qxd5",
              "Qxd5",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+",
              "Kh6",
              "Qxd5+",
              "Kh7",
              "Qxd5+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Bc8",
              "Rfe1",
              "Rb6",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Rce1",
              "Qxa2",
              "b3",
              "Bf5",
              "Qc4+",
              "Kg7",
              "R1e7+",
              "Kh6",
              "Qc1+",
              "g5",
              "Rxf8",
              "Kg6",
              "Rg8+",
              "Kh6",
              "h4",
              "Kh5",
              "Rxh7+",
              "Bxh7",
              "Rxg5+",
              "Kxh4",
              "Qf4#",
              "d5",
              "Qb8+",
              "Qxb8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 233,
            "completion_tokens": 158,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 701,
          "total_completion_tokens": 1438,
          "total_tokens": 2139
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 233,
            "completion_tokens": 158,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1r2k2r/p2b3p/p1p2pp1/3q1p2/3P4/2Q1P3/PP1N1PPP/2R2RK1 w k - 4 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe4",
          "aggressive_uci": "d2e4",
          "aggressive_response": "17. Nxe4 O-O 18. Nc5 Bf5 19. Nxa6 Rb6 20. Nb4 Qb5 21. Nxc6 Qxb2 22. Ne7+ Kh8\n23. Nxf5 gxf5 24. Qc5 Rg8 25. Qxf5 Qxd4 26. Rc7 Rg7 27. Rc8+ Rg8 28. Rxg8+ Kxg8\n29. Qc8+ Kg7 30. Qc7+ Kg6 31. Qxa7 Qb4 32. Qd7 Rd6 33. Qe8+ Kg7 34. Qe7+ Kg6\n35. Qe3 Qa4 36. Qg3+ Kf7 37. Qxd6 Qxa2 38. Qd7+ Kg6 39. Qg4+ Kf7 40. Rd1 Qa5\n41. Rd7+ Ke8 42. Qe6+ Kf8 43. Qf7# d4 Qxd4 Qa1+ Kh2 Qe5+ g3 Qe4+ Kg1 Qe1+ Kg2 Qe4+ Kh3 Qe6+ g4 Qb3+ Kh4 Qc4+ Kh5 Qe4+ Kh6 Qe6+ Kh7 Qe4+ Kh6 Qe3+ Kh7 Qe7+ Kh6 Qf8+ Kh7 Qf7+ Kh6 Qxf6+ Kh7 Qf5+ Kh6 Qf4+ Kh7 Qe4+ Kh6 Qe3+ Kh7 Qd3+ Kh6 Qd6+ Kh7 Qd7+ Kh6 Qd6+ Kh7 Qd3+ Kh6 Qe3+ Kh7 Qe7+ Kh6 Qf8+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf5+ Kh6 Qf4+ Kh7 Qe4+ Kh6 Qe3+ Kh7 Qd3+ Kh6 Qd6+ Kh7 Qd7+ Kh6 Qd6+ Kh7 Qd3+ Kh6 Qe3+ Kh7 Qe7+ Kh6 Qf8+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf5+ Kh6 Qf4+ Kh7 Qe4+ Kh6 Qe3+ Kh7 Qd3+ Kh6 Qd6+ Kh7 Qd7+ Kh6 Qd6+ Kh7 Qd3+ Kh6 Qe3+ Kh7 Qe7+ Kh6 Qf8+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf5+ Kh6 Qf4+ Kh7 Qe4+ Kh6 Qe3+ Kh7 Qd3+ Kh6 Qd6+ Kh7 Qd7+ Kh6 Qd6+ Kh7",
          "aggressive_tokens": {
            "prompt_tokens": 242,
            "completion_tokens": 640,
            "total_tokens": 882,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nc5",
            "Bf5",
            "Nxa6",
            "Rb6",
            "Nb4",
            "Qb5",
            "Nxc6",
            "Qxb2",
            "Ne7+",
            "Kh8",
            "Nxf5",
            "gxf5",
            "Qc5",
            "Rg8",
            "Qxf5",
            "Qxd4",
            "Rc7",
            "Rg7",
            "Rc8+",
            "Rg8",
            "Rxg8+",
            "Kxg8",
            "Qc8+",
            "Kg7",
            "Qc7+",
            "Kg6",
            "Qxa7",
            "Qb4",
            "Qd7",
            "Rd6",
            "Qe8+",
            "Kg7",
            "Qe7+",
            "Kg6",
            "Qe3",
            "Qa4",
            "Qg3+",
            "Kf7",
            "Qxd6",
            "Qxa2",
            "Qd7+",
            "Kg6",
            "Qg4+",
            "Kf7",
            "Rd1",
            "Qa5",
            "Rd7+",
            "Ke8",
            "Qe6+",
            "Kf8",
            "Qf7#",
            "d4",
            "Qxd4",
            "Qa1+",
            "Kh2",
            "Qe5+",
            "g3",
            "Qe4+",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe4+",
            "Kh3",
            "Qe6+",
            "g4",
            "Qb3+",
            "Kh4",
            "Qc4+",
            "Kh5",
            "Qe4+",
            "Kh6",
            "Qe6+",
            "Kh7",
            "Qe4+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qe7+",
            "Kh6",
            "Qf8+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qxf6+",
            "Kh7",
            "Qf5+",
            "Kh6",
            "Qf4+",
            "Kh7",
            "Qe4+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qd3+",
            "Kh6",
            "Qd6+",
            "Kh7",
            "Qd7+",
            "Kh6",
            "Qd6+",
            "Kh7",
            "Qd3+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qe7+",
            "Kh6",
            "Qf8+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf5+",
            "Kh6",
            "Qf4+",
            "Kh7",
            "Qe4+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qd3+",
            "Kh6",
            "Qd6+",
            "Kh7",
            "Qd7+",
            "Kh6",
            "Qd6+",
            "Kh7",
            "Qd3+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qe7+",
            "Kh6",
            "Qf8+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf5+",
            "Kh6",
            "Qf4+",
            "Kh7",
            "Qe4+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qd3+",
            "Kh6",
            "Qd6+",
            "Kh7",
            "Qd7+",
            "Kh6",
            "Qd6+",
            "Kh7",
            "Qd3+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qe7+",
            "Kh6",
            "Qf8+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf5+",
            "Kh6",
            "Qf4+",
            "Kh7",
            "Qe4+",
            "Kh6",
            "Qe3+",
            "Kh7",
            "Qd3+",
            "Kh6",
            "Qd6+",
            "Kh7",
            "Qd7+",
            "Kh6",
            "Qd6+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe4",
          "positional_uci": "d2e4",
          "positional_response": "17. Nxe4 O-O 18. Nc5 Bf5 19. Nxa6 Rb6 20. Nb4 Qb5 21. Nxc6 Qxb2 22. Ne7+ Kh8 23. Nxf5 gxf5 24. Qc5 Rg8 25. Qxf5 Qxd4 26. Rc7 Qh4 27. Rxa7 Rb2 28. g3 Qh6 29. a4 Rb4 30. a5 Rh4 31. Ra6 Rxh2 32. Qxf6+ Qxf6 33. Rxf6 Rh5 34. Ra1 Ra8 35. a6 Kg7 36. Rb6 Rf5 37. a7 Rf7 38. Rba6 h5 39. Kg2 Rb7 40. Kh3 Rb4 41. f4 Rb5 42. Kh4 Rf5 43. R1a5 Rxa5 44. Rxa5 Kg6 45. Ra6+ Kf5 46. Kxh5 Rh8+ 47. Rh6 Ra8 48. Rh7 Kf6 49. g4 Rg8 50. g5+ Kf5 51. Rf7+ Ke6 52. g6 Rh8+ 53. Kg5 Ra8 54. f5+ Ke5 55. g7 Rg8 56. Kg6 Ra8 57. Rf8 Rxa7 58. g8=Q Ra6+ 59. f6 Ra1 60. Re8+ Kf4 61. Qc4+ Kg3 62. Re3+ Kf2 63. Qe2+ Kg1 64. Rg3+ Kh1 65. Qg2# d5 e6 d4",
          "positional_tokens": {
            "prompt_tokens": 242,
            "completion_tokens": 415,
            "total_tokens": 657,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nc5",
            "Bf5",
            "Nxa6",
            "Rb6",
            "Nb4",
            "Qb5",
            "Nxc6",
            "Qxb2",
            "Ne7+",
            "Kh8",
            "Nxf5",
            "gxf5",
            "Qc5",
            "Rg8",
            "Qxf5",
            "Qxd4",
            "Rc7",
            "Qh4",
            "Rxa7",
            "Rb2",
            "g3",
            "Qh6",
            "a4",
            "Rb4",
            "a5",
            "Rh4",
            "Ra6",
            "Rxh2",
            "Qxf6+",
            "Qxf6",
            "Rxf6",
            "Rh5",
            "Ra1",
            "Ra8",
            "a6",
            "Kg7",
            "Rb6",
            "Rf5",
            "a7",
            "Rf7",
            "Rba6",
            "h5",
            "Kg2",
            "Rb7",
            "Kh3",
            "Rb4",
            "f4",
            "Rb5",
            "Kh4",
            "Rf5",
            "R1a5",
            "Rxa5",
            "Rxa5",
            "Kg6",
            "Ra6+",
            "Kf5",
            "Kxh5",
            "Rh8+",
            "Rh6",
            "Ra8",
            "Rh7",
            "Kf6",
            "g4",
            "Rg8",
            "g5+",
            "Kf5",
            "Rf7+",
            "Ke6",
            "g6",
            "Rh8+",
            "Kg5",
            "Ra8",
            "f5+",
            "Ke5",
            "g7",
            "Rg8",
            "Kg6",
            "Ra8",
            "Rf8",
            "Rxa7",
            "g8=Q",
            "Ra6+",
            "f6",
            "Ra1",
            "Re8+",
            "Kf4",
            "Qc4+",
            "Kg3",
            "Re3+",
            "Kf2",
            "Qe2+",
            "Kg1",
            "Rg3+",
            "Kh1",
            "Qg2#",
            "d5",
            "e6",
            "d4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe4",
          "neutral_uci": "d2e4",
          "neutral_response": "17. Nxe4 O-O 18. Nc5 Bf5 19. Nxa6 Rb6 20. Nb4 Qb5 21. Nxc6 Qxb2 22. Ne7+ Kh8\n23. Nxf5 gxf5 24. Qc5 Rg8 25. Qxf5 Qxd4 26. Rc7 Rg7 27. Rc8+ Rg8 28. Rxg8+ Kxg8\n29. Qc8+ Kg7 30. Qc7+ Kg6 31. Qxa7 Qb4 32. Qd7 Rd6 33. Qe8+ Kg7 34. Qe7+ Kg6\n35. Qe3 Qa4 36. Qg3+ Kf7 37. Qxd6 Qxa2 38. Qd7+ Kg6 39. Qg4+ Kf7 40. Rd1 Qa4\n41. Qxa4 Kg6 42. Qg4+ Kf7 43. Rd7+ Ke8 44. Qe6+ Kf8 45. Qf7# d4 e5 Qe6",
          "neutral_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 264,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nc5",
            "Bf5",
            "Nxa6",
            "Rb6",
            "Nb4",
            "Qb5",
            "Nxc6",
            "Qxb2",
            "Ne7+",
            "Kh8",
            "Nxf5",
            "gxf5",
            "Qc5",
            "Rg8",
            "Qxf5",
            "Qxd4",
            "Rc7",
            "Rg7",
            "Rc8+",
            "Rg8",
            "Rxg8+",
            "Kxg8",
            "Qc8+",
            "Kg7",
            "Qc7+",
            "Kg6",
            "Qxa7",
            "Qb4",
            "Qd7",
            "Rd6",
            "Qe8+",
            "Kg7",
            "Qe7+",
            "Kg6",
            "Qe3",
            "Qa4",
            "Qg3+",
            "Kf7",
            "Qxd6",
            "Qxa2",
            "Qd7+",
            "Kg6",
            "Qg4+",
            "Kf7",
            "Rd1",
            "Qa4",
            "Qxa4",
            "Kg6",
            "Qg4+",
            "Kf7",
            "Rd7+",
            "Ke8",
            "Qe6+",
            "Kf8",
            "Qf7#",
            "d4",
            "e5",
            "Qe6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2e4",
          "positional_uci": "d2e4",
          "neutral_uci": "d2e4",
          "consensus_move": "d2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nc5",
              "Bf5",
              "Nxa6",
              "Rb6",
              "Nb4",
              "Qb5",
              "Nxc6",
              "Qxb2",
              "Ne7+",
              "Kh8",
              "Nxf5",
              "gxf5",
              "Qc5",
              "Rg8",
              "Qxf5",
              "Qxd4",
              "Rc7",
              "Rg7",
              "Rc8+",
              "Rg8",
              "Rxg8+",
              "Kxg8",
              "Qc8+",
              "Kg7",
              "Qc7+",
              "Kg6",
              "Qxa7",
              "Qb4",
              "Qd7",
              "Rd6",
              "Qe8+",
              "Kg7",
              "Qe7+",
              "Kg6",
              "Qe3",
              "Qa4",
              "Qg3+",
              "Kf7",
              "Qxd6",
              "Qxa2",
              "Qd7+",
              "Kg6",
              "Qg4+",
              "Kf7",
              "Rd1",
              "Qa5",
              "Rd7+",
              "Ke8",
              "Qe6+",
              "Kf8",
              "Qf7#",
              "d4",
              "Qxd4",
              "Qa1+",
              "Kh2",
              "Qe5+",
              "g3",
              "Qe4+",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe4+",
              "Kh3",
              "Qe6+",
              "g4",
              "Qb3+",
              "Kh4",
              "Qc4+",
              "Kh5",
              "Qe4+",
              "Kh6",
              "Qe6+",
              "Kh7",
              "Qe4+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qe7+",
              "Kh6",
              "Qf8+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qxf6+",
              "Kh7",
              "Qf5+",
              "Kh6",
              "Qf4+",
              "Kh7",
              "Qe4+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qd3+",
              "Kh6",
              "Qd6+",
              "Kh7",
              "Qd7+",
              "Kh6",
              "Qd6+",
              "Kh7",
              "Qd3+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qe7+",
              "Kh6",
              "Qf8+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf5+",
              "Kh6",
              "Qf4+",
              "Kh7",
              "Qe4+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qd3+",
              "Kh6",
              "Qd6+",
              "Kh7",
              "Qd7+",
              "Kh6",
              "Qd6+",
              "Kh7",
              "Qd3+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qe7+",
              "Kh6",
              "Qf8+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf5+",
              "Kh6",
              "Qf4+",
              "Kh7",
              "Qe4+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qd3+",
              "Kh6",
              "Qd6+",
              "Kh7",
              "Qd7+",
              "Kh6",
              "Qd6+",
              "Kh7",
              "Qd3+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qe7+",
              "Kh6",
              "Qf8+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf5+",
              "Kh6",
              "Qf4+",
              "Kh7",
              "Qe4+",
              "Kh6",
              "Qe3+",
              "Kh7",
              "Qd3+",
              "Kh6",
              "Qd6+",
              "Kh7",
              "Qd7+",
              "Kh6",
              "Qd6+",
              "Kh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Nc5",
              "Bf5",
              "Nxa6",
              "Rb6",
              "Nb4",
              "Qb5",
              "Nxc6",
              "Qxb2",
              "Ne7+",
              "Kh8",
              "Nxf5",
              "gxf5",
              "Qc5",
              "Rg8",
              "Qxf5",
              "Qxd4",
              "Rc7",
              "Qh4",
              "Rxa7",
              "Rb2",
              "g3",
              "Qh6",
              "a4",
              "Rb4",
              "a5",
              "Rh4",
              "Ra6",
              "Rxh2",
              "Qxf6+",
              "Qxf6",
              "Rxf6",
              "Rh5",
              "Ra1",
              "Ra8",
              "a6",
              "Kg7",
              "Rb6",
              "Rf5",
              "a7",
              "Rf7",
              "Rba6",
              "h5",
              "Kg2",
              "Rb7",
              "Kh3",
              "Rb4",
              "f4",
              "Rb5",
              "Kh4",
              "Rf5",
              "R1a5",
              "Rxa5",
              "Rxa5",
              "Kg6",
              "Ra6+",
              "Kf5",
              "Kxh5",
              "Rh8+",
              "Rh6",
              "Ra8",
              "Rh7",
              "Kf6",
              "g4",
              "Rg8",
              "g5+",
              "Kf5",
              "Rf7+",
              "Ke6",
              "g6",
              "Rh8+",
              "Kg5",
              "Ra8",
              "f5+",
              "Ke5",
              "g7",
              "Rg8",
              "Kg6",
              "Ra8",
              "Rf8",
              "Rxa7",
              "g8=Q",
              "Ra6+",
              "f6",
              "Ra1",
              "Re8+",
              "Kf4",
              "Qc4+",
              "Kg3",
              "Re3+",
              "Kf2",
              "Qe2+",
              "Kg1",
              "Rg3+",
              "Kh1",
              "Qg2#",
              "d5",
              "e6",
              "d4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Nc5",
              "Bf5",
              "Nxa6",
              "Rb6",
              "Nb4",
              "Qb5",
              "Nxc6",
              "Qxb2",
              "Ne7+",
              "Kh8",
              "Nxf5",
              "gxf5",
              "Qc5",
              "Rg8",
              "Qxf5",
              "Qxd4",
              "Rc7",
              "Rg7",
              "Rc8+",
              "Rg8",
              "Rxg8+",
              "Kxg8",
              "Qc8+",
              "Kg7",
              "Qc7+",
              "Kg6",
              "Qxa7",
              "Qb4",
              "Qd7",
              "Rd6",
              "Qe8+",
              "Kg7",
              "Qe7+",
              "Kg6",
              "Qe3",
              "Qa4",
              "Qg3+",
              "Kf7",
              "Qxd6",
              "Qxa2",
              "Qd7+",
              "Kg6",
              "Qg4+",
              "Kf7",
              "Rd1",
              "Qa4",
              "Qxa4",
              "Kg6",
              "Qg4+",
              "Kf7",
              "Rd7+",
              "Ke8",
              "Qe6+",
              "Kf8",
              "Qf7#",
              "d4",
              "e5",
              "Qe6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 242,
            "completion_tokens": 640,
            "total_tokens": 882,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 242,
            "completion_tokens": 415,
            "total_tokens": 657,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 241,
            "completion_tokens": 264,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 725,
          "total_completion_tokens": 1319,
          "total_tokens": 2044
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 242,
            "completion_tokens": 640,
            "total_tokens": 882,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 242,
            "completion_tokens": 415,
            "total_tokens": 657,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 241,
            "completion_tokens": 264,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1r2k2r/p2b3p/p1p2pp1/3q4/3Pp3/2Q5/PP1N1PPP/2R2RK1 w k - 0 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc5",
          "aggressive_uci": "e4c5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Bf5 19. Nxa6 Rb6 20.\nNc5 Qxa2 21. b3 Rfb8 22. Ra1 Qc2 23. Qxc2 Bxc2 24. Nd7 Rxb3 25. Nxb8 Rxb8 26.\nRxa7 Rd8 27. Rc1 Be4 28. f3 Bd5 29. Rb1 Bf7 30. Rbb7 Rf8 31. Rc7 Kg7 32. Rxc6\nKh6 33. Rxf6 Kg7 34. Rfxf7+ Rxf7 35. Rxf7+ Kxf7 36. Kf2 Ke6 37. Ke3 Kd5 38.\nKd3 h6 39. f4 h5 40. h4 Ke6 41. Ke4 Kd6 42. d5 Ke7 43. Ke5 Kd7 44. d6 Ke8 45.\nKe6 Kd8 46. d7 Kc7 47. Ke7 Kc6 48. d8=Q Kc5 49. Qd3 Kb4 50. Qc2 Kb5 51. Qc3\nKb6 52. Qc4 Kb7 53. Qc5 Ka6 54. Qb4 Ka7 55. Kd7 Ka6 56. Kc7 Ka7 57. Qa5# 1-0\nKg8 Kf8 Kg7",
          "aggressive_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 483,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxa2",
            "b3",
            "Rfb8",
            "Ra1",
            "Qc2",
            "Qxc2",
            "Bxc2",
            "Nd7",
            "Rxb3",
            "Nxb8",
            "Rxb8",
            "Rxa7",
            "Rd8",
            "Rc1",
            "Be4",
            "f3",
            "Bd5",
            "Rb1",
            "Bf7",
            "Rbb7",
            "Rf8",
            "Rc7",
            "Kg7",
            "Rxc6",
            "Kh6",
            "Rxf6",
            "Kg7",
            "Rfxf7+",
            "Rxf7",
            "Rxf7+",
            "Kxf7",
            "Kf2",
            "Ke6",
            "Ke3",
            "Kd5",
            "Kd3",
            "h6",
            "f4",
            "h5",
            "h4",
            "Ke6",
            "Ke4",
            "Kd6",
            "d5",
            "Ke7",
            "Ke5",
            "Kd7",
            "d6",
            "Ke8",
            "Ke6",
            "Kd8",
            "d7",
            "Kc7",
            "Ke7",
            "Kc6",
            "d8=Q",
            "Kc5",
            "Qd3",
            "Kb4",
            "Qc2",
            "Kb5",
            "Qc3",
            "Kb6",
            "Qc4",
            "Kb7",
            "Qc5",
            "Ka6",
            "Qb4",
            "Ka7",
            "Kd7",
            "Ka6",
            "Kc7",
            "Ka7",
            "Qa5#",
            "Kg8",
            "Kf8",
            "Kg7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc5",
          "positional_uci": "e4c5",
          "positional_response": "18. Nc5 Bf5 19. Nxa6 Rb6 20. Nb4 Qb5 21. Nxc6 Qxb2 22. Ne7+ Kg7 23. Nxf5+ gxf5\n24. Qg3+ Kh8 25. Rc7 Rg8 26. Qh4 Rg7 27. Rc8+ Rg8 28. Rxg8+ Kxg8 29. Re1 Qb1\n30. f3 Qxa2 31. Qg3+ Kf7 32. Qc7+ Kg6 33. h4 Rb1 34. Qg3+ Kf7 35. Rxb1 Qxb1+\n36. Kh2 Qb6 37. Qf4 Kg6 38. h5+ Kxh5 39. Qxf5+ Kh6 40. d5 Qd6+ 41. Kh3 Kg7\n42. Qg4+ Kf7 43. Qh5+ Kg7 44. Qg4+ Kf7 45. Qh5+ Kg7 46. Qg4+ Kf7 47. Qh5+ Kg7\n48. Qg4+ Kf7 49. Qh5+ Kg7 50. Qg4+ Kf7 51. Qh5+ Kg7 52. Qg4+ Kf7 53. Qh5+ Kg7\n54. Qg4+ Kf7 55. Qh5+ Kg7 56. Qg4+ Kf7 57. Qh5+ Kg7 58. Qg4+ Kf7 59. Qh5+ Kg7\n60. Qg4+ Kf7 61. Qh5+ Kg7 62. Qg4+ Kf7 63. Qh5+ Kg7 64. Qg4+ Kf7 65. Qh5+ Kg7\n66. Qg4+ Kf7 67. Qh5+ Kg7 68. Qg4+ Kf7 69. Qh5+ Kg7 70. Qg4+ Kf7 71. Qh5+ Kg7\n72. Qg4+ Kf7 73. Qh5+ Kg7 74. Qg4+ Kf7 75. Qh5+ Kg7 76. Qg4+ Kf7 77. Qh5+ Kg7\n78. Qg4+ Kf7 79. Qh5+ Kg7 80. Qg4+ Kf7 81. Qh5+ Kg7 82. Qg4+ Kf7 83. Qh5+ Kg7\n84. Qg4+ Kf7 85. Qh5+ Kg7 86. Qg4+ Kf7",
          "positional_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bf5",
            "Nxa6",
            "Rb6",
            "Nb4",
            "Qb5",
            "Nxc6",
            "Qxb2",
            "Ne7+",
            "Kg7",
            "Nxf5+",
            "gxf5",
            "Qg3+",
            "Kh8",
            "Rc7",
            "Rg8",
            "Qh4",
            "Rg7",
            "Rc8+",
            "Rg8",
            "Rxg8+",
            "Kxg8",
            "Re1",
            "Qb1",
            "f3",
            "Qxa2",
            "Qg3+",
            "Kf7",
            "Qc7+",
            "Kg6",
            "h4",
            "Rb1",
            "Qg3+",
            "Kf7",
            "Rxb1",
            "Qxb1+",
            "Kh2",
            "Qb6",
            "Qf4",
            "Kg6",
            "h5+",
            "Kxh5",
            "Qxf5+",
            "Kh6",
            "d5",
            "Qd6+",
            "Kh3",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7",
            "Qh5+",
            "Kg7",
            "Qg4+",
            "Kf7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxf6+",
          "neutral_uci": "e4f6",
          "neutral_response": "18. Nxf6+ Rxf6 19. Qxf6 Rf8 20. Qe5 Qxa2 21. Ra1 Qxb2 22. Rxa6 Qb7 23. Rfa1\nRa8 24. Qc5 Qb2 25. Rxa7 Rxa7 26. Qxa7 Be6 27. Qa8+ Kg7 28. Ra7+ Kh6 29. Qf8+ Kg5\n30. h4+ Kg4 31. Qf3+ Kxh4 32. Rxh7+ Kg5 33. Qe3+ Kf6 34. Qe5# dxe4 Qf4+ Kg5\nQe5+ Kh6 Qh8+ Kg5 Qh4# d4 Qf4+ Kg5 Qe5+ Kh6 Qh8+ Kg5 Qh4#",
          "neutral_tokens": {
            "prompt_tokens": 249,
            "completion_tokens": 201,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf6",
            "Qxf6",
            "Rf8",
            "Qe5",
            "Qxa2",
            "Ra1",
            "Qxb2",
            "Rxa6",
            "Qb7",
            "Rfa1",
            "Ra8",
            "Qc5",
            "Qb2",
            "Rxa7",
            "Rxa7",
            "Qxa7",
            "Be6",
            "Qa8+",
            "Kg7",
            "Ra7+",
            "Kh6",
            "Qf8+",
            "Kg5",
            "h4+",
            "Kg4",
            "Qf3+",
            "Kxh4",
            "Rxh7+",
            "Kg5",
            "Qe3+",
            "Kf6",
            "Qe5#",
            "dxe4",
            "Qf4+",
            "Kg5",
            "Qe5+",
            "Kh6",
            "Qh8+",
            "Kg5",
            "Qh4#",
            "d4",
            "Qf4+",
            "Kg5",
            "Qe5+",
            "Kh6",
            "Qh8+",
            "Kg5",
            "Qh4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4c5",
          "positional_uci": "e4c5",
          "neutral_uci": "e4f6",
          "consensus_move": "e4c5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxa2",
              "b3",
              "Rfb8",
              "Ra1",
              "Qc2",
              "Qxc2",
              "Bxc2",
              "Nd7",
              "Rxb3",
              "Nxb8",
              "Rxb8",
              "Rxa7",
              "Rd8",
              "Rc1",
              "Be4",
              "f3",
              "Bd5",
              "Rb1",
              "Bf7",
              "Rbb7",
              "Rf8",
              "Rc7",
              "Kg7",
              "Rxc6",
              "Kh6",
              "Rxf6",
              "Kg7",
              "Rfxf7+",
              "Rxf7",
              "Rxf7+",
              "Kxf7",
              "Kf2",
              "Ke6",
              "Ke3",
              "Kd5",
              "Kd3",
              "h6",
              "f4",
              "h5",
              "h4",
              "Ke6",
              "Ke4",
              "Kd6",
              "d5",
              "Ke7",
              "Ke5",
              "Kd7",
              "d6",
              "Ke8",
              "Ke6",
              "Kd8",
              "d7",
              "Kc7",
              "Ke7",
              "Kc6",
              "d8=Q",
              "Kc5",
              "Qd3",
              "Kb4",
              "Qc2",
              "Kb5",
              "Qc3",
              "Kb6",
              "Qc4",
              "Kb7",
              "Qc5",
              "Ka6",
              "Qb4",
              "Ka7",
              "Kd7",
              "Ka6",
              "Kc7",
              "Ka7",
              "Qa5#",
              "Kg8",
              "Kf8",
              "Kg7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bf5",
              "Nxa6",
              "Rb6",
              "Nb4",
              "Qb5",
              "Nxc6",
              "Qxb2",
              "Ne7+",
              "Kg7",
              "Nxf5+",
              "gxf5",
              "Qg3+",
              "Kh8",
              "Rc7",
              "Rg8",
              "Qh4",
              "Rg7",
              "Rc8+",
              "Rg8",
              "Rxg8+",
              "Kxg8",
              "Re1",
              "Qb1",
              "f3",
              "Qxa2",
              "Qg3+",
              "Kf7",
              "Qc7+",
              "Kg6",
              "h4",
              "Rb1",
              "Qg3+",
              "Kf7",
              "Rxb1",
              "Qxb1+",
              "Kh2",
              "Qb6",
              "Qf4",
              "Kg6",
              "h5+",
              "Kxh5",
              "Qxf5+",
              "Kh6",
              "d5",
              "Qd6+",
              "Kh3",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7",
              "Qh5+",
              "Kg7",
              "Qg4+",
              "Kf7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxf6",
              "Qxf6",
              "Rf8",
              "Qe5",
              "Qxa2",
              "Ra1",
              "Qxb2",
              "Rxa6",
              "Qb7",
              "Rfa1",
              "Ra8",
              "Qc5",
              "Qb2",
              "Rxa7",
              "Rxa7",
              "Qxa7",
              "Be6",
              "Qa8+",
              "Kg7",
              "Ra7+",
              "Kh6",
              "Qf8+",
              "Kg5",
              "h4+",
              "Kg4",
              "Qf3+",
              "Kxh4",
              "Rxh7+",
              "Kg5",
              "Qe3+",
              "Kf6",
              "Qe5#",
              "dxe4",
              "Qf4+",
              "Kg5",
              "Qe5+",
              "Kh6",
              "Qh8+",
              "Kg5",
              "Qh4#",
              "d4",
              "Qf4+",
              "Kg5",
              "Qe5+",
              "Kh6",
              "Qh8+",
              "Kg5",
              "Qh4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 250,
            "completion_tokens": 483,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 249,
            "completion_tokens": 201,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 749,
          "total_completion_tokens": 1324,
          "total_tokens": 2073
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 250,
            "completion_tokens": 483,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 249,
            "completion_tokens": 201,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1r3rk1/p2b3p/p1p2pp1/3q4/3PN3/2Q5/PP3PPP/2R2RK1 w - - 1 18"
    },
    {
      "turn": 37,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa6",
          "aggressive_uci": "c5a6",
          "aggressive_response": "19. Nxa6 Rb6 20. Nc5 Bf5 21. Rfe1 Kg7 22. b3 h5 23. Re8 h4 24. h3 g5 25. Rce1\ng4 26. hxg4 Bxg4 27. R1e4 f5 28. R4e5 Qd6 29. Ne6+ Kh7 30. Ng5+ Kg7 31. Nxf7\nKxf7 32. Qc4+ Kg7 33. Qg8+ Kh6 34. Qh8+ Kg5 35. Rg8+ Kf4 36. Qxh4 Qxd4 37.\nQg3# Qd1+ 38. Kh2 Qd6 39. Qf4# Qh6+ 40. Kg1 Qd6 41. g3# Qd1+ 42. Kh2 Qd6 43.\nQe3# Qh6+ 44. Kg1 Qd6 45. Qxf4# Qd1+ 46. Kh2 Qd6 47. Qe3# Qh6+ 48. Kg1 Qd6\n49. Qxf4# Qd1+ 50. Kh2 Qd6 51. Qe3# Qh6+ 52. Kg1 Qd6 53. Qxf4# Qd1+ 54.\nKh2 Qd6 55. Qe3# Qh6+ 56. Kg1 Qd6 57. Qxf4# Qd1+ 58. Kh2 Qd6 59. Qe3# Qh6+\n60. Kg1 Qd6 61. Qxf4# Qd1+ 62. Kh2 Qd6 63. Qe3# Qh6+ 64. Kg1 Qd6 65. Qxf4# Qd1+ 66. Kh2 Qd6 67. Qe3# Qh6+ 68. Kg1 Qd6 69. Qxf4# Qd1+ 70. Kh2 Qd6 71. Qe3# Qh6+ 72. Kg1 Qd6 73. Qxf4# Qd1+ 74. Kh2 Qd6 75. Qe3# Qh6+ 76. Kg1 Qd6 77. Qxf4# Qd1+ 78. Kh2 Qd6 79. Qe3# Qh6+ 80. Kg1 Qd6 81. Qxf4# Qd1+ 82. Kh2 Qd6 83. Qe3# Qh6+ 84. Kg1 Qd6 85. Qxf4# Qd1+ 86. Kh2 Qd6 87. Qe3# Qh",
          "aggressive_tokens": {
            "prompt_tokens": 259,
            "completion_tokens": 640,
            "total_tokens": 899,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rb6",
            "Nc5",
            "Bf5",
            "Rfe1",
            "Kg7",
            "b3",
            "h5",
            "Re8",
            "h4",
            "h3",
            "g5",
            "Rce1",
            "g4",
            "hxg4",
            "Bxg4",
            "R1e4",
            "f5",
            "R4e5",
            "Qd6",
            "Ne6+",
            "Kh7",
            "Ng5+",
            "Kg7",
            "Nxf7",
            "Kxf7",
            "Qc4+",
            "Kg7",
            "Qg8+",
            "Kh6",
            "Qh8+",
            "Kg5",
            "Rg8+",
            "Kf4",
            "Qxh4",
            "Qxd4",
            "Qg3#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qf4#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "g3#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#",
            "Qh6+",
            "Kg1",
            "Qd6",
            "Qxf4#",
            "Qd1+",
            "Kh2",
            "Qd6",
            "Qe3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxa6",
          "positional_uci": "c5a6",
          "positional_response": "19. Nxa6 Rb6 20. Nc5 Qxa2 21. Ra1 Qxb2 22. Qxb2 Rxb2 23. Rxa7 Be8 24. Ra8 Re7 25. h3 Kf7 26. Rfa1 Rd2 27. R1a4 g5 28. Rb8 Kg6 29. Rb7 Re1+ 30. Kh2 Rxf2 31. Raa7 Ree2 32. Rg7+ Kf5 33. Rae7 Rxg2+ 34. Kh1 Rh2+ 35. Kg1 Reg2+ 36. Kf1 Bh5 37. Rxh7 Be2+ 38. Ke1 Bc4 39. Kd1 Rg1+ 40. Re1 Be2+ 41. Kd2 Bf3+ 42. Ke3 Rxe1+ 43. Kxf3 Kg6 44. Rc7 Rxh3+ 45. Kf2 Rd1 46. Rxc6 Rxd4 47. Ne6 Rd2+ 48. Ke1 Ra2 49. Nf8+ Kf7 50. Rc7+ Kxf8 51. Rc8+ Kg7 52. Rc7+ Kg6 53. Rc2 Rxc2 54. Kd1 Rg2 55. Ke1 Rh1#",
          "positional_tokens": {
            "prompt_tokens": 259,
            "completion_tokens": 314,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb6",
            "Nc5",
            "Qxa2",
            "Ra1",
            "Qxb2",
            "Qxb2",
            "Rxb2",
            "Rxa7",
            "Be8",
            "Ra8",
            "Re7",
            "h3",
            "Kf7",
            "Rfa1",
            "Rd2",
            "R1a4",
            "g5",
            "Rb8",
            "Kg6",
            "Rb7",
            "Re1+",
            "Kh2",
            "Rxf2",
            "Raa7",
            "Ree2",
            "Rg7+",
            "Kf5",
            "Rae7",
            "Rxg2+",
            "Kh1",
            "Rh2+",
            "Kg1",
            "Reg2+",
            "Kf1",
            "Bh5",
            "Rxh7",
            "Be2+",
            "Ke1",
            "Bc4",
            "Kd1",
            "Rg1+",
            "Re1",
            "Be2+",
            "Kd2",
            "Bf3+",
            "Ke3",
            "Rxe1+",
            "Kxf3",
            "Kg6",
            "Rc7",
            "Rxh3+",
            "Kf2",
            "Rd1",
            "Rxc6",
            "Rxd4",
            "Ne6",
            "Rd2+",
            "Ke1",
            "Ra2",
            "Nf8+",
            "Kf7",
            "Rc7+",
            "Kxf8",
            "Rc8+",
            "Kg7",
            "Rc7+",
            "Kg6",
            "Rc2",
            "Rxc2",
            "Kd1",
            "Rg2",
            "Ke1",
            "Rh1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxa6",
          "neutral_uci": "c5a6",
          "neutral_response": "19. Nxa6 Rb6 20. Nc5 Bf5 21. Rfe1 Kg7 22. b3 h5 23. Re8 h4 24. h3 g5 25. Rce1\ng4 26. hxg4 Bxg4 27. Qe3 h3 28. Qg3 Qxg2+ 29. Qxg2 hxg2 30. Kxg2 Rb4 31.\nRd8 Kg6 32. Kg3 Bf5 33. Kf4 Rb5 34. Rg1+ Kh7 35. Kxf5 Rxc5+ 36. dxc5 Re7 37.\nRd3 Re5+ 38. Kxf6 Rh5 39. Rd7+ Kh8 40. Rd8+ Kh7 41. Rg7+ Kh6 42. Rh8# Rf7\n43. Rxf7 Kh5 44. Rg7 Kh6 45. Rh8# Rf7 46. Rxf7 Kh5 47. Rg7 Kh6 48. Rh8# Rf7",
          "neutral_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 258,
            "total_tokens": 516,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb6",
            "Nc5",
            "Bf5",
            "Rfe1",
            "Kg7",
            "b3",
            "h5",
            "Re8",
            "h4",
            "h3",
            "g5",
            "Rce1",
            "g4",
            "hxg4",
            "Bxg4",
            "Qe3",
            "h3",
            "Qg3",
            "Qxg2+",
            "Qxg2",
            "hxg2",
            "Kxg2",
            "Rb4",
            "Rd8",
            "Kg6",
            "Kg3",
            "Bf5",
            "Kf4",
            "Rb5",
            "Rg1+",
            "Kh7",
            "Kxf5",
            "Rxc5+",
            "dxc5",
            "Re7",
            "Rd3",
            "Re5+",
            "Kxf6",
            "Rh5",
            "Rd7+",
            "Kh8",
            "Rd8+",
            "Kh7",
            "Rg7+",
            "Kh6",
            "Rh8#",
            "Rf7",
            "Rxf7",
            "Kh5",
            "Rg7",
            "Kh6",
            "Rh8#",
            "Rf7",
            "Rxf7",
            "Kh5",
            "Rg7",
            "Kh6",
            "Rh8#",
            "Rf7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5a6",
          "positional_uci": "c5a6",
          "neutral_uci": "c5a6",
          "consensus_move": "c5a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rb6",
              "Nc5",
              "Bf5",
              "Rfe1",
              "Kg7",
              "b3",
              "h5",
              "Re8",
              "h4",
              "h3",
              "g5",
              "Rce1",
              "g4",
              "hxg4",
              "Bxg4",
              "R1e4",
              "f5",
              "R4e5",
              "Qd6",
              "Ne6+",
              "Kh7",
              "Ng5+",
              "Kg7",
              "Nxf7",
              "Kxf7",
              "Qc4+",
              "Kg7",
              "Qg8+",
              "Kh6",
              "Qh8+",
              "Kg5",
              "Rg8+",
              "Kf4",
              "Qxh4",
              "Qxd4",
              "Qg3#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qf4#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "g3#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#",
              "Qh6+",
              "Kg1",
              "Qd6",
              "Qxf4#",
              "Qd1+",
              "Kh2",
              "Qd6",
              "Qe3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rb6",
              "Nc5",
              "Qxa2",
              "Ra1",
              "Qxb2",
              "Qxb2",
              "Rxb2",
              "Rxa7",
              "Be8",
              "Ra8",
              "Re7",
              "h3",
              "Kf7",
              "Rfa1",
              "Rd2",
              "R1a4",
              "g5",
              "Rb8",
              "Kg6",
              "Rb7",
              "Re1+",
              "Kh2",
              "Rxf2",
              "Raa7",
              "Ree2",
              "Rg7+",
              "Kf5",
              "Rae7",
              "Rxg2+",
              "Kh1",
              "Rh2+",
              "Kg1",
              "Reg2+",
              "Kf1",
              "Bh5",
              "Rxh7",
              "Be2+",
              "Ke1",
              "Bc4",
              "Kd1",
              "Rg1+",
              "Re1",
              "Be2+",
              "Kd2",
              "Bf3+",
              "Ke3",
              "Rxe1+",
              "Kxf3",
              "Kg6",
              "Rc7",
              "Rxh3+",
              "Kf2",
              "Rd1",
              "Rxc6",
              "Rxd4",
              "Ne6",
              "Rd2+",
              "Ke1",
              "Ra2",
              "Nf8+",
              "Kf7",
              "Rc7+",
              "Kxf8",
              "Rc8+",
              "Kg7",
              "Rc7+",
              "Kg6",
              "Rc2",
              "Rxc2",
              "Kd1",
              "Rg2",
              "Ke1",
              "Rh1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rb6",
              "Nc5",
              "Bf5",
              "Rfe1",
              "Kg7",
              "b3",
              "h5",
              "Re8",
              "h4",
              "h3",
              "g5",
              "Rce1",
              "g4",
              "hxg4",
              "Bxg4",
              "Qe3",
              "h3",
              "Qg3",
              "Qxg2+",
              "Qxg2",
              "hxg2",
              "Kxg2",
              "Rb4",
              "Rd8",
              "Kg6",
              "Kg3",
              "Bf5",
              "Kf4",
              "Rb5",
              "Rg1+",
              "Kh7",
              "Kxf5",
              "Rxc5+",
              "dxc5",
              "Re7",
              "Rd3",
              "Re5+",
              "Kxf6",
              "Rh5",
              "Rd7+",
              "Kh8",
              "Rd8+",
              "Kh7",
              "Rg7+",
              "Kh6",
              "Rh8#",
              "Rf7",
              "Rxf7",
              "Kh5",
              "Rg7",
              "Kh6",
              "Rh8#",
              "Rf7",
              "Rxf7",
              "Kh5",
              "Rg7",
              "Kh6",
              "Rh8#",
              "Rf7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 259,
            "completion_tokens": 640,
            "total_tokens": 899,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 259,
            "completion_tokens": 314,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 258,
            "completion_tokens": 258,
            "total_tokens": 516,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 776,
          "total_completion_tokens": 1212,
          "total_tokens": 1988
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 259,
            "completion_tokens": 640,
            "total_tokens": 899,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 259,
            "completion_tokens": 314,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 258,
            "completion_tokens": 258,
            "total_tokens": 516,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1r4k1/p2b1r1p/p1p2pp1/2Nq4/3P4/2Q5/PP3PPP/2R2RK1 w - - 3 19"
    },
    {
      "turn": 39,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc7",
          "aggressive_uci": "a6c7",
          "aggressive_response": "20. Nc7 Qxa2 21. Ra1 Qxb2 22. Qxb2 Rxb2 23. Rxa7 Bf5 24. Ra8+ Kg7 25. Ne8+ Kh6\n26. Nd6 Rd7 27. Nxf5+ gxf5 28. Rc8 Rxd4 29. Rxc6 Kg6 30. g3 f4 31. Kg2 fxg3\n32. hxg3 Rdd2 33. Rc4 h5 34. Rf4 Kg5 35. Rh1 f5 36. Rhh4 Rb1 37. Rb4 Rxb4\n38. Rxb4 Rd5 39. Kh3 Rd2 40. f4+ Kg6 41. Rb6+ Kg7 42. Kh4 Rh2+ 43. Kg5 Rh3\n44. Rb7+ Kf8 45. Kf6 Ke8 46. Rg7 h4 47. gxh4 Rxh4 48. Kxf5 Kf8 49. Rg4 Rh5+\n50. Kg6 Rh8 51. f5 Rg8+ 52. Kh5 Rxg4 53. Kxg4 Kf7 54. Kg5 Kg7 55. f6+ Kf7\n56. Kf5 Kf8 57. Ke6 Ke8 58. f7+ Kf8 59. Kf6 *",
          "aggressive_tokens": {
            "prompt_tokens": 268,
            "completion_tokens": 329,
            "total_tokens": 597,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxa2",
            "Ra1",
            "Qxb2",
            "Qxb2",
            "Rxb2",
            "Rxa7",
            "Bf5",
            "Ra8+",
            "Kg7",
            "Ne8+",
            "Kh6",
            "Nd6",
            "Rd7",
            "Nxf5+",
            "gxf5",
            "Rc8",
            "Rxd4",
            "Rxc6",
            "Kg6",
            "g3",
            "f4",
            "Kg2",
            "fxg3",
            "hxg3",
            "Rdd2",
            "Rc4",
            "h5",
            "Rf4",
            "Kg5",
            "Rh1",
            "f5",
            "Rhh4",
            "Rb1",
            "Rb4",
            "Rxb4",
            "Rxb4",
            "Rd5",
            "Kh3",
            "Rd2",
            "f4+",
            "Kg6",
            "Rb6+",
            "Kg7",
            "Kh4",
            "Rh2+",
            "Kg5",
            "Rh3",
            "Rb7+",
            "Kf8",
            "Kf6",
            "Ke8",
            "Rg7",
            "h4",
            "gxh4",
            "Rxh4",
            "Kxf5",
            "Kf8",
            "Rg4",
            "Rh5+",
            "Kg6",
            "Rh8",
            "f5",
            "Rg8+",
            "Kh5",
            "Rxg4",
            "Kxg4",
            "Kf7",
            "Kg5",
            "Kg7",
            "f6+",
            "Kf7",
            "Kf5",
            "Kf8",
            "Ke6",
            "Ke8",
            "f7+",
            "Kf8",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc7",
          "positional_uci": "a6c7",
          "positional_response": "20. Nc7 Qxa2 21. Ra1 Qxb2 22. Qxb2 Rxb2 23. Rxa7 Bf5 24. Ra8+ Kg7 25. Ne8+ Kh6 26. Nd6 Rd7 27. Nxf5+ gxf5 28. Rc8 Rxd4 29. Rxc6 Kg6 30. g3 f4 31. Kg2 fxg3 32. hxg3 Rdd2 33. Rc3 h5 34. Rf3 f5 35. Ra1 Kg5 36. Ra5 Kg6 37. Raxf5 Rd6 38. Rf8 Kg7 39. R3f7+ Kg6 40. Rf4 Kg7 41. R8f5 Kg6 42. Kh3 Rb1 43. Kg2 Rb2 44. Rf8 Kg7 45. R8f7+ Kg6 46. Rf8 Kg7 47. R8f5 Kg6 48. Ra5 Rf6 49. Rxf6+ Kxf6 50. Rxh5 Kg6 51. Ra5 Kf6 52. g4 Kg6 53. Kg3 Rb3+ 54. f3 Rb1 55. Ra6+ Kg5 56. f4#",
          "positional_tokens": {
            "prompt_tokens": 268,
            "completion_tokens": 304,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxa2",
            "Ra1",
            "Qxb2",
            "Qxb2",
            "Rxb2",
            "Rxa7",
            "Bf5",
            "Ra8+",
            "Kg7",
            "Ne8+",
            "Kh6",
            "Nd6",
            "Rd7",
            "Nxf5+",
            "gxf5",
            "Rc8",
            "Rxd4",
            "Rxc6",
            "Kg6",
            "g3",
            "f4",
            "Kg2",
            "fxg3",
            "hxg3",
            "Rdd2",
            "Rc3",
            "h5",
            "Rf3",
            "f5",
            "Ra1",
            "Kg5",
            "Ra5",
            "Kg6",
            "Raxf5",
            "Rd6",
            "Rf8",
            "Kg7",
            "R3f7+",
            "Kg6",
            "Rf4",
            "Kg7",
            "R8f5",
            "Kg6",
            "Kh3",
            "Rb1",
            "Kg2",
            "Rb2",
            "Rf8",
            "Kg7",
            "R8f7+",
            "Kg6",
            "Rf8",
            "Kg7",
            "R8f5",
            "Kg6",
            "Ra5",
            "Rf6",
            "Rxf6+",
            "Kxf6",
            "Rxh5",
            "Kg6",
            "Ra5",
            "Kf6",
            "g4",
            "Kg6",
            "Kg3",
            "Rb3+",
            "f3",
            "Rb1",
            "Ra6+",
            "Kg5",
            "f4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc7",
          "neutral_uci": "a6c7",
          "neutral_response": "20. Nc7 Qxa2 21. Ra1 Qxb2 22. Qxb2 Rxb2 23. Rxa7 Bf5 24. Ra8+ Kg7 25. Ne8+ Kh6\n26. Nd6 Rd7 27. Nxf5+ gxf5 28. Rc8 Rxd4 29. Rxc6 Kg6 30. g3 Rdd2 31. Rc4 h5\n32. h4 Rdc2 33. Rxc2 Rxc2 34. Kg2 f4 35. gxf4 Kf5 36. Kg3 Rc3+ 37. f3 Rc4\n38. Ra1 Rxf4 39. Ra5+ *",
          "neutral_tokens": {
            "prompt_tokens": 267,
            "completion_tokens": 162,
            "total_tokens": 429,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxa2",
            "Ra1",
            "Qxb2",
            "Qxb2",
            "Rxb2",
            "Rxa7",
            "Bf5",
            "Ra8+",
            "Kg7",
            "Ne8+",
            "Kh6",
            "Nd6",
            "Rd7",
            "Nxf5+",
            "gxf5",
            "Rc8",
            "Rxd4",
            "Rxc6",
            "Kg6",
            "g3",
            "Rdd2",
            "Rc4",
            "h5",
            "h4",
            "Rdc2",
            "Rxc2",
            "Rxc2",
            "Kg2",
            "f4",
            "gxf4",
            "Kf5",
            "Kg3",
            "Rc3+",
            "f3",
            "Rc4",
            "Ra1",
            "Rxf4",
            "Ra5+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a6c7",
          "positional_uci": "a6c7",
          "neutral_uci": "a6c7",
          "consensus_move": "a6c7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxa2",
              "Ra1",
              "Qxb2",
              "Qxb2",
              "Rxb2",
              "Rxa7",
              "Bf5",
              "Ra8+",
              "Kg7",
              "Ne8+",
              "Kh6",
              "Nd6",
              "Rd7",
              "Nxf5+",
              "gxf5",
              "Rc8",
              "Rxd4",
              "Rxc6",
              "Kg6",
              "g3",
              "f4",
              "Kg2",
              "fxg3",
              "hxg3",
              "Rdd2",
              "Rc4",
              "h5",
              "Rf4",
              "Kg5",
              "Rh1",
              "f5",
              "Rhh4",
              "Rb1",
              "Rb4",
              "Rxb4",
              "Rxb4",
              "Rd5",
              "Kh3",
              "Rd2",
              "f4+",
              "Kg6",
              "Rb6+",
              "Kg7",
              "Kh4",
              "Rh2+",
              "Kg5",
              "Rh3",
              "Rb7+",
              "Kf8",
              "Kf6",
              "Ke8",
              "Rg7",
              "h4",
              "gxh4",
              "Rxh4",
              "Kxf5",
              "Kf8",
              "Rg4",
              "Rh5+",
              "Kg6",
              "Rh8",
              "f5",
              "Rg8+",
              "Kh5",
              "Rxg4",
              "Kxg4",
              "Kf7",
              "Kg5",
              "Kg7",
              "f6+",
              "Kf7",
              "Kf5",
              "Kf8",
              "Ke6",
              "Ke8",
              "f7+",
              "Kf8",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxa2",
              "Ra1",
              "Qxb2",
              "Qxb2",
              "Rxb2",
              "Rxa7",
              "Bf5",
              "Ra8+",
              "Kg7",
              "Ne8+",
              "Kh6",
              "Nd6",
              "Rd7",
              "Nxf5+",
              "gxf5",
              "Rc8",
              "Rxd4",
              "Rxc6",
              "Kg6",
              "g3",
              "f4",
              "Kg2",
              "fxg3",
              "hxg3",
              "Rdd2",
              "Rc3",
              "h5",
              "Rf3",
              "f5",
              "Ra1",
              "Kg5",
              "Ra5",
              "Kg6",
              "Raxf5",
              "Rd6",
              "Rf8",
              "Kg7",
              "R3f7+",
              "Kg6",
              "Rf4",
              "Kg7",
              "R8f5",
              "Kg6",
              "Kh3",
              "Rb1",
              "Kg2",
              "Rb2",
              "Rf8",
              "Kg7",
              "R8f7+",
              "Kg6",
              "Rf8",
              "Kg7",
              "R8f5",
              "Kg6",
              "Ra5",
              "Rf6",
              "Rxf6+",
              "Kxf6",
              "Rxh5",
              "Kg6",
              "Ra5",
              "Kf6",
              "g4",
              "Kg6",
              "Kg3",
              "Rb3+",
              "f3",
              "Rb1",
              "Ra6+",
              "Kg5",
              "f4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxa2",
              "Ra1",
              "Qxb2",
              "Qxb2",
              "Rxb2",
              "Rxa7",
              "Bf5",
              "Ra8+",
              "Kg7",
              "Ne8+",
              "Kh6",
              "Nd6",
              "Rd7",
              "Nxf5+",
              "gxf5",
              "Rc8",
              "Rxd4",
              "Rxc6",
              "Kg6",
              "g3",
              "Rdd2",
              "Rc4",
              "h5",
              "h4",
              "Rdc2",
              "Rxc2",
              "Rxc2",
              "Kg2",
              "f4",
              "gxf4",
              "Kf5",
              "Kg3",
              "Rc3+",
              "f3",
              "Rc4",
              "Ra1",
              "Rxf4",
              "Ra5+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 268,
            "completion_tokens": 329,
            "total_tokens": 597,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 268,
            "completion_tokens": 304,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 267,
            "completion_tokens": 162,
            "total_tokens": 429,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 803,
          "total_completion_tokens": 795,
          "total_tokens": 1598
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 268,
            "completion_tokens": 329,
            "total_tokens": 597,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 268,
            "completion_tokens": 304,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 267,
            "completion_tokens": 162,
            "total_tokens": 429,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/p2b1r1p/Nrp2pp1/3q4/3P4/2Q5/PP3PPP/2R2RK1 w - - 1 20"
    },
    {
      "turn": 41,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qa5",
          "aggressive_uci": "c3a5",
          "aggressive_response": "21. Qa5 Rxb2 22. Qxa7 Be6 23. Qa8+ Rf8 24. Qxc6 Qxc6 25. Rxc6 Bxa2 26. d5\nRd2 27. d6 Rd8 28. Nb5 Bd5 29. Rc7 Be6 30. Re1 Bd7 31. Nc3 Rxd6 32. Ne4 Re6\n33. f3 f5 34. Rd1 fxe4 35. Rdxd7 Rxd7 36. Rxd7 exf3 37. gxf3 Rf6 38. Kg2 Rf7\n39. Rd8+ Kg7 40. Kg3 h5 41. h4 Kh6 42. Rh8+ Kg7 43. Rd8 Kh6 44. Rh8+ Kg7 45.\nRd8 Kh6 46. Rh8+ Kg7 47. Rd8 Kh6 48. Rh8+ Kg7 49. Rd8 Kh6 50. Rh8+ Kg7 51.\nRd8 Kh6 52. Rh8+ Kg7 53. Rd8 Kh6 54. Rh8+ Kg7 55. Rd8 Kh6 56. Rh8+ Kg7 57.\nRd8 Kh6 58. Rh8+ Kg7 59. Rd8 Kh6 60. Rh8+ Kg7 61. Rd8 Kh6 62. Rh8+ Kg7 63.\nRd8 Kh6 64. Rh8+ Kg7 65. Rd8 Kh6 66. Rh8+ Kg7 67. Rd8 Kh6 68. Rh8+ Kg7 69.\nRd8 Kh6 70. Rh8+ Kg7 71. Rd8 Kh6 72. Rh8+ Kg7 73. Rd8 Kh6 74. Rh8+ Kg7 75.\nRd8 Kh6 76. Rh8+ Kg7 77. Rd8 Kh6 78. Rh8+ Kg7 79. Rd8 Kh6 80. Rh8+ Kg7 81.\nRd8 Kh6 82. Rh8+ Kg7 83. Rd8 Kh6 84. Rh8+ Kg7 85. Rd8 Kh6 86. Rh8+ Kg7 87.\nRd8 Kh6 88. Rh8+ Kg7 89. Rd8 Kh6 90. Rh8+ Kg7 91. Rd8 Kh6 92. Rh8+ Kg7 93.\nRd8 Kh6 94. Rh8+ Kg7 95. Rd8 Kh6 96. Rh8+ Kg7 97. Rd8 Kh6 98. Rh8+ Kg7 99.\nRd8 Kh6 100. Rh8+ Kg7 101. Rd8 Kh6 102. Rh8+ Kg7 103",
          "aggressive_tokens": {
            "prompt_tokens": 278,
            "completion_tokens": 640,
            "total_tokens": 918,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxb2",
            "Qxa7",
            "Be6",
            "Qa8+",
            "Rf8",
            "Qxc6",
            "Qxc6",
            "Rxc6",
            "Bxa2",
            "d5",
            "Rd2",
            "d6",
            "Rd8",
            "Nb5",
            "Bd5",
            "Rc7",
            "Be6",
            "Re1",
            "Bd7",
            "Nc3",
            "Rxd6",
            "Ne4",
            "Re6",
            "f3",
            "f5",
            "Rd1",
            "fxe4",
            "Rdxd7",
            "Rxd7",
            "Rxd7",
            "exf3",
            "gxf3",
            "Rf6",
            "Kg2",
            "Rf7",
            "Rd8+",
            "Kg7",
            "Kg3",
            "h5",
            "h4",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rd8",
            "Kh6",
            "Rh8+",
            "Kg7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qa5",
          "positional_uci": "c3a5",
          "positional_response": "21. Qa5 Rxb2 22. Qxa7 Be6 23. Qa8+ Rf8 24. Qxc6 Qxc6 25. Rxc6 Bxa2 26. d5 Rd2 27. d6 Rd8 28. Nb5 Bd5 29. Rc7 Be6 30. Re1 Bd7 31. Nc3 Rxd6 32. Ne4 Re6 33. f3 f5 34. Rd1 fxe4 35. Rdxd7 Rxd7 36. Rxd7 exf3 37. gxf3 Re2 38. Rd4 Kg7 39. Re4 Rxe4 40. fxe4 Kf6 41. Kf2 Ke5 42. Ke3 g5 43. Kf3 h5 44. h3 Kd4 45. h4 g4+ 46. Kf4 Kd3 47. e5 Ke2 48. e6 Kf2 49. e7 g3 50. e8=Q g2 51. Qe3+ Kf1 52. Qf3+ Kg1 53. Kg3 Kh1 54. Qxg2# g1=Q 55. Qxg1+ Kxg1",
          "positional_tokens": {
            "prompt_tokens": 278,
            "completion_tokens": 290,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb2",
            "Qxa7",
            "Be6",
            "Qa8+",
            "Rf8",
            "Qxc6",
            "Qxc6",
            "Rxc6",
            "Bxa2",
            "d5",
            "Rd2",
            "d6",
            "Rd8",
            "Nb5",
            "Bd5",
            "Rc7",
            "Be6",
            "Re1",
            "Bd7",
            "Nc3",
            "Rxd6",
            "Ne4",
            "Re6",
            "f3",
            "f5",
            "Rd1",
            "fxe4",
            "Rdxd7",
            "Rxd7",
            "Rxd7",
            "exf3",
            "gxf3",
            "Re2",
            "Rd4",
            "Kg7",
            "Re4",
            "Rxe4",
            "fxe4",
            "Kf6",
            "Kf2",
            "Ke5",
            "Ke3",
            "g5",
            "Kf3",
            "h5",
            "h3",
            "Kd4",
            "h4",
            "g4+",
            "Kf4",
            "Kd3",
            "e5",
            "Ke2",
            "e6",
            "Kf2",
            "e7",
            "g3",
            "e8=Q",
            "g2",
            "Qe3+",
            "Kf1",
            "Qf3+",
            "Kg1",
            "Kg3",
            "Kh1",
            "Qxg2#",
            "g1=Q",
            "Qxg1+",
            "Kxg1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qa5",
          "neutral_uci": "c3a5",
          "neutral_response": "21. Qa5 Rxb2 22. Qxa7 Bf5 23. Qa8+ Kg7 24. Ne8+ Kh6 25. Nxd6 Rd7 26. Nxf5+ gxf5\n27. Qxc6 Rxd4 28. Qxf6+ Kh5 29. Qxd4 Rxa2 30. Rc5 Kg5 31. h4+ Kg6 32. Qd6+ Kh5\n33. Rxf5+ Kxh4 34. Qg3# d5 Qxd5 Rxd5 Rxd5#",
          "neutral_tokens": {
            "prompt_tokens": 277,
            "completion_tokens": 134,
            "total_tokens": 411,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb2",
            "Qxa7",
            "Bf5",
            "Qa8+",
            "Kg7",
            "Ne8+",
            "Kh6",
            "Nxd6",
            "Rd7",
            "Nxf5+",
            "gxf5",
            "Qxc6",
            "Rxd4",
            "Qxf6+",
            "Kh5",
            "Qxd4",
            "Rxa2",
            "Rc5",
            "Kg5",
            "h4+",
            "Kg6",
            "Qd6+",
            "Kh5",
            "Rxf5+",
            "Kxh4",
            "Qg3#",
            "d5",
            "Qxd5",
            "Rxd5",
            "Rxd5#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c3a5",
          "positional_uci": "c3a5",
          "neutral_uci": "c3a5",
          "consensus_move": "c3a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxb2",
              "Qxa7",
              "Be6",
              "Qa8+",
              "Rf8",
              "Qxc6",
              "Qxc6",
              "Rxc6",
              "Bxa2",
              "d5",
              "Rd2",
              "d6",
              "Rd8",
              "Nb5",
              "Bd5",
              "Rc7",
              "Be6",
              "Re1",
              "Bd7",
              "Nc3",
              "Rxd6",
              "Ne4",
              "Re6",
              "f3",
              "f5",
              "Rd1",
              "fxe4",
              "Rdxd7",
              "Rxd7",
              "Rxd7",
              "exf3",
              "gxf3",
              "Rf6",
              "Kg2",
              "Rf7",
              "Rd8+",
              "Kg7",
              "Kg3",
              "h5",
              "h4",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rd8",
              "Kh6",
              "Rh8+",
              "Kg7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxb2",
              "Qxa7",
              "Be6",
              "Qa8+",
              "Rf8",
              "Qxc6",
              "Qxc6",
              "Rxc6",
              "Bxa2",
              "d5",
              "Rd2",
              "d6",
              "Rd8",
              "Nb5",
              "Bd5",
              "Rc7",
              "Be6",
              "Re1",
              "Bd7",
              "Nc3",
              "Rxd6",
              "Ne4",
              "Re6",
              "f3",
              "f5",
              "Rd1",
              "fxe4",
              "Rdxd7",
              "Rxd7",
              "Rxd7",
              "exf3",
              "gxf3",
              "Re2",
              "Rd4",
              "Kg7",
              "Re4",
              "Rxe4",
              "fxe4",
              "Kf6",
              "Kf2",
              "Ke5",
              "Ke3",
              "g5",
              "Kf3",
              "h5",
              "h3",
              "Kd4",
              "h4",
              "g4+",
              "Kf4",
              "Kd3",
              "e5",
              "Ke2",
              "e6",
              "Kf2",
              "e7",
              "g3",
              "e8=Q",
              "g2",
              "Qe3+",
              "Kf1",
              "Qf3+",
              "Kg1",
              "Kg3",
              "Kh1",
              "Qxg2#",
              "g1=Q",
              "Qxg1+",
              "Kxg1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxb2",
              "Qxa7",
              "Bf5",
              "Qa8+",
              "Kg7",
              "Ne8+",
              "Kh6",
              "Nxd6",
              "Rd7",
              "Nxf5+",
              "gxf5",
              "Qxc6",
              "Rxd4",
              "Qxf6+",
              "Kh5",
              "Qxd4",
              "Rxa2",
              "Rc5",
              "Kg5",
              "h4+",
              "Kg6",
              "Qd6+",
              "Kh5",
              "Rxf5+",
              "Kxh4",
              "Qg3#",
              "d5",
              "Qxd5",
              "Rxd5",
              "Rxd5#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 278,
            "completion_tokens": 640,
            "total_tokens": 918,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 278,
            "completion_tokens": 290,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 277,
            "completion_tokens": 134,
            "total_tokens": 411,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 833,
          "total_completion_tokens": 1064,
          "total_tokens": 1897
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 278,
            "completion_tokens": 640,
            "total_tokens": 918,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 278,
            "completion_tokens": 290,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 277,
            "completion_tokens": 134,
            "total_tokens": 411,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/p1Nb1r1p/1rpq1pp1/8/3P4/2Q5/PP3PPP/2R2RK1 w - - 3 21"
    },
    {
      "turn": 43,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d4d5",
          "aggressive_response": "22. d5 Rb7 23. Qxc7 Rxc7 24. d6 Rb7 25. b3 Rb6 26. Rfe1 Kf8 27. Rc5 Rb5 28.\nRxb5 cxb5 29. Rc1 Ke8 30. Rc7 Be6 31. Rc5 Rb7 32. f3 Kd7 33. Kf2 Kxd6 34. Rc2\nRc7 35. Rd2+ Bd5 36. Ke3 Rc3+ 37. Kd4 Rc1 38. Ke3 Re1+ 39. Kf2 Re5 40. f4 Re4\n41. g3 Kc5 42. Rc2+ Kb4 43. Rc7 a5 44. Rxh7 Ka3 45. Ra7 a4 46. bxa4 bxa4 47.\nRd7 Bxa2 48. Rd6 Re6 49. Rd3+ Bb3 50. g4 Kb2 51. f5 gxf5 52. gxf5 Re5 53. Rd2+\nKc3 54. Rd6 Rxf5+ 55. Ke3 a3 56. Rc6+ Kb2 57. Kd2 a2 58. Rc1 Rd5+ 59. Ke3\nKxc1 60. h4 a1=Q 61. h5 Qe5+ 62. Kf3 Rd3+ 63. Kg4 Rg3+ 64. Kh4 Qg5# Qg5#",
          "aggressive_tokens": {
            "prompt_tokens": 287,
            "completion_tokens": 356,
            "total_tokens": 643,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb7",
            "Qxc7",
            "Rxc7",
            "d6",
            "Rb7",
            "b3",
            "Rb6",
            "Rfe1",
            "Kf8",
            "Rc5",
            "Rb5",
            "Rxb5",
            "cxb5",
            "Rc1",
            "Ke8",
            "Rc7",
            "Be6",
            "Rc5",
            "Rb7",
            "f3",
            "Kd7",
            "Kf2",
            "Kxd6",
            "Rc2",
            "Rc7",
            "Rd2+",
            "Bd5",
            "Ke3",
            "Rc3+",
            "Kd4",
            "Rc1",
            "Ke3",
            "Re1+",
            "Kf2",
            "Re5",
            "f4",
            "Re4",
            "g3",
            "Kc5",
            "Rc2+",
            "Kb4",
            "Rc7",
            "a5",
            "Rxh7",
            "Ka3",
            "Ra7",
            "a4",
            "bxa4",
            "bxa4",
            "Rd7",
            "Bxa2",
            "Rd6",
            "Re6",
            "Rd3+",
            "Bb3",
            "g4",
            "Kb2",
            "f5",
            "gxf5",
            "gxf5",
            "Re5",
            "Rd2+",
            "Kc3",
            "Rd6",
            "Rxf5+",
            "Ke3",
            "a3",
            "Rc6+",
            "Kb2",
            "Kd2",
            "a2",
            "Rc1",
            "Rd5+",
            "Ke3",
            "Kxc1",
            "h4",
            "a1=Q",
            "h5",
            "Qe5+",
            "Kf3",
            "Rd3+",
            "Kg4",
            "Rg3+",
            "Kh4",
            "Qg5#",
            "Qg5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe7 Rxe7 Re8 Qb8 Rfe7 Rxe",
          "positional_tokens": {
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qb8",
            "Rfe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d5",
          "neutral_uci": "d4d5",
          "neutral_response": "Repeating the entire game so far:\n1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7\n* Next 3 moves:\n22. d5 Rb5 23. Qxc7 Rxc7 24. dxc6",
          "neutral_tokens": {
            "prompt_tokens": 286,
            "completion_tokens": 214,
            "total_tokens": 500,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb5",
            "Qxc7",
            "Rxc7",
            "dxc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4d5",
          "positional_uci": null,
          "neutral_uci": "d4d5",
          "consensus_move": "d4d5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rb7",
              "Qxc7",
              "Rxc7",
              "d6",
              "Rb7",
              "b3",
              "Rb6",
              "Rfe1",
              "Kf8",
              "Rc5",
              "Rb5",
              "Rxb5",
              "cxb5",
              "Rc1",
              "Ke8",
              "Rc7",
              "Be6",
              "Rc5",
              "Rb7",
              "f3",
              "Kd7",
              "Kf2",
              "Kxd6",
              "Rc2",
              "Rc7",
              "Rd2+",
              "Bd5",
              "Ke3",
              "Rc3+",
              "Kd4",
              "Rc1",
              "Ke3",
              "Re1+",
              "Kf2",
              "Re5",
              "f4",
              "Re4",
              "g3",
              "Kc5",
              "Rc2+",
              "Kb4",
              "Rc7",
              "a5",
              "Rxh7",
              "Ka3",
              "Ra7",
              "a4",
              "bxa4",
              "bxa4",
              "Rd7",
              "Bxa2",
              "Rd6",
              "Re6",
              "Rd3+",
              "Bb3",
              "g4",
              "Kb2",
              "f5",
              "gxf5",
              "gxf5",
              "Re5",
              "Rd2+",
              "Kc3",
              "Rd6",
              "Rxf5+",
              "Ke3",
              "a3",
              "Rc6+",
              "Kb2",
              "Kd2",
              "a2",
              "Rc1",
              "Rd5+",
              "Ke3",
              "Kxc1",
              "h4",
              "a1=Q",
              "h5",
              "Qe5+",
              "Kf3",
              "Rd3+",
              "Kg4",
              "Rg3+",
              "Kh4",
              "Qg5#",
              "Qg5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qb8",
              "Rfe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rb5",
              "Qxc7",
              "Rxc7",
              "dxc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 287,
            "completion_tokens": 356,
            "total_tokens": 643,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 286,
            "completion_tokens": 214,
            "total_tokens": 500,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 860,
          "total_completion_tokens": 1210,
          "total_tokens": 2070
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 287,
            "completion_tokens": 356,
            "total_tokens": 643,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 286,
            "completion_tokens": 214,
            "total_tokens": 500,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/p1qb1r1p/1rp2pp1/Q7/3P4/8/PP3PPP/2R2RK1 w - - 0 22"
    },
    {
      "turn": 45,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxc6",
          "aggressive_uci": "d5c6",
          "aggressive_response": "23. dxc6 Bxc6 24. Rfd1 Bxg2 25. Rd8+ Kg7 26. Rcc8 Bh1 27. Rg8+ Kh6 28. Qd2+ g5 29. f4 Rxb2 30. fxg5+ Kh5 31. Qd1+ Bf3 32. Qf1 Qb6+ 33. Qf2 Qxf2#",
          "aggressive_tokens": {
            "prompt_tokens": 295,
            "completion_tokens": 100,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc6",
            "Rfd1",
            "Bxg2",
            "Rd8+",
            "Kg7",
            "Rcc8",
            "Bh1",
            "Rg8+",
            "Kh6",
            "Qd2+",
            "g5",
            "f4",
            "Rxb2",
            "fxg5+",
            "Kh5",
            "Qd1+",
            "Bf3",
            "Qf1",
            "Qb6+",
            "Qf2",
            "Qxf2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxc6",
          "positional_uci": "d5c6",
          "positional_response": "23. dxc6 Bxc6 24. Rfd1 Bxg2 25. Rd8+ Kg7 26. Rcc8 Bh1 27. Rg8+ Kh6 28. Qd2+ g5 29. f4 Rxb2 30. fxg5+ Kh5 31. Qd1+ Bf3 32. Qf1 Qb6+ 33. Qf2 Qxf2#",
          "positional_tokens": {
            "prompt_tokens": 295,
            "completion_tokens": 100,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc6",
            "Rfd1",
            "Bxg2",
            "Rd8+",
            "Kg7",
            "Rcc8",
            "Bh1",
            "Rg8+",
            "Kh6",
            "Qd2+",
            "g5",
            "f4",
            "Rxb2",
            "fxg5+",
            "Kh5",
            "Qd1+",
            "Bf3",
            "Qf1",
            "Qb6+",
            "Qf2",
            "Qxf2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxc6",
          "neutral_uci": "d5c6",
          "neutral_response": "23. dxc6 Bxc6 24. Rfd1 Bxg2 25. Rd8+ Kg7 26. Rcc8 Bh1 27. Rg8+ Kh6 28. Qd2+ g5\n29. f4 Rxb2 30. fxg5+ Kh5 31. Qd1+ Bf3 32. Qf1 Qb6+ 33. Qf2 Qxf2# Bb7+ Qxb7 Qg2#",
          "neutral_tokens": {
            "prompt_tokens": 294,
            "completion_tokens": 111,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc6",
            "Rfd1",
            "Bxg2",
            "Rd8+",
            "Kg7",
            "Rcc8",
            "Bh1",
            "Rg8+",
            "Kh6",
            "Qd2+",
            "g5",
            "f4",
            "Rxb2",
            "fxg5+",
            "Kh5",
            "Qd1+",
            "Bf3",
            "Qf1",
            "Qb6+",
            "Qf2",
            "Qxf2#",
            "Bb7+",
            "Qxb7",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d5c6",
          "positional_uci": "d5c6",
          "neutral_uci": "d5c6",
          "consensus_move": "d5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxc6",
              "Rfd1",
              "Bxg2",
              "Rd8+",
              "Kg7",
              "Rcc8",
              "Bh1",
              "Rg8+",
              "Kh6",
              "Qd2+",
              "g5",
              "f4",
              "Rxb2",
              "fxg5+",
              "Kh5",
              "Qd1+",
              "Bf3",
              "Qf1",
              "Qb6+",
              "Qf2",
              "Qxf2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxc6",
              "Rfd1",
              "Bxg2",
              "Rd8+",
              "Kg7",
              "Rcc8",
              "Bh1",
              "Rg8+",
              "Kh6",
              "Qd2+",
              "g5",
              "f4",
              "Rxb2",
              "fxg5+",
              "Kh5",
              "Qd1+",
              "Bf3",
              "Qf1",
              "Qb6+",
              "Qf2",
              "Qxf2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxc6",
              "Rfd1",
              "Bxg2",
              "Rd8+",
              "Kg7",
              "Rcc8",
              "Bh1",
              "Rg8+",
              "Kh6",
              "Qd2+",
              "g5",
              "f4",
              "Rxb2",
              "fxg5+",
              "Kh5",
              "Qd1+",
              "Bf3",
              "Qf1",
              "Qb6+",
              "Qf2",
              "Qxf2#",
              "Bb7+",
              "Qxb7",
              "Qg2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 295,
            "completion_tokens": 100,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 295,
            "completion_tokens": 100,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 294,
            "completion_tokens": 111,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 884,
          "total_completion_tokens": 311,
          "total_tokens": 1195
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 295,
            "completion_tokens": 100,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 295,
            "completion_tokens": 100,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 294,
            "completion_tokens": 111,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/pq1b1r1p/1rp2pp1/Q2P4/8/8/PP3PPP/2R2RK1 w - - 1 23"
    },
    {
      "turn": 47,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rfd1",
          "aggressive_uci": "f1d1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bxg2 25. Rd8+ Kg7 26. Rcc8 Bh3 27. Rg8+ Kh6",
          "aggressive_tokens": {
            "prompt_tokens": 304,
            "completion_tokens": 230,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg2",
            "Rd8+",
            "Kg7",
            "Rcc8",
            "Bh3",
            "Rg8+",
            "Kh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc6",
          "positional_uci": "c1c6",
          "positional_response": "24. Rxc6 Rxc6 25. Qd8+ Kg7 26. Re1 Qxb2 27. h3 Rc1 28. Rxc1 Qxc1+ 29. Kh2 Qc7+ 30. Qxc7 Rxc7 31. a4 Rc4 32. a5 Ra4 33. a6 Rxa6 34. g4 Ra3 35. Kg2 a5 36. f3 a4 37. Kg3 Rb3 38. h4 a3 39. g5 fxg5 40. hxg5 a2 41. Kg4 a1=Q 42. f4 Qg1+ 43. Kh4 Qg3# Qb7 44. Kg4 Qf3+ 45. Kh4 Qh3#",
          "positional_tokens": {
            "prompt_tokens": 304,
            "completion_tokens": 183,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8+",
            "Kg7",
            "Re1",
            "Qxb2",
            "h3",
            "Rc1",
            "Rxc1",
            "Qxc1+",
            "Kh2",
            "Qc7+",
            "Qxc7",
            "Rxc7",
            "a4",
            "Rc4",
            "a5",
            "Ra4",
            "a6",
            "Rxa6",
            "g4",
            "Ra3",
            "Kg2",
            "a5",
            "f3",
            "a4",
            "Kg3",
            "Rb3",
            "h4",
            "a3",
            "g5",
            "fxg5",
            "hxg5",
            "a2",
            "Kg4",
            "a1=Q",
            "f4",
            "Qg1+",
            "Kh4",
            "Qg3#",
            "Qb7",
            "Kg4",
            "Qf3+",
            "Kh4",
            "Qh3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rfd1",
          "neutral_uci": "f1d1",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bxg2 25. Rd8+ Kg7 26. Rcc8 Bh3 27. Rg8+ Kh6 28. Qd2+ g5",
          "neutral_tokens": {
            "prompt_tokens": 303,
            "completion_tokens": 239,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg2",
            "Rd8+",
            "Kg7",
            "Rcc8",
            "Bh3",
            "Rg8+",
            "Kh6",
            "Qd2+",
            "g5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d1",
          "positional_uci": "c1c6",
          "neutral_uci": "f1d1",
          "consensus_move": "f1d1",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxg2",
              "Rd8+",
              "Kg7",
              "Rcc8",
              "Bh3",
              "Rg8+",
              "Kh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd8+",
              "Kg7",
              "Re1",
              "Qxb2",
              "h3",
              "Rc1",
              "Rxc1",
              "Qxc1+",
              "Kh2",
              "Qc7+",
              "Qxc7",
              "Rxc7",
              "a4",
              "Rc4",
              "a5",
              "Ra4",
              "a6",
              "Rxa6",
              "g4",
              "Ra3",
              "Kg2",
              "a5",
              "f3",
              "a4",
              "Kg3",
              "Rb3",
              "h4",
              "a3",
              "g5",
              "fxg5",
              "hxg5",
              "a2",
              "Kg4",
              "a1=Q",
              "f4",
              "Qg1+",
              "Kh4",
              "Qg3#",
              "Qb7",
              "Kg4",
              "Qf3+",
              "Kh4",
              "Qh3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxg2",
              "Rd8+",
              "Kg7",
              "Rcc8",
              "Bh3",
              "Rg8+",
              "Kh6",
              "Qd2+",
              "g5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 304,
            "completion_tokens": 230,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 304,
            "completion_tokens": 183,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 303,
            "completion_tokens": 239,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 911,
          "total_completion_tokens": 652,
          "total_tokens": 1563
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 304,
            "completion_tokens": 230,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 304,
            "completion_tokens": 183,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 303,
            "completion_tokens": 239,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/pq3r1p/1rb2pp1/Q7/8/8/PP3PPP/2R2RK1 w - - 0 24"
    },
    {
      "turn": 49,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd8+",
          "aggressive_uci": "d1d8",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qb4\nBc6 27. Qd6 Bxg2 28. Rcc8 Rxd6 29. Rg8+ Kh6 30. Rc4 Rd1#",
          "aggressive_tokens": {
            "prompt_tokens": 313,
            "completion_tokens": 258,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg7",
            "Qb4",
            "Bc6",
            "Qd6",
            "Bxg2",
            "Rcc8",
            "Rxd6",
            "Rg8+",
            "Kh6",
            "Rc4",
            "Rd1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd8+",
          "positional_uci": "d1d8",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Rcc8 Kh6 27. Qd2+ g5 28. h4 Rg7 29. hxg5+ Rxg5 30. f4 Rg4 31. f5+ Kh5 32. Rc3 Rh4 33. Rg3 Qe4 34. Rg7 h6 35. Rg6 Qf4 36. Qd1+ Be2 37. Qxe2+ Rg4 38. Rh3+ Qh2+ 39. Rxh2#",
          "positional_tokens": {
            "prompt_tokens": 313,
            "completion_tokens": 332,
            "total_tokens": 645,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg7",
            "Rcc8",
            "Kh6",
            "Qd2+",
            "g5",
            "h4",
            "Rg7",
            "hxg5+",
            "Rxg5",
            "f4",
            "Rg4",
            "f5+",
            "Kh5",
            "Rc3",
            "Rh4",
            "Rg3",
            "Qe4",
            "Rg7",
            "h6",
            "Rg6",
            "Qf4",
            "Qd1+",
            "Be2",
            "Qxe2+",
            "Rg4",
            "Rh3+",
            "Qh2+",
            "Rxh2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd8+",
          "neutral_uci": "d1d8",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Rcc8 Kh6 27. Qd2+ g5 28. h4 Rg7 29. hxg5+ Rxg5 30. f4 Rg4 31. f5+ Kh5 32. Rc3 Rh4 33. Rg8 Qe4 34. Qd1+ Be2 35. Qd7 Qb1+ 36. Kf2 Qf1+ 37. Ke3 Qf4+ 38. Kxe2 Rxb2+ 39. Kd3 Qd2#",
          "neutral_tokens": {
            "prompt_tokens": 312,
            "completion_tokens": 337,
            "total_tokens": 649,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg7",
            "Rcc8",
            "Kh6",
            "Qd2+",
            "g5",
            "h4",
            "Rg7",
            "hxg5+",
            "Rxg5",
            "f4",
            "Rg4",
            "f5+",
            "Kh5",
            "Rc3",
            "Rh4",
            "Rg8",
            "Qe4",
            "Qd1+",
            "Be2",
            "Qd7",
            "Qb1+",
            "Kf2",
            "Qf1+",
            "Ke3",
            "Qf4+",
            "Kxe2",
            "Rxb2+",
            "Kd3",
            "Qd2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1d8",
          "positional_uci": "d1d8",
          "neutral_uci": "d1d8",
          "consensus_move": "d1d8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg7",
              "Qb4",
              "Bc6",
              "Qd6",
              "Bxg2",
              "Rcc8",
              "Rxd6",
              "Rg8+",
              "Kh6",
              "Rc4",
              "Rd1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg7",
              "Rcc8",
              "Kh6",
              "Qd2+",
              "g5",
              "h4",
              "Rg7",
              "hxg5+",
              "Rxg5",
              "f4",
              "Rg4",
              "f5+",
              "Kh5",
              "Rc3",
              "Rh4",
              "Rg3",
              "Qe4",
              "Rg7",
              "h6",
              "Rg6",
              "Qf4",
              "Qd1+",
              "Be2",
              "Qxe2+",
              "Rg4",
              "Rh3+",
              "Qh2+",
              "Rxh2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg7",
              "Rcc8",
              "Kh6",
              "Qd2+",
              "g5",
              "h4",
              "Rg7",
              "hxg5+",
              "Rxg5",
              "f4",
              "Rg4",
              "f5+",
              "Kh5",
              "Rc3",
              "Rh4",
              "Rg8",
              "Qe4",
              "Qd1+",
              "Be2",
              "Qd7",
              "Qb1+",
              "Kf2",
              "Qf1+",
              "Ke3",
              "Qf4+",
              "Kxe2",
              "Rxb2+",
              "Kd3",
              "Qd2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 313,
            "completion_tokens": 258,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 313,
            "completion_tokens": 332,
            "total_tokens": 645,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 312,
            "completion_tokens": 337,
            "total_tokens": 649,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 938,
          "total_completion_tokens": 927,
          "total_tokens": 1865
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 313,
            "completion_tokens": 258,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 313,
            "completion_tokens": 332,
            "total_tokens": 645,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 312,
            "completion_tokens": 337,
            "total_tokens": 649,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/pq3r1p/1r3pp1/Qb6/8/8/PP3PPP/2RR2K1 w - - 2 25"
    },
    {
      "turn": 51,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc3",
          "aggressive_uci": "a5c3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6 27. Qe1 Rxc1 28. Qxc1 Qc7 29. Qxc7 Rxc7",
          "aggressive_tokens": {
            "prompt_tokens": 321,
            "completion_tokens": 247,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc6",
            "Qe1",
            "Rxc1",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Rxc7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qc3",
          "positional_uci": "a5c3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6 27. Qe1 Rxc1 28. Qxc1 Qc7 29. Qxc7 Rxc7",
          "positional_tokens": {
            "prompt_tokens": 321,
            "completion_tokens": 247,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc6",
            "Qe1",
            "Rxc1",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Rxc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qc3",
          "neutral_uci": "a5c3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6 27. Qd2 Rxc1+ 28. Qxc1 Qc7 29. Qxc7 Rxc7",
          "neutral_tokens": {
            "prompt_tokens": 320,
            "completion_tokens": 248,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc6",
            "Qd2",
            "Rxc1+",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Rxc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a5c3",
          "positional_uci": "a5c3",
          "neutral_uci": "a5c3",
          "consensus_move": "a5c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rc6",
              "Qe1",
              "Rxc1",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Rxc7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rc6",
              "Qe1",
              "Rxc1",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Rxc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rc6",
              "Qd2",
              "Rxc1+",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Rxc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 321,
            "completion_tokens": 247,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 321,
            "completion_tokens": 247,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 320,
            "completion_tokens": 248,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 962,
          "total_completion_tokens": 742,
          "total_tokens": 1704
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 321,
            "completion_tokens": 247,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 321,
            "completion_tokens": 247,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 320,
            "completion_tokens": 248,
            "total_tokens": 568,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/pq3rkp/1r3pp1/Qb6/8/8/PP3PPP/2R3K1 w - - 4 26"
    },
    {
      "turn": 53,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe1",
          "aggressive_uci": "c3e1",
          "aggressive_response": "27. Qe1 Rxc1 28. Qxc1 Qc7 29. Qxc7 Rxc7",
          "aggressive_tokens": {
            "prompt_tokens": 330,
            "completion_tokens": 27,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc1",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Rxc7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe1",
          "positional_uci": "c3e1",
          "positional_response": "26... Rc6 27. Qe1 Rxc1 28. Qxc1 Qc7 29. Qxc7 Rxc7 30. Rd1 Rc2 31. Rb1 Bd3 32. a4 Rxf2 33. Kxf2 Bxb1",
          "positional_tokens": {
            "prompt_tokens": 330,
            "completion_tokens": 63,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc1",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Rxc7",
            "Rd1",
            "Rc2",
            "Rb1",
            "Bd3",
            "a4",
            "Rxf2",
            "Kxf2",
            "Bxb1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe1",
          "neutral_uci": "c3e1",
          "neutral_response": "26... Rc6 27. Qe1 Rxc1 28. Qxc1 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 329,
            "completion_tokens": 23,
            "total_tokens": 352,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc1",
            "Qxc1",
            "Qe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c3e1",
          "positional_uci": "c3e1",
          "neutral_uci": "c3e1",
          "consensus_move": "c3e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxc1",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Rxc7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxc1",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Rxc7",
              "Rd1",
              "Rc2",
              "Rb1",
              "Bd3",
              "a4",
              "Rxf2",
              "Kxf2",
              "Bxb1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxc1",
              "Qxc1",
              "Qe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 330,
            "completion_tokens": 27,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 330,
            "completion_tokens": 63,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 329,
            "completion_tokens": 23,
            "total_tokens": 352,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 989,
          "total_completion_tokens": 113,
          "total_tokens": 1102
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 330,
            "completion_tokens": 27,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 330,
            "completion_tokens": 63,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 329,
            "completion_tokens": 23,
            "total_tokens": 352,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/pq3rkp/2r2pp1/1b6/8/2Q5/PP3PPP/2R3K1 w - - 6 27"
    },
    {
      "turn": 55,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc6",
          "aggressive_uci": "c1c6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Qxc6 29. h3 Qc7 30. Rd5 Bc6 31. Rc5 Qd6 32. Qc1 Rc7 33. b4\na6 34. a4 Qd7 35. b5 axb5 36. axb5 Bxb5 37. Rxc7 Qxc7 38. Qxc7+ Kg6 39. Qc2+\nKg7 40. Qc5 Be8 41. Qe7+ Bf7 42. g4 Kg6 43. Kg2 Kg7 44. Kg3 Kg6 45. f4 gxf4+\n46. Kxf4 Kg7 47. h4 Kg6 48. h5+ Kg7 49. Kf5 Kg8 50. Kxf6 Kh8 51. Qf8+ Bg8\n52. Qg7# Bxg7 53. hxg7# Kg8 54. g5 Bg6 55. Ke7 Kxg7 56. Ke6 h6 57. gxh6+ Kxh6\n58. Ke5 Kg5 59. Kd4 Kf4 60. Kd5 Bf5 61. Kd4 Be4 62. Kc5 Ke5 63. Kc4 Bd5+ 64.\nKd3 Kf4 65. Kd4 Be4 66. Kc5 Ke5 67. Kc4 Bf5 68. Kc5 Be6 69. Kc6 Kd4 70. Kd6\nBd5 71. Ke7 Ke5 72. Kd7 Bb7 73. Kc7 Ba6 74. Kb6 Bc4 75. Kc5 Bd5 76. Kb4 Kd4",
          "aggressive_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxc6",
            "h3",
            "Qc7",
            "Rd5",
            "Bc6",
            "Rc5",
            "Qd6",
            "Qc1",
            "Rc7",
            "b4",
            "a6",
            "a4",
            "Qd7",
            "b5",
            "axb5",
            "axb5",
            "Bxb5",
            "Rxc7",
            "Qxc7",
            "Qxc7+",
            "Kg6",
            "Qc2+",
            "Kg7",
            "Qc5",
            "Be8",
            "Qe7+",
            "Bf7",
            "g4",
            "Kg6",
            "Kg2",
            "Kg7",
            "Kg3",
            "Kg6",
            "f4",
            "gxf4+",
            "Kxf4",
            "Kg7",
            "h4",
            "Kg6",
            "h5+",
            "Kg7",
            "Kf5",
            "Kg8",
            "Kxf6",
            "Kh8",
            "Qf8+",
            "Bg8",
            "Qg7#",
            "Bxg7",
            "hxg7#",
            "Kg8",
            "g5",
            "Bg6",
            "Ke7",
            "Kxg7",
            "Ke6",
            "h6",
            "gxh6+",
            "Kxh6",
            "Ke5",
            "Kg5",
            "Kd4",
            "Kf4",
            "Kd5",
            "Bf5",
            "Kd4",
            "Be4",
            "Kc5",
            "Ke5",
            "Kc4",
            "Bd5+",
            "Kd3",
            "Kf4",
            "Kd4",
            "Be4",
            "Kc5",
            "Ke5",
            "Kc4",
            "Bf5",
            "Kc5",
            "Be6",
            "Kc6",
            "Kd4",
            "Kd6",
            "Bd5",
            "Ke7",
            "Ke5",
            "Kd7",
            "Bb7",
            "Kc7",
            "Ba6",
            "Kb6",
            "Bc4",
            "Kc5",
            "Bd5",
            "Kb4",
            "Kd4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc6",
          "positional_uci": "c1c6",
          "positional_response": "28. Rxc6 Qxc6 29. h3 Qc4 30. b3 Qc2 31. Rd2 Qc3 32. Qd1 Re7 33. Kh2 Qe5+ 34. g3 Qe1 35. Qc2 Qf1 36. Qc5 Re1 37. Qc7+ Kg6 38. Qc2+ Kh6 39. g4 Qg1# Bb7 Qh1+ Kg3 Qg1#",
          "positional_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 115,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc6",
            "h3",
            "Qc4",
            "b3",
            "Qc2",
            "Rd2",
            "Qc3",
            "Qd1",
            "Re7",
            "Kh2",
            "Qe5+",
            "g3",
            "Qe1",
            "Qc2",
            "Qf1",
            "Qc5",
            "Re1",
            "Qc7+",
            "Kg6",
            "Qc2+",
            "Kh6",
            "g4",
            "Qg1#",
            "Bb7",
            "Qh1+",
            "Kg3",
            "Qg1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc6",
          "neutral_uci": "c1c6",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Qxc6 29. Qd1 Qc4 30. b3 Qe2 31. Qxe2 Bxe2 32. Rd2 Bb5 33.\na4 Rd7 34. Rxd7+ Bxd7 35. Kf1 Be6 36. b4 Bb3 37. a5 Bc4+ 38. Ke1 Kf7 39. Kd2 Ke6\n40. Kc3 Kd5 41. g3 Bb5 42. f3 h5 43. h3 f5 44. g4 fxg4 45. fxg4 hxg4 46. hxg4\nBe2 47. Kd2 Bxg4 48. b5 Kc5 49. b6 axb6 50. axb6 Kxb6 51. Ke3 Kc5 52. Kf2 Kd4\n53. Kg3 Bf5 54. Kf3 Ke5 55. Kg3 Ke4 56. Kf2 Kf4 57. Kg2 Be4+ 58. Kf2 g4 59. Kg1\nKg3 60. Kf1 Kh2 61. Kf2 g3+ 62. Ke3 g2 63. Kxe4 g1=Q 64. Kf3 Qg3+ 65. Ke4 Kg2\n66. Kd4 Kf2 67. Ke4 Qe3+ 68. Kd5 Kf3 69. Kc4 Ke4 70. Kb5 Qc3 71. Kb6 Kd5 72.\nKb5 Qb3+ 73. Ka6 Kc6 74. Ka5 Qb5# g5 g4 g3 g2 g1=Q#",
          "neutral_tokens": {
            "prompt_tokens": 336,
            "completion_tokens": 637,
            "total_tokens": 973,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc6",
            "Qd1",
            "Qc4",
            "b3",
            "Qe2",
            "Qxe2",
            "Bxe2",
            "Rd2",
            "Bb5",
            "a4",
            "Rd7",
            "Rxd7+",
            "Bxd7",
            "Kf1",
            "Be6",
            "b4",
            "Bb3",
            "a5",
            "Bc4+",
            "Ke1",
            "Kf7",
            "Kd2",
            "Ke6",
            "Kc3",
            "Kd5",
            "g3",
            "Bb5",
            "f3",
            "h5",
            "h3",
            "f5",
            "g4",
            "fxg4",
            "fxg4",
            "hxg4",
            "hxg4",
            "Be2",
            "Kd2",
            "Bxg4",
            "b5",
            "Kc5",
            "b6",
            "axb6",
            "axb6",
            "Kxb6",
            "Ke3",
            "Kc5",
            "Kf2",
            "Kd4",
            "Kg3",
            "Bf5",
            "Kf3",
            "Ke5",
            "Kg3",
            "Ke4",
            "Kf2",
            "Kf4",
            "Kg2",
            "Be4+",
            "Kf2",
            "g4",
            "Kg1",
            "Kg3",
            "Kf1",
            "Kh2",
            "Kf2",
            "g3+",
            "Ke3",
            "g2",
            "Kxe4",
            "g1=Q",
            "Kf3",
            "Qg3+",
            "Ke4",
            "Kg2",
            "Kd4",
            "Kf2",
            "Ke4",
            "Qe3+",
            "Kd5",
            "Kf3",
            "Kc4",
            "Ke4",
            "Kb5",
            "Qc3",
            "Kb6",
            "Kd5",
            "Kb5",
            "Qb3+",
            "Ka6",
            "Kc6",
            "Ka5",
            "Qb5#",
            "g5",
            "g4",
            "g3",
            "g2",
            "g1=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1c6",
          "positional_uci": "c1c6",
          "neutral_uci": "c1c6",
          "consensus_move": "c1c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxc6",
              "h3",
              "Qc7",
              "Rd5",
              "Bc6",
              "Rc5",
              "Qd6",
              "Qc1",
              "Rc7",
              "b4",
              "a6",
              "a4",
              "Qd7",
              "b5",
              "axb5",
              "axb5",
              "Bxb5",
              "Rxc7",
              "Qxc7",
              "Qxc7+",
              "Kg6",
              "Qc2+",
              "Kg7",
              "Qc5",
              "Be8",
              "Qe7+",
              "Bf7",
              "g4",
              "Kg6",
              "Kg2",
              "Kg7",
              "Kg3",
              "Kg6",
              "f4",
              "gxf4+",
              "Kxf4",
              "Kg7",
              "h4",
              "Kg6",
              "h5+",
              "Kg7",
              "Kf5",
              "Kg8",
              "Kxf6",
              "Kh8",
              "Qf8+",
              "Bg8",
              "Qg7#",
              "Bxg7",
              "hxg7#",
              "Kg8",
              "g5",
              "Bg6",
              "Ke7",
              "Kxg7",
              "Ke6",
              "h6",
              "gxh6+",
              "Kxh6",
              "Ke5",
              "Kg5",
              "Kd4",
              "Kf4",
              "Kd5",
              "Bf5",
              "Kd4",
              "Be4",
              "Kc5",
              "Ke5",
              "Kc4",
              "Bd5+",
              "Kd3",
              "Kf4",
              "Kd4",
              "Be4",
              "Kc5",
              "Ke5",
              "Kc4",
              "Bf5",
              "Kc5",
              "Be6",
              "Kc6",
              "Kd4",
              "Kd6",
              "Bd5",
              "Ke7",
              "Ke5",
              "Kd7",
              "Bb7",
              "Kc7",
              "Ba6",
              "Kb6",
              "Bc4",
              "Kc5",
              "Bd5",
              "Kb4",
              "Kd4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxc6",
              "h3",
              "Qc4",
              "b3",
              "Qc2",
              "Rd2",
              "Qc3",
              "Qd1",
              "Re7",
              "Kh2",
              "Qe5+",
              "g3",
              "Qe1",
              "Qc2",
              "Qf1",
              "Qc5",
              "Re1",
              "Qc7+",
              "Kg6",
              "Qc2+",
              "Kh6",
              "g4",
              "Qg1#",
              "Bb7",
              "Qh1+",
              "Kg3",
              "Qg1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxc6",
              "Qd1",
              "Qc4",
              "b3",
              "Qe2",
              "Qxe2",
              "Bxe2",
              "Rd2",
              "Bb5",
              "a4",
              "Rd7",
              "Rxd7+",
              "Bxd7",
              "Kf1",
              "Be6",
              "b4",
              "Bb3",
              "a5",
              "Bc4+",
              "Ke1",
              "Kf7",
              "Kd2",
              "Ke6",
              "Kc3",
              "Kd5",
              "g3",
              "Bb5",
              "f3",
              "h5",
              "h3",
              "f5",
              "g4",
              "fxg4",
              "fxg4",
              "hxg4",
              "hxg4",
              "Be2",
              "Kd2",
              "Bxg4",
              "b5",
              "Kc5",
              "b6",
              "axb6",
              "axb6",
              "Kxb6",
              "Ke3",
              "Kc5",
              "Kf2",
              "Kd4",
              "Kg3",
              "Bf5",
              "Kf3",
              "Ke5",
              "Kg3",
              "Ke4",
              "Kf2",
              "Kf4",
              "Kg2",
              "Be4+",
              "Kf2",
              "g4",
              "Kg1",
              "Kg3",
              "Kf1",
              "Kh2",
              "Kf2",
              "g3+",
              "Ke3",
              "g2",
              "Kxe4",
              "g1=Q",
              "Kf3",
              "Qg3+",
              "Ke4",
              "Kg2",
              "Kd4",
              "Kf2",
              "Ke4",
              "Qe3+",
              "Kd5",
              "Kf3",
              "Kc4",
              "Ke4",
              "Kb5",
              "Qc3",
              "Kb6",
              "Kd5",
              "Kb5",
              "Qb3+",
              "Ka6",
              "Kc6",
              "Ka5",
              "Qb5#",
              "g5",
              "g4",
              "g3",
              "g2",
              "g1=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 337,
            "completion_tokens": 115,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 336,
            "completion_tokens": 637,
            "total_tokens": 973,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1010,
          "total_completion_tokens": 1392,
          "total_tokens": 2402
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 337,
            "completion_tokens": 115,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 336,
            "completion_tokens": 637,
            "total_tokens": 973,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/pq3rkp/2r2p2/1b4p1/8/8/PP3PPP/2R1Q1K1 w - - 0 28"
    },
    {
      "turn": 57,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc3",
          "aggressive_uci": "e1c3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Bxg2 30. Qg3 Be4 31. h4 h6 32. hxg5 hxg5 33. Qh3 Bh7 34. Qc3 Qe4 35. Rd4 Qb1+ 36. Kh2 Be4 37. f3 Bf5 38. Rd2 Kg6 39. Kg3 Rh7 40. Rh2 Qg1+ 41. Rg2 Rh3#",
          "aggressive_tokens": {
            "prompt_tokens": 346,
            "completion_tokens": 344,
            "total_tokens": 690,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe4",
            "Rd4",
            "Qb1+",
            "Kh2",
            "Be4",
            "f3",
            "Bf5",
            "Rd2",
            "Kg6",
            "Kg3",
            "Rh7",
            "Rh2",
            "Qg1+",
            "Rg2",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qc3",
          "positional_uci": "e1c3",
          "positional_response": "29. Qc3 Bxg2 30. Qg3 Be4 31. h4 Qxb2 32. hxg5 Qb1+ 33. Kh2 Qh1#",
          "positional_tokens": {
            "prompt_tokens": 346,
            "completion_tokens": 45,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg2",
            "Qg3",
            "Be4",
            "h4",
            "Qxb2",
            "hxg5",
            "Qb1+",
            "Kh2",
            "Qh1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe8",
          "neutral_uci": "e1e8",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qe8 Bxe8 30. Rxe8 Qxb2 31. h3 Qxa2 32. Kh2 Qxf2 33.\nRa8 Qf4+ 34. Kg1 Qd4+ 35. Kh2 Qd6+ 36. Kg1 Qb6+ 37. Kh2 Qb7 38. Re8 a5 39. Re2 a4\n40. Ra2 Qb3 41. Re2 a3 42. Re1 a2 43. Ra1 Qb2 44. Rxa2 Qxa2 45. Kg3 Qb3+ 46. Kh2\nQe3 47. Kh1 Qf4 48. Kg1 Qg3 49. Kh1 Re7 50. Kg1 Re1# Rf7 Rf7 Rf7",
          "neutral_tokens": {
            "prompt_tokens": 345,
            "completion_tokens": 426,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe8",
            "Rxe8",
            "Qxb2",
            "h3",
            "Qxa2",
            "Kh2",
            "Qxf2",
            "Ra8",
            "Qf4+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qb6+",
            "Kh2",
            "Qb7",
            "Re8",
            "a5",
            "Re2",
            "a4",
            "Ra2",
            "Qb3",
            "Re2",
            "a3",
            "Re1",
            "a2",
            "Ra1",
            "Qb2",
            "Rxa2",
            "Qxa2",
            "Kg3",
            "Qb3+",
            "Kh2",
            "Qe3",
            "Kh1",
            "Qf4",
            "Kg1",
            "Qg3",
            "Kh1",
            "Re7",
            "Kg1",
            "Re1#",
            "Rf7",
            "Rf7",
            "Rf7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1c3",
          "positional_uci": "e1c3",
          "neutral_uci": "e1e8",
          "consensus_move": "e1c3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe4",
              "Rd4",
              "Qb1+",
              "Kh2",
              "Be4",
              "f3",
              "Bf5",
              "Rd2",
              "Kg6",
              "Kg3",
              "Rh7",
              "Rh2",
              "Qg1+",
              "Rg2",
              "Rh3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxg2",
              "Qg3",
              "Be4",
              "h4",
              "Qxb2",
              "hxg5",
              "Qb1+",
              "Kh2",
              "Qh1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxe8",
              "Rxe8",
              "Qxb2",
              "h3",
              "Qxa2",
              "Kh2",
              "Qxf2",
              "Ra8",
              "Qf4+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qb6+",
              "Kh2",
              "Qb7",
              "Re8",
              "a5",
              "Re2",
              "a4",
              "Ra2",
              "Qb3",
              "Re2",
              "a3",
              "Re1",
              "a2",
              "Ra1",
              "Qb2",
              "Rxa2",
              "Qxa2",
              "Kg3",
              "Qb3+",
              "Kh2",
              "Qe3",
              "Kh1",
              "Qf4",
              "Kg1",
              "Qg3",
              "Kh1",
              "Re7",
              "Kg1",
              "Re1#",
              "Rf7",
              "Rf7",
              "Rf7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 346,
            "completion_tokens": 344,
            "total_tokens": 690,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 346,
            "completion_tokens": 45,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 345,
            "completion_tokens": 426,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1037,
          "total_completion_tokens": 815,
          "total_tokens": 1852
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 346,
            "completion_tokens": 344,
            "total_tokens": 690,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 346,
            "completion_tokens": 45,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 345,
            "completion_tokens": 426,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/pq3rkp/2b2p2/6p1/8/8/PP3PPP/4Q1K1 w - - 0 29"
    },
    {
      "turn": 59,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd1",
          "aggressive_uci": "d8d1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe4 31. f3 Qe6 32. Re1 Qd6 33. Qe3 Qd5 34. b3 Rd7 35. h3 Qd4 36. Qxd4 Rxd4 37. Re7+ Kg6 38. Rxa7 Rd1+ 39. Kf2 Rd2+ 40. Kg3 h5 41. Ra6 h4+ 42. Kh2 Bxf3 43. Kg1 Rxg2+ 44. Kf1 Rh2 45. b4 Be2+ 46. Kg1 Bxa6 47. Kxh2 Bc4 48. a4 Kf5 49. b5 Ke6 50. b6 Kd6 51. a5 Kc6 52. Kg2 Kb5 53. b7 Bd5+ 54. Kf2 Bxb7 55. Ke3 Kxa5 56. Kd4 Bg2 57. Kc5 Bxh3 58. Kd6 g4 59. Ke6 g3+ 60. Kxf6 g2 61. Kg5 g1=Q+ 62. Kxh4 Qg4#",
          "aggressive_tokens": {
            "prompt_tokens": 355,
            "completion_tokens": 522,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf2",
            "Rd2+",
            "Kg3",
            "h5",
            "Ra6",
            "h4+",
            "Kh2",
            "Bxf3",
            "Kg1",
            "Rxg2+",
            "Kf1",
            "Rh2",
            "b4",
            "Be2+",
            "Kg1",
            "Bxa6",
            "Kxh2",
            "Bc4",
            "a4",
            "Kf5",
            "b5",
            "Ke6",
            "b6",
            "Kd6",
            "a5",
            "Kc6",
            "Kg2",
            "Kb5",
            "b7",
            "Bd5+",
            "Kf2",
            "Bxb7",
            "Ke3",
            "Kxa5",
            "Kd4",
            "Bg2",
            "Kc5",
            "Bxh3",
            "Kd6",
            "g4",
            "Ke6",
            "g3+",
            "Kxf6",
            "g2",
            "Kg5",
            "g1=Q+",
            "Kxh4",
            "Qg4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd1",
          "positional_uci": "d8d1",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe4 31. f3 Qe6 32. Re1 Qd5 33. Rc1 Bb7 34. Qe3 Rd7 35. h3 Qd4 36. Qxd4 Rxd4 37. Rc7+ Kg6 38. Rxb7 Rd1+ 39. Kf2 Rd2+ 40. Kg3 h5 41. Rxa7 h4+ 42. Kh2 Rxb2 43. a4 Kf5 44. a5 Kf4 45. a6 Ke3 46. Re7+ Kf2 47. a7 Kf1 48. a8=Q Rxg2+ 49. Kh1 Rg1+ 50. Kh2 Rg2+ 51. Kh1 Rg1+ 52. Kh2 Rg2+ 53. Kh1 Rg1+ 54. Kh2 Rg2+ 55. Kh1 Rg1+ 56. Kh2 Rg2+ 57. Kh1 Rg1+ 58. Kh2 Rg2+ 59. Kh1 Rg1+ 60. Kh2 Rg2+ 61. Kh1 Rg1+ 62. Kh2 Rg2+ 63. Kh1 Rg1+ 64. Kh2 Rg2+ 65. Kh1 Rg1+ 66. Kh2 Rg2+ 67. Kh1 Rg1+ 68. Kh2 Rg2+ 69. Kh1 Rg1+ 70. Kh2 Rg2+ 71. Kh1 Rg1+ 72. Kh2 Rg2+ 73. Kh1 Rg1+ 74. Kh2 Rg2+ 75",
          "positional_tokens": {
            "prompt_tokens": 355,
            "completion_tokens": 640,
            "total_tokens": 995,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf2",
            "Rd2+",
            "Kg3",
            "h5",
            "Rxa7",
            "h4+",
            "Kh2",
            "Rxb2",
            "a4",
            "Kf5",
            "a5",
            "Kf4",
            "a6",
            "Ke3",
            "Re7+",
            "Kf2",
            "a7",
            "Kf1",
            "a8=Q",
            "Rxg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh1",
            "Rg1+",
            "Kh2",
            "Rg2+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd1",
          "neutral_uci": "d8d1",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe4 31. f3 Qe6 32. Re1 Qd6 33. Qe3 Qd5 34. b3 Rd7 35. h3 Qd4 36. Qxd4 Rxd4 37. Re7+ Kg6 38. Rxa7 Rd1+ 39. Kf2 Rd2+ 40. Kg3 h5 41. Ra6 h4+ 42. Kh2 Bxf3 43. Kg1 Rxg2+ 44. Kf1 Rh2 45. b4 Be2+ 46. Kg1 Bxa6 47. Kxh2 Bc4 48. a4 Kf5 49. b5 Ke6 50. b6 Kd7 51. a5 Kc6 52. Kg2 Kb5 53. b7 Bd5+ 54. Kf2 Bxb7 55. Ke3 Kxa5 56. Kd4 Bg2 57. Kc5 Bxh3 58. Kd6 g4 59. Ke6 g3+ 60. Kxf6 g2 61. Kg5 g1=Q+ 62. Kxh4 Qg4#",
          "neutral_tokens": {
            "prompt_tokens": 354,
            "completion_tokens": 522,
            "total_tokens": 876,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf2",
            "Rd2+",
            "Kg3",
            "h5",
            "Ra6",
            "h4+",
            "Kh2",
            "Bxf3",
            "Kg1",
            "Rxg2+",
            "Kf1",
            "Rh2",
            "b4",
            "Be2+",
            "Kg1",
            "Bxa6",
            "Kxh2",
            "Bc4",
            "a4",
            "Kf5",
            "b5",
            "Ke6",
            "b6",
            "Kd7",
            "a5",
            "Kc6",
            "Kg2",
            "Kb5",
            "b7",
            "Bd5+",
            "Kf2",
            "Bxb7",
            "Ke3",
            "Kxa5",
            "Kd4",
            "Bg2",
            "Kc5",
            "Bxh3",
            "Kd6",
            "g4",
            "Ke6",
            "g3+",
            "Kxf6",
            "g2",
            "Kg5",
            "g1=Q+",
            "Kxh4",
            "Qg4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8d1",
          "positional_uci": "d8d1",
          "neutral_uci": "d8d1",
          "consensus_move": "d8d1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf2",
              "Rd2+",
              "Kg3",
              "h5",
              "Ra6",
              "h4+",
              "Kh2",
              "Bxf3",
              "Kg1",
              "Rxg2+",
              "Kf1",
              "Rh2",
              "b4",
              "Be2+",
              "Kg1",
              "Bxa6",
              "Kxh2",
              "Bc4",
              "a4",
              "Kf5",
              "b5",
              "Ke6",
              "b6",
              "Kd6",
              "a5",
              "Kc6",
              "Kg2",
              "Kb5",
              "b7",
              "Bd5+",
              "Kf2",
              "Bxb7",
              "Ke3",
              "Kxa5",
              "Kd4",
              "Bg2",
              "Kc5",
              "Bxh3",
              "Kd6",
              "g4",
              "Ke6",
              "g3+",
              "Kxf6",
              "g2",
              "Kg5",
              "g1=Q+",
              "Kxh4",
              "Qg4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf2",
              "Rd2+",
              "Kg3",
              "h5",
              "Rxa7",
              "h4+",
              "Kh2",
              "Rxb2",
              "a4",
              "Kf5",
              "a5",
              "Kf4",
              "a6",
              "Ke3",
              "Re7+",
              "Kf2",
              "a7",
              "Kf1",
              "a8=Q",
              "Rxg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh1",
              "Rg1+",
              "Kh2",
              "Rg2+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf2",
              "Rd2+",
              "Kg3",
              "h5",
              "Ra6",
              "h4+",
              "Kh2",
              "Bxf3",
              "Kg1",
              "Rxg2+",
              "Kf1",
              "Rh2",
              "b4",
              "Be2+",
              "Kg1",
              "Bxa6",
              "Kxh2",
              "Bc4",
              "a4",
              "Kf5",
              "b5",
              "Ke6",
              "b6",
              "Kd7",
              "a5",
              "Kc6",
              "Kg2",
              "Kb5",
              "b7",
              "Bd5+",
              "Kf2",
              "Bxb7",
              "Ke3",
              "Kxa5",
              "Kd4",
              "Bg2",
              "Kc5",
              "Bxh3",
              "Kd6",
              "g4",
              "Ke6",
              "g3+",
              "Kxf6",
              "g2",
              "Kg5",
              "g1=Q+",
              "Kxh4",
              "Qg4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 355,
            "completion_tokens": 522,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 355,
            "completion_tokens": 640,
            "total_tokens": 995,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 354,
            "completion_tokens": 522,
            "total_tokens": 876,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1064,
          "total_completion_tokens": 1684,
          "total_tokens": 2748
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 355,
            "completion_tokens": 522,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 355,
            "completion_tokens": 640,
            "total_tokens": 995,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 354,
            "completion_tokens": 522,
            "total_tokens": 876,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/p3qrkp/2b2p2/6p1/8/2Q5/PP3PPP/6K1 w - - 2 30"
    },
    {
      "turn": 61,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re1",
          "aggressive_uci": "d1e1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. f3 Rd7 33. h3\nQd4+ 34. Qxd4 Rxd4 35. Re7+ Kg6 36. Rxa7 Rd2 37. b3 h5 38. Ra6 Bd5 39. Ra5 g4\n40. hxg4 hxg4 41. fxg4 Rxg2+ 42. Kf1 Rd2 43. Ke1 Rd4 44. Ke2 Be6 45. g5 fxg5\n46. Ke3 Rd5 47. Ra6 Kf5 48. b4 g4 49. Ra8 Re5+ 50. Kf2 Kf4 51. Rf8+ Bf5 52.\na4 g3+ 53. Kg2 Re2+ 54. Kf1 Rb2 55. b5 g2+ 56. Kg1 Kg3 57. Rg8+ Bg4 58. Rxg4+\nKxg4 59. Kh2 Kf3 60. b6 Rb1 61. Kh3 Rh1#",
          "aggressive_tokens": {
            "prompt_tokens": 363,
            "completion_tokens": 508,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd5",
            "f3",
            "Rd7",
            "h3",
            "Qd4+",
            "Qxd4",
            "Rxd4",
            "Re7+",
            "Kg6",
            "Rxa7",
            "Rd2",
            "b3",
            "h5",
            "Ra6",
            "Bd5",
            "Ra5",
            "g4",
            "hxg4",
            "hxg4",
            "fxg4",
            "Rxg2+",
            "Kf1",
            "Rd2",
            "Ke1",
            "Rd4",
            "Ke2",
            "Be6",
            "g5",
            "fxg5",
            "Ke3",
            "Rd5",
            "Ra6",
            "Kf5",
            "b4",
            "g4",
            "Ra8",
            "Re5+",
            "Kf2",
            "Kf4",
            "Rf8+",
            "Bf5",
            "a4",
            "g3+",
            "Kg2",
            "Re2+",
            "Kf1",
            "Rb2",
            "b5",
            "g2+",
            "Kg1",
            "Kg3",
            "Rg8+",
            "Bg4",
            "Rxg4+",
            "Kxg4",
            "Kh2",
            "Kf3",
            "b6",
            "Rb1",
            "Kh3",
            "Rh1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "d1e1",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. f3 Rd7 33. h3\nQd4+ 34. Qxd4 Rxd4 35. Re7+ Kg6 36. Rxa7 Rd2 37. b4 Bd5 38. a4 Rb2 39. b5 Bb3\n40. b6 Bxa4 41. Rxa4 Rxb6 42. Ra7 h5 43. Kh2 h4 44. Ra4 Rb2 45. f4 Rf2 46.\nfxg5 fxg5 47. Ra6+ Kh5 48. Ra8 Rb2 49. Rh8+ Kg6 50. Rg8+ Kh6 51. Rh8+ Kg7 52.\nRh5 Kg6 53. Rh8 Rb7 54. Rg8+ Rg7 55. Rxg7+ Kxg7 56. g3 hxg3+ 57. Kxg3 Kg6 58.\nKg4 Kh6 59. h4 gxh4 60. Kxh4 *",
          "positional_tokens": {
            "prompt_tokens": 363,
            "completion_tokens": 502,
            "total_tokens": 865,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd5",
            "f3",
            "Rd7",
            "h3",
            "Qd4+",
            "Qxd4",
            "Rxd4",
            "Re7+",
            "Kg6",
            "Rxa7",
            "Rd2",
            "b4",
            "Bd5",
            "a4",
            "Rb2",
            "b5",
            "Bb3",
            "b6",
            "Bxa4",
            "Rxa4",
            "Rxb6",
            "Ra7",
            "h5",
            "Kh2",
            "h4",
            "Ra4",
            "Rb2",
            "f4",
            "Rf2",
            "fxg5",
            "fxg5",
            "Ra6+",
            "Kh5",
            "Ra8",
            "Rb2",
            "Rh8+",
            "Kg6",
            "Rg8+",
            "Kh6",
            "Rh8+",
            "Kg7",
            "Rh5",
            "Kg6",
            "Rh8",
            "Rb7",
            "Rg8+",
            "Rg7",
            "Rxg7+",
            "Kxg7",
            "g3",
            "hxg3+",
            "Kxg3",
            "Kg6",
            "Kg4",
            "Kh6",
            "h4",
            "gxh4",
            "Kxh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re1",
          "neutral_uci": "d1e1",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. f3 Rd7 33. h3\nQd4+ 34. Qxd4 Rxd4 35. Re7+ Kg6 36. Rxa7 Rd1+ 37. Kh2 Rd2 38. Kg3 Rxb2 39. a4\nh5 40. a5 h4+ 41. Kh2 Bxf3 42. Kg1 Rxg2+ 43. Kf1 Ra2 44. a6 Bg2+ 45. Kg1 Bxh3\n46. Ra8 Bg2 47. Rg8+ Kf5 48. a7 h3 49. Rh8 Rxa7 50. Kh2 Ra1 51. Kg3 Ra3+ 52.\nKh2 g4 53. Rh5+ Kf4 54. Rh4 f5 55. Rh5 g3+ 56. Kg1 Ra1#",
          "neutral_tokens": {
            "prompt_tokens": 362,
            "completion_tokens": 466,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd5",
            "f3",
            "Rd7",
            "h3",
            "Qd4+",
            "Qxd4",
            "Rxd4",
            "Re7+",
            "Kg6",
            "Rxa7",
            "Rd1+",
            "Kh2",
            "Rd2",
            "Kg3",
            "Rxb2",
            "a4",
            "h5",
            "a5",
            "h4+",
            "Kh2",
            "Bxf3",
            "Kg1",
            "Rxg2+",
            "Kf1",
            "Ra2",
            "a6",
            "Bg2+",
            "Kg1",
            "Bxh3",
            "Ra8",
            "Bg2",
            "Rg8+",
            "Kf5",
            "a7",
            "h3",
            "Rh8",
            "Rxa7",
            "Kh2",
            "Ra1",
            "Kg3",
            "Ra3+",
            "Kh2",
            "g4",
            "Rh5+",
            "Kf4",
            "Rh4",
            "f5",
            "Rh5",
            "g3+",
            "Kg1",
            "Ra1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1e1",
          "positional_uci": "d1e1",
          "neutral_uci": "d1e1",
          "consensus_move": "d1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd5",
              "f3",
              "Rd7",
              "h3",
              "Qd4+",
              "Qxd4",
              "Rxd4",
              "Re7+",
              "Kg6",
              "Rxa7",
              "Rd2",
              "b3",
              "h5",
              "Ra6",
              "Bd5",
              "Ra5",
              "g4",
              "hxg4",
              "hxg4",
              "fxg4",
              "Rxg2+",
              "Kf1",
              "Rd2",
              "Ke1",
              "Rd4",
              "Ke2",
              "Be6",
              "g5",
              "fxg5",
              "Ke3",
              "Rd5",
              "Ra6",
              "Kf5",
              "b4",
              "g4",
              "Ra8",
              "Re5+",
              "Kf2",
              "Kf4",
              "Rf8+",
              "Bf5",
              "a4",
              "g3+",
              "Kg2",
              "Re2+",
              "Kf1",
              "Rb2",
              "b5",
              "g2+",
              "Kg1",
              "Kg3",
              "Rg8+",
              "Bg4",
              "Rxg4+",
              "Kxg4",
              "Kh2",
              "Kf3",
              "b6",
              "Rb1",
              "Kh3",
              "Rh1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd5",
              "f3",
              "Rd7",
              "h3",
              "Qd4+",
              "Qxd4",
              "Rxd4",
              "Re7+",
              "Kg6",
              "Rxa7",
              "Rd2",
              "b4",
              "Bd5",
              "a4",
              "Rb2",
              "b5",
              "Bb3",
              "b6",
              "Bxa4",
              "Rxa4",
              "Rxb6",
              "Ra7",
              "h5",
              "Kh2",
              "h4",
              "Ra4",
              "Rb2",
              "f4",
              "Rf2",
              "fxg5",
              "fxg5",
              "Ra6+",
              "Kh5",
              "Ra8",
              "Rb2",
              "Rh8+",
              "Kg6",
              "Rg8+",
              "Kh6",
              "Rh8+",
              "Kg7",
              "Rh5",
              "Kg6",
              "Rh8",
              "Rb7",
              "Rg8+",
              "Rg7",
              "Rxg7+",
              "Kxg7",
              "g3",
              "hxg3+",
              "Kxg3",
              "Kg6",
              "Kg4",
              "Kh6",
              "h4",
              "gxh4",
              "Kxh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd5",
              "f3",
              "Rd7",
              "h3",
              "Qd4+",
              "Qxd4",
              "Rxd4",
              "Re7+",
              "Kg6",
              "Rxa7",
              "Rd1+",
              "Kh2",
              "Rd2",
              "Kg3",
              "Rxb2",
              "a4",
              "h5",
              "a5",
              "h4+",
              "Kh2",
              "Bxf3",
              "Kg1",
              "Rxg2+",
              "Kf1",
              "Ra2",
              "a6",
              "Bg2+",
              "Kg1",
              "Bxh3",
              "Ra8",
              "Bg2",
              "Rg8+",
              "Kf5",
              "a7",
              "h3",
              "Rh8",
              "Rxa7",
              "Kh2",
              "Ra1",
              "Kg3",
              "Ra3+",
              "Kh2",
              "g4",
              "Rh5+",
              "Kf4",
              "Rh4",
              "f5",
              "Rh5",
              "g3+",
              "Kg1",
              "Ra1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 363,
            "completion_tokens": 508,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 363,
            "completion_tokens": 502,
            "total_tokens": 865,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 362,
            "completion_tokens": 466,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1088,
          "total_completion_tokens": 1476,
          "total_tokens": 2564
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 363,
            "completion_tokens": 508,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 363,
            "completion_tokens": 502,
            "total_tokens": 865,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 362,
            "completion_tokens": 466,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/p4rkp/2b1qp2/6p1/8/2Q5/PP3PPP/3R2K1 w - - 4 31"
    },
    {
      "turn": 63,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qg3",
          "aggressive_uci": "c3g3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 h6 33. h4 Qxa2 34. hxg5 hxg5 35. Qc3 Qd5 36. f3 Rd7 37. Kh1 Qd4 38. Qxc6 Qh4+ 39. Kg1 Qxe1+ 40. Kh2 Qh4+ 41. Kg1 Rd1#",
          "aggressive_tokens": {
            "prompt_tokens": 371,
            "completion_tokens": 347,
            "total_tokens": 718,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "h4",
            "Qxa2",
            "hxg5",
            "hxg5",
            "Qc3",
            "Qd5",
            "f3",
            "Rd7",
            "Kh1",
            "Qd4",
            "Qxc6",
            "Qh4+",
            "Kg1",
            "Qxe1+",
            "Kh2",
            "Qh4+",
            "Kg1",
            "Rd1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qg3",
          "positional_uci": "c3g3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 h6 33. h4 Qxa2 34. hxg5 hxg5 35. Qc3 Qd5 36. f3 Rd7 37. Kh1 Qd4 38. Qxd4 Rxd4 39. Re7+ Kg6 40. Rxa7 Rd2 41. Ra6 Bd5 42. Rd6 Kf5 43. b4 Ke5 44. Rd8 Rb2 45. Rb8 Kf4 46. Kh2 Bxf3 47. Rf8 Rxg2+ 48. Kh3 g4+ 49. Kh4 Rh2#",
          "positional_tokens": {
            "prompt_tokens": 371,
            "completion_tokens": 409,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "h4",
            "Qxa2",
            "hxg5",
            "hxg5",
            "Qc3",
            "Qd5",
            "f3",
            "Rd7",
            "Kh1",
            "Qd4",
            "Qxd4",
            "Rxd4",
            "Re7+",
            "Kg6",
            "Rxa7",
            "Rd2",
            "Ra6",
            "Bd5",
            "Rd6",
            "Kf5",
            "b4",
            "Ke5",
            "Rd8",
            "Rb2",
            "Rb8",
            "Kf4",
            "Kh2",
            "Bxf3",
            "Rf8",
            "Rxg2+",
            "Kh3",
            "g4+",
            "Kh4",
            "Rh2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qg3",
          "neutral_uci": "c3g3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 h6 33. h4 Qxa2 34. hxg5 hxg5 35. Qc3 Qd5 36. f3 Rd7 37. Kh2 Qd6+ 38. Kh1 Kg6 39. Qc2+ f5 40. Qc4 Rh7+ 41. Kg1 Qh2+ 42. Kf2 Qh4+ 43. Qxh4 Rxh4 44. Re6+ Kh5 45. Rxc6 Rb4 46. Rc2 a5 47. Kg3 f4+ 48. Kh3 a4 49. g4+ fxg3 50. Kxg3 Rb3 51. Rh2+ Kg6 52. Kg4 Rb4+ 53. Kg3 Kf5 54. Rc2 Rb5 55. Rc4 Rxb2 56. Rxa4 Rb5 57. Ra8 Rb6 58. Rf8+ Rf6 59. Rxf6+ Kxf6 60. Kg4 Kg6 61. f4 gxf4 62. Kxf4 1/2-1/2\nd5 e6 Nf3 Nc6 Bb5 Bxb5 Qd5 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rc1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe6 Re1 Qd5 Qe7 Qd6 Q",
          "neutral_tokens": {
            "prompt_tokens": 370,
            "completion_tokens": 640,
            "total_tokens": 1010,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h6",
            "h4",
            "Qxa2",
            "hxg5",
            "hxg5",
            "Qc3",
            "Qd5",
            "f3",
            "Rd7",
            "Kh2",
            "Qd6+",
            "Kh1",
            "Kg6",
            "Qc2+",
            "f5",
            "Qc4",
            "Rh7+",
            "Kg1",
            "Qh2+",
            "Kf2",
            "Qh4+",
            "Qxh4",
            "Rxh4",
            "Re6+",
            "Kh5",
            "Rxc6",
            "Rb4",
            "Rc2",
            "a5",
            "Kg3",
            "f4+",
            "Kh3",
            "a4",
            "g4+",
            "fxg3",
            "Kxg3",
            "Rb3",
            "Rh2+",
            "Kg6",
            "Kg4",
            "Rb4+",
            "Kg3",
            "Kf5",
            "Rc2",
            "Rb5",
            "Rc4",
            "Rxb2",
            "Rxa4",
            "Rb5",
            "Ra8",
            "Rb6",
            "Rf8+",
            "Rf6",
            "Rxf6+",
            "Kxf6",
            "Kg4",
            "Kg6",
            "f4",
            "gxf4",
            "Kxf4",
            "d5",
            "e6",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bxb5",
            "Qd5",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe6",
            "Re1",
            "Qd5",
            "Qe7",
            "Qd6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c3g3",
          "positional_uci": "c3g3",
          "neutral_uci": "c3g3",
          "consensus_move": "c3g3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h6",
              "h4",
              "Qxa2",
              "hxg5",
              "hxg5",
              "Qc3",
              "Qd5",
              "f3",
              "Rd7",
              "Kh1",
              "Qd4",
              "Qxc6",
              "Qh4+",
              "Kg1",
              "Qxe1+",
              "Kh2",
              "Qh4+",
              "Kg1",
              "Rd1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h6",
              "h4",
              "Qxa2",
              "hxg5",
              "hxg5",
              "Qc3",
              "Qd5",
              "f3",
              "Rd7",
              "Kh1",
              "Qd4",
              "Qxd4",
              "Rxd4",
              "Re7+",
              "Kg6",
              "Rxa7",
              "Rd2",
              "Ra6",
              "Bd5",
              "Rd6",
              "Kf5",
              "b4",
              "Ke5",
              "Rd8",
              "Rb2",
              "Rb8",
              "Kf4",
              "Kh2",
              "Bxf3",
              "Rf8",
              "Rxg2+",
              "Kh3",
              "g4+",
              "Kh4",
              "Rh2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h6",
              "h4",
              "Qxa2",
              "hxg5",
              "hxg5",
              "Qc3",
              "Qd5",
              "f3",
              "Rd7",
              "Kh2",
              "Qd6+",
              "Kh1",
              "Kg6",
              "Qc2+",
              "f5",
              "Qc4",
              "Rh7+",
              "Kg1",
              "Qh2+",
              "Kf2",
              "Qh4+",
              "Qxh4",
              "Rxh4",
              "Re6+",
              "Kh5",
              "Rxc6",
              "Rb4",
              "Rc2",
              "a5",
              "Kg3",
              "f4+",
              "Kh3",
              "a4",
              "g4+",
              "fxg3",
              "Kxg3",
              "Rb3",
              "Rh2+",
              "Kg6",
              "Kg4",
              "Rb4+",
              "Kg3",
              "Kf5",
              "Rc2",
              "Rb5",
              "Rc4",
              "Rxb2",
              "Rxa4",
              "Rb5",
              "Ra8",
              "Rb6",
              "Rf8+",
              "Rf6",
              "Rxf6+",
              "Kxf6",
              "Kg4",
              "Kg6",
              "f4",
              "gxf4",
              "Kxf4",
              "d5",
              "e6",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bxb5",
              "Qd5",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe6",
              "Re1",
              "Qd5",
              "Qe7",
              "Qd6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 371,
            "completion_tokens": 347,
            "total_tokens": 718,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 371,
            "completion_tokens": 409,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 370,
            "completion_tokens": 640,
            "total_tokens": 1010,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1112,
          "total_completion_tokens": 1396,
          "total_tokens": 2508
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 371,
            "completion_tokens": 347,
            "total_tokens": 718,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 371,
            "completion_tokens": 409,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 370,
            "completion_tokens": 640,
            "total_tokens": 1010,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/p4rkp/2b2p2/3q2p1/8/2Q5/PP3PPP/4R1K1 w - - 6 32"
    },
    {
      "turn": 65,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h4",
          "aggressive_uci": "h2h4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4 h6 34. hxg5 hxg5 35. f4 Qd4+ 36. Kh2 Qxf4 37. Qxf4 gxf4 38. Rf1 Re7 39. Rxf4 Re2 40. Rg4+ Kf7 41. Rc4 Bxg2 42. Rc7+ Kg6 43. Ra7 Rxb2 44. Rxa5 Bd5+ 45. Kg3 Bxa2 46. Ra4 Be6 47. Ra6 Bf5 48. Ra5 Kg5 49. Ra4 Rb3+ 50. Kf2 Bg4 51. Ra5+ f5 52. Ra4 f4 53. Ra5+ Kh4 54. Ra4 Rb2+ 55. Kg1 Kg3 56. Ra3+ f3 57. Ra1 Bh3 58. Kh1 Rh2+ 59. Kg1 f2#",
          "aggressive_tokens": {
            "prompt_tokens": 379,
            "completion_tokens": 490,
            "total_tokens": 869,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "hxg5",
            "hxg5",
            "f4",
            "Qd4+",
            "Kh2",
            "Qxf4",
            "Qxf4",
            "gxf4",
            "Rf1",
            "Re7",
            "Rxf4",
            "Re2",
            "Rg4+",
            "Kf7",
            "Rc4",
            "Bxg2",
            "Rc7+",
            "Kg6",
            "Ra7",
            "Rxb2",
            "Rxa5",
            "Bd5+",
            "Kg3",
            "Bxa2",
            "Ra4",
            "Be6",
            "Ra6",
            "Bf5",
            "Ra5",
            "Kg5",
            "Ra4",
            "Rb3+",
            "Kf2",
            "Bg4",
            "Ra5+",
            "f5",
            "Ra4",
            "f4",
            "Ra5+",
            "Kh4",
            "Ra4",
            "Rb2+",
            "Kg1",
            "Kg3",
            "Ra3+",
            "f3",
            "Ra1",
            "Bh3",
            "Kh1",
            "Rh2+",
            "Kg1",
            "f2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h4",
          "positional_uci": "h2h4",
          "positional_response": "33. h4 h6 34. hxg5 hxg5 35. f4 Qd4+ 36. Kh1 Kg6 37. fxg5 Rh7+ 38. Qh2 Rxh2+ 39. Kxh2 Qh4+ 40. Kg1 Qxe1+ 41. Kh2 Qf2 42. gxf6 Qxg2#",
          "positional_tokens": {
            "prompt_tokens": 379,
            "completion_tokens": 90,
            "total_tokens": 469,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "hxg5",
            "hxg5",
            "f4",
            "Qd4+",
            "Kh1",
            "Kg6",
            "fxg5",
            "Rh7+",
            "Qh2",
            "Rxh2+",
            "Kxh2",
            "Qh4+",
            "Kg1",
            "Qxe1+",
            "Kh2",
            "Qf2",
            "gxf6",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "h4",
          "neutral_uci": "h2h4",
          "neutral_response": "33. h4 h6 34. hxg5 hxg5 35. f4 Qd4+ 36. Kh1 Kg6 37. fxg5 Rh7+ 38. Qh2 Rxh2+ 39. Kxh2 Qh4+ 40. Kg1 Qxe1+ 41. Kh2 Qf2 42. Kh3 Qxg2+ 43. Kh4 fxg5#",
          "neutral_tokens": {
            "prompt_tokens": 378,
            "completion_tokens": 98,
            "total_tokens": 476,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "hxg5",
            "hxg5",
            "f4",
            "Qd4+",
            "Kh1",
            "Kg6",
            "fxg5",
            "Rh7+",
            "Qh2",
            "Rxh2+",
            "Kxh2",
            "Qh4+",
            "Kg1",
            "Qxe1+",
            "Kh2",
            "Qf2",
            "Kh3",
            "Qxg2+",
            "Kh4",
            "fxg5#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h2h4",
          "positional_uci": "h2h4",
          "neutral_uci": "h2h4",
          "consensus_move": "h2h4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h6",
              "hxg5",
              "hxg5",
              "f4",
              "Qd4+",
              "Kh2",
              "Qxf4",
              "Qxf4",
              "gxf4",
              "Rf1",
              "Re7",
              "Rxf4",
              "Re2",
              "Rg4+",
              "Kf7",
              "Rc4",
              "Bxg2",
              "Rc7+",
              "Kg6",
              "Ra7",
              "Rxb2",
              "Rxa5",
              "Bd5+",
              "Kg3",
              "Bxa2",
              "Ra4",
              "Be6",
              "Ra6",
              "Bf5",
              "Ra5",
              "Kg5",
              "Ra4",
              "Rb3+",
              "Kf2",
              "Bg4",
              "Ra5+",
              "f5",
              "Ra4",
              "f4",
              "Ra5+",
              "Kh4",
              "Ra4",
              "Rb2+",
              "Kg1",
              "Kg3",
              "Ra3+",
              "f3",
              "Ra1",
              "Bh3",
              "Kh1",
              "Rh2+",
              "Kg1",
              "f2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h6",
              "hxg5",
              "hxg5",
              "f4",
              "Qd4+",
              "Kh1",
              "Kg6",
              "fxg5",
              "Rh7+",
              "Qh2",
              "Rxh2+",
              "Kxh2",
              "Qh4+",
              "Kg1",
              "Qxe1+",
              "Kh2",
              "Qf2",
              "gxf6",
              "Qxg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h6",
              "hxg5",
              "hxg5",
              "f4",
              "Qd4+",
              "Kh1",
              "Kg6",
              "fxg5",
              "Rh7+",
              "Qh2",
              "Rxh2+",
              "Kxh2",
              "Qh4+",
              "Kg1",
              "Qxe1+",
              "Kh2",
              "Qf2",
              "Kh3",
              "Qxg2+",
              "Kh4",
              "fxg5#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 379,
            "completion_tokens": 490,
            "total_tokens": 869,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 379,
            "completion_tokens": 90,
            "total_tokens": 469,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 378,
            "completion_tokens": 98,
            "total_tokens": 476,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1136,
          "total_completion_tokens": 678,
          "total_tokens": 1814
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 379,
            "completion_tokens": 490,
            "total_tokens": 869,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 379,
            "completion_tokens": 90,
            "total_tokens": 469,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 378,
            "completion_tokens": 98,
            "total_tokens": 476,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/5rkp/2b2p2/p2q2p1/8/6Q1/PP3PPP/4R1K1 w - - 0 33"
    },
    {
      "turn": 67,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "hxg5",
          "aggressive_uci": "h4g5",
          "aggressive_response": "34. hxg5 Qxg5 35. Qh3 Rd3 36. Re7+ Kf8 37. Qc8+ Kxe7 38. Qc7+ Bd7 39. Qc2 Qd5 40. Qe2+ Kf7 41. Kh2 Qd6+ 42. g3 Rd2 43. Qh5+ Kg7 44. Qf3 Qd4 45. Kg1 Rd1+ 46. Kh2 Qd5 47. Qxd5 Rxd5 48. Kg2 Rd2 49. Kf3 Rxb2 50. a3 Ra2 51. Ke3 Rxa3+ 52. Kd4 Rf3 53. Kc5 Rxf2 54. Kd6 a4 55. Kxd7 a3 56. Kc6 a2 57. Kd5 a1=Q 58. Kc4 Qa4+ 59. Kd3 Rf3+ 60. Ke2 Qe4+ 61. Kd2 Qd3+ 62. Kc1 Rf1+ 63. Kb2 Rb1+ 64. Ka2 Qb3# Rb1 65. g4 Qb2# Rb1 66. g5 Qb3# Rb1 67. gxf6+ Kf8 68. f7 Qb2# Rb1 69. f4 Qb3# Rb1 70. f5 Qb2# Rb1 71. f6 Qb3# Rb1 72. f7 Qb2# Rb1 73. f8=Q#",
          "aggressive_tokens": {
            "prompt_tokens": 388,
            "completion_tokens": 380,
            "total_tokens": 768,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg5",
            "Qh3",
            "Rd3",
            "Re7+",
            "Kf8",
            "Qc8+",
            "Kxe7",
            "Qc7+",
            "Bd7",
            "Qc2",
            "Qd5",
            "Qe2+",
            "Kf7",
            "Kh2",
            "Qd6+",
            "g3",
            "Rd2",
            "Qh5+",
            "Kg7",
            "Qf3",
            "Qd4",
            "Kg1",
            "Rd1+",
            "Kh2",
            "Qd5",
            "Qxd5",
            "Rxd5",
            "Kg2",
            "Rd2",
            "Kf3",
            "Rxb2",
            "a3",
            "Ra2",
            "Ke3",
            "Rxa3+",
            "Kd4",
            "Rf3",
            "Kc5",
            "Rxf2",
            "Kd6",
            "a4",
            "Kxd7",
            "a3",
            "Kc6",
            "a2",
            "Kd5",
            "a1=Q",
            "Kc4",
            "Qa4+",
            "Kd3",
            "Rf3+",
            "Ke2",
            "Qe4+",
            "Kd2",
            "Qd3+",
            "Kc1",
            "Rf1+",
            "Kb2",
            "Rb1+",
            "Ka2",
            "Qb3#",
            "Rb1",
            "g4",
            "Qb2#",
            "Rb1",
            "g5",
            "Qb3#",
            "Rb1",
            "gxf6+",
            "Kf8",
            "f7",
            "Qb2#",
            "Rb1",
            "f4",
            "Qb3#",
            "Rb1",
            "f5",
            "Qb2#",
            "Rb1",
            "f6",
            "Qb3#",
            "Rb1",
            "f7",
            "Qb2#",
            "Rb1",
            "f8=Q#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "hxg5",
          "positional_uci": "h4g5",
          "positional_response": "34. hxg5 Qxg5 35. Qh3 Rd3 36. Re7+ Kf8 37. Qc8+ Kxe7 38. Qc7+ Bd7 39. Qc2 Qd5 40. Qe2+ Kd8 41. f3 Rd1+ 42. Kf2 Rd2 43. Ke1 Rxe2+ 44. Kxe2 Bb5+ 45. Kf2 Qd4+ 46. Kg3 Qe5+ 47. Kf2 Qxb2+ 48. Kg3 Qxa2 49. Kf4 Qxg2 50. Ke3 Qe2+ 51. Kf4 Qe5+ 52. Kg4 Bd7+ 53. Kh4 Qg5#",
          "positional_tokens": {
            "prompt_tokens": 388,
            "completion_tokens": 183,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg5",
            "Qh3",
            "Rd3",
            "Re7+",
            "Kf8",
            "Qc8+",
            "Kxe7",
            "Qc7+",
            "Bd7",
            "Qc2",
            "Qd5",
            "Qe2+",
            "Kd8",
            "f3",
            "Rd1+",
            "Kf2",
            "Rd2",
            "Ke1",
            "Rxe2+",
            "Kxe2",
            "Bb5+",
            "Kf2",
            "Qd4+",
            "Kg3",
            "Qe5+",
            "Kf2",
            "Qxb2+",
            "Kg3",
            "Qxa2",
            "Kf4",
            "Qxg2",
            "Ke3",
            "Qe2+",
            "Kf4",
            "Qe5+",
            "Kg4",
            "Bd7+",
            "Kh4",
            "Qg5#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "hxg5",
          "neutral_uci": "h4g5",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 Qxg5 35. Qh3 Rd3 36. Re7+ Kf8 37. Qc8+ Kxe7 38. Qxc6 Rd1+ 39. Kh2 Qh4# R\n1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 Qxg5 35. Qh3 Rd3 36. Re7+ Kf",
          "neutral_tokens": {
            "prompt_tokens": 387,
            "completion_tokens": 640,
            "total_tokens": 1027,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxg5",
            "Qh3",
            "Rd3",
            "Re7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4g5",
          "positional_uci": "h4g5",
          "neutral_uci": "h4g5",
          "consensus_move": "h4g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxg5",
              "Qh3",
              "Rd3",
              "Re7+",
              "Kf8",
              "Qc8+",
              "Kxe7",
              "Qc7+",
              "Bd7",
              "Qc2",
              "Qd5",
              "Qe2+",
              "Kf7",
              "Kh2",
              "Qd6+",
              "g3",
              "Rd2",
              "Qh5+",
              "Kg7",
              "Qf3",
              "Qd4",
              "Kg1",
              "Rd1+",
              "Kh2",
              "Qd5",
              "Qxd5",
              "Rxd5",
              "Kg2",
              "Rd2",
              "Kf3",
              "Rxb2",
              "a3",
              "Ra2",
              "Ke3",
              "Rxa3+",
              "Kd4",
              "Rf3",
              "Kc5",
              "Rxf2",
              "Kd6",
              "a4",
              "Kxd7",
              "a3",
              "Kc6",
              "a2",
              "Kd5",
              "a1=Q",
              "Kc4",
              "Qa4+",
              "Kd3",
              "Rf3+",
              "Ke2",
              "Qe4+",
              "Kd2",
              "Qd3+",
              "Kc1",
              "Rf1+",
              "Kb2",
              "Rb1+",
              "Ka2",
              "Qb3#",
              "Rb1",
              "g4",
              "Qb2#",
              "Rb1",
              "g5",
              "Qb3#",
              "Rb1",
              "gxf6+",
              "Kf8",
              "f7",
              "Qb2#",
              "Rb1",
              "f4",
              "Qb3#",
              "Rb1",
              "f5",
              "Qb2#",
              "Rb1",
              "f6",
              "Qb3#",
              "Rb1",
              "f7",
              "Qb2#",
              "Rb1",
              "f8=Q#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxg5",
              "Qh3",
              "Rd3",
              "Re7+",
              "Kf8",
              "Qc8+",
              "Kxe7",
              "Qc7+",
              "Bd7",
              "Qc2",
              "Qd5",
              "Qe2+",
              "Kd8",
              "f3",
              "Rd1+",
              "Kf2",
              "Rd2",
              "Ke1",
              "Rxe2+",
              "Kxe2",
              "Bb5+",
              "Kf2",
              "Qd4+",
              "Kg3",
              "Qe5+",
              "Kf2",
              "Qxb2+",
              "Kg3",
              "Qxa2",
              "Kf4",
              "Qxg2",
              "Ke3",
              "Qe2+",
              "Kf4",
              "Qe5+",
              "Kg4",
              "Bd7+",
              "Kh4",
              "Qg5#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxg5",
              "Qh3",
              "Rd3",
              "Re7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 388,
            "completion_tokens": 380,
            "total_tokens": 768,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 388,
            "completion_tokens": 183,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 387,
            "completion_tokens": 640,
            "total_tokens": 1027,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1163,
          "total_completion_tokens": 1203,
          "total_tokens": 2366
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 388,
            "completion_tokens": 380,
            "total_tokens": 768,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 388,
            "completion_tokens": 183,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 387,
            "completion_tokens": 640,
            "total_tokens": 1027,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/3r2kp/2b2p2/p2q2p1/7P/6Q1/PP3PP1/4R1K1 w - - 1 34"
    },
    {
      "turn": 69,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re5",
          "aggressive_uci": "e1e5",
          "aggressive_response": "35. Re5 Qd1+ 36. Kh2 Qh5+ 37. Qh3 Qxh3+ 38. Kxh3 Rd5 39. Re7+ Kf6 40. Rxh7 Bd7+ 41. Kg3 Rd3+ 42. f3 Rd2 43. Rh6+ Ke5 44. Ra6 a4 45. Ra5+ Kf6 46. Ra6+ Be6 47. Rxa4 Rxb2 48. Ra6 Ke5 49. Ra5+ Bd5 50. a4 Ra2 51. Ra7 Bc4 52. Ra5+ Kf6 53. Ra7 Bf1 54. a5 Rxg2+ 55. Kh3 Rf2+ 56. Kg3 Rg2+ 57. Kh3 Rg1+ 58. Kh2 Rg2+ 59. Kh3 Ra2+ 60. Kg3 Rg2+ 61. Kh3 Rg1+ 62. Kh2 Rg2+ 63. Kh3 Ra2+ 64. Kg3 Rg2+ 65. Kh3 Rg1+ 66. Kh2 Rg2+ 67. Kh3 Ra2+ 68. Kg3 Rg2+ 69. Kh3 Rg1+ 70. Kh2 Rg2+ 71. Kh3 Ra2+ 72. Kg3 Rg2+ 73. Kh3 Rg1+ 74. Kh2 Rg2+ 75. Kh3 Ra2+ 76. Kg3 Rg2+ 77. Kh3 Rg1+ 78. Kh2 Rg2+ 79. Kh3 Ra2+ 80. Kg3 Rg2+ 81. Kh3 Rg1+ 82. Kh2 Rg2+ 83. Kh3 Ra2+ 84. Kg3 Rg2+ 85. Kh3 Rg1+ 86. Kh2 Rg2+ 87. Kh3 Ra2+ 88. Kg3 Rg2+ 89. Kh3 Rg1+ 90. Kh2 Rg2+ 91. Kh3 Ra2+ 92. Kg3 Rg2+ 93. Kh3 Rg1+ 94. Kh2 Rg2+ 95. Kh3 Ra2+ 96. Kg3 Rg2+ 97. Kh3 Rg1+ 98. Kh2 Rg2+ 99. Kh3 Ra2+ 100. Kg3 Rg2+ 101. Kh3 Rg1+ 102. Kh2 Rg2+ 103. Kh3 Ra2+ 104. Kg3 Rg2+ 105. Kh3 Rg1+ 106. Kh2 Rg2+ 107. Kh3 Ra2+ 108. Kg3 Rg2",
          "aggressive_tokens": {
            "prompt_tokens": 397,
            "completion_tokens": 640,
            "total_tokens": 1037,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Qh3",
            "Qxh3+",
            "Kxh3",
            "Rd5",
            "Re7+",
            "Kf6",
            "Rxh7",
            "Bd7+",
            "Kg3",
            "Rd3+",
            "f3",
            "Rd2",
            "Rh6+",
            "Ke5",
            "Ra6",
            "a4",
            "Ra5+",
            "Kf6",
            "Ra6+",
            "Be6",
            "Rxa4",
            "Rxb2",
            "Ra6",
            "Ke5",
            "Ra5+",
            "Bd5",
            "a4",
            "Ra2",
            "Ra7",
            "Bc4",
            "Ra5+",
            "Kf6",
            "Ra7",
            "Bf1",
            "a5",
            "Rxg2+",
            "Kh3",
            "Rf2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re5",
          "positional_uci": "e1e5",
          "positional_response": "35. Re5 Qd1+ 36. Kh2 Qh5+ 37. Qh3 Qxh3+ 38. Kxh3 Rd5 39. Re7+ Kf6 40. Rxh7 Bd7+ 41. Kg3 Rd3+ 42. f3 Rd2 43. Rh6+ Ke5 44. Ra6 a4 45. Ra5+ Kf6 46. Ra6+ Be6 47. Rxa4 Rxb2 48. Ra6 Ke5 49. Ra5+ Bd5 50. a4 Ra2 51. Ra7 Bc4 52. Ra5+ Kf6 53. Ra7 Bf1 54. a5 Rxg2+ 55. Kh3 Rg1+ 56. Kh2 Rg2+ 57. Kh3 Ra2+ 58. Kg3 Rg2+ 59. Kh3 Rg1+ 60. Kh2 Rg2+ 61. Kh3 Ra2+ 62. Kg3 Rg2+ 63. Kh3 Rg1+ 64. Kh2 Rg2+ 65. Kh3 Ra2+ 66. Kg3 Rg2+ 67. Kh3 Rg1+ 68. Kh2 Rg2+ 69. Kh3 Ra2+ 70. Kg3 Rg2+ 71. Kh3 Rg1+ 72. Kh2 Rg2+ 73. Kh3 Ra2+ 74. Kg3 Rg2+ 75. Kh3 Rg1+ 76. Kh2 Rg2+ 77. Kh3 Ra2+ 78. Kg3 Rg2+ 79. Kh3 Rg1+ 80. Kh2 Rg2+ 81. Kh3 Ra2+ 82. Kg3 Rg2+ 83. Kh3 Rg1+ 84. Kh2 Rg2+ 85. Kh3 Ra2+ 86. Kg3 Rg2+ 87. Kh3 Rg1+ 88. Kh2 Rg2+ 89. Kh3 Ra2+ 90. Kg3 Rg2+ 91. Kh3 Rg1+ 92. Kh2 Rg2+ 93. Kh3 Ra2+ 94. Kg3 Rg2+ 95. Kh3 Rg1+ 96. Kh2 Rg2+ 97. Kh3 Ra2+ 98. Kg3 Rg2+ 99. Kh3 Rg1+ 100. Kh2 Rg2+ 101. Kh3 Ra2+ 102. Kg3 Rg2+ 103. Kh3 Rg1+ 104. Kh2 Rg2+ 105. Kh3 Ra2+ 106. Kg3 Rg2+ 107. Kh3 Rg1+ 108. Kh2 Rg2",
          "positional_tokens": {
            "prompt_tokens": 397,
            "completion_tokens": 640,
            "total_tokens": 1037,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Qh3",
            "Qxh3+",
            "Kxh3",
            "Rd5",
            "Re7+",
            "Kf6",
            "Rxh7",
            "Bd7+",
            "Kg3",
            "Rd3+",
            "f3",
            "Rd2",
            "Rh6+",
            "Ke5",
            "Ra6",
            "a4",
            "Ra5+",
            "Kf6",
            "Ra6+",
            "Be6",
            "Rxa4",
            "Rxb2",
            "Ra6",
            "Ke5",
            "Ra5+",
            "Bd5",
            "a4",
            "Ra2",
            "Ra7",
            "Bc4",
            "Ra5+",
            "Kf6",
            "Ra7",
            "Bf1",
            "a5",
            "Rxg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2+",
            "Kh3",
            "Ra2+",
            "Kg3",
            "Rg2+",
            "Kh3",
            "Rg1+",
            "Kh2",
            "Rg2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re5",
          "neutral_uci": "e1e5",
          "neutral_response": "35. Re5 Qd1+ 36. Kh2 Qh5+ 37. Qh3 Qxh3+ 38. Kxh3 Rd5 39. Re7+ Kf6 40. Rxh7\nRd2 41. Rh6+ Kf5 42. Rxc6 Rxf2 43. Rc5+ Kf4 44. Rxa5 g4+ 45. Kh2 g3+ 46. Kh3\nRxb2 47. Ra4+ Ke3 48. Kxg3 Kd3 49. Ra8 Kc3 50. a4 Kb4 51. a5 Ra2 52. a6 Kb5\n53. a7 Kb6 54. Kf3 Kb7 55. Rb8+ Kxa7 56. Rb3 Ra4 57. g4 Ra6 58. g5 Rg6 59.\nKg4 Ka6 60. Kf5 Rg8 61. g6 Ka5 62. Kf6 Ka4 63. Rb7 Ka5 64. g7 Ka6 65. Rb1\nKa5 66. Kf7 Ra8 67. g8=Q Rxg8 68. Kxg8 Ka4 69. Kf7 Ka3 70. Ke6 Ka2 71. Rb8\nKa3 72. Kd5 Ka4 73. Kc5 Ka3 74. Kc4 Ka2 75. Kc3 Ka1 76. Kc2 Ka2 77. Ra8# Rg7\nKb3 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5 Rb7+ Ka4 Ra7+ Kb5",
          "neutral_tokens": {
            "prompt_tokens": 396,
            "completion_tokens": 640,
            "total_tokens": 1036,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Qh3",
            "Qxh3+",
            "Kxh3",
            "Rd5",
            "Re7+",
            "Kf6",
            "Rxh7",
            "Rd2",
            "Rh6+",
            "Kf5",
            "Rxc6",
            "Rxf2",
            "Rc5+",
            "Kf4",
            "Rxa5",
            "g4+",
            "Kh2",
            "g3+",
            "Kh3",
            "Rxb2",
            "Ra4+",
            "Ke3",
            "Kxg3",
            "Kd3",
            "Ra8",
            "Kc3",
            "a4",
            "Kb4",
            "a5",
            "Ra2",
            "a6",
            "Kb5",
            "a7",
            "Kb6",
            "Kf3",
            "Kb7",
            "Rb8+",
            "Kxa7",
            "Rb3",
            "Ra4",
            "g4",
            "Ra6",
            "g5",
            "Rg6",
            "Kg4",
            "Ka6",
            "Kf5",
            "Rg8",
            "g6",
            "Ka5",
            "Kf6",
            "Ka4",
            "Rb7",
            "Ka5",
            "g7",
            "Ka6",
            "Rb1",
            "Ka5",
            "Kf7",
            "Ra8",
            "g8=Q",
            "Rxg8",
            "Kxg8",
            "Ka4",
            "Kf7",
            "Ka3",
            "Ke6",
            "Ka2",
            "Rb8",
            "Ka3",
            "Kd5",
            "Ka4",
            "Kc5",
            "Ka3",
            "Kc4",
            "Ka2",
            "Kc3",
            "Ka1",
            "Kc2",
            "Ka2",
            "Ra8#",
            "Rg7",
            "Kb3",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5",
            "Rb7+",
            "Ka4",
            "Ra7+",
            "Kb5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1e5",
          "positional_uci": "e1e5",
          "neutral_uci": "e1e5",
          "consensus_move": "e1e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Qh3",
              "Qxh3+",
              "Kxh3",
              "Rd5",
              "Re7+",
              "Kf6",
              "Rxh7",
              "Bd7+",
              "Kg3",
              "Rd3+",
              "f3",
              "Rd2",
              "Rh6+",
              "Ke5",
              "Ra6",
              "a4",
              "Ra5+",
              "Kf6",
              "Ra6+",
              "Be6",
              "Rxa4",
              "Rxb2",
              "Ra6",
              "Ke5",
              "Ra5+",
              "Bd5",
              "a4",
              "Ra2",
              "Ra7",
              "Bc4",
              "Ra5+",
              "Kf6",
              "Ra7",
              "Bf1",
              "a5",
              "Rxg2+",
              "Kh3",
              "Rf2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Qh3",
              "Qxh3+",
              "Kxh3",
              "Rd5",
              "Re7+",
              "Kf6",
              "Rxh7",
              "Bd7+",
              "Kg3",
              "Rd3+",
              "f3",
              "Rd2",
              "Rh6+",
              "Ke5",
              "Ra6",
              "a4",
              "Ra5+",
              "Kf6",
              "Ra6+",
              "Be6",
              "Rxa4",
              "Rxb2",
              "Ra6",
              "Ke5",
              "Ra5+",
              "Bd5",
              "a4",
              "Ra2",
              "Ra7",
              "Bc4",
              "Ra5+",
              "Kf6",
              "Ra7",
              "Bf1",
              "a5",
              "Rxg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2+",
              "Kh3",
              "Ra2+",
              "Kg3",
              "Rg2+",
              "Kh3",
              "Rg1+",
              "Kh2",
              "Rg2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Qh3",
              "Qxh3+",
              "Kxh3",
              "Rd5",
              "Re7+",
              "Kf6",
              "Rxh7",
              "Rd2",
              "Rh6+",
              "Kf5",
              "Rxc6",
              "Rxf2",
              "Rc5+",
              "Kf4",
              "Rxa5",
              "g4+",
              "Kh2",
              "g3+",
              "Kh3",
              "Rxb2",
              "Ra4+",
              "Ke3",
              "Kxg3",
              "Kd3",
              "Ra8",
              "Kc3",
              "a4",
              "Kb4",
              "a5",
              "Ra2",
              "a6",
              "Kb5",
              "a7",
              "Kb6",
              "Kf3",
              "Kb7",
              "Rb8+",
              "Kxa7",
              "Rb3",
              "Ra4",
              "g4",
              "Ra6",
              "g5",
              "Rg6",
              "Kg4",
              "Ka6",
              "Kf5",
              "Rg8",
              "g6",
              "Ka5",
              "Kf6",
              "Ka4",
              "Rb7",
              "Ka5",
              "g7",
              "Ka6",
              "Rb1",
              "Ka5",
              "Kf7",
              "Ra8",
              "g8=Q",
              "Rxg8",
              "Kxg8",
              "Ka4",
              "Kf7",
              "Ka3",
              "Ke6",
              "Ka2",
              "Rb8",
              "Ka3",
              "Kd5",
              "Ka4",
              "Kc5",
              "Ka3",
              "Kc4",
              "Ka2",
              "Kc3",
              "Ka1",
              "Kc2",
              "Ka2",
              "Ra8#",
              "Rg7",
              "Kb3",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5",
              "Rb7+",
              "Ka4",
              "Ra7+",
              "Kb5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 397,
            "completion_tokens": 640,
            "total_tokens": 1037,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 397,
            "completion_tokens": 640,
            "total_tokens": 1037,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 396,
            "completion_tokens": 640,
            "total_tokens": 1036,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1190,
          "total_completion_tokens": 1920,
          "total_tokens": 3110
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 397,
            "completion_tokens": 640,
            "total_tokens": 1037,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 397,
            "completion_tokens": 640,
            "total_tokens": 1037,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 396,
            "completion_tokens": 640,
            "total_tokens": 1036,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/3r2kp/2b5/p2q2p1/8/6Q1/PP3PP1/4R1K1 w - - 0 35"
    },
    {
      "turn": 71,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re1",
          "aggressive_uci": "e5e1",
          "aggressive_response": "Re1 Qd1+ 37. Kh2 Qh5+ 38. Kg1 Rd1+ 39. Re1 Rxe1#",
          "aggressive_tokens": {
            "prompt_tokens": 406,
            "completion_tokens": 32,
            "total_tokens": 438,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh2",
          "positional_uci": "g1h2",
          "positional_response": "35... Qd1+ 36. Kh2 Qh5+ 37. Qh3 Qxh3+",
          "positional_tokens": {
            "prompt_tokens": 406,
            "completion_tokens": 27,
            "total_tokens": 433,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5+",
            "Qh3",
            "Qxh3+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re1",
          "neutral_uci": "e5e1",
          "neutral_response": "Re1 Qd1+ 37. Kh2 Qh5+ 38. Kg1 Rd1+ 39. Re1 Rxe1#",
          "neutral_tokens": {
            "prompt_tokens": 405,
            "completion_tokens": 32,
            "total_tokens": 437,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5e1",
          "positional_uci": "g1h2",
          "neutral_uci": "e5e1",
          "consensus_move": "e5e1",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxe1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh5+",
              "Qh3",
              "Qxh3+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 406,
            "completion_tokens": 32,
            "total_tokens": 438,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 406,
            "completion_tokens": 27,
            "total_tokens": 433,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 405,
            "completion_tokens": 32,
            "total_tokens": 437,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1217,
          "total_completion_tokens": 91,
          "total_tokens": 1308
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 406,
            "completion_tokens": 32,
            "total_tokens": 438,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 406,
            "completion_tokens": 27,
            "total_tokens": 433,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 405,
            "completion_tokens": 32,
            "total_tokens": 437,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/3r2kp/2b5/p3R1p1/8/6Q1/PP3PP1/3q2K1 w - - 2 36"
    },
    {
      "turn": 73,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kh2",
          "aggressive_uci": "g1h2",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe6 38. Qxg5+ Qg6 39. Qe5+ Qf6 40. Qg3+ Kh8 41. Qb8+ Rd8 42. Qg3 Rg8 43. Qh3 Rxg2+ 44. Qxg2 Bxg2 45. Kxg2 Qxb2 46. Kg3 Qxa2 47. f4 Qf7 48. Kg4 a4 49. f5 a3 50. Kg5 a2 51. f6 a1=Q 52. Kf5 Qaxf6+ 53. Ke4 Q7e6+ 54. Kd3 Qd8+ 55. Kc3 Qc6+ 56. Kb4 Qb8+ 57. Ka5 Qca8#",
          "aggressive_tokens": {
            "prompt_tokens": 415,
            "completion_tokens": 498,
            "total_tokens": 913,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe6",
            "Qxg5+",
            "Qg6",
            "Qe5+",
            "Qf6",
            "Qg3+",
            "Kh8",
            "Qb8+",
            "Rd8",
            "Qg3",
            "Rg8",
            "Qh3",
            "Rxg2+",
            "Qxg2",
            "Bxg2",
            "Kxg2",
            "Qxb2",
            "Kg3",
            "Qxa2",
            "f4",
            "Qf7",
            "Kg4",
            "a4",
            "f5",
            "a3",
            "Kg5",
            "a2",
            "f6",
            "a1=Q",
            "Kf5",
            "Qaxf6+",
            "Ke4",
            "Q7e6+",
            "Kd3",
            "Qd8+",
            "Kc3",
            "Qc6+",
            "Kb4",
            "Qb8+",
            "Ka5",
            "Qca8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh2",
          "positional_uci": "g1h2",
          "positional_response": "37. Kh2 Qe6 38. Qxg5+ Qg6 39. Qe5+ Qf6 40. Qg3+ Kf7 41. Qb3+ Bd5 42. Qh3 Qf4+ 43. Kg1 Ke8 44. Qh5+ Kd8 45. Qe2 Qe4 46. Qf1 Rg7 47. f3 Qxf3 48. Qxf3 Bxf3 49. Kf2 Bxg2 50. Ke3 h5 51. Kd4 h4 52. Kc5 h3 53. Kb5 h2 54. Kxa5 h1=Q 55. b4 Qh5+ 56. b5 Ra7+ 57. Kb4 Qg4+ 58. Kc5 Rc7+ 59. Kb6 Qd4+ 60. Ka5 Ra7#",
          "positional_tokens": {
            "prompt_tokens": 415,
            "completion_tokens": 212,
            "total_tokens": 627,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe6",
            "Qxg5+",
            "Qg6",
            "Qe5+",
            "Qf6",
            "Qg3+",
            "Kf7",
            "Qb3+",
            "Bd5",
            "Qh3",
            "Qf4+",
            "Kg1",
            "Ke8",
            "Qh5+",
            "Kd8",
            "Qe2",
            "Qe4",
            "Qf1",
            "Rg7",
            "f3",
            "Qxf3",
            "Qxf3",
            "Bxf3",
            "Kf2",
            "Bxg2",
            "Ke3",
            "h5",
            "Kd4",
            "h4",
            "Kc5",
            "h3",
            "Kb5",
            "h2",
            "Kxa5",
            "h1=Q",
            "b4",
            "Qh5+",
            "b5",
            "Ra7+",
            "Kb4",
            "Qg4+",
            "Kc5",
            "Rc7+",
            "Kb6",
            "Qd4+",
            "Ka5",
            "Ra7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kh2",
          "neutral_uci": "g1h2",
          "neutral_response": "37. Kh2 Qe6 38. Qxg5+ Qg6 39. Qe5+ Qf6 40. Qg3+ Kf7 41. Qb3+ Bd5 42. Qh3 Qf4+ 43. Kg1 Ke8 44. Qh5+ Kd8 45. Qe2 Qe4 46. Qf1 Rg7 47. f3 Qxf3 48. Qxf3 Bxf3 49. Kf2 Bxg2 50. Ke3 h5 51. Kf4 h4 52. Ke5 h3 53. Kf6 Rg3 54. Kf5 h2 55. Kf4 Rf3+ 56. Kg4 h1=Q 57. Kg5 Qh3 58. Kg6 Qg4+ 59. Kh6 Rh3#",
          "neutral_tokens": {
            "prompt_tokens": 414,
            "completion_tokens": 203,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe6",
            "Qxg5+",
            "Qg6",
            "Qe5+",
            "Qf6",
            "Qg3+",
            "Kf7",
            "Qb3+",
            "Bd5",
            "Qh3",
            "Qf4+",
            "Kg1",
            "Ke8",
            "Qh5+",
            "Kd8",
            "Qe2",
            "Qe4",
            "Qf1",
            "Rg7",
            "f3",
            "Qxf3",
            "Qxf3",
            "Bxf3",
            "Kf2",
            "Bxg2",
            "Ke3",
            "h5",
            "Kf4",
            "h4",
            "Ke5",
            "h3",
            "Kf6",
            "Rg3",
            "Kf5",
            "h2",
            "Kf4",
            "Rf3+",
            "Kg4",
            "h1=Q",
            "Kg5",
            "Qh3",
            "Kg6",
            "Qg4+",
            "Kh6",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1h2",
          "positional_uci": "g1h2",
          "neutral_uci": "g1h2",
          "consensus_move": "g1h2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe6",
              "Qxg5+",
              "Qg6",
              "Qe5+",
              "Qf6",
              "Qg3+",
              "Kh8",
              "Qb8+",
              "Rd8",
              "Qg3",
              "Rg8",
              "Qh3",
              "Rxg2+",
              "Qxg2",
              "Bxg2",
              "Kxg2",
              "Qxb2",
              "Kg3",
              "Qxa2",
              "f4",
              "Qf7",
              "Kg4",
              "a4",
              "f5",
              "a3",
              "Kg5",
              "a2",
              "f6",
              "a1=Q",
              "Kf5",
              "Qaxf6+",
              "Ke4",
              "Q7e6+",
              "Kd3",
              "Qd8+",
              "Kc3",
              "Qc6+",
              "Kb4",
              "Qb8+",
              "Ka5",
              "Qca8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe6",
              "Qxg5+",
              "Qg6",
              "Qe5+",
              "Qf6",
              "Qg3+",
              "Kf7",
              "Qb3+",
              "Bd5",
              "Qh3",
              "Qf4+",
              "Kg1",
              "Ke8",
              "Qh5+",
              "Kd8",
              "Qe2",
              "Qe4",
              "Qf1",
              "Rg7",
              "f3",
              "Qxf3",
              "Qxf3",
              "Bxf3",
              "Kf2",
              "Bxg2",
              "Ke3",
              "h5",
              "Kd4",
              "h4",
              "Kc5",
              "h3",
              "Kb5",
              "h2",
              "Kxa5",
              "h1=Q",
              "b4",
              "Qh5+",
              "b5",
              "Ra7+",
              "Kb4",
              "Qg4+",
              "Kc5",
              "Rc7+",
              "Kb6",
              "Qd4+",
              "Ka5",
              "Ra7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe6",
              "Qxg5+",
              "Qg6",
              "Qe5+",
              "Qf6",
              "Qg3+",
              "Kf7",
              "Qb3+",
              "Bd5",
              "Qh3",
              "Qf4+",
              "Kg1",
              "Ke8",
              "Qh5+",
              "Kd8",
              "Qe2",
              "Qe4",
              "Qf1",
              "Rg7",
              "f3",
              "Qxf3",
              "Qxf3",
              "Bxf3",
              "Kf2",
              "Bxg2",
              "Ke3",
              "h5",
              "Kf4",
              "h4",
              "Ke5",
              "h3",
              "Kf6",
              "Rg3",
              "Kf5",
              "h2",
              "Kf4",
              "Rf3+",
              "Kg4",
              "h1=Q",
              "Kg5",
              "Qh3",
              "Kg6",
              "Qg4+",
              "Kh6",
              "Rh3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 415,
            "completion_tokens": 498,
            "total_tokens": 913,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 415,
            "completion_tokens": 212,
            "total_tokens": 627,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 414,
            "completion_tokens": 203,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1244,
          "total_completion_tokens": 913,
          "total_tokens": 2157
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 415,
            "completion_tokens": 498,
            "total_tokens": 913,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 415,
            "completion_tokens": 212,
            "total_tokens": 627,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 414,
            "completion_tokens": 203,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/3r2kp/2b5/p5p1/8/6Q1/PP3PP1/4q1K1 w - - 0 37"
    },
    {
      "turn": 75,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc3+",
          "aggressive_uci": "g3c3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Qf6 39. Qxa5 Qf4+ 40. Kh3 Qh4#",
          "aggressive_tokens": {
            "prompt_tokens": 423,
            "completion_tokens": 343,
            "total_tokens": 766,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf6",
            "Qxa5",
            "Qf4+",
            "Kh3",
            "Qh4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qc3+",
          "positional_uci": "g3c3",
          "positional_response": "38. Qc3+ Qf6 39. Qxa5 Qf4+ 40. Kh3 Qh4#",
          "positional_tokens": {
            "prompt_tokens": 423,
            "completion_tokens": 29,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf6",
            "Qxa5",
            "Qf4+",
            "Kh3",
            "Qh4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qc3+",
          "neutral_uci": "g3c3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Qf6 39. Qxa5 Qf4+ 40. Kh3 Qh4#",
          "neutral_tokens": {
            "prompt_tokens": 422,
            "completion_tokens": 343,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf6",
            "Qxa5",
            "Qf4+",
            "Kh3",
            "Qh4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3c3",
          "positional_uci": "g3c3",
          "neutral_uci": "g3c3",
          "consensus_move": "g3c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qf6",
              "Qxa5",
              "Qf4+",
              "Kh3",
              "Qh4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf6",
              "Qxa5",
              "Qf4+",
              "Kh3",
              "Qh4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qf6",
              "Qxa5",
              "Qf4+",
              "Kh3",
              "Qh4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 423,
            "completion_tokens": 343,
            "total_tokens": 766,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 423,
            "completion_tokens": 29,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 422,
            "completion_tokens": 343,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1268,
          "total_completion_tokens": 715,
          "total_tokens": 1983
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 423,
            "completion_tokens": 343,
            "total_tokens": 766,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 423,
            "completion_tokens": 29,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 422,
            "completion_tokens": 343,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/3rq1kp/2b5/p5p1/8/6Q1/PP3PPK/8 w - - 2 38"
    },
    {
      "turn": 77,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxc6",
          "aggressive_uci": "c3c6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6 Qd6+ 40. Qxd6 Rxd6 41. Kg3 Rd2 42. Kg4 Rxb2 43. Kxg5 Rxf2 44. g4 Rxa2 45. Kh6 Rg2 46. g5 a4 47. Kxh7 Rh2#",
          "aggressive_tokens": {
            "prompt_tokens": 433,
            "completion_tokens": 401,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd6+",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Rd2",
            "Kg4",
            "Rxb2",
            "Kxg5",
            "Rxf2",
            "g4",
            "Rxa2",
            "Kh6",
            "Rg2",
            "g5",
            "a4",
            "Kxh7",
            "Rh2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxc6",
          "positional_uci": "c3c6",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6 Qd6+ 40. Qxd6 Rxd6 41. Kg3 Rd2 42. Kg4 Kg6 43. f4 h5+ 44. Kf3 g4+ 45. Ke4 Rxb2 46. f5+ Kf6 47. Kf4 Rxa2 48. g3 Ra4+ 49. Ke3 Kxf5 50. Kf2 Ke4 51. Kg2 Ra2+ 52. Kf1 Ke3 53. Kg1 Kf3 54. Kh1 Kxg3 55. Kg1 Ra1#",
          "positional_tokens": {
            "prompt_tokens": 433,
            "completion_tokens": 465,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd6+",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Rd2",
            "Kg4",
            "Kg6",
            "f4",
            "h5+",
            "Kf3",
            "g4+",
            "Ke4",
            "Rxb2",
            "f5+",
            "Kf6",
            "Kf4",
            "Rxa2",
            "g3",
            "Ra4+",
            "Ke3",
            "Kxf5",
            "Kf2",
            "Ke4",
            "Kg2",
            "Ra2+",
            "Kf1",
            "Ke3",
            "Kg1",
            "Kf3",
            "Kh1",
            "Kxg3",
            "Kg1",
            "Ra1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxc6",
          "neutral_uci": "c3c6",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6 Qd6+ 40. Qxd6 Rxd6 41. Kg3 Rd2 42. Kg4 Rxb2 43. Kxg5 Rxa2 44. f4 Rxg2+ 45. Kf5 a4 46. Ke5 a3 47. f5 a2 48. f6 a1=Q+ 49. Kd6 Qxf6+ 50. Kd7 Rd2+ 51. Kc7 Qc3+ 52. Kb6 Rb2+ 53. Ka6 Qa3#",
          "neutral_tokens": {
            "prompt_tokens": 432,
            "completion_tokens": 456,
            "total_tokens": 888,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd6+",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Rd2",
            "Kg4",
            "Rxb2",
            "Kxg5",
            "Rxa2",
            "f4",
            "Rxg2+",
            "Kf5",
            "a4",
            "Ke5",
            "a3",
            "f5",
            "a2",
            "f6",
            "a1=Q+",
            "Kd6",
            "Qxf6+",
            "Kd7",
            "Rd2+",
            "Kc7",
            "Qc3+",
            "Kb6",
            "Rb2+",
            "Ka6",
            "Qa3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c3c6",
          "positional_uci": "c3c6",
          "neutral_uci": "c3c6",
          "consensus_move": "c3c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd6+",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Rd2",
              "Kg4",
              "Rxb2",
              "Kxg5",
              "Rxf2",
              "g4",
              "Rxa2",
              "Kh6",
              "Rg2",
              "g5",
              "a4",
              "Kxh7",
              "Rh2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd6+",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Rd2",
              "Kg4",
              "Kg6",
              "f4",
              "h5+",
              "Kf3",
              "g4+",
              "Ke4",
              "Rxb2",
              "f5+",
              "Kf6",
              "Kf4",
              "Rxa2",
              "g3",
              "Ra4+",
              "Ke3",
              "Kxf5",
              "Kf2",
              "Ke4",
              "Kg2",
              "Ra2+",
              "Kf1",
              "Ke3",
              "Kg1",
              "Kf3",
              "Kh1",
              "Kxg3",
              "Kg1",
              "Ra1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd6+",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Rd2",
              "Kg4",
              "Rxb2",
              "Kxg5",
              "Rxa2",
              "f4",
              "Rxg2+",
              "Kf5",
              "a4",
              "Ke5",
              "a3",
              "f5",
              "a2",
              "f6",
              "a1=Q+",
              "Kd6",
              "Qxf6+",
              "Kd7",
              "Rd2+",
              "Kc7",
              "Qc3+",
              "Kb6",
              "Rb2+",
              "Ka6",
              "Qa3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 433,
            "completion_tokens": 401,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 433,
            "completion_tokens": 465,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 432,
            "completion_tokens": 456,
            "total_tokens": 888,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1298,
          "total_completion_tokens": 1322,
          "total_tokens": 2620
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 433,
            "completion_tokens": 401,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 433,
            "completion_tokens": 465,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 432,
            "completion_tokens": 456,
            "total_tokens": 888,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/3rqk1p/2b5/p5p1/8/2Q5/PP3PPK/8 w - - 4 39"
    },
    {
      "turn": 79,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxd6",
          "aggressive_uci": "c6d6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Rd2 42. Kg4 Rxf2 43. Kxg5 Rxg2+ 44. Kf4 Rxb2 45. a4\nRa2 46. Ke5 Rxa4 47. Kd5 Rb4 48. Kc5 Rb8 49. Kc6 a4 50. Kc7 Rb1 51. Kc6 a3 52.\nKc5 a2 53. Kc4 a1=Q 54. Kd3 Qa4 55. Kc3 Rb3+ 56. Kc2 Qa2+ 57. Kc1 Rb1# Qd6 Qd6 Qd6",
          "aggressive_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 504,
            "total_tokens": 948,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxd6",
            "Kg3",
            "Rd2",
            "Kg4",
            "Rxf2",
            "Kxg5",
            "Rxg2+",
            "Kf4",
            "Rxb2",
            "a4",
            "Ra2",
            "Ke5",
            "Rxa4",
            "Kd5",
            "Rb4",
            "Kc5",
            "Rb8",
            "Kc6",
            "a4",
            "Kc7",
            "Rb1",
            "Kc6",
            "a3",
            "Kc5",
            "a2",
            "Kc4",
            "a1=Q",
            "Kd3",
            "Qa4",
            "Kc3",
            "Rb3+",
            "Kc2",
            "Qa2+",
            "Kc1",
            "Rb1#",
            "Qd6",
            "Qd6",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxd6",
          "positional_uci": "c6d6",
          "positional_response": "39... Qd6+ 40. Qxd6 Rxd6 41. Kg3 Rd2 42. b3 Rxa2 43. Kf3 Rb2 44. Ke3 Rxb3+ 45. Kd4 a4 46. Kc4 Rb8 47. Kc3 a3 48. Kc2 a2 49. Kc3 a1=Q+ 50. Kc4 Qd1 51. Kc5 Rc8+ 52. Kb6 Qb1+ 53. Ka7 Rc2 54. Ka6 Ra2#",
          "positional_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 135,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxd6",
            "Kg3",
            "Rd2",
            "b3",
            "Rxa2",
            "Kf3",
            "Rb2",
            "Ke3",
            "Rxb3+",
            "Kd4",
            "a4",
            "Kc4",
            "Rb8",
            "Kc3",
            "a3",
            "Kc2",
            "a2",
            "Kc3",
            "a1=Q+",
            "Kc4",
            "Qd1",
            "Kc5",
            "Rc8+",
            "Kb6",
            "Qb1+",
            "Ka7",
            "Rc2",
            "Ka6",
            "Ra2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxd6",
          "neutral_uci": "c6d6",
          "neutral_response": "39... Qd6+ 40. Qxd6 Rxd6 41. Kg3 Rd2 42. b4 axb4 43. a4 bxa3 44. f4 gxf4+ 45. Kxf4 a2 46. g4 a1=Q 47. g5 Qd4+ 48. Kf5 Rf2#",
          "neutral_tokens": {
            "prompt_tokens": 443,
            "completion_tokens": 84,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxd6",
            "Kg3",
            "Rd2",
            "b4",
            "axb4",
            "a4",
            "bxa3",
            "f4",
            "gxf4+",
            "Kxf4",
            "a2",
            "g4",
            "a1=Q",
            "g5",
            "Qd4+",
            "Kf5",
            "Rf2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6d6",
          "positional_uci": "c6d6",
          "neutral_uci": "c6d6",
          "consensus_move": "c6d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxd6",
              "Kg3",
              "Rd2",
              "Kg4",
              "Rxf2",
              "Kxg5",
              "Rxg2+",
              "Kf4",
              "Rxb2",
              "a4",
              "Ra2",
              "Ke5",
              "Rxa4",
              "Kd5",
              "Rb4",
              "Kc5",
              "Rb8",
              "Kc6",
              "a4",
              "Kc7",
              "Rb1",
              "Kc6",
              "a3",
              "Kc5",
              "a2",
              "Kc4",
              "a1=Q",
              "Kd3",
              "Qa4",
              "Kc3",
              "Rb3+",
              "Kc2",
              "Qa2+",
              "Kc1",
              "Rb1#",
              "Qd6",
              "Qd6",
              "Qd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxd6",
              "Kg3",
              "Rd2",
              "b3",
              "Rxa2",
              "Kf3",
              "Rb2",
              "Ke3",
              "Rxb3+",
              "Kd4",
              "a4",
              "Kc4",
              "Rb8",
              "Kc3",
              "a3",
              "Kc2",
              "a2",
              "Kc3",
              "a1=Q+",
              "Kc4",
              "Qd1",
              "Kc5",
              "Rc8+",
              "Kb6",
              "Qb1+",
              "Ka7",
              "Rc2",
              "Ka6",
              "Ra2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxd6",
              "Kg3",
              "Rd2",
              "b4",
              "axb4",
              "a4",
              "bxa3",
              "f4",
              "gxf4+",
              "Kxf4",
              "a2",
              "g4",
              "a1=Q",
              "g5",
              "Qd4+",
              "Kf5",
              "Rf2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 444,
            "completion_tokens": 504,
            "total_tokens": 948,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 444,
            "completion_tokens": 135,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 443,
            "completion_tokens": 84,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1331,
          "total_completion_tokens": 723,
          "total_tokens": 2054
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 444,
            "completion_tokens": 504,
            "total_tokens": 948,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 444,
            "completion_tokens": 135,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 443,
            "completion_tokens": 84,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/3r1k1p/2Qq4/p5p1/8/8/PP3PPK/8 w - - 1 40"
    },
    {
      "turn": 81,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc3+",
          "aggressive_uci": null,
          "aggressive_response": "Re8+ Kg7 Qc3+ Kf7 Qc7+ Ke6 Qc6+ Kd5 Qc5+ Ke4 Qc4+ Kd3\nQc3+ Kd2 Qc2+ Kd1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke1 Qc1+ Ke2 Qc2+ Ke",
          "aggressive_tokens": {
            "prompt_tokens": 453,
            "completion_tokens": 640,
            "total_tokens": 1093,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kd2",
            "Qc2+",
            "Kd1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Ke1",
            "Qc1+",
            "Ke2",
            "Qc2+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg3",
          "positional_uci": "h2g3",
          "positional_response": "41. Kg3 Rd2 42. b3 Rxa2 43. Kg4 Kg6 44. f4 Rxg2+ 45. Kf3 Rb2 46. fxg5 Rxb3+ 47. Ke4 a4 48. Kd4 a3 49. Kc4 Rb8 50. Kc3 a2 51. Kc2 a1=Q",
          "positional_tokens": {
            "prompt_tokens": 453,
            "completion_tokens": 92,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd2",
            "b3",
            "Rxa2",
            "Kg4",
            "Kg6",
            "f4",
            "Rxg2+",
            "Kf3",
            "Rb2",
            "fxg5",
            "Rxb3+",
            "Ke4",
            "a4",
            "Kd4",
            "a3",
            "Kc4",
            "Rb8",
            "Kc3",
            "a2",
            "Kc2",
            "a1=Q"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": null,
          "neutral_response": "Re8+ Kg7 Qc7+ Kf6 Qc3+ Ke5 Qc5+ Kd6 Qc6+ Kd5 Qc5+ Ke4 Qc4+ Kd3 Qc3+ Kd2 Qc2+ Kd1 Qc1+ Ke2 Qc2+ Kf3 Qc3+ Kg4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+ g4 Qc4+ Kh5 Qc5+",
          "neutral_tokens": {
            "prompt_tokens": 452,
            "completion_tokens": 640,
            "total_tokens": 1092,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Qc7+",
            "Kf6",
            "Qc3+",
            "Ke5",
            "Qc5+",
            "Kd6",
            "Qc6+",
            "Kd5",
            "Qc5+",
            "Ke4",
            "Qc4+",
            "Kd3",
            "Qc3+",
            "Kd2",
            "Qc2+",
            "Kd1",
            "Qc1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Kg4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+",
            "g4",
            "Qc4+",
            "Kh5",
            "Qc5+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "h2g3",
          "neutral_uci": null,
          "consensus_move": "h2g3",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kd2",
              "Qc2+",
              "Kd1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Ke1",
              "Qc1+",
              "Ke2",
              "Qc2+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rd2",
              "b3",
              "Rxa2",
              "Kg4",
              "Kg6",
              "f4",
              "Rxg2+",
              "Kf3",
              "Rb2",
              "fxg5",
              "Rxb3+",
              "Ke4",
              "a4",
              "Kd4",
              "a3",
              "Kc4",
              "Rb8",
              "Kc3",
              "a2",
              "Kc2",
              "a1=Q"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg7",
              "Qc7+",
              "Kf6",
              "Qc3+",
              "Ke5",
              "Qc5+",
              "Kd6",
              "Qc6+",
              "Kd5",
              "Qc5+",
              "Ke4",
              "Qc4+",
              "Kd3",
              "Qc3+",
              "Kd2",
              "Qc2+",
              "Kd1",
              "Qc1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Kg4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+",
              "g4",
              "Qc4+",
              "Kh5",
              "Qc5+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 453,
            "completion_tokens": 640,
            "total_tokens": 1093,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 453,
            "completion_tokens": 92,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 452,
            "completion_tokens": 640,
            "total_tokens": 1092,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1358,
          "total_completion_tokens": 1372,
          "total_tokens": 2730
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 453,
            "completion_tokens": 640,
            "total_tokens": 1093,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 453,
            "completion_tokens": 92,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 452,
            "completion_tokens": 640,
            "total_tokens": 1092,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/5k1p/3r4/p5p1/8/8/PP3PPK/8 w - - 0 41"
    },
    {
      "turn": 83,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "f4",
          "aggressive_uci": "f2f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Kg6 42. f4 gxf4+ 43. Kxf4 Rd2 44. g4 Rxb2 45. a4\nRb4+ 46. Ke5 Rxa4 47. Kd5 Rxg4 48. Kc5 a4 49. Kb5 a3 50. Kc5 a2 51. Kd5 a1=Q\n52. Kc5 Qd4+ 53. Kc6 Rg5 54. Kc7 Rc5+ 55. Kb6 Qb4+ 56. Ka6 Ra5#",
          "aggressive_tokens": {
            "prompt_tokens": 460,
            "completion_tokens": 481,
            "total_tokens": 941,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf4+",
            "Kxf4",
            "Rd2",
            "g4",
            "Rxb2",
            "a4",
            "Rb4+",
            "Ke5",
            "Rxa4",
            "Kd5",
            "Rxg4",
            "Kc5",
            "a4",
            "Kb5",
            "a3",
            "Kc5",
            "a2",
            "Kd5",
            "a1=Q",
            "Kc5",
            "Qd4+",
            "Kc6",
            "Rg5",
            "Kc7",
            "Rc5+",
            "Kb6",
            "Qb4+",
            "Ka6",
            "Ra5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f4",
          "positional_uci": "f2f4",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Kg6 42. f4 gxf4+ 43. Kxf4 Rd2 44. g4 Rxb2 45. a4\nRb4+ 46. Ke5 Rxa4 47. Kd5 Rxg4 48. Kc5 a4 49. Kb5 a3 50. Kc5 a2 51. Kd5 a1=Q\n52. Kc5 Qa5+ 53. Kd6 Rd4+ 54. Ke6 Qd5+ 55. Ke7 Re4+ 56. Kf8 Qf7#",
          "positional_tokens": {
            "prompt_tokens": 460,
            "completion_tokens": 482,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf4+",
            "Kxf4",
            "Rd2",
            "g4",
            "Rxb2",
            "a4",
            "Rb4+",
            "Ke5",
            "Rxa4",
            "Kd5",
            "Rxg4",
            "Kc5",
            "a4",
            "Kb5",
            "a3",
            "Kc5",
            "a2",
            "Kd5",
            "a1=Q",
            "Kc5",
            "Qa5+",
            "Kd6",
            "Rd4+",
            "Ke6",
            "Qd5+",
            "Ke7",
            "Re4+",
            "Kf8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "f4",
          "neutral_uci": "f2f4",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Kg6 42. f4 gxf4+ 43. Kxf4 Rd2 44. g4 Rxb2 45. a4\nRb4+ 46. Ke5 Rxa4 47. Kd5 Rxg4 48. Kc5 a4 49. Kb5 a3 50. Kc5 a2 51. Kd5 a1=Q\n52. Kc5 Qa5+ 53. Kd6 Rd4+ 54. Ke6 Qd5+ 55. Ke7 Re4+ 56. Kf8 Qf7#",
          "neutral_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 482,
            "total_tokens": 941,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf4+",
            "Kxf4",
            "Rd2",
            "g4",
            "Rxb2",
            "a4",
            "Rb4+",
            "Ke5",
            "Rxa4",
            "Kd5",
            "Rxg4",
            "Kc5",
            "a4",
            "Kb5",
            "a3",
            "Kc5",
            "a2",
            "Kd5",
            "a1=Q",
            "Kc5",
            "Qa5+",
            "Kd6",
            "Rd4+",
            "Ke6",
            "Qd5+",
            "Ke7",
            "Re4+",
            "Kf8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f2f4",
          "positional_uci": "f2f4",
          "neutral_uci": "f2f4",
          "consensus_move": "f2f4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "gxf4+",
              "Kxf4",
              "Rd2",
              "g4",
              "Rxb2",
              "a4",
              "Rb4+",
              "Ke5",
              "Rxa4",
              "Kd5",
              "Rxg4",
              "Kc5",
              "a4",
              "Kb5",
              "a3",
              "Kc5",
              "a2",
              "Kd5",
              "a1=Q",
              "Kc5",
              "Qd4+",
              "Kc6",
              "Rg5",
              "Kc7",
              "Rc5+",
              "Kb6",
              "Qb4+",
              "Ka6",
              "Ra5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "gxf4+",
              "Kxf4",
              "Rd2",
              "g4",
              "Rxb2",
              "a4",
              "Rb4+",
              "Ke5",
              "Rxa4",
              "Kd5",
              "Rxg4",
              "Kc5",
              "a4",
              "Kb5",
              "a3",
              "Kc5",
              "a2",
              "Kd5",
              "a1=Q",
              "Kc5",
              "Qa5+",
              "Kd6",
              "Rd4+",
              "Ke6",
              "Qd5+",
              "Ke7",
              "Re4+",
              "Kf8",
              "Qf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf4+",
              "Kxf4",
              "Rd2",
              "g4",
              "Rxb2",
              "a4",
              "Rb4+",
              "Ke5",
              "Rxa4",
              "Kd5",
              "Rxg4",
              "Kc5",
              "a4",
              "Kb5",
              "a3",
              "Kc5",
              "a2",
              "Kd5",
              "a1=Q",
              "Kc5",
              "Qa5+",
              "Kd6",
              "Rd4+",
              "Ke6",
              "Qd5+",
              "Ke7",
              "Re4+",
              "Kf8",
              "Qf7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 460,
            "completion_tokens": 481,
            "total_tokens": 941,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 460,
            "completion_tokens": 482,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 459,
            "completion_tokens": 482,
            "total_tokens": 941,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1379,
          "total_completion_tokens": 1445,
          "total_tokens": 2824
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 460,
            "completion_tokens": 481,
            "total_tokens": 941,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 460,
            "completion_tokens": 482,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 459,
            "completion_tokens": 482,
            "total_tokens": 941,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/7p/3r2k1/p5p1/8/6K1/PP3PP1/8 w - - 2 42"
    },
    {
      "turn": 85,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "fxg5",
          "aggressive_uci": "f4g5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Kg6 42. f4 Kf5 43. fxg5 Kxg5",
          "aggressive_tokens": {
            "prompt_tokens": 468,
            "completion_tokens": 369,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "fxg5",
          "positional_uci": "f4g5",
          "positional_response": "43. fxg5 Kxg5 44. Kf3 Rd2 45. b4 axb4 46. a4 bxa3 47. g4 a2 48. Ke3 Rd8 49. Ke4 a1=Q 50. Kf3 Qc3+ 51. Ke4 Rd4+ 52. Ke5 Qc5+ 53. Ke6 Rd6+ 54. Ke7 Qc7+ 55. Ke8 Rd8#",
          "positional_tokens": {
            "prompt_tokens": 468,
            "completion_tokens": 109,
            "total_tokens": 577,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxg5",
            "Kf3",
            "Rd2",
            "b4",
            "axb4",
            "a4",
            "bxa3",
            "g4",
            "a2",
            "Ke3",
            "Rd8",
            "Ke4",
            "a1=Q",
            "Kf3",
            "Qc3+",
            "Ke4",
            "Rd4+",
            "Ke5",
            "Qc5+",
            "Ke6",
            "Rd6+",
            "Ke7",
            "Qc7+",
            "Ke8",
            "Rd8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "fxg5",
          "neutral_uci": "f4g5",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Kg6 42. f4 Kf5 43. fxg5 Kxg5",
          "neutral_tokens": {
            "prompt_tokens": 467,
            "completion_tokens": 369,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f4g5",
          "positional_uci": "f4g5",
          "neutral_uci": "f4g5",
          "consensus_move": "f4g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxg5",
              "Kf3",
              "Rd2",
              "b4",
              "axb4",
              "a4",
              "bxa3",
              "g4",
              "a2",
              "Ke3",
              "Rd8",
              "Ke4",
              "a1=Q",
              "Kf3",
              "Qc3+",
              "Ke4",
              "Rd4+",
              "Ke5",
              "Qc5+",
              "Ke6",
              "Rd6+",
              "Ke7",
              "Qc7+",
              "Ke8",
              "Rd8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 468,
            "completion_tokens": 369,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 468,
            "completion_tokens": 109,
            "total_tokens": 577,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 467,
            "completion_tokens": 369,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1403,
          "total_completion_tokens": 847,
          "total_tokens": 2250
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 468,
            "completion_tokens": 369,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 468,
            "completion_tokens": 109,
            "total_tokens": 577,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 467,
            "completion_tokens": 369,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/7p/3r4/p4kp1/5P2/6K1/PP4P1/8 w - - 1 43"
    },
    {
      "turn": 87,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kh4",
          "aggressive_uci": "g3h4",
          "aggressive_response": "44. Kh4 Rd2 45. g4+\nKf4 46. Kh3 Rxb2 47. g6 hxg6 48. g5 Rxa2 49. Kh4 Rh2# Rf7 50. Kh3 Kf3 51. Kh2\nKf2 52. Kh3 Rf4 53. Kh2 Rh4# Rf7 54. Kh3 Kf3 55. Kh2 Rf4 56. Kh3 Kf2 57. Kh2\nRh4# Rf7 58. Kh3 Kf3 59. Kh2 Rf4 60. Kh3 Kf2 61. Kh2 Rh4# Rf7 62. Kh3 Kf3 63.\nKh2 Rf4 64. Kh3 Kf2 65. Kh2 Rh4# Rf7 66. Kh3 Kf3 67. Kh2 Rf4 68. Kh3 Kf2 69.\nKh2 Rh4# Rf7 70. Kh3 Kf3 71. Kh2 Rf4 72. Kh3 Kf2 73. Kh2 Rh4# Rf7 74. Kh3 Kf3\n75. Kh2 Rf4 76. Kh3 Kf2 77. Kh2 Rh4# Rf7 78. Kh3 Kf3 79. Kh2 Rf4 80. Kh3 Kf2\n81. Kh2 Rh4# Rf7 82. Kh3 Kf3 83. Kh2 Rf4 84. Kh3 Kf2 85. Kh2 Rh4# Rf7 86. Kh3\nKf3 87. Kh2 Rf4 88. Kh3 Kf2 89. Kh2 Rh4# Rf7 90. Kh3 Kf3 91. Kh2 Rf4 92. Kh3\nKf2 93. Kh2 Rh4# Rf7 94. Kh3 Kf3 95. Kh2 Rf4 96. Kh3 Kf2 97. Kh2 Rh4# Rf7\n98. Kh3 Kf3 99. Kh2 Rf4 100. Kh3 Kf2 101. Kh2 Rh4# Rf7 102. Kh3 Kf3 103.\nKh2 Rf4 104. Kh3 Kf2 105. Kh2 Rh4# Rf7 106. Kh3 Kf3 107. Kh2 Rf4 108. Kh3 Kf2\n109. Kh2 Rh4# Rf7 110. Kh3 Kf3 111. Kh2 Rf4 112. Kh3 Kf2 113. Kh2 Rh4# Rf7\n114. Kh3 Kf3 115. Kh2 Rf4 116. Kh3 Kf2",
          "aggressive_tokens": {
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rh2#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Kf2",
            "Kh3",
            "Rf4",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2",
            "Kh2",
            "Rh4#",
            "Rf7",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rf4",
            "Kh3",
            "Kf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd3+",
          "positional_uci": null,
          "positional_response": "Rd3+ Kf4 Qd4+ Ke3 Qd3+ Kf2 Qd2+ Kg1 Qd1+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4+ Kh2 Qd6+ Kg1 Qd4",
          "positional_tokens": {
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf4",
            "Qd4+",
            "Ke3",
            "Qd3+",
            "Kf2",
            "Qd2+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4+",
            "Kh2",
            "Qd6+",
            "Kg1",
            "Qd4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kh4",
          "neutral_uci": "g3h4",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Kg6 42. f4 Kf5 43. fxg5 Rd3+ 44. Kh4 *",
          "neutral_tokens": {
            "prompt_tokens": 476,
            "completion_tokens": 374,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3h4",
          "positional_uci": null,
          "neutral_uci": "g3h4",
          "consensus_move": "g3h4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rh2#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Kf2",
              "Kh3",
              "Rf4",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2",
              "Kh2",
              "Rh4#",
              "Rf7",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rf4",
              "Kh3",
              "Kf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf4",
              "Qd4+",
              "Ke3",
              "Qd3+",
              "Kf2",
              "Qd2+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4+",
              "Kh2",
              "Qd6+",
              "Kg1",
              "Qd4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 476,
            "completion_tokens": 374,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1430,
          "total_completion_tokens": 1654,
          "total_tokens": 3084
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 477,
            "completion_tokens": 640,
            "total_tokens": 1117,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 476,
            "completion_tokens": 374,
            "total_tokens": 850,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/7p/8/p4kP1/8/3r2K1/PP4P1/8 w - - 1 44"
    },
    {
      "turn": 89,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g4+",
          "aggressive_uci": "g2g4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 g6 4. Bxf6 exf6 5. e3 c6 6. c4 Bb4+ 7. Nc3 Na6 8.\nQb3 Bxc3+ 9. Qxc3 Qe7 10. c5 Rb8 11. Bxa6 bxa6 12. O-O d5 13. cxd6 Qxd6 14.\nRac1 Bd7 15. Nd2 Qd5 16. e4 fxe4 17. Nxe4 O-O 18. Nc5 Rf7 19. Nxa6 Rb6 20. Nc7\nQd6 21. Qa5 Qxc7 22. d5 Qb7 23. dxc6 Bxc6 24. Rfd1 Bb5 25. Rd8+ Kg7 26. Qc3 Rc6\n27. Qe1 g5 28. Rxc6 Bxc6 29. Qc3 Qe7 30. Rd1 Qe6 31. Re1 Qd5 32. Qg3 a5 33. h4\nRd7 34. hxg5 fxg5 35. Re5 Qd1+ 36. Re1 Qxe1+ 37. Kh2 Qe7 38. Qc3+ Kf7 39. Qxc6\nQd6+ 40. Qxd6 Rxd6 41. Kg3 Kg6 42. f4 Kf5 43. fxg5 Rd3+ 44. Kh4 Rd2 45. g4+ Kf4 46. Kh3 Rxb2 47. g6 hxg6 48. g5 Rxa2 49. Kh4 Rh2#",
          "aggressive_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 416,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf4",
            "Kh3",
            "Rxb2",
            "g6",
            "hxg6",
            "g5",
            "Rxa2",
            "Kh4",
            "Rh2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g4+",
          "positional_uci": "g2g4",
          "positional_response": "45. g4+ Kf4 46. Kh3 Rxb2 47. g6 hxg6 48. g5 Rxa2 49. Kh4 Rh2#",
          "positional_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 41,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf4",
            "Kh3",
            "Rxb2",
            "g6",
            "hxg6",
            "g5",
            "Rxa2",
            "Kh4",
            "Rh2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd2",
          "neutral_uci": null,
          "neutral_response": "Rd2 Rg2 Kf3",
          "neutral_tokens": {
            "prompt_tokens": 483,
            "completion_tokens": 8,
            "total_tokens": 491,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg2",
            "Kf3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g2g4",
          "positional_uci": "g2g4",
          "neutral_uci": null,
          "consensus_move": "g2g4",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf4",
              "Kh3",
              "Rxb2",
              "g6",
              "hxg6",
              "g5",
              "Rxa2",
              "Kh4",
              "Rh2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf4",
              "Kh3",
              "Rxb2",
              "g6",
              "hxg6",
              "g5",
              "Rxa2",
              "Kh4",
              "Rh2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg2",
              "Kf3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 484,
            "completion_tokens": 416,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 484,
            "completion_tokens": 41,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 483,
            "completion_tokens": 8,
            "total_tokens": 491,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1451,
          "total_completion_tokens": 465,
          "total_tokens": 1916
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 484,
            "completion_tokens": 416,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 484,
            "completion_tokens": 41,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 483,
            "completion_tokens": 8,
            "total_tokens": 491,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/7p/8/p4kP1/7K/8/PP1r2P1/8 w - - 3 45"
    },
    {
      "turn": 91,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "d4 f5 Nf3 Nf6 Bg5 g6 Bxf6 exf6 e3 c6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rac1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bc6 Rd1 Qe6 Re1 Qd5 Qg3 a5 h4 Rb7 hxg5 fxg5 Re5 Qd1+ Re1 Qxe1+ Kh2 Qe7 Qc3+ Kf7 Qxc6 Qd6+ Qxd6 Rxd6 Kg3 Kf5 f4 Kf5 fxg5 Rd3+ Kh4 Rd2 g4+ Kf4 Rd2 g3+ Kf5 *",
          "aggressive_tokens": {
            "prompt_tokens": 494,
            "completion_tokens": 216,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "g6",
            "Bxf6",
            "exf6",
            "e3",
            "c6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rac1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bc6",
            "Rd1",
            "Qe6",
            "Re1",
            "Qd5",
            "Qg3",
            "a5",
            "h4",
            "Rb7",
            "hxg5",
            "fxg5",
            "Re5",
            "Qd1+",
            "Re1",
            "Qxe1+",
            "Kh2",
            "Qe7",
            "Qc3+",
            "Kf7",
            "Qxc6",
            "Qd6+",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Kf5",
            "f4",
            "Kf5",
            "fxg5",
            "Rd3+",
            "Kh4",
            "Rd2",
            "g4+",
            "Kf4",
            "Rd2",
            "g3+",
            "Kf5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "d4 d5 Nf3 Nc6 Bg5 Bxg4 e3 e6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rc1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qd5 Re1 Qd6 Qc3 Qd5 Qg3 Rd7 h4 Rxc6 bxc6 Qxc6 Qxc6 Bxc6 Rd2 f4 Kf5 fxg5 Rd3 Kh4 Rd2 g4 Kf5 g5 Kf4 g6 Kf5 g7 Kf6 g8=Q Kf5 Qg5+ Ke6 Qxg4+ Kd6 Qf4+ Kc6 Qe4+ Kb6 Qd4+ Kc6 Qc4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Qb4+ Kc6 Qa4+ Kb6 Q",
          "positional_tokens": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bg5",
            "Bxg4",
            "e3",
            "e6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qd5",
            "Re1",
            "Qd6",
            "Qc3",
            "Qd5",
            "Qg3",
            "Rd7",
            "h4",
            "Rxc6",
            "bxc6",
            "Qxc6",
            "Qxc6",
            "Bxc6",
            "Rd2",
            "f4",
            "Kf5",
            "fxg5",
            "Rd3",
            "Kh4",
            "Rd2",
            "g4",
            "Kf5",
            "g5",
            "Kf4",
            "g6",
            "Kf5",
            "g7",
            "Kf6",
            "g8=Q",
            "Kf5",
            "Qg5+",
            "Ke6",
            "Qxg4+",
            "Kd6",
            "Qf4+",
            "Kc6",
            "Qe4+",
            "Kb6",
            "Qd4+",
            "Kc6",
            "Qc4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Qa4+",
            "Kb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": null,
          "neutral_response": "d4 f5 Nf3 Nf6 Bg5 g6 Bxf6 exf6 e3 c6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rac1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bc6 Rd1 Qe6 Re1 Qd5 Qg3 a5 h4 Rb7 hxg5 fxg5 Re5 Qd1+ Re1 Qxe1+ Kh2 Qe7 Qc3+ Kf7 Qxc6 Qd6+ Qxd6 Rxd6 Kg3 Kf5 f4 Kf5 fxg5 Rd3+ Kh4 Rd2 g4+ Kf4 Rd2 g3+ Kf5 * d4 f5 Nf3 Nf6 Bg5 g6 Bxf6 exf6 e3 c6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rac1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bc6 Rd1 Qe6 Re1 Qd5 Qg3 a5 h4 Rb7 hxg5 fxg5 Re5 Qd1+ Re1 Qxe1+ Kh2 Qe7 Qc3+ Kf7 Qxc6 Qd6+ Qxd6 Rxd6 Kg3 Kf5 f4 Kf5 fxg5 Rd3+ Kh4 Rd2 g4+ Kf4 Rd2 g3+ Kf5 * d4 f5 Nf3 Nf6 Bg5 g6 Bxf6 exf6 e3 c6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rac1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bc6 Rd1 Qe6 Re1 Qd5 Qg3 a5 h4 Rb7 hxg5 fxg5 Re5 Qd1+ Re1 Qxe1+ Kh2 Qe7 Qc3+ Kf7 Qxc6 Qd6+ Qxd6 Rxd6 Kg3 Kf5 f4 Kf5 fxg5 Rd3+ Kh4 Rd2 g4+ Kf4 Rd",
          "neutral_tokens": {
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "g6",
            "Bxf6",
            "exf6",
            "e3",
            "c6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rac1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bc6",
            "Rd1",
            "Qe6",
            "Re1",
            "Qd5",
            "Qg3",
            "a5",
            "h4",
            "Rb7",
            "hxg5",
            "fxg5",
            "Re5",
            "Qd1+",
            "Re1",
            "Qxe1+",
            "Kh2",
            "Qe7",
            "Qc3+",
            "Kf7",
            "Qxc6",
            "Qd6+",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Kf5",
            "f4",
            "Kf5",
            "fxg5",
            "Rd3+",
            "Kh4",
            "Rd2",
            "g4+",
            "Kf4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "g6",
              "Bxf6",
              "exf6",
              "e3",
              "c6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rac1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bc6",
              "Rd1",
              "Qe6",
              "Re1",
              "Qd5",
              "Qg3",
              "a5",
              "h4",
              "Rb7",
              "hxg5",
              "fxg5",
              "Re5",
              "Qd1+",
              "Re1",
              "Qxe1+",
              "Kh2",
              "Qe7",
              "Qc3+",
              "Kf7",
              "Qxc6",
              "Qd6+",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Kf5",
              "f4",
              "Kf5",
              "fxg5",
              "Rd3+",
              "Kh4",
              "Rd2",
              "g4+",
              "Kf4",
              "Rd2",
              "g3+",
              "Kf5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bg5",
              "Bxg4",
              "e3",
              "e6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qd5",
              "Re1",
              "Qd6",
              "Qc3",
              "Qd5",
              "Qg3",
              "Rd7",
              "h4",
              "Rxc6",
              "bxc6",
              "Qxc6",
              "Qxc6",
              "Bxc6",
              "Rd2",
              "f4",
              "Kf5",
              "fxg5",
              "Rd3",
              "Kh4",
              "Rd2",
              "g4",
              "Kf5",
              "g5",
              "Kf4",
              "g6",
              "Kf5",
              "g7",
              "Kf6",
              "g8=Q",
              "Kf5",
              "Qg5+",
              "Ke6",
              "Qxg4+",
              "Kd6",
              "Qf4+",
              "Kc6",
              "Qe4+",
              "Kb6",
              "Qd4+",
              "Kc6",
              "Qc4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Qa4+",
              "Kb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "g6",
              "Bxf6",
              "exf6",
              "e3",
              "c6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rac1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bc6",
              "Rd1",
              "Qe6",
              "Re1",
              "Qd5",
              "Qg3",
              "a5",
              "h4",
              "Rb7",
              "hxg5",
              "fxg5",
              "Re5",
              "Qd1+",
              "Re1",
              "Qxe1+",
              "Kh2",
              "Qe7",
              "Qc3+",
              "Kf7",
              "Qxc6",
              "Qd6+",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Kf5",
              "f4",
              "Kf5",
              "fxg5",
              "Rd3+",
              "Kh4",
              "Rd2",
              "g4+",
              "Kf4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 494,
            "completion_tokens": 216,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1481,
          "total_completion_tokens": 1496,
          "total_tokens": 2977
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 494,
            "completion_tokens": 216,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/7p/8/p5P1/5kPK/8/PP1r4/8 w - - 1 46"
    },
    {
      "turn": 91,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "d4 f5 Nf3 Nf6 Bg5 g6 Bxf6 exf6 e3 c6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rac1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bc6 Rd1 Qe6 Re1 Qd5 Qg3 a5 h4 Rb7 hxg5 fxg5 Re5 Qd1+ Re1 Qxe1+ Kh2 Qe7 Qc3+ Kf7 Qxc6 Qd6+ Qxd6 Rxd6 Kg3 Kf5 f4 Kf5 fxg5 Rd3+ Kh4 Rd2 g4+ Kf4 Rd2 g3+ Kf5 *",
          "aggressive_tokens": {
            "prompt_tokens": 494,
            "completion_tokens": 216,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "g6",
            "Bxf6",
            "exf6",
            "e3",
            "c6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rac1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bc6",
            "Rd1",
            "Qe6",
            "Re1",
            "Qd5",
            "Qg3",
            "a5",
            "h4",
            "Rb7",
            "hxg5",
            "fxg5",
            "Re5",
            "Qd1+",
            "Re1",
            "Qxe1+",
            "Kh2",
            "Qe7",
            "Qc3+",
            "Kf7",
            "Qxc6",
            "Qd6+",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Kf5",
            "f4",
            "Kf5",
            "fxg5",
            "Rd3+",
            "Kh4",
            "Rd2",
            "g4+",
            "Kf4",
            "Rd2",
            "g3+",
            "Kf5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "d4 d5 Nf3 Nc6 Bg5 Bxg4 e3 e6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rc1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rb6 h5 Rd1+ Kf2 Qe6 Qc3 Qd5 Qg3 Rb6 h4 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e4 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6 e5 fxe5 Nxe4 O-O Nc5 Rf7 Nd2 Qd6",
          "positional_tokens": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bg5",
            "Bxg4",
            "e3",
            "e6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rb6",
            "h5",
            "Rd1+",
            "Kf2",
            "Qe6",
            "Qc3",
            "Qd5",
            "Qg3",
            "Rb6",
            "h4",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6",
            "e5",
            "fxe5",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nd2",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": null,
          "neutral_response": "d4 d5 Nf3 Nc6 Bg5 Bxg4 e3 c5 cxd4 Qxd4 Rc1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 Rd1 Qe6 Qg3 Rg6 Rd1 Rf7 Nc5 Qd6 Qxd6 Rxd6 Kg3 Kf8 f4 Ke8 f5 Rb6 b3 Rc7 Ne6 Rc3+ Kf4 Rb4+ Ke5 Re3+ Kd6 Rb5 Kc6 Rb4 a5 Rd4 Rb5+ Kc4 Rb4+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 Rb4 Rb5+ Kc5 Rb5+ Kc6 R",
          "neutral_tokens": {
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bg5",
            "Bxg4",
            "e3",
            "c5",
            "cxd4",
            "Qxd4",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "Rd1",
            "Qe6",
            "Qg3",
            "Rg6",
            "Rd1",
            "Rf7",
            "Nc5",
            "Qd6",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Kf8",
            "f4",
            "Ke8",
            "f5",
            "Rb6",
            "b3",
            "Rc7",
            "Ne6",
            "Rc3+",
            "Kf4",
            "Rb4+",
            "Ke5",
            "Re3+",
            "Kd6",
            "Rb5",
            "Kc6",
            "Rb4",
            "a5",
            "Rd4",
            "Rb5+",
            "Kc4",
            "Rb4+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6",
            "Rb4",
            "Rb5+",
            "Kc5",
            "Rb5+",
            "Kc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "g6",
              "Bxf6",
              "exf6",
              "e3",
              "c6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rac1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bc6",
              "Rd1",
              "Qe6",
              "Re1",
              "Qd5",
              "Qg3",
              "a5",
              "h4",
              "Rb7",
              "hxg5",
              "fxg5",
              "Re5",
              "Qd1+",
              "Re1",
              "Qxe1+",
              "Kh2",
              "Qe7",
              "Qc3+",
              "Kf7",
              "Qxc6",
              "Qd6+",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Kf5",
              "f4",
              "Kf5",
              "fxg5",
              "Rd3+",
              "Kh4",
              "Rd2",
              "g4+",
              "Kf4",
              "Rd2",
              "g3+",
              "Kf5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bg5",
              "Bxg4",
              "e3",
              "e6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rb6",
              "h5",
              "Rd1+",
              "Kf2",
              "Qe6",
              "Qc3",
              "Qd5",
              "Qg3",
              "Rb6",
              "h4",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6",
              "e5",
              "fxe5",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nd2",
              "Qd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bg5",
              "Bxg4",
              "e3",
              "c5",
              "cxd4",
              "Qxd4",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "Rd1",
              "Qe6",
              "Qg3",
              "Rg6",
              "Rd1",
              "Rf7",
              "Nc5",
              "Qd6",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Kf8",
              "f4",
              "Ke8",
              "f5",
              "Rb6",
              "b3",
              "Rc7",
              "Ne6",
              "Rc3+",
              "Kf4",
              "Rb4+",
              "Ke5",
              "Re3+",
              "Kd6",
              "Rb5",
              "Kc6",
              "Rb4",
              "a5",
              "Rd4",
              "Rb5+",
              "Kc4",
              "Rb4+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6",
              "Rb4",
              "Rb5+",
              "Kc5",
              "Rb5+",
              "Kc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 494,
            "completion_tokens": 216,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1481,
          "total_completion_tokens": 1496,
          "total_tokens": 2977
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 494,
            "completion_tokens": 216,
            "total_tokens": 710,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/7p/8/p5P1/5kPK/8/PP1r4/8 w - - 1 46"
    },
    {
      "turn": 91,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "d4 f5 Nf3 Nf6 Bg5 g6 Bxf6 exf6 e3 c6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rac1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bc6 Rd1 Qe6 Re1 Qd5 Qg3 a5 h4 Rb7 hxg5 fxg5 Re5 Qd1+ Re1 Qxe1+ Kh2 Qe7 Qc3+ Kf7 Qxc6 Qd6+ Qxd6 Rxd6 Kg3 Kf5 f4 Kf5 fxg5 Rd3+ Kh4 Rd2 g4+ Kf4 Rd2 g3+ Kf5 g2 Rg8 Rf2+ Ke6 Rf3 Rg2+ Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg2 Kf4 Rf2+ Ke3 Rg",
          "aggressive_tokens": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "g6",
            "Bxf6",
            "exf6",
            "e3",
            "c6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rac1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bc6",
            "Rd1",
            "Qe6",
            "Re1",
            "Qd5",
            "Qg3",
            "a5",
            "h4",
            "Rb7",
            "hxg5",
            "fxg5",
            "Re5",
            "Qd1+",
            "Re1",
            "Qxe1+",
            "Kh2",
            "Qe7",
            "Qc3+",
            "Kf7",
            "Qxc6",
            "Qd6+",
            "Qxd6",
            "Rxd6",
            "Kg3",
            "Kf5",
            "f4",
            "Kf5",
            "fxg5",
            "Rd3+",
            "Kh4",
            "Rd2",
            "g4+",
            "Kf4",
            "Rd2",
            "g3+",
            "Kf5",
            "g2",
            "Rg8",
            "Rf2+",
            "Ke6",
            "Rf3",
            "Rg2+",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3",
            "Rg2",
            "Kf4",
            "Rf2+",
            "Ke3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "d4 d5 Nf3 Nc6 Bg5 Bxg4 e3 e6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rc1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rb6 h5 Rd7 Rxc6 Bxc6 Qxc6 Qd6 Qg3 Rb6 h4 Rxc6 Qxc6 Qd6 Re1 Qd5 Qg3 a5 h4 Rf7 h5 Rb6 Rc1 Bd7 Nd2 Qd6 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rbxc6 Qxc6 Qd6 Qg3 a5 h5 Rf5 h6 Rb6 Rc1 Bd7 Nd2 Qd6 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rbxc6 Qxc6 Qd6 Qg3 a5 h5 Rf5 h6 Rb6 Rc1 Bd7 Nd2 Qd6 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rbxc6 Qxc6 Qd6 Qg3 a5 h5 Rf5 h6 Rb6 Rc1 Bd7 Nd2 Qd6 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rbxc6 Qxc6 Qd6 Qg3 a5 h5 Rf5 h6 Rb6 Rc1 Bd7 Nd2 Qd6 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rbxc6 Qxc6 Qd6 Qg3 a5 h5 Rf5 h6 Rb6 Rc1 Bd7 Nd2 Qd6 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe7 h4 Rbxc6 Qxc6 Q",
          "positional_tokens": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bg5",
            "Bxg4",
            "e3",
            "e6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rb6",
            "h5",
            "Rd7",
            "Rxc6",
            "Bxc6",
            "Qxc6",
            "Qd6",
            "Qg3",
            "Rb6",
            "h4",
            "Rxc6",
            "Qxc6",
            "Qd6",
            "Re1",
            "Qd5",
            "Qg3",
            "a5",
            "h4",
            "Rf7",
            "h5",
            "Rb6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rbxc6",
            "Qxc6",
            "Qd6",
            "Qg3",
            "a5",
            "h5",
            "Rf5",
            "h6",
            "Rb6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rbxc6",
            "Qxc6",
            "Qd6",
            "Qg3",
            "a5",
            "h5",
            "Rf5",
            "h6",
            "Rb6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rbxc6",
            "Qxc6",
            "Qd6",
            "Qg3",
            "a5",
            "h5",
            "Rf5",
            "h6",
            "Rb6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rbxc6",
            "Qxc6",
            "Qd6",
            "Qg3",
            "a5",
            "h5",
            "Rf5",
            "h6",
            "Rb6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rbxc6",
            "Qxc6",
            "Qd6",
            "Qg3",
            "a5",
            "h5",
            "Rf5",
            "h6",
            "Rb6",
            "Rc1",
            "Bd7",
            "Nd2",
            "Qd6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe7",
            "h4",
            "Rbxc6",
            "Qxc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": null,
          "neutral_response": "d4 d5 Nf3 Nc6 Bg5 Bxg4 e3 e6 c4 Bb4+ Nc3 Na6 Qb3 Bxc3+ Qxc3 Qe7 c5 Rb8 Bxa6 bxa6 O-O d5 cxd6 Qxd6 Rac1 Bd7 Nd2 Qd5 e4 fxe4 Nxe4 O-O Nc5 Rf7 Nxa6 Rb6 Nc7 Qd6 Qa5 Qxc7 d5 Bb5 Rd1 Qe6 Re1 Qd5 Qc3 Qd6 Qe1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd6 Re1 Qd5 Re5 Qd",
          "neutral_tokens": {
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bg5",
            "Bxg4",
            "e3",
            "e6",
            "c4",
            "Bb4+",
            "Nc3",
            "Na6",
            "Qb3",
            "Bxc3+",
            "Qxc3",
            "Qe7",
            "c5",
            "Rb8",
            "Bxa6",
            "bxa6",
            "O-O",
            "d5",
            "cxd6",
            "Qxd6",
            "Rac1",
            "Bd7",
            "Nd2",
            "Qd5",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Nc5",
            "Rf7",
            "Nxa6",
            "Rb6",
            "Nc7",
            "Qd6",
            "Qa5",
            "Qxc7",
            "d5",
            "Bb5",
            "Rd1",
            "Qe6",
            "Re1",
            "Qd5",
            "Qc3",
            "Qd6",
            "Qe1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5",
            "Qd6",
            "Re1",
            "Qd5",
            "Re5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "g6",
              "Bxf6",
              "exf6",
              "e3",
              "c6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rac1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bc6",
              "Rd1",
              "Qe6",
              "Re1",
              "Qd5",
              "Qg3",
              "a5",
              "h4",
              "Rb7",
              "hxg5",
              "fxg5",
              "Re5",
              "Qd1+",
              "Re1",
              "Qxe1+",
              "Kh2",
              "Qe7",
              "Qc3+",
              "Kf7",
              "Qxc6",
              "Qd6+",
              "Qxd6",
              "Rxd6",
              "Kg3",
              "Kf5",
              "f4",
              "Kf5",
              "fxg5",
              "Rd3+",
              "Kh4",
              "Rd2",
              "g4+",
              "Kf4",
              "Rd2",
              "g3+",
              "Kf5",
              "g2",
              "Rg8",
              "Rf2+",
              "Ke6",
              "Rf3",
              "Rg2+",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3",
              "Rg2",
              "Kf4",
              "Rf2+",
              "Ke3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bg5",
              "Bxg4",
              "e3",
              "e6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rb6",
              "h5",
              "Rd7",
              "Rxc6",
              "Bxc6",
              "Qxc6",
              "Qd6",
              "Qg3",
              "Rb6",
              "h4",
              "Rxc6",
              "Qxc6",
              "Qd6",
              "Re1",
              "Qd5",
              "Qg3",
              "a5",
              "h4",
              "Rf7",
              "h5",
              "Rb6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rbxc6",
              "Qxc6",
              "Qd6",
              "Qg3",
              "a5",
              "h5",
              "Rf5",
              "h6",
              "Rb6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rbxc6",
              "Qxc6",
              "Qd6",
              "Qg3",
              "a5",
              "h5",
              "Rf5",
              "h6",
              "Rb6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rbxc6",
              "Qxc6",
              "Qd6",
              "Qg3",
              "a5",
              "h5",
              "Rf5",
              "h6",
              "Rb6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rbxc6",
              "Qxc6",
              "Qd6",
              "Qg3",
              "a5",
              "h5",
              "Rf5",
              "h6",
              "Rb6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rbxc6",
              "Qxc6",
              "Qd6",
              "Qg3",
              "a5",
              "h5",
              "Rf5",
              "h6",
              "Rb6",
              "Rc1",
              "Bd7",
              "Nd2",
              "Qd6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe7",
              "h4",
              "Rbxc6",
              "Qxc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bg5",
              "Bxg4",
              "e3",
              "e6",
              "c4",
              "Bb4+",
              "Nc3",
              "Na6",
              "Qb3",
              "Bxc3+",
              "Qxc3",
              "Qe7",
              "c5",
              "Rb8",
              "Bxa6",
              "bxa6",
              "O-O",
              "d5",
              "cxd6",
              "Qxd6",
              "Rac1",
              "Bd7",
              "Nd2",
              "Qd5",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Nc5",
              "Rf7",
              "Nxa6",
              "Rb6",
              "Nc7",
              "Qd6",
              "Qa5",
              "Qxc7",
              "d5",
              "Bb5",
              "Rd1",
              "Qe6",
              "Re1",
              "Qd5",
              "Qc3",
              "Qd6",
              "Qe1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5",
              "Qd6",
              "Re1",
              "Qd5",
              "Re5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1481,
          "total_completion_tokens": 1920,
          "total_tokens": 3401
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 494,
            "completion_tokens": 640,
            "total_tokens": 1134,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 493,
            "completion_tokens": 640,
            "total_tokens": 1133,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/7p/8/p5P1/5kPK/8/PP1r4/8 w - - 1 46"
    }
  ],
  "black_responses": [],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [],
  "black_plan_log": [],
  "timestamp": "2025-11-29T23:20:56.069351",
  "game_id": "gpt-3.5-turbo-instruct_vs_Stockfish_SC_5",
  "configuration": "SC"
}