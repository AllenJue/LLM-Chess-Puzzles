{
  "query1": {
    "aggressive_move": "Rc5+",
    "aggressive_uci": "c4c5",
    "aggressive_response": "1. e4 c5 2. Nf3 g6 3. c3 Bg7 4. d4 cxd4 5. cxd4 e6 6. Nc3 Ne7 7. Be3 O-O 8. Qd2 a6 9. Bh6 b5 10. Bxg7 Kxg7 11. O-O-O Bb7 12. d5 exd5 13. exd5 d6 14. Qd4+ Kg8 15. Bd3 Nd7 16. Qh4 Nf5 17. Bxf5 Qxh4 18. Nxh4 gxf5 19. Nxf5 Nf6 20. Nxd6 Bc8 21. Nde4 Ng4 22. h3 Ne5 23. d6 Bf5 24. g4 Bg6 25. d7 b4 26. Nf6+ Kg7 27. Ncd5 Rfd8 28. Rhe1 Nxd7 29. Nxd7 Rxd7 30. Nb6 Rc7+ 31. Kd2 Rd8+ 32. Ke2 Rc2+ 33. Kf1 Rxd1 34. Rxd1 Rxb2 35. Ra1 a5 36. Kg1 h5 37. gxh5 Bxh5 38. Nc4 Rc2 39. Nxa5 Bf3 40. Nb3 Rc6 41. Nd4 Rg6+ 42. Kf1 Bg2+ 43. Ke1 Bxh3 44. Ke2 Bg4+ 45. f3 Bd7 46. Ke3 Ra6 47. Nb3 Ra3 48. Kd4 Be6 49. Nc1 Rxf3 50. Nd3 b3 51. axb3 Bxb3 52. Rg1+ Kf8 53. Ne5 Rf4+ 54. Kc3 Be6 55. Nd3 Ke7 56. Re1 Rc4+ 57. Kd2 Rd4 58. Ke3 Rh4 59. Nf4 Rh6 60. Kf3 Rf6 61. Kg3 Kd6 62. Rd1+ Ke5 63. Re1+ Kf5 64. Rf1 Ke4 65. Re1+ Kd4 66. Rd1+ Ke3 67. Rd3+ Ke4 68. Ra3 Bc4 69. Ra4 Rc6 70. Ra7 Rc5 71. Re7+ Re5 72. Rc7 Rg5+ 73. Kh4 Kxf4 74. Rxc4+ Kf5 75. Rc5+ Kf6 76. Rxg5 Kxg5",
    "aggressive_tokens": {
      "prompt_tokens": 723,
      "completion_tokens": 618,
      "total_tokens": 1341,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Kf6",
      "Rxg5",
      "Kxg5"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Rc5+",
    "positional_uci": "c4c5",
    "positional_response": "1. e4 c5 2. Nf3 g6 3. c3 Bg7 4. d4 cxd4 5. cxd4 e6 6. Nc3 Ne7 7. Be3 O-O 8. Qd2 a6 9. Bh6 b5 10. Bxg7 Kxg7 11. O-O-O Bb7 12. d5 exd5 13. exd5 d6 14. Qd4+ Kg8 15. Bd3 Nd7 16. Qh4 Nf5 17. Bxf5 Qxh4 18. Nxh4 gxf5 19. Nxf5 Nf6 20. Nxd6 Bc8 21. Nde4 Ng4 22. h3 Ne5 23. d6 Bf5 24. g4 Bg6 25. d7 b4 26. Nf6+ Kg7 27. Ncd5 Rfd8 28. Rhe1 Nxd7 29. Nxd7 Rxd7 30. Nb6 Rc7+ 31. Kd2 Rd8+ 32. Ke2 Rc2+ 33. Kf1 Rxd1 34. Rxd1 Rxb2 35. Ra1 a5 36. Kg1 h5 37. gxh5 Bxh5 38. Nc4 Rc2 39. Nxa5 Bf3 40. Nb3 Rc6 41. Nd4 Rg6+ 42. Kf1 Bg2+ 43. Ke1 Bxh3 44. Ke2 Bg4+ 45. f3 Bd7 46. Ke3 Ra6 47. Nb3 Ra3 48. Kd4 Be6 49. Nc1 Rxf3 50. Nd3 b3 51. axb3 Bxb3 52. Rg1+ Kf8 53. Ne5 Rf4+ 54. Kc3 Be6 55. Nd3 Ke7 56. Re1 Rc4+ 57. Kd2 Rd4 58. Ke3 Rh4 59. Nf4 Rh6 60. Kf3 Rf6 61. Kg3 Kd6 62. Rd1+ Ke5 63. Re1+ Kf5 64. Rf1 Ke4 65. Re1+ Kd4 66. Rd1+ Ke3 67. Rd3+ Ke4 68. Ra3 Bc4 69. Ra4 Rc6 70. Ra7 Rc5 71. Re7+ Re5 72. Rc7 Rg5+ 73. Kh4 Kxf4 74. Rxc4+ Kf5 75. Rc5+ Kf6 76. Rxg5 Kxg5",
    "positional_tokens": {
      "prompt_tokens": 723,
      "completion_tokens": 618,
      "total_tokens": 1341,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Kf6",
      "Rxg5",
      "Kxg5"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Rc5+",
    "neutral_uci": "c4c5",
    "neutral_response": "1. e4 c5 2. Nf3 g6 3. c3 Bg7 4. d4 cxd4 5. cxd4 e6 6. Nc3 Ne7 7. Be3 O-O 8. Qd2 a6 9. Bh6 b5 10. Bxg7 Kxg7 11. O-O-O Bb7 12. d5 exd5 13. exd5 d6 14. Qd4+ Kg8 15. Bd3 Nd7 16. Qh4 Nf5 17. Bxf5 Qxh4 18. Nxh4 gxf5 19. Nxf5 Nf6 20. Nxd6 Bc8 21. Nde4 Ng4 22. h3 Ne5 23. d6 Bf5 24. g4 Bg6 25. d7 b4 26. Nf6+ Kg7 27. Ncd5 Rfd8 28. Rhe1 Nxd7 29. Nxd7 Rxd7 30. Nb6 Rc7+ 31. Kd2 Rd8+ 32. Ke2 Rc2+ 33. Kf1 Rxd1 34. Rxd1 Rxb2 35. Ra1 a5 36. Kg1 h5 37. gxh5 Bxh5 38. Nc4 Rc2 39. Nxa5 Bf3 40. Nb3 Rc6 41. Nd4 Rg6+ 42. Kf1 Bg2+ 43. Ke1 Bxh3 44. Ke2 Bg4+ 45. f3 Bd7 46. Ke3 Ra6 47. Nb3 Ra3 48. Kd4 Be6 49. Nc1 Rxf3 50. Nd3 b3 51. axb3 Bxb3 52. Rg1+ Kf8 53. Ne5 Rf4+ 54. Kc3 Be6 55. Nd3 Ke7 56. Re1 Rc4+ 57. Kd2 Rd4 58. Ke3 Rh4 59. Nf4 Rh6 60. Kf3 Rf6 61. Kg3 Kd6 62. Rd1+ Ke5 63. Re1+ Kf5 64. Rf1 Ke4 65. Re1+ Kd4 66. Rd1+ Ke3 67. Rd3+ Ke4 68. Ra3 Bc4 69. Ra4 Rc6 70. Ra7 Rc5 71. Re7+ Re5 72. Rc7 Rg5+ 73. Kh4 Kxf4 74. Rxc4+ Kf5 75. Rc5+ Kf6 76. Rxg5 Kxg5",
    "neutral_tokens": {
      "prompt_tokens": 722,
      "completion_tokens": 618,
      "total_tokens": 1340,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Kf6",
      "Rxg5",
      "Kxg5"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "c4c5",
    "positional_uci": "c4c5",
    "neutral_uci": "c4c5",
    "consensus_move": "c4c5",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Kf6",
        "Rxg5",
        "Kxg5"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Kf6",
        "Rxg5",
        "Kxg5"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Kf6",
        "Rxg5",
        "Kxg5"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 723,
      "completion_tokens": 618,
      "total_tokens": 1341,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 723,
      "completion_tokens": 618,
      "total_tokens": 1341,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 722,
      "completion_tokens": 618,
      "total_tokens": 1340,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 2168,
    "total_completion_tokens": 1854,
    "total_tokens": 4022
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 148,
      "turn_number": 75,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 723,
      "completion_tokens": 618,
      "total_tokens": 1341,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 148,
      "turn_number": 75,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 723,
      "completion_tokens": 618,
      "total_tokens": 1341,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 148,
      "turn_number": 75,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 722,
      "completion_tokens": 618,
      "total_tokens": 1340,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}