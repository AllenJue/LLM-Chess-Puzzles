{
  "query1": {
    "aggressive_move": "Rad8",
    "aggressive_uci": null,
    "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. O-O Bd7 5. Nc3 Nf6 6. Re1 Be7 7. d4 exd4 8. Nxd4 Nxd4 9. Bxd7+ Nxd7 10. Qxd4 O-O 11. Nd5 c5 12. Nxe7+ Qxe7 13. Qd5 Nf6 14. Qc4 a6 15. Bg5 b5 16. Qe2 h6 17. Bh4 Qe5 18. Bg3 Qxb2 19. Bxd6 Rfe8 20. e5 Nd5 21. Bxc5 Qc3 22. Bd6 Qc8 23. Rad1 Rad8 24. Rxd5 Rxd6 25. Rxd6 Qc5 26. Rxa6 Rxe5",
    "aggressive_tokens": {
      "prompt_tokens": 301,
      "completion_tokens": 210,
      "total_tokens": 511,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rxd5",
      "Rxd6",
      "Rxd6",
      "Qc5",
      "Rxa6",
      "Rxe5"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Rad8",
    "positional_uci": null,
    "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. O-O Bd7 5. Nc3 Nf6 6. Re1 Be7 7. d4 exd4 8. Nxd4 Nxd4 9. Bxd7+ Nxd7 10. Qxd4 O-O 11. Nd5 c5 12. Nxe7+ Qxe7 13. Qd5 Nf6 14. Qc4 a6 15. Bg5 b5 16. Qe2 h6 17. Bh4 Qe5 18. Bg3 Qxb2 19. Bxd6 Rfe8 20. e5 Nd5 21. Bxc5 Qc3 22. Bd6 Qc8 23. Rad1 Rad8 24. Rxd5 Qc4 25. Qxc4 bxc4 26. Red1 Rc8",
    "positional_tokens": {
      "prompt_tokens": 301,
      "completion_tokens": 208,
      "total_tokens": 509,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rxd5",
      "Qc4",
      "Qxc4",
      "bxc4",
      "Red1",
      "Rc8"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Rad8",
    "neutral_uci": null,
    "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. O-O Bd7 5. Nc3 Nf6 6. Re1 Be7 7. d4 exd4 8. Nxd4 Nxd4 9. Bxd7+ Nxd7 10. Qxd4 O-O 11. Nd5 c5 12. Nxe7+ Qxe7 13. Qd5 Nf6 14. Qc4 a6 15. Bg5 b5 16. Qe2 h6 17. Bh4 Qe5 18. Bg3 Qxb2 19. Bxd6 Rfe8 20. e5 Nd5 21. Bxc5 Qc3 22. Bd6 Qc8 23. Rad1 Rad8 24. Rxd5 Qc4 25. Qxc4 bxc4 26. Red1 Re6\n\nRd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd1 Rd5 Qxc4 bxc4 Rd",
    "neutral_tokens": {
      "prompt_tokens": 300,
      "completion_tokens": 640,
      "total_tokens": 940,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Rxd5",
      "Qc4",
      "Qxc4",
      "bxc4",
      "Red1",
      "Re6",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4",
      "Rd1",
      "Rd5",
      "Qxc4",
      "bxc4"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": null,
    "positional_uci": null,
    "neutral_uci": null,
    "consensus_move": null,
    "source_agents": [],
    "selected_agent": null
  },
  "plans": {
    "aggressive": {
      "full": [
        "Rxd5",
        "Rxd6",
        "Rxd6",
        "Qc5",
        "Rxa6",
        "Rxe5"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Rxd5",
        "Qc4",
        "Qxc4",
        "bxc4",
        "Red1",
        "Rc8"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Rxd5",
        "Qc4",
        "Qxc4",
        "bxc4",
        "Red1",
        "Re6",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4",
        "Rd1",
        "Rd5",
        "Qxc4",
        "bxc4"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 301,
      "completion_tokens": 210,
      "total_tokens": 511,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 301,
      "completion_tokens": 208,
      "total_tokens": 509,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 300,
      "completion_tokens": 640,
      "total_tokens": 940,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "total_prompt_tokens": 902,
    "total_completion_tokens": 1058,
    "total_tokens": 1960
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 45,
      "turn_number": 23,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 301,
      "completion_tokens": 210,
      "total_tokens": 511,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 45,
      "turn_number": 23,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 301,
      "completion_tokens": 208,
      "total_tokens": 509,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 45,
      "turn_number": 23,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 300,
      "completion_tokens": 640,
      "total_tokens": 940,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    }
  ]
}