{
  "query1": {
    "aggressive_move": "Qxd4+",
    "aggressive_uci": "h8d4",
    "aggressive_response": "1. d4 Nf6 2. Nf3 d5 3. g3 Bg4 4. Bg2 Bxf3 5. Bxf3 e6 6. O-O Nbd7 7. Re1 Be7 8. Nd2 O-O 9. c4 c6 10. cxd5 cxd5 11. e4 dxe4 12. Nxe4 Qb6 13. Be3 Nd5 14. b3 Rac8 15. Rc1 Ba3 16. Rc2 Rc6 17. Rxc6 bxc6 18. Qc2 g6 19. Nc5 Nxc5 20. dxc5 Qb4 21. Bd2 Qxc5 22. Qxc5 Bxc5 23. Rc1 Bb6 24. Rxc6 Rd8 25. Bxd5 Rxd5 26. Rc8+ Kg7 27. Bc3+ e5 28. Re8 Bd4 29. Bb4 h5 30. Bf8+ Kh7 31. Kg2 Rd7 32. h4 f5 33. Re7+ Rxe7 34. Bxe7 e4 35. b4 Kg8 36. Bc5 Bxc5 37. bxc5 Kf7 38. Kf1 Ke6 39. Ke2 Kd5 40. Ke3 Kxc5 41. Kf4 Kd4 42. Kg5 Ke5 43. Kxg6 f4 44. gxf4+ Kxf4 45. Kxh5 Kf3 46. Kg6 Kxf2 47. h5 e3 48. h6 e2 49. h7 e1=Q 50. h8=Q Qe4+ 51. Kf7 Qd5+ 52. Ke7 Qb7+ 53. Kd6 Qb6+ 54. Kd5 Qb5+ 55. Kd6 Qb4+ 56. Kc7 Qb6+ 57. Kd7 Qb7+ 58. Ke6 Qb6+ 59. Kd5 Qb5+ 60. Ke4 Qc4+ 61. Kf5 Qd3+ 62. Ke6 Qc4+ 63. Kd7 Qxa2 64. Qxd4+",
    "aggressive_tokens": {
      "prompt_tokens": 649,
      "completion_tokens": 534,
      "total_tokens": 1183,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Qxd4+",
    "positional_uci": "h8d4",
    "positional_response": "1. d4 Nf6 2. Nf3 d5 3. g3 Bg4 4. Bg2 Bxf3 5. Bxf3 e6 6. O-O Nbd7 7. Re1 Be7 8. Nd2 O-O 9. c4 c6 10. cxd5 cxd5 11. e4 dxe4 12. Nxe4 Qb6 13. Be3 Nd5 14. b3 Rac8 15. Rc1 Ba3 16. Rc2 Rc6 17. Rxc6 bxc6 18. Qc2 g6 19. Nc5 Nxc5 20. dxc5 Qb4 21. Bd2 Qxc5 22. Qxc5 Bxc5 23. Rc1 Bb6 24. Rxc6 Rd8 25. Bxd5 Rxd5 26. Rc8+ Kg7 27. Bc3+ e5 28. Re8 Bd4 29. Bb4 h5 30. Bf8+ Kh7 31. Kg2 Rd7 32. h4 f5 33. Re7+ Rxe7 34. Bxe7 e4 35. b4 Kg8 36. Bc5 Bxc5 37. bxc5 Kf7 38. Kf1 Ke6 39. Ke2 Kd5 40. Ke3 Kxc5 41. Kf4 Kd4 42. Kg5 Ke5 43. Kxg6 f4 44. gxf4+ Kxf4 45. Kxh5 Kf3 46. Kg6 Kxf2 47. h5 e3 48. h6 e2 49. h7 e1=Q 50. h8=Q Qe4+ 51. Kf7 Qd5+ 52. Ke7 Qb7+ 53. Kd6 Qb6+ 54. Kd5 Qb5+ 55. Kd6 Qb4+ 56. Kc7 Qb6+ 57. Kd7 Qb7+ 58. Ke6 Qb6+ 59. Kd5 Qb5+ 60. Ke4 Qc4+ 61. Kf5 Qd3+ 62. Ke6 Qc4+ 63. Kd7 Qxa2 64. Qxd4+ Kxg3 65. Qe3+ Kg4 66. Qe4+ Kg5 67. Qe5+ Kg6",
    "positional_tokens": {
      "prompt_tokens": 649,
      "completion_tokens": 565,
      "total_tokens": 1214,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Kxg3",
      "Qe3+",
      "Kg4",
      "Qe4+",
      "Kg5",
      "Qe5+",
      "Kg6"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Qh2+",
    "neutral_uci": "h8h2",
    "neutral_response": "1. d4 Nf6 2. Nf3 d5 3. g3 Bg4 4. Bg2 Bxf3 5. Bxf3 e6 6. O-O Nbd7 7. Re1 Be7 8. Nd2 O-O 9. c4 c6 10. cxd5 cxd5 11. e4 dxe4 12. Nxe4 Qb6 13. Be3 Nd5 14. b3 Rac8 15. Rc1 Ba3 16. Rc2 Rc6 17. Rxc6 bxc6 18. Qc2 g6 19. Nc5 Nxc5 20. dxc5 Qb4 21. Bd2 Qxc5 22. Qxc5 Bxc5 23. Rc1 Bb6 24. Rxc6 Rd8 25. Bxd5 Rxd5 26. Rc8+ Kg7 27. Bc3+ e5 28. Re8 Bd4 29. Bb4 h5 30. Bf8+ Kh7 31. Kg2 Rd7 32. h4 f5 33. Re7+ Rxe7 34. Bxe7 e4 35. b4 Kg8 36. Bc5 Bxc5 37. bxc5 Kf7 38. Kf1 Ke6 39. Ke2 Kd5 40. Ke3 Kxc5 41. Kf4 Kd4 42. Kg5 Ke5 43. Kxg6 f4 44. gxf4+ Kxf4 45. Kxh5 Kf3 46. Kg6 Kxf2 47. h5 e3 48. h6 e2 49. h7 e1=Q 50. h8=Q Qe4+ 51. Kf7 Qd5+ 52. Ke7 Qb7+ 53. Kd6 Qb6+ 54. Kd5 Qb5+ 55. Kd6 Qb4+ 56. Kc7 Qb6+ 57. Kd7 Qb7+ 58. Ke6 Qb6+ 59. Kd5 Qb5+ 60. Ke4 Qc4+ 61. Kf5 Qd3+ 62. Ke6 Qc4+ 63. Kd7 Qxa2 64. Qh2+ Kf3 65. Qh3+ Ke4 66. Qg4+ Ke5\n\n64. Qh2+ Kf3 65. Qh3+ Ke4 66. Qg4+ Ke5",
    "neutral_tokens": {
      "prompt_tokens": 648,
      "completion_tokens": 583,
      "total_tokens": 1231,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Kf3",
      "Qh3+",
      "Ke4",
      "Qg4+",
      "Ke5"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "h8d4",
    "positional_uci": "h8d4",
    "neutral_uci": "h8h2",
    "consensus_move": "h8d4",
    "source_agents": [
      "aggressive",
      "positional"
    ],
    "selected_agent": "aggressive"
  },
  "plans": {
    "aggressive": {
      "full": [],
      "execute": []
    },
    "positional": {
      "full": [
        "Kxg3",
        "Qe3+",
        "Kg4",
        "Qe4+",
        "Kg5",
        "Qe5+",
        "Kg6"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Kf3",
        "Qh3+",
        "Ke4",
        "Qg4+",
        "Ke5"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 649,
      "completion_tokens": 534,
      "total_tokens": 1183,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 649,
      "completion_tokens": 565,
      "total_tokens": 1214,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 648,
      "completion_tokens": 583,
      "total_tokens": 1231,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 1946,
    "total_completion_tokens": 1682,
    "total_tokens": 3628
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 126,
      "turn_number": 64,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 649,
      "completion_tokens": 534,
      "total_tokens": 1183,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 126,
      "turn_number": 64,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 649,
      "completion_tokens": 565,
      "total_tokens": 1214,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 126,
      "turn_number": 64,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 648,
      "completion_tokens": 583,
      "total_tokens": 1231,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}