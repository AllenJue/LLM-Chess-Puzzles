{
  "query1": {
    "aggressive_move": "Kg5",
    "aggressive_uci": "f4g5",
    "aggressive_response": "1. d4 d5 2. c4 c6 3. Nf3 Nf6 4. Qc2 Bg4 5. Nbd2 e6 6. g3 Be7 7. Bg2 Bf5 8. Qb3 Qb6 9. O-O Nbd7 10. c5 Qxb3 11. axb3 O-O 12. b4 a6 13. Nh4 Rfe8 14. Nxf5 exf5 15. Nb3 Ne4 16. e3 Bd8 17. f3 Nef6 18. Kf2 Bc7 19. Bh3 g6 20. Re1 Kg7 21. Bd2 Nf8 22. Bf1 h5 23. Bd3 Rab8 24. Bc3 Re7 25. Nd2 Rbe8 26. Re2 N8h7 27. Rae1 Ng5 28. h4 Ngh7 29. e4 fxe4 30. fxe4 Ng4+ 31. Kg2 Nhf6 32. e5 Nd7 33. Nf3 Nf8 34. Bd2 Ne6 35. Ng5 Bd8 36. Nxe6+ Rxe6 37. Rf1 f6 38. exf6+ Bxf6 39. Rxe6 Rxe6 40. Rf4 Ne3+ 41. Kf3 Ng4 42. Bc3 Bd8 43. Kg2 Ne3+ 44. Kg1 Bc7 45. Rf3 Ng4 46. Kg2 Nf6 47. Rf1 Ne4 48. Re1 Kf7 49. Bxe4 Rxe4 50. Rf1+ Kg7 51. Kf3 Re6 52. Rg1 Rf6+ 53. Ke3 Re6+ 54. Kd3 Bd8 55. Bd2 Bf6 56. Bf4 Re4 57. Be3 Kf7 58. Rf1 Ke6 59. Rf3 Rg4 60. b3 Re4 61. Bf2 Rg4 62. Re3+ Re4 63. Rxe4+ dxe4+ 64. Kxe4 Be7 65. Be3 Bf6 66. Bf4 Bg7 67. Be5 Bf8 68. Kf4 Be7 69. Bd6 Bxd6+ 70. cxd6 Kxd6 71. Kg5 Kd5 72. Kxg6 Kxd4 73. Kxh5 Kc3 74. g4 Kxb3 75. g5 Kxb4 76. g6 c5 77. g7 c4 78. g8=Q c3 79. Qg1",
    "aggressive_tokens": {
      "prompt_tokens": 689,
      "completion_tokens": 640,
      "total_tokens": 1329,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Kd5",
      "Kxg6",
      "Kxd4",
      "Kxh5",
      "Kc3",
      "g4",
      "Kxb3",
      "g5",
      "Kxb4",
      "g6",
      "c5",
      "g7",
      "c4",
      "g8=Q",
      "c3",
      "Qg1"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Kg5",
    "positional_uci": "f4g5",
    "positional_response": "1. d4 d5 2. c4 c6 3. Nf3 Nf6 4. Qc2 Bg4 5. Nbd2 e6 6. g3 Be7 7. Bg2 Bf5 8. Qb3 Qb6 9. O-O Nbd7 10. c5 Qxb3 11. axb3 O-O 12. b4 a6 13. Nh4 Rfe8 14. Nxf5 exf5 15. Nb3 Ne4 16. e3 Bd8 17. f3 Nef6 18. Kf2 Bc7 19. Bh3 g6 20. Re1 Kg7 21. Bd2 Nf8 22. Bf1 h5 23. Bd3 Rab8 24. Bc3 Re7 25. Nd2 Rbe8 26. Re2 N1h7 27. Rae1 Ng5 28. h4 Ngh7 29. e4 fxe4 30. fxe4 Ng4+ 31. Kg2 Nhf6 32. e5 Nd7 33. Nf3 Nf8 34. Bd2 Ne6 35. Ng5 Bd8 36. Nxe6+ Rxe6 37. Rf1 f6 38. exf6+ Bxf6 39. Rxe6 Rxe6 40. Rf4 Ne3+ 41. Kf3 Ng4 42. Bc3 Bd8 43. Kg2 Ne3+ 44. Kg1 Bc7 45. Rf3 Ng4 46. Kg2 Nf6 47. Rf1 Ne4 48. Re1 Kf7 49. Bxe4 Rxe4 50. Rf1+ Kg7 51. Kf3 Re6 52. Rg1 Rf6+ 53. Ke3 Re6+ 54. Kd3 Bd8 55. Bd2 Bf6 56. Bf4 Re4 57. Be3 Kf7 58. Rf1 Ke6 59. Rf3 Rg4 60. b3 Re4 61. Bf2 Rg4 62. Re3+ Re4 63. Rxe4+ dxe4+ 64. Kxe4 Be7 65. Be3 Bf6 66. Bf4 Bg7 67. Be5 Bf8 68. Kf4 Be7 69. Bd6 Bxd6+ 70. cxd6 Kxd6 71. Kg5 Kd5 72. Kxg6 Kxd4 73. Kxh5 Kc3 74. g4 Kxb3 75. g5 Kxb4 76. g6 a5 77. g7 a4 78. g8=Q a3 79. Qa2 Ka",
    "positional_tokens": {
      "prompt_tokens": 689,
      "completion_tokens": 640,
      "total_tokens": 1329,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Kd5",
      "Kxg6",
      "Kxd4",
      "Kxh5",
      "Kc3",
      "g4",
      "Kxb3",
      "g5",
      "Kxb4",
      "g6",
      "a5",
      "g7",
      "a4",
      "g8=Q",
      "a3",
      "Qa2"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Kg5",
    "neutral_uci": "f4g5",
    "neutral_response": "1. d4 d5 2. c4 c6 3. Nf3 Nf6 4. Qc2 Bg4 5. Nbd2 e6 6. g3 Be7 7. Bg2 Bf5 8. Qb3 Qb6 9. O-O Nbd7 10. c5 Qxb3 11. axb3 O-O 12. b4 a6 13. Nh4 Rfe8 14. Nxf5 exf5 15. Nb3 Ne4 16. e3 Bd8 17. f3 Nef6 18. Kf2 Bc7 19. Bh3 g6 20. Re1 Kg7 21. Bd2 Nf8 22. Bf1 h5 23. Bd3 Rab8 24. Bc3 Re7 25. Nd2 Rbe8 26. Re2 N8h7 27. Rae1 Ng5 28. h4 Ngh7 29. e4 fxe4 30. fxe4 Ng4+ 31. Kg2 Nhf6 32. e5 Nd7 33. Nf3 Nf8 34. Bd2 Ne6 35. Ng5 Bd8 36. Nxe6+ Rxe6 37. Rf1 f6 38. exf6+ Bxf6 39. Rxe6 Rxe6 40. Rf4 Ne3+ 41. Kf3 Ng4 42. Bc3 Bd8 43. Kg2 Ne3+ 44. Kg1 Bc7 45. Rf3 Ng4 46. Kg2 Nf6 47. Rf1 Ne4 48. Re1 Kf7 49. Bxe4 Rxe4 50. Rf1+ Kg7 51. Kf3 Re6 52. Rg1 Rf6+ 53. Ke3 Re6+ 54. Kd3 Bd8 55. Bd2 Bf6 56. Bf4 Re4 57. Be3 Kf7 58. Rf1 Ke6 59. Rf3 Rg4 60. b3 Re4 61. Bf2 Rg4 62. Re3+ Re4 63. Rxe4+ dxe4+ 64. Kxe4 Be7 65. Be3 Bf6 66. Bf4 Bg7 67. Be5 Bf8 68. Kf4 Be7 69. Bd6 Bxd6+ 70. cxd6 Kxd6 71. Kg5 Kd5 72. Kxg6 Kxd4 73. Kxh5 Kc3 74. g4 Kxb3 75. g5 Kxb4 76. g6 c5 77. g7 c4 78. g8=Q c3 79. Qg1",
    "neutral_tokens": {
      "prompt_tokens": 688,
      "completion_tokens": 640,
      "total_tokens": 1328,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Kd5",
      "Kxg6",
      "Kxd4",
      "Kxh5",
      "Kc3",
      "g4",
      "Kxb3",
      "g5",
      "Kxb4",
      "g6",
      "c5",
      "g7",
      "c4",
      "g8=Q",
      "c3",
      "Qg1"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "f4g5",
    "positional_uci": "f4g5",
    "neutral_uci": "f4g5",
    "consensus_move": "f4g5",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Kd5",
        "Kxg6",
        "Kxd4",
        "Kxh5",
        "Kc3",
        "g4",
        "Kxb3",
        "g5",
        "Kxb4",
        "g6",
        "c5",
        "g7",
        "c4",
        "g8=Q",
        "c3",
        "Qg1"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Kd5",
        "Kxg6",
        "Kxd4",
        "Kxh5",
        "Kc3",
        "g4",
        "Kxb3",
        "g5",
        "Kxb4",
        "g6",
        "a5",
        "g7",
        "a4",
        "g8=Q",
        "a3",
        "Qa2"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Kd5",
        "Kxg6",
        "Kxd4",
        "Kxh5",
        "Kc3",
        "g4",
        "Kxb3",
        "g5",
        "Kxb4",
        "g6",
        "c5",
        "g7",
        "c4",
        "g8=Q",
        "c3",
        "Qg1"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 689,
      "completion_tokens": 640,
      "total_tokens": 1329,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "positional": {
      "prompt_tokens": 689,
      "completion_tokens": 640,
      "total_tokens": 1329,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "neutral": {
      "prompt_tokens": 688,
      "completion_tokens": 640,
      "total_tokens": 1328,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "total_prompt_tokens": 2066,
    "total_completion_tokens": 1920,
    "total_tokens": 3986
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 140,
      "turn_number": 71,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 689,
      "completion_tokens": 640,
      "total_tokens": 1329,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 140,
      "turn_number": 71,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 689,
      "completion_tokens": 640,
      "total_tokens": 1329,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 140,
      "turn_number": 71,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 688,
      "completion_tokens": 640,
      "total_tokens": 1328,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    }
  ]
}