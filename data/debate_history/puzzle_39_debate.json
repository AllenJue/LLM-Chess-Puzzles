{
  "query1": {
    "aggressive_move": "Rxh7#",
    "aggressive_uci": "a7h7",
    "aggressive_response": "1. e4 c5 2. Nf3 g6 3. g3 Bg7 4. Nc3 d6 5. Bg2 Nc6 6. O-O Nf6 7. d3 O-O 8. a3 Bg4 9. Ne2 Qd7 10. c3 Bh3 11. Nf4 Bxg2 12. Kxg2 b5 13. Qe2 a5 14. Rb1 Rab8 15. Be3 b4 16. axb4 axb4 17. c4 Qb7 18. Nd5 e6 19. Nxf6+ Bxf6 20. Bh6 Rfe8 21. h4 Qc7 22. h5 d5 23. hxg6 fxg6 24. Bf4 e5 25. Be3 dxe4 26. dxe4 Nd4 27. Nxd4 exd4 28. Bf4 Be5 29. Bxe5 Qxe5 30. Rh1 Qxe4+ 31. Qxe4 Rxe4 32. Kf3 Rbe8 33. Ra1 d3 34. Ra5 R4e5 35. Rd1 Rf8+ 36. Kg2 Re2 37. Rxd3 Rfxf2+ 38. Kh3 Rh2+ 39. Kg4 Re4+ 40. Kf3 Rxc4 41. Ra7 Rd4 42. Re3 Rd8 43. Ra5 c4 44. Ra4 Rxb2 45. Ra7 Rd3 46. Ra8+ Kg7 47. Ra7+ Kh6 48. g4 Rbb3 49. Rxd3 Rxd3+ 50. Kf4 c3 51. g5+ Kh5 52. Rxh7#",
    "aggressive_tokens": {
      "prompt_tokens": 532,
      "completion_tokens": 418,
      "total_tokens": 950,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Rxh7#",
    "positional_uci": "a7h7",
    "positional_response": "1. e4 c5 2. Nf3 g6 3. g3 Bg7 4. Nc3 d6 5. Bg2 Nc6 6. O-O Nf6 7. d3 O-O 8. a3 Bg4 9. Ne2 Qd7 10. c3 Bh3 11. Nf4 Bxg2 12. Kxg2 b5 13. Qe2 a5 14. Rb1 Rab8 15. Be3 b4 16. axb4 axb4 17. c4 Qb7 18. Nd5 e6 19. Nxf6+ Bxf6 20. Bh6 Rfe8 21. h4 Qc7 22. h5 d5 23. hxg6 fxg6 24. Bf4 e5 25. Be3 dxe4 26. dxe4 Nd4 27. Nxd4 exd4 28. Bf4 Be5 29. Bxe5 Qxe5 30. Rh1 Qxe4+ 31. Qxe4 Rxe4 32. Kf3 Rbe8 33. Ra1 d3 34. Ra5 R4e5 35. Rd1 Rf8+ 36. Kg2 Re2 37. Rxd3 Rfxf2+ 38. Kh3 Rh2+ 39. Kg4 Re4+ 40. Kf3 Rxc4 41. Ra7 Rd4 42. Re3 Rd8 43. Ra5 c4 44. Ra4 Rxb2 45. Ra7 Rd3 46. Ra8+ Kg7 47. Ra7+ Kh6 48. g4 Rbb3 49. Rxd3 Rxd3+ 50. Kf4 c3 51. g5+ Kh5 52. Rxh7# 1-0\n\n52. Rxh7#",
    "positional_tokens": {
      "prompt_tokens": 532,
      "completion_tokens": 429,
      "total_tokens": 961,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Rxh7#",
    "neutral_uci": "a7h7",
    "neutral_response": "1. e4 c5 2. Nf3 g6 3. g3 Bg7 4. Nc3 d6 5. Bg2 Nc6 6. O-O Nf6 7. d3 O-O 8. a3 Bg4 9. Ne2 Qd7 10. c3 Bh3 11. Nf4 Bxg2 12. Kxg2 b5 13. Qe2 a5 14. Rb1 Rab8 15. Be3 b4 16. axb4 axb4 17. c4 Qb7 18. Nd5 e6 19. Nxf6+ Bxf6 20. Bh6 Rfe8 21. h4 Qc7 22. h5 d5 23. hxg6 fxg6 24. Bf4 e5 25. Be3 dxe4 26. dxe4 Nd4 27. Nxd4 exd4 28. Bf4 Be5 29. Bxe5 Qxe5 30. Rh1 Qxe4+ 31. Qxe4 Rxe4 32. Kf3 Rbe8 33. Ra1 d3 34. Ra5 R4e5 35. Rd1 Rf8+ 36. Kg2 Re2 37. Rxd3 Rfxf2+ 38. Kh3 Rh2+ 39. Kg4 Re4+ 40. Kf3 Rxc4 41. Ra7 Rd4 42. Re3 Rd8 43. Ra5 c4 44. Ra4 Rxb2 45. Ra7 Rd3 46. Ra8+ Kg7 47. Ra7+ Kh6 48. g4 Rbb3 49. Rxd3 Rxd3+ 50. Kf4 c3 51. g5+ Kh5 52. Rxh7# \n\n52. Rxh7#",
    "neutral_tokens": {
      "prompt_tokens": 531,
      "completion_tokens": 425,
      "total_tokens": 956,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "a7h7",
    "positional_uci": "a7h7",
    "neutral_uci": "a7h7",
    "consensus_move": "a7h7",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [],
      "execute": []
    },
    "positional": {
      "full": [],
      "execute": []
    },
    "neutral": {
      "full": [],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 532,
      "completion_tokens": 418,
      "total_tokens": 950,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 532,
      "completion_tokens": 429,
      "total_tokens": 961,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 531,
      "completion_tokens": 425,
      "total_tokens": 956,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 1595,
    "total_completion_tokens": 1272,
    "total_tokens": 2867
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 102,
      "turn_number": 52,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 532,
      "completion_tokens": 418,
      "total_tokens": 950,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 102,
      "turn_number": 52,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 532,
      "completion_tokens": 429,
      "total_tokens": 961,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 102,
      "turn_number": 52,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 531,
      "completion_tokens": 425,
      "total_tokens": 956,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}