{
  "query1": {
    "aggressive_move": "O-O-O",
    "aggressive_uci": "e8c8",
    "aggressive_response": "1. d4 d5 2. c4 c6 3. Nf3 Nf6 4. e3 Bg4 5. Nbd2 e6 6. h3 Bh5 7. g4 Bg6 8. Ne5 Nbd7 9. h4 dxc4 10. Ndxc4 Be4 11. f3 Bd5 12. e4 Nxe5 13. Nxe5 Nxe4 14. fxe4 Bxe4 15. Rg1 Qxh4+ 16. Ke2 O-O-O 17. Nxf7 Bc5 18. Be3 Qh2+ 19. Rg2 Bxg2 20. Bxg2 Qxg2+",
    "aggressive_tokens": {
      "prompt_tokens": 246,
      "completion_tokens": 166,
      "total_tokens": 412,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Nxf7",
      "Bc5",
      "Be3",
      "Qh2+",
      "Rg2",
      "Bxg2",
      "Bxg2",
      "Qxg2+"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "O-O-O",
    "positional_uci": "e8c8",
    "positional_response": "1. d4 d5 2. c4 c6 3. Nf3 Nf6 4. e3 Bg4 5. Nbd2 e6 6. h3 Bh5 7. g4 Bg6 8. Ne5 Nbd7 9. h4 dxc4 10. Ndxc4 Be4 11. f3 Bd5 12. e4 Nxe5 13. Nxe5 Nxe4 14. fxe4 Bxe4 15. Rg1 Qxh4+ 16. Ke2 O-O-O 17. Be3 Qh2+ 18. Bf2 Qxe5 19. Qa4\n\nO-O-O Be7 Qa4",
    "positional_tokens": {
      "prompt_tokens": 246,
      "completion_tokens": 157,
      "total_tokens": 403,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Be7",
      "Qa4"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "O-O-O",
    "neutral_uci": "e8c8",
    "neutral_response": "1. d4 d5 2. c4 c6 3. Nf3 Nf6 4. e3 Bg4 5. Nbd2 e6 6. h3 Bh5 7. g4 Bg6 8. Ne5 Nbd7 9. h4 dxc4 10. Ndxc4 Be4 11. f3 Bd5 12. e4 Nxe5 13. Nxe5 Nxe4 14. fxe4 Bxe4 15. Rg1 Qxh4+ 16. Ke2 O-O-O 17. Be3 Qh2+ 18. Bf2 Qxe5 19. Qa4\n\nO-O-O Be7 Qa4 Bg5",
    "neutral_tokens": {
      "prompt_tokens": 245,
      "completion_tokens": 159,
      "total_tokens": 404,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Be7",
      "Qa4",
      "Bg5"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "e8c8",
    "positional_uci": "e8c8",
    "neutral_uci": "e8c8",
    "consensus_move": "e8c8",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Nxf7",
        "Bc5",
        "Be3",
        "Qh2+",
        "Rg2",
        "Bxg2",
        "Bxg2",
        "Qxg2+"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Be7",
        "Qa4"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Be7",
        "Qa4",
        "Bg5"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 246,
      "completion_tokens": 166,
      "total_tokens": 412,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 246,
      "completion_tokens": 157,
      "total_tokens": 403,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 245,
      "completion_tokens": 159,
      "total_tokens": 404,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 737,
    "total_completion_tokens": 482,
    "total_tokens": 1219
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 31,
      "turn_number": 16,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 246,
      "completion_tokens": 166,
      "total_tokens": 412,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 31,
      "turn_number": 16,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 246,
      "completion_tokens": 157,
      "total_tokens": 403,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 31,
      "turn_number": 16,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 245,
      "completion_tokens": 159,
      "total_tokens": 404,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}