{
  "query1": {
    "aggressive_move": "Nxd5",
    "aggressive_uci": "f6d5",
    "aggressive_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. a3 Bc5 7. Nb3 Bb6 8. Be2 d5 9. exd5 exd5 10. Bg5 O-O 11. Nxd5 Qxd5 12. Qxd5 Nxd5 13. O-O-O Be6 14. Bf3 Nde7 15. Rhe1 Rfd8",
    "aggressive_tokens": {
      "prompt_tokens": 212,
      "completion_tokens": 119,
      "total_tokens": 331,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "O-O-O",
      "Be6",
      "Bf3",
      "Nde7",
      "Rhe1",
      "Rfd8"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Nxd5",
    "positional_uci": "f6d5",
    "positional_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. a3 Bc5 7. Nb3 Bb6 8. Be2 d5 9. exd5 exd5 10. Bg5 O-O 11. Nxd5 Qxd5 12. Qxd5 Nxd5 13. O-O-O Be6 14. Bf3 Nde7\n\n13. O-O-O Be6 14. Bf3 Nde7",
    "positional_tokens": {
      "prompt_tokens": 212,
      "completion_tokens": 128,
      "total_tokens": 340,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "O-O-O",
      "Be6",
      "Bf3",
      "Nde7",
      "O-O-O",
      "Be6",
      "Bf3",
      "Nde7"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Nxd5",
    "neutral_uci": "f6d5",
    "neutral_response": "1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. a3 Bc5 7. Nb3 Bb6 8. Be2 d5 9. exd5 exd5 10. Bg5 O-O 11. Nxd5 Qxd5 12. Qxd5 Nxd5 13. O-O-O Be6 14. Bf3 Nde7\n\n13. O-O-O Be6 14. Bf3 Nde7",
    "neutral_tokens": {
      "prompt_tokens": 211,
      "completion_tokens": 128,
      "total_tokens": 339,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "O-O-O",
      "Be6",
      "Bf3",
      "Nde7",
      "O-O-O",
      "Be6",
      "Bf3",
      "Nde7"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "f6d5",
    "positional_uci": "f6d5",
    "neutral_uci": "f6d5",
    "consensus_move": "f6d5",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "O-O-O",
        "Be6",
        "Bf3",
        "Nde7",
        "Rhe1",
        "Rfd8"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "O-O-O",
        "Be6",
        "Bf3",
        "Nde7",
        "O-O-O",
        "Be6",
        "Bf3",
        "Nde7"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "O-O-O",
        "Be6",
        "Bf3",
        "Nde7",
        "O-O-O",
        "Be6",
        "Bf3",
        "Nde7"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 212,
      "completion_tokens": 119,
      "total_tokens": 331,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 212,
      "completion_tokens": 128,
      "total_tokens": 340,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 211,
      "completion_tokens": 128,
      "total_tokens": 339,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 635,
    "total_completion_tokens": 375,
    "total_tokens": 1010
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 23,
      "turn_number": 12,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 212,
      "completion_tokens": 119,
      "total_tokens": 331,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 23,
      "turn_number": 12,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 212,
      "completion_tokens": 128,
      "total_tokens": 340,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 23,
      "turn_number": 12,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 211,
      "completion_tokens": 128,
      "total_tokens": 339,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}