{
  "query1": {
    "aggressive_move": "Kc7",
    "aggressive_uci": "d6c7",
    "aggressive_response": "1. e4 e6 2. d4 d5 3. exd5 exd5 4. Nf3 Nf6 5. Bd3 c5 6. c3 Nc6 7. O-O Bd6 8. h3 O-O 9. Re1 Re8 10. Bg5 Be6 11. Nbd2 c4 12. Bc2 h6 13. Bh4 g5 14. Bg3 Bxg3 15. fxg3 Qd6 16. Nf1 Re7 17. Qd2 Nh7 18. Ne3 Rae8 19. Bf5 Qxg3 20. Rf1 Nf8 21. Qc2 Qd6 22. Ng4 Kg7 23. Nfe5 Nxe5 24. Nxe5 Bxf5 25. Qxf5 Qe6 26. Qf3 Ng6 27. Rae1 Nf4 28. Nd3 Qf5 29. Rxe7 Rxe7 30. Nxf4 Qxf4 31. Qxd5 Qe3+ 32. Kh2 Qe6 33. Qxe6 Rxe6 34. Rf2 Kg6 35. g4 h5 36. Kg3 hxg4 37. hxg4 Re4 38. Rf5 Re2 39. Rc5 Rxb2 40. Rxc4 Rxa2 41. Rb4 b6 42. Rb5 Ra3 43. Kf3 Rxc3+ 44. Ke4 Rc1 45. Ke5 Rg1 46. d5 Rxg4 47. d6 Rg1 48. d7 Re1+ 49. Kd6 Re6+ 50. Kc7 Re7 51. Kc8 Rxd7 52. Kxd7 f5 53. Ke6 f4 54. Rf5 Kh5 55. Kf6 Kg4 56. Rxg5+ Kh4 57. Kf5 f3 58. Kf4 f2 59. Rg4+ Kh3 60. Rg3+ Kh2 61. Rf3 Kg2 62. Rg3+ Kh2 63. Kf3 f1=Q+ 64. Kg4 Qf2 65. Rh3+ Kg2 66. Rg3+ Qxg3+ 67. Kf5 Qf3+ 68. Ke6 Qe3+ 69. Kd7 Qd3+ 70. Kc8 Qc3+ 71. Kb7 Qb3 72. Ka6 Qa3+ 73. Kb7 Qa4 74. Kc7 Qa5 75. Kb7 b5 76. Kc6 b4 77. Kd6 b",
    "aggressive_tokens": {
      "prompt_tokens": 523,
      "completion_tokens": 640,
      "total_tokens": 1163,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Qa5",
      "Kb7",
      "b5",
      "Kc6",
      "b4",
      "Kd6"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Kc7",
    "positional_uci": "d6c7",
    "positional_response": "1. e4 e6 2. d4 d5 3. exd5 exd5 4. Nf3 Nf6 5. Bd3 c5 6. c3 Nc6 7. O-O Bd6 8. h3 O-O 9. Re1 Re8 10. Bg5 Be6 11. Nbd2 c4 12. Bc2 h6 13. Bh4 g5 14. Bg3 Bxg3 15. fxg3 Qd6 16. Nf1 Re7 17. Qd2 Nh7 18. Ne3 Rae8 19. Bf5 Qxg3 20. Rf1 Nf8 21. Qc2 Qd6 22. Ng4 Kg7 23. Nfe5 Nxe5 24. Nxe5 Bxf5 25. Qxf5 Qe6 26. Qf3 Ng6 27. Rae1 Nf4 28. Nd3 Qf5 29. Rxe7 Rxe7 30. Nxf4 Qxf4 31. Qxd5 Qe3+ 32. Kh2 Qe6 33. Qxe6 Rxe6 34. Rf2 Kg6 35. g4 h5 36. Kg3 hxg4 37. hxg4 Re4 38. Rf5 Re2 39. Rc5 Rxb2 40. Rxc4 Rxa2 41. Rb4 b6 42. Rb5 Ra3 43. Kf3 Rxc3+ 44. Ke4 Rc1 45. Ke5 Rg1 46. d5 Rxg4 47. d6 Rg1 48. d7 Re1+ 49. Kd6 Re6+ 50. Kc7 Re7 51. Kc8 Rxd7 52. Kxd7 f5 53. Ke6 f4 54. Rf5 Kh5 55. Kf6 Kg4 56. Rxg5+ Kf3 57. Kf5 Ke3 58. Rg4 f3 59. Re4+ Kf2 60. Kf4 Kg2 61. Re3 f2 62. Rg3+ Kh2 63. Rf3 Kg2 64. Rg3+ Kh2 65. Rf3 Kg2 66. Rg3+ Kh2 67. Rf3 Kg2 68. Rg3+ Kh2 69. Rf3 Kg2 70. Rg3+ Kh2 71. Rf3 Kg2 72. Rg3+ Kh2 73. Rf3 Kg2 74. Rg3+ Kh2 75. Rf3 Kg2 76. Rg3+ Kh2 77. Rf3 Kg2 78. Rg3+ Kh",
    "positional_tokens": {
      "prompt_tokens": 523,
      "completion_tokens": 640,
      "total_tokens": 1163,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Re7",
      "Kc8",
      "Rxd7",
      "Kxd7",
      "f5",
      "Ke6",
      "f4",
      "Rf5",
      "Kh5",
      "Kf6",
      "Kg4",
      "Rxg5+",
      "Kf3",
      "Kf5",
      "Ke3",
      "Rg4",
      "f3",
      "Re4+",
      "Kf2",
      "Kf4",
      "Kg2",
      "Re3",
      "f2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+",
      "Kh2",
      "Rf3",
      "Kg2",
      "Rg3+"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Kc7",
    "neutral_uci": "d6c7",
    "neutral_response": "1. e4 e6 2. d4 d5 3. exd5 exd5 4. Nf3 Nf6 5. Bd3 c5 6. c3 Nc6 7. O-O Bd6 8. h3 O-O 9. Re1 Re8 10. Bg5 Be6 11. Nbd2 c4 12. Bc2 h6 13. Bh4 g5 14. Bg3 Bxg3 15. fxg3 Qd6 16. Nf1 Re7 17. Qd2 Nh7 18. Ne3 Rae8 19. Bf5 Qxg3 20. Rf1 Nf8 21. Qc2 Qd6 22. Ng4 Kg7 23. Nfe5 Nxe5 24. Nxe5 Bxf5 25. Qxf5 Qe6 26. Qf3 Ng6 27. Rae1 Nf4 28. Nd3 Qf5 29. Rxe7 Rxe7 30. Nxf4 Qxf4 31. Qxd5 Qe3+ 32. Kh2 Qe6 33. Qxe6 Rxe6 34. Rf2 Kg6 35. g4 h5 36. Kg3 hxg4 37. hxg4 Re4 38. Rf5 Re2 39. Rc5 Rxb2 40. Rxc4 Rxa2 41. Rb4 b6 42. Rb5 Ra3 43. Kf3 Rxc3+ 44. Ke4 Rc1 45. Ke5 Rg1 46. d5 Rxg4 47. d6 Rg1 48. d7 Re1+ 49. Kd6 Re6+ 50. Kc7 Re7 51. Kc8 Rxd7 52. Kxd7 f5 53. Ke6 f4 54. Rf5 Kh5 55. Kf6 Kg4 56. Rxg5+ Kf3 57. Kf5 Ke3 58. Rg4 f3 59. Rg3 Ke2 60. Kf4 f2 61. Re3+ Kd2 62. Rf3 Ke2 63. Re3+ Kd2 64. Rf3 Ke2 65. Re3+ Kd2 66. Rf3 Ke2 67. Re3+ Kd2 68. Rf3 Ke2 69. Re3+ Kd2 70. Rf3 Ke2 71. Re3+ Kd2 72. Rf3 Ke2 73. Re3+ Kd2 74. Rf3 Ke2 75. Re3+ Kd2 76. Rf3 Ke2 77. Re3+ Kd2 78. Rf3 Ke",
    "neutral_tokens": {
      "prompt_tokens": 522,
      "completion_tokens": 640,
      "total_tokens": 1162,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Re7",
      "Kc8",
      "Rxd7",
      "Kxd7",
      "f5",
      "Ke6",
      "f4",
      "Rf5",
      "Kh5",
      "Kf6",
      "Kg4",
      "Rxg5+",
      "Kf3",
      "Kf5",
      "Ke3",
      "Rg4",
      "f3",
      "Rg3",
      "Ke2",
      "Kf4",
      "f2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3",
      "Ke2",
      "Re3+",
      "Kd2",
      "Rf3"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "d6c7",
    "positional_uci": "d6c7",
    "neutral_uci": "d6c7",
    "consensus_move": "d6c7",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Qa5",
        "Kb7",
        "b5",
        "Kc6",
        "b4",
        "Kd6"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Re7",
        "Kc8",
        "Rxd7",
        "Kxd7",
        "f5",
        "Ke6",
        "f4",
        "Rf5",
        "Kh5",
        "Kf6",
        "Kg4",
        "Rxg5+",
        "Kf3",
        "Kf5",
        "Ke3",
        "Rg4",
        "f3",
        "Re4+",
        "Kf2",
        "Kf4",
        "Kg2",
        "Re3",
        "f2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+",
        "Kh2",
        "Rf3",
        "Kg2",
        "Rg3+"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Re7",
        "Kc8",
        "Rxd7",
        "Kxd7",
        "f5",
        "Ke6",
        "f4",
        "Rf5",
        "Kh5",
        "Kf6",
        "Kg4",
        "Rxg5+",
        "Kf3",
        "Kf5",
        "Ke3",
        "Rg4",
        "f3",
        "Rg3",
        "Ke2",
        "Kf4",
        "f2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3",
        "Ke2",
        "Re3+",
        "Kd2",
        "Rf3"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 523,
      "completion_tokens": 640,
      "total_tokens": 1163,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "positional": {
      "prompt_tokens": 523,
      "completion_tokens": 640,
      "total_tokens": 1163,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "neutral": {
      "prompt_tokens": 522,
      "completion_tokens": 640,
      "total_tokens": 1162,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "total_prompt_tokens": 1568,
    "total_completion_tokens": 1920,
    "total_tokens": 3488
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 98,
      "turn_number": 50,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 523,
      "completion_tokens": 640,
      "total_tokens": 1163,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 98,
      "turn_number": 50,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 523,
      "completion_tokens": 640,
      "total_tokens": 1163,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 98,
      "turn_number": 50,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 522,
      "completion_tokens": 640,
      "total_tokens": 1162,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    }
  ]
}