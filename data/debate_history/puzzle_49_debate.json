{
  "query1": {
    "aggressive_move": "Qxe5",
    "aggressive_uci": null,
    "aggressive_response": "1. e4 c5 2. Nf3 e6 3. d3 Nc6 4. Be3 Nf6 5. h3 d5 6. e5 Nd7 7. d4 cxd4 8. Bxd4 Nxd4 9. Qxd4 Qc7 10. Nc3 g6 11. O-O-O Bg7 12. Nb5 Qa5 13. Nd6+ Ke7 14. Qf4 Nxe5 15. Nxe5 Bxe5 16. Qxe5 Rd8 17. Rxd5 Qxe5 18. Rxe5 Rxd6 19. Be2 Bd7 20. Bf3 Bc6 21. Rhe1 Rad8 22. Bxc6 Rxc6 23. Rb5 b6",
    "aggressive_tokens": {
      "prompt_tokens": 253,
      "completion_tokens": 183,
      "total_tokens": 436,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rxe5",
      "Rxd6",
      "Be2",
      "Bd7",
      "Bf3",
      "Bc6",
      "Rhe1",
      "Rad8",
      "Bxc6",
      "Rxc6",
      "Rb5",
      "b6"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Rxd5",
    "positional_uci": null,
    "positional_response": "1. e4 c5 2. Nf3 e6 3. d3 Nc6 4. Be3 Nf6 5. h3 d5 6. e5 Nd7 7. d4 cxd4 8. Bxd4 Nxd4 9. Qxd4 Qc7 10. Nc3 g6 11. O-O-O Bg7 12. Nb5 Qa5 13. Nd6+ Ke7 14. Qf4 Nxe5 15. Nxe5 Bxe5 16. Qxe5 Rd8 17. Rxd5 Rxd5 18. Nxc8+ Rxc8 19. Qg7 Qe1#",
    "positional_tokens": {
      "prompt_tokens": 253,
      "completion_tokens": 154,
      "total_tokens": 407,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Nxc8+",
      "Rxc8",
      "Qg7",
      "Qe1#"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Rxd5",
    "neutral_uci": null,
    "neutral_response": "1. e4 c5 2. Nf3 e6 3. d3 Nc6 4. Be3 Nf6 5. h3 d5 6. e5 Nd7 7. d4 cxd4 8. Bxd4 Nxd4 9. Qxd4 Qc7 10. Nc3 g6 11. O-O-O Bg7 12. Nb5 Qa5 13. Nd6+ Ke7 14. Qf4 Nxe5 15. Nxe5 Bxe5 16. Qxe5 Rd8 17. Rxd5 Rxd5 18. Nxc8+ Rxc8 19. Qg7 Qd2+ 20. Kb1 Qd1#",
    "neutral_tokens": {
      "prompt_tokens": 252,
      "completion_tokens": 164,
      "total_tokens": 416,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Nxc8+",
      "Rxc8",
      "Qg7",
      "Qd2+",
      "Kb1",
      "Qd1#"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": null,
    "positional_uci": null,
    "neutral_uci": null,
    "consensus_move": null,
    "source_agents": [],
    "selected_agent": null
  },
  "plans": {
    "aggressive": {
      "full": [
        "Rxe5",
        "Rxd6",
        "Be2",
        "Bd7",
        "Bf3",
        "Bc6",
        "Rhe1",
        "Rad8",
        "Bxc6",
        "Rxc6",
        "Rb5",
        "b6"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Nxc8+",
        "Rxc8",
        "Qg7",
        "Qe1#"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Nxc8+",
        "Rxc8",
        "Qg7",
        "Qd2+",
        "Kb1",
        "Qd1#"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 253,
      "completion_tokens": 183,
      "total_tokens": 436,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 253,
      "completion_tokens": 154,
      "total_tokens": 407,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 252,
      "completion_tokens": 164,
      "total_tokens": 416,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 758,
    "total_completion_tokens": 501,
    "total_tokens": 1259
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 33,
      "turn_number": 17,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 253,
      "completion_tokens": 183,
      "total_tokens": 436,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 33,
      "turn_number": 17,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 253,
      "completion_tokens": 154,
      "total_tokens": 407,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 33,
      "turn_number": 17,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 252,
      "completion_tokens": 164,
      "total_tokens": 416,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}