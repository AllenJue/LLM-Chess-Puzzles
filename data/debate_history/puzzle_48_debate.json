{
  "query1": {
    "aggressive_move": "Ra4",
    "aggressive_uci": "a5a4",
    "aggressive_response": "1. d4 d5 2. Bf4 Bf5 3. e3 Nf6 4. Bd3 Bxd3 5. Qxd3 e6 6. Nf3 Bd6 7. Bg3 Bxg3 8. hxg3 Nc6 9. Nbd2 Qd7 10. O-O-O O-O-O 11. a3 Kb8 12. b4 h6 13. Nb3 Ne4 14. Nc5 Qd6 15. Nxe4 dxe4 16. Qxe4 Nxb4 17. axb4 Qxb4 18. Qd3 Rd5 19. Qb3 Qa5 20. Nd2 Rb5 21. Nc4 Rxb3 22. Nxa5 Ra3 23. Nc4 Ra1+ 24. Kd2 Ra4 25. Ne5 f6 26. Ng6 Rd8 27. f4 Rd5 28. c3 Ra2+ 29. Kd3 Rxg2 30. Ne7 Rd7 31. Ng6 Rxg3 32. Nh4 e5 33. fxe5 fxe5 34. Rdg1 Rxg1 35. Rxg1 exd4 36. cxd4 a5 37. Nf5 g5 38. Nxh6 a4 39. Nf5 Rd5 40. Ne7 Ra5 41. Kc4 a3 42. Kb3 a2 43. Ra1 g4 44. Rxa2 Ra4 45. Rxa4 * 45... b5 46. Ra5 Kb7 47. Rxb5+ Ka6",
    "aggressive_tokens": {
      "prompt_tokens": 472,
      "completion_tokens": 381,
      "total_tokens": 853,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rxa4",
      "b5",
      "Ra5",
      "Kb7",
      "Rxb5+",
      "Ka6"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "a1=Q",
    "positional_uci": null,
    "positional_response": "1. d4 d5 2. Bf4 Bf5 3. e3 Nf6 4. Bd3 Bxd3 5. Qxd3 e6 6. Nf3 Bd6 7. Bg3 Bxg3 8. hxg3 Nc6 9. Nbd2 Qd7 10. O-O-O O-O-O 11. a3 Kb8 12. b4 h6 13. Nb3 Ne4 14. Nc5 Qd6 15. Nxe4 dxe4 16. Qxe4 Nxb4 17. axb4 Qxb4 18. Qd3 Rd5 19. Qb3 Qa5 20. Nd2 Rb5 21. Nc4 Rxb3 22. Nxa5 Ra3 23. Nc4 Ra1+ 24. Kd2 Ra4 25. Ne5 f6 26. Ng6 Rd8 27. f4 Rd5 28. c3 Ra2+ 29. Kd3 Rxg2 30. Ne7 Rd7 31. Ng6 Rxg3 32. Nh4 e5 33. fxe5 fxe5 34. Rdg1 Rxg1 35. Rxg1 exd4 36. cxd4 a5 37. Nf5 g5 38. Nxh6 a4 39. Nf5 Rd5 40. Ne7 Ra5 41. Kc4 a3 42. Kb3 a2 43. Ra1 g4 44. Rxa2 a1=Q 45. Rxa1 Rxa1 46. e4 Re1 47. e5 g3 48. Nf5 g2 49. Ng3 g1=Q 50. Ne2 Rxe2 51. Kc4 Qe3 52. Kd5 Rd2 53. Ke6 Rxd4 54. Kf5 Re4 55. Ke6 Rxe5+ 56. Kd6 Qd4# 57. Kc6 Qd5# 58. Kb6 Qc5#",
    "positional_tokens": {
      "prompt_tokens": 472,
      "completion_tokens": 474,
      "total_tokens": 946,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rxa1",
      "Rxa1",
      "e4",
      "Re1",
      "e5",
      "g3",
      "Nf5",
      "g2",
      "Ng3",
      "g1=Q",
      "Ne2",
      "Rxe2",
      "Kc4",
      "Qe3",
      "Kd5",
      "Rd2",
      "Ke6",
      "Rxd4",
      "Kf5",
      "Re4",
      "Ke6",
      "Rxe5+",
      "Kd6",
      "Qd4#",
      "Kc6",
      "Qd5#",
      "Kb6",
      "Qc5#"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Ra4",
    "neutral_uci": "a5a4",
    "neutral_response": "1. d4 d5 2. Bf4 Bf5 3. e3 Nf6 4. Bd3 Bxd3 5. Qxd3 e6 6. Nf3 Bd6 7. Bg3 Bxg3 8. hxg3 Nc6 9. Nbd2 Qd7 10. O-O-O O-O-O 11. a3 Kb8 12. b4 h6 13. Nb3 Ne4 14. Nc5 Qd6 15. Nxe4 dxe4 16. Qxe4 Nxb4 17. axb4 Qxb4 18. Qd3 Rd5 19. Qb3 Qa5 20. Nd2 Rb5 21. Nc4 Rxb3 22. Nxa5 Ra3 23. Nc4 Ra1+ 24. Kd2 Ra4 25. Ne5 f6 26. Ng6 Rd8 27. f4 Rd5 28. c3 Ra2+ 29. Kd3 Rxg2 30. Ne7 Rd7 31. Ng6 Rxg3 32. Nh4 e5 33. fxe5 fxe5 34. Rdg1 Rxg1 35. Rxg1 exd4 36. cxd4 a5 37. Nf5 g5 38. Nxh6 a4 39. Nf5 Rd5 40. Ne7 Ra5 41. Kc4 a3 42. Kb3 a2 43. Ra1 g4 44. Rxa2 Ra4\n\n45. Rxa4 bxa4+ 46. Kxa4 g3 47. Nf5 g2",
    "neutral_tokens": {
      "prompt_tokens": 471,
      "completion_tokens": 378,
      "total_tokens": 849,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rxa4",
      "bxa4+",
      "Kxa4",
      "g3",
      "Nf5",
      "g2"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "a5a4",
    "positional_uci": null,
    "neutral_uci": "a5a4",
    "consensus_move": "a5a4",
    "source_agents": [
      "aggressive",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Rxa4",
        "b5",
        "Ra5",
        "Kb7",
        "Rxb5+",
        "Ka6"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Rxa1",
        "Rxa1",
        "e4",
        "Re1",
        "e5",
        "g3",
        "Nf5",
        "g2",
        "Ng3",
        "g1=Q",
        "Ne2",
        "Rxe2",
        "Kc4",
        "Qe3",
        "Kd5",
        "Rd2",
        "Ke6",
        "Rxd4",
        "Kf5",
        "Re4",
        "Ke6",
        "Rxe5+",
        "Kd6",
        "Qd4#",
        "Kc6",
        "Qd5#",
        "Kb6",
        "Qc5#"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Rxa4",
        "bxa4+",
        "Kxa4",
        "g3",
        "Nf5",
        "g2"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 472,
      "completion_tokens": 381,
      "total_tokens": 853,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 472,
      "completion_tokens": 474,
      "total_tokens": 946,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 471,
      "completion_tokens": 378,
      "total_tokens": 849,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 1415,
    "total_completion_tokens": 1233,
    "total_tokens": 2648
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 87,
      "turn_number": 44,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 472,
      "completion_tokens": 381,
      "total_tokens": 853,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 87,
      "turn_number": 44,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 472,
      "completion_tokens": 474,
      "total_tokens": 946,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 87,
      "turn_number": 44,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 471,
      "completion_tokens": 378,
      "total_tokens": 849,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}