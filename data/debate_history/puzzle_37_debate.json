{
  "query1": {
    "aggressive_move": "Qg2+",
    "aggressive_uci": "f3g2",
    "aggressive_response": "1. d4 e6 2. e4 d5 3. Be3 Nf6 4. f3 b6 5. Nd2 Bb7 6. e5 Nfd7 7. Nh3 c5 8. c3 h6 9. Bd3 a6 10. O-O Qc7 11. Rc1 b5 12. Bb1 Nc6 13. Qe2 g5 14. Rfd1 Ncxe5 15. dxe5 Qxe5 16. Nf1 d4 17. cxd4 cxd4 18. Rxd4 Bc5 19. Rd3 Bd6 20. Nf2 h5 21. Qd2 Ke7 22. Bxg5+ f6 23. Bh4 Rag8 24. Bg3 Rxg3 25. Nxg3 h4 26. Nf1 Rg8 27. Rd1 Qh5 28. Rxd6 Rxg2+ 29. Kxg2 Qxf3+ 30. Kg1 Qg2+ 31. Qxg2 Bxg2 32. Kxg2 Kxd6 33. Ne4+ Ke5 34. Rxd7 Kxe4 35. Rd6 f5 36. Rxa6 e5 37. Rb6 f4 38. Rxb5 f3+ 39. Kf2 Kf4 40. Rb4+ e4 41. Rxe4+ Kxe4 42. a4 Kd4 43. a5 Kc5 44. a6 Kb6 45. Kxf3 Kxa6 46. Kg4 Kb5 47. Kxh4 Kb4 48. Kg5 Kb3 49. h4 Kxb2 50. h5 Kc3 51. h6 Kd4 52. h7 Ke5 53. h8=Q+ Ke6 54. Qf6+ Kd7 55. Kf5 Kc7 56. Ke5 Kb7 57. Kd5 Ka7 58. Kc5 Kb7 59. Qe7+ Ka6 60. Qd7 Ka5 61. Qa7# 1-0 f4 e5 Qg4",
    "aggressive_tokens": {
      "prompt_tokens": 359,
      "completion_tokens": 516,
      "total_tokens": 875,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Qxg2",
      "Bxg2",
      "Kxg2",
      "Kxd6",
      "Ne4+",
      "Ke5",
      "Rxd7",
      "Kxe4",
      "Rd6",
      "f5",
      "Rxa6",
      "e5",
      "Rb6",
      "f4",
      "Rxb5",
      "f3+",
      "Kf2",
      "Kf4",
      "Rb4+",
      "e4",
      "Rxe4+",
      "Kxe4",
      "a4",
      "Kd4",
      "a5",
      "Kc5",
      "a6",
      "Kb6",
      "Kxf3",
      "Kxa6",
      "Kg4",
      "Kb5",
      "Kxh4",
      "Kb4",
      "Kg5",
      "Kb3",
      "h4",
      "Kxb2",
      "h5",
      "Kc3",
      "h6",
      "Kd4",
      "h7",
      "Ke5",
      "h8=Q+",
      "Ke6",
      "Qf6+",
      "Kd7",
      "Kf5",
      "Kc7",
      "Ke5",
      "Kb7",
      "Kd5",
      "Ka7",
      "Kc5",
      "Kb7",
      "Qe7+",
      "Ka6",
      "Qd7",
      "Ka5",
      "Qa7#",
      "f4",
      "e5",
      "Qg4"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Qg2+",
    "positional_uci": "f3g2",
    "positional_response": "1. d4 e6 2. e4 d5 3. Be3 Nf6 4. f3 b6 5. Nd2 Bb7 6. e5 Nfd7 7. Nh3 c5 8. c3 h6 9. Bd3 a6 10. O-O Qc7 11. Rc1 b5 12. Bb1 Nc6 13. Qe2 g5 14. Rfd1 Ncxe5 15. dxe5 Qxe5 16. Nf1 d4 17. cxd4 cxd4 18. Rxd4 Bc5 19. Rd3 Bd6 20. Nf2 h5 21. Qd2 Ke7 22. Bxg5+ f6 23. Bh4 Rag8 24. Bg3 Rxg3 25. Nxg3 h4 26. Nf1 Rg8 27. Rd1 Qh5 28. Rxd6 Rxg2+ 29. Kxg2 Qxf3+ 30. Kg1\n\n30... Qg2+ 31. Nxg2 h3 32. Rxd7+ Kf8",
    "positional_tokens": {
      "prompt_tokens": 359,
      "completion_tokens": 262,
      "total_tokens": 621,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Nxg2",
      "h3",
      "Rxd7+",
      "Kf8"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Qg2+",
    "neutral_uci": "f3g2",
    "neutral_response": "1. d4 e6 2. e4 d5 3. Be3 Nf6 4. f3 b6 5. Nd2 Bb7 6. e5 Nfd7 7. Nh3 c5 8. c3 h6 9. Bd3 a6 10. O-O Qc7 11. Rc1 b5 12. Bb1 Nc6 13. Qe2 g5 14. Rfd1 Ncxe5 15. dxe5 Qxe5 16. Nf1 d4 17. cxd4 cxd4 18. Rxd4 Bc5 19. Rd3 Bd6 20. Nf2 h5 21. Qd2 Ke7 22. Bxg5+ f6 23. Bh4 Rag8 24. Bg3 Rxg3 25. Nxg3 h4 26. Nf1 Rg8 27. Rd1 Qh5 28. Rxd6 Rxg2+ 29. Kxg2 Qxf3+ 30. Kg1 Qg2+ 31. Qxg2 Bxg2 32. Kxg2 Ne5 33. Ne3 f5 34. Rxa6 f4 35. Nf1 f3+ 36. Kf2 Ng4+ 37. Kxf3 Nxh2+ 38. Nxh2 e5 39. Ke4 b4 40. Kxe5 b3 41. axb3 h3 42. Ra7+ Kd8 43. Kd6 Kc8 44. Be4 Kb8 45. Ra8#",
    "neutral_tokens": {
      "prompt_tokens": 358,
      "completion_tokens": 367,
      "total_tokens": 725,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Qxg2",
      "Bxg2",
      "Kxg2",
      "Ne5",
      "Ne3",
      "f5",
      "Rxa6",
      "f4",
      "Nf1",
      "f3+",
      "Kf2",
      "Ng4+",
      "Kxf3",
      "Nxh2+",
      "Nxh2",
      "e5",
      "Ke4",
      "b4",
      "Kxe5",
      "b3",
      "axb3",
      "h3",
      "Ra7+",
      "Kd8",
      "Kd6",
      "Kc8",
      "Be4",
      "Kb8",
      "Ra8#"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "f3g2",
    "positional_uci": "f3g2",
    "neutral_uci": "f3g2",
    "consensus_move": "f3g2",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Qxg2",
        "Bxg2",
        "Kxg2",
        "Kxd6",
        "Ne4+",
        "Ke5",
        "Rxd7",
        "Kxe4",
        "Rd6",
        "f5",
        "Rxa6",
        "e5",
        "Rb6",
        "f4",
        "Rxb5",
        "f3+",
        "Kf2",
        "Kf4",
        "Rb4+",
        "e4",
        "Rxe4+",
        "Kxe4",
        "a4",
        "Kd4",
        "a5",
        "Kc5",
        "a6",
        "Kb6",
        "Kxf3",
        "Kxa6",
        "Kg4",
        "Kb5",
        "Kxh4",
        "Kb4",
        "Kg5",
        "Kb3",
        "h4",
        "Kxb2",
        "h5",
        "Kc3",
        "h6",
        "Kd4",
        "h7",
        "Ke5",
        "h8=Q+",
        "Ke6",
        "Qf6+",
        "Kd7",
        "Kf5",
        "Kc7",
        "Ke5",
        "Kb7",
        "Kd5",
        "Ka7",
        "Kc5",
        "Kb7",
        "Qe7+",
        "Ka6",
        "Qd7",
        "Ka5",
        "Qa7#",
        "f4",
        "e5",
        "Qg4"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Nxg2",
        "h3",
        "Rxd7+",
        "Kf8"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Qxg2",
        "Bxg2",
        "Kxg2",
        "Ne5",
        "Ne3",
        "f5",
        "Rxa6",
        "f4",
        "Nf1",
        "f3+",
        "Kf2",
        "Ng4+",
        "Kxf3",
        "Nxh2+",
        "Nxh2",
        "e5",
        "Ke4",
        "b4",
        "Kxe5",
        "b3",
        "axb3",
        "h3",
        "Ra7+",
        "Kd8",
        "Kd6",
        "Kc8",
        "Be4",
        "Kb8",
        "Ra8#"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 359,
      "completion_tokens": 516,
      "total_tokens": 875,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 359,
      "completion_tokens": 262,
      "total_tokens": 621,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 358,
      "completion_tokens": 367,
      "total_tokens": 725,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 1076,
    "total_completion_tokens": 1145,
    "total_tokens": 2221
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 59,
      "turn_number": 30,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 359,
      "completion_tokens": 516,
      "total_tokens": 875,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 59,
      "turn_number": 30,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 359,
      "completion_tokens": 262,
      "total_tokens": 621,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 59,
      "turn_number": 30,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 358,
      "completion_tokens": 367,
      "total_tokens": 725,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}