{
  "query1": {
    "aggressive_move": "Qxf6",
    "aggressive_uci": "g5f6",
    "aggressive_response": "1. e4 e5 2. f4 Nc6 3. Nf3 d6 4. Bb5 exf4 5. d4 Bd7 6. Bxf4 Nf6 7. O-O a6 8. Ba4 b5 9. Bb3 Be7 10. Nc3 O-O 11. Ng5 h6 12. e5 hxg5 13. exf6 Bxf6 14. Bd2 Nxd4 15. Qh5 Re8 16. Nd5 Nxb3 17. Nxf6+ Qxf6 18. Rxf6 gxf6 19. Rf1 Nxd2 20. Rxf6 Re1+ 21. Kf2 Ne4+ 22. Kxe1 Nxf6 23. Qxg5+ Kh7 24. Qxf6 Re8+ 25. Kd2 Be6 26. h4 Rg8",
    "aggressive_tokens": {
      "prompt_tokens": 307,
      "completion_tokens": 211,
      "total_tokens": 518,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Re8+",
      "Kd2",
      "Be6",
      "h4",
      "Rg8"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Qxf6",
    "positional_uci": "g5f6",
    "positional_response": "1. e4 e5 2. f4 Nc6 3. Nf3 d6 4. Bb5 exf4 5. d4 Bd7 6. Bxf4 Nf6 7. O-O a6 8. Ba4 b5 9. Bb3 Be7 10. Nc3 O-O 11. Ng5 h6 12. e5 hxg5 13. exf6 Bxf6 14. Bd2 Nxd4 15. Qh5 Re8 16. Nd5 Nxb3 17. Nxf6+ Qxf6 18. Rxf6 gxf6 19. Rf1 Nxd2 20. Rxf6 Re1+ 21. Kf2 Ne4+ 22. Kxe1 Nxf6 23. Qxg5+ Kh7 24. Qxf6 Be6 25. b3 Rg8 26. g3 Rg6 27. Qe7 c5",
    "positional_tokens": {
      "prompt_tokens": 307,
      "completion_tokens": 218,
      "total_tokens": 525,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Be6",
      "b3",
      "Rg8",
      "g3",
      "Rg6",
      "Qe7",
      "c5"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Qxf6",
    "neutral_uci": "g5f6",
    "neutral_response": "1. e4 e5 2. f4 Nc6 3. Nf3 d6 4. Bb5 exf4 5. d4 Bd7 6. Bxf4 Nf6 7. O-O a6 8. Ba4 b5 9. Bb3 Be7 10. Nc3 O-O 11. Ng5 h6 12. e5 hxg5 13. exf6 Bxf6 14. Bd2 Nxd4 15. Qh5 Re8 16. Nd5 Nxb3 17. Nxf6+ Qxf6 18. Rxf6 gxf6 19. Rf1 Nxd2 20. Rxf6 Re1+ 21. Kf2 Ne4+ 22. Kxe1 Nxf6 23. Qxg5+ Kh7 23...Ng8 24. Qxf6 Re8+ 25. Kd2 Be6",
    "neutral_tokens": {
      "prompt_tokens": 306,
      "completion_tokens": 208,
      "total_tokens": 514,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Re8+",
      "Kd2",
      "Be6"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "g5f6",
    "positional_uci": "g5f6",
    "neutral_uci": "g5f6",
    "consensus_move": "g5f6",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Re8+",
        "Kd2",
        "Be6",
        "h4",
        "Rg8"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Be6",
        "b3",
        "Rg8",
        "g3",
        "Rg6",
        "Qe7",
        "c5"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Re8+",
        "Kd2",
        "Be6"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 307,
      "completion_tokens": 211,
      "total_tokens": 518,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 307,
      "completion_tokens": 218,
      "total_tokens": 525,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 306,
      "completion_tokens": 208,
      "total_tokens": 514,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 920,
    "total_completion_tokens": 637,
    "total_tokens": 1557
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 46,
      "turn_number": 24,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 307,
      "completion_tokens": 211,
      "total_tokens": 518,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 46,
      "turn_number": 24,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 307,
      "completion_tokens": 218,
      "total_tokens": 525,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 46,
      "turn_number": 24,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 306,
      "completion_tokens": 208,
      "total_tokens": 514,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}