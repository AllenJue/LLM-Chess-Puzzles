{
  "query1": {
    "aggressive_move": "Rg6+",
    "aggressive_uci": "g7g6",
    "aggressive_response": "1. b3 e5 2. Bb2 Nc6 3. e3 d5 4. Bb5 Bd6 5. Nf3 Nf6 6. O-O O-O 7. Bxc6 bxc6 8. Nxe5 Bxe5 9. Bxe5 Ng4 10. Bb2 Nf6 11. f4 Ne4 12. d3 Nd6 13. Rf3 Bg4 14. Rg3 Bxd1 15. Rxg7+ Kh8 16. Rg6+ f6 17. Rxf6 Kg8 18. Rxf8+ Kxf8",
    "aggressive_tokens": {
      "prompt_tokens": 239,
      "completion_tokens": 144,
      "total_tokens": 383,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "f6",
      "Rxf6",
      "Kg8",
      "Rxf8+",
      "Kxf8"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Rg6+",
    "positional_uci": "g7g6",
    "positional_response": "1. b3 e5 2. Bb2 Nc6 3. e3 d5 4. Bb5 Bd6 5. Nf3 Nf6 6. O-O O-O 7. Bxc6 bxc6 8. Nxe5 Bxe5 9. Bxe5 Ng4 10. Bb2 Nf6 11. f4 Ne4 12. d3 Nd6 13. Rf3 Bg4 14. Rg3 Bxd1 15. Rxg7+ Kh8 16. Rg6+ f6 17. Rxf6 Kg8 18. Rxf8+ Kxf8",
    "positional_tokens": {
      "prompt_tokens": 239,
      "completion_tokens": 144,
      "total_tokens": 383,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "f6",
      "Rxf6",
      "Kg8",
      "Rxf8+",
      "Kxf8"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Rg6+",
    "neutral_uci": "g7g6",
    "neutral_response": "1. b3 e5 2. Bb2 Nc6 3. e3 d5 4. Bb5 Bd6 5. Nf3 Nf6 6. O-O O-O 7. Bxc6 bxc6 8. Nxe5 Bxe5 9. Bxe5 Ng4 10. Bb2 Nf6 11. f4 Ne4 12. d3 Nd6 13. Rf3 Bg4 14. Rg3 Bxd1 15. Rxg7+ Kh8 16. Rg6+ f6 17. Rxf6 Kg8 18. Rxf8+ Kxf8",
    "neutral_tokens": {
      "prompt_tokens": 238,
      "completion_tokens": 144,
      "total_tokens": 382,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "f6",
      "Rxf6",
      "Kg8",
      "Rxf8+",
      "Kxf8"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "g7g6",
    "positional_uci": "g7g6",
    "neutral_uci": "g7g6",
    "consensus_move": "g7g6",
    "source_agents": [
      "aggressive",
      "positional",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "f6",
        "Rxf6",
        "Kg8",
        "Rxf8+",
        "Kxf8"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "f6",
        "Rxf6",
        "Kg8",
        "Rxf8+",
        "Kxf8"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "f6",
        "Rxf6",
        "Kg8",
        "Rxf8+",
        "Kxf8"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 239,
      "completion_tokens": 144,
      "total_tokens": 383,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "positional": {
      "prompt_tokens": 239,
      "completion_tokens": 144,
      "total_tokens": 383,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 238,
      "completion_tokens": 144,
      "total_tokens": 382,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 716,
    "total_completion_tokens": 432,
    "total_tokens": 1148
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 30,
      "turn_number": 16,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 239,
      "completion_tokens": 144,
      "total_tokens": 383,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 30,
      "turn_number": 16,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 239,
      "completion_tokens": 144,
      "total_tokens": 383,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 30,
      "turn_number": 16,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 238,
      "completion_tokens": 144,
      "total_tokens": 382,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}