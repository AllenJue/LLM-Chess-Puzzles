{
  "query1": {
    "aggressive_move": "Qb7",
    "aggressive_uci": "b2b7",
    "aggressive_response": "1. e4 c6 2. d4 d5 3. exd5 cxd5 4. Nf3 Nc6 5. Bb5 Bg4 6. O-O e6 7. h3 Bxf3 8. Qxf3 a6 9. Bxc6+ bxc6 10. Nd2 Qb6 11. c3 Nf6 12. Re1 c5 13. Nb3 cxd4 14. Nxd4 Bc5 15. Bg5 Bxd4 16. cxd4 Qxd4 17. Rad1 Qxb2 18. Bxf6 Qxf6 19. Qxd5 O-O 20. Qb7 g6 21. Rd7 Rfb8 22. Qc7 Rb2 23. Qg3 Rxa2 24. Red1 Rb2 25. h4 h5 26. Qa3 Rbb8 27. Qa5 Kg7 28. Rc7 Rd8 29. Rdc1 Qxh4 30. Qa2 Rd5 31. Qb2+ Qf6 32. Qb7 Rf8 33. Qxa6 Rd2 34. Qa7 Qb2 35. Rf1 Qf6 36. Qe3 Rd5 37. Rc4 Rfd8 38. Rf4 Rf5 39. Rxf5 Qxf5 40. Qc3+ Qf6 41. Qc7 Rd5 42. Qc2 Qd4 43. Qe2 Re5 44. Qf3 Rf5 45. Qe2 Re5 46. Qf3 Rf5 47. Qe2 Re5 48. Qf3 Rf5 49. Qe2 Re5 50. Qf3 Rf5 51. Qe2 Re5 52. Qf3 Rf5 53. Qe2 Re5 54. Qf3 Rf5 55. Qe2 Re5 56. Qf3 Rf5 57. Qe2 Re5 58. Qf3 Rf5 59. Qe2 Re5 60. Qf3 Rf5 61. Qe2 Re5 62. Qf3 Rf5 63. Qe2 Re5 64. Qf3 Rf5 65. Qe2 Re5 66. Qf3 Rf5 67. Qe2 Re5 68. Qf3 Rf5 69. Qe2 Re5 70. Qf3 Rf5 71. Qe2 Re5 72. Qf3 Rf5 73. Qe2 Re5 74. Qf3 Rf5 75. Qe2 Re5 76. Qf3 Rf5 77. Qe2 Re",
    "aggressive_tokens": {
      "prompt_tokens": 371,
      "completion_tokens": 640,
      "total_tokens": 1011,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "plan_full": [
      "Rf8",
      "Qxa6",
      "Rd2",
      "Qa7",
      "Qb2",
      "Rf1",
      "Qf6",
      "Qe3",
      "Rd5",
      "Rc4",
      "Rfd8",
      "Rf4",
      "Rf5",
      "Rxf5",
      "Qxf5",
      "Qc3+",
      "Qf6",
      "Qc7",
      "Rd5",
      "Qc2",
      "Qd4",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2",
      "Re5",
      "Qf3",
      "Rf5",
      "Qe2"
    ],
    "plan_execute": []
  },
  "query2": {
    "positional_move": "Qa3",
    "positional_uci": "b2a3",
    "positional_response": "1. e4 c6 2. d4 d5 3. exd5 cxd5 4. Nf3 Nc6 5. Bb5 Bg4 6. O-O e6 7. h3 Bxf3 8. Qxf3 a6 9. Bxc6+ bxc6 10. Nd2 Qb6 11. c3 Nf6 12. Re1 c5 13. Nb3 cxd4 14. Nxd4 Bc5 15. Bg5 Bxd4 16. cxd4 Qxd4 17. Rad1 Qxb2 18. Bxf6 Qxf6 19. Qxd5 O-O 20. Qb7 g6 21. Rd7 Rfb8 22. Qc7 Rb2 23. Qg3 Rxa2 24. Red1 Rb2 25. h4 h5 26. Qa3 Rbb8 27. Qa5 Kg7 28. Rc7 Rd8 29. Rdc1 Qxh4 30. Qa2 Rd5 31. Qb2+ Qf6 32. Qa3 Rad8 33. Qxa6 Rd1+ 34. Rxd1 Rxd1+ 35. Kh2 Qh4#",
    "positional_tokens": {
      "prompt_tokens": 371,
      "completion_tokens": 284,
      "total_tokens": 655,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rad8",
      "Qxa6",
      "Rd1+",
      "Rxd1",
      "Rxd1+",
      "Kh2",
      "Qh4#"
    ],
    "plan_execute": []
  },
  "query3": {
    "neutral_move": "Qb7",
    "neutral_uci": "b2b7",
    "neutral_response": "1. e4 c6 2. d4 d5 3. exd5 cxd5 4. Nf3 Nc6 5. Bb5 Bg4 6. O-O e6 7. h3 Bxf3 8. Qxf3 a6 9. Bxc6+ bxc6 10. Nd2 Qb6 11. c3 Nf6 12. Re1 c5 13. Nb3 cxd4 14. Nxd4 Bc5 15. Bg5 Bxd4 16. cxd4 Qxd4 17. Rad1 Qxb2 18. Bxf6 Qxf6 19. Qxd5 O-O 20. Qb7 g6 21. Rd7 Rfb8 22. Qc7 Rb2 23. Qg3 Rxa2 24. Red1 Rb2 25. h4 h5 26. Qa3 Rbb8 27. Qa5 Kg7 28. Rc7 Rd8 29. Rdc1 Qxh4 30. Qa2 Rd5 31. Qb2+ Qf6 32. Qb7 Rf8 33. Qxa6 Rd2 34. Qa7 Rfd8 35. Rf1 Rd1 36. Rc1 Rxf1+ 37. Rxf1 Rd2 38. Qe3 Qd4 39. Qxd4+ Rxd4 40. g3 g5 41. Kg2 g4 42. Rh1 Kg6 43. Rh4 f5",
    "neutral_tokens": {
      "prompt_tokens": 370,
      "completion_tokens": 346,
      "total_tokens": 716,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "plan_full": [
      "Rf8",
      "Qxa6",
      "Rd2",
      "Qa7",
      "Rfd8",
      "Rf1",
      "Rd1",
      "Rc1",
      "Rxf1+",
      "Rxf1",
      "Rd2",
      "Qe3",
      "Qd4",
      "Qxd4+",
      "Rxd4",
      "g3",
      "g5",
      "Kg2",
      "g4",
      "Rh1",
      "Kg6",
      "Rh4",
      "f5"
    ],
    "plan_execute": []
  },
  "final_moves": {
    "aggressive_uci": "b2b7",
    "positional_uci": "b2a3",
    "neutral_uci": "b2b7",
    "consensus_move": "b2b7",
    "source_agents": [
      "aggressive",
      "neutral"
    ],
    "selected_agent": "neutral"
  },
  "plans": {
    "aggressive": {
      "full": [
        "Rf8",
        "Qxa6",
        "Rd2",
        "Qa7",
        "Qb2",
        "Rf1",
        "Qf6",
        "Qe3",
        "Rd5",
        "Rc4",
        "Rfd8",
        "Rf4",
        "Rf5",
        "Rxf5",
        "Qxf5",
        "Qc3+",
        "Qf6",
        "Qc7",
        "Rd5",
        "Qc2",
        "Qd4",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2",
        "Re5",
        "Qf3",
        "Rf5",
        "Qe2"
      ],
      "execute": []
    },
    "positional": {
      "full": [
        "Rad8",
        "Qxa6",
        "Rd1+",
        "Rxd1",
        "Rxd1+",
        "Kh2",
        "Qh4#"
      ],
      "execute": []
    },
    "neutral": {
      "full": [
        "Rf8",
        "Qxa6",
        "Rd2",
        "Qa7",
        "Rfd8",
        "Rf1",
        "Rd1",
        "Rc1",
        "Rxf1+",
        "Rxf1",
        "Rd2",
        "Qe3",
        "Qd4",
        "Qxd4+",
        "Rxd4",
        "g3",
        "g5",
        "Kg2",
        "g4",
        "Rh1",
        "Kg6",
        "Rh4",
        "f5"
      ],
      "execute": []
    }
  },
  "final_plan": {
    "moves_for_execution": [],
    "full_moves": [],
    "source_agent": null
  },
  "total_tokens": {
    "aggressive": {
      "prompt_tokens": 371,
      "completion_tokens": 640,
      "total_tokens": 1011,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    "positional": {
      "prompt_tokens": 371,
      "completion_tokens": 284,
      "total_tokens": 655,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "neutral": {
      "prompt_tokens": 370,
      "completion_tokens": 346,
      "total_tokens": 716,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    "total_prompt_tokens": 1112,
    "total_completion_tokens": 1270,
    "total_tokens": 2382
  },
  "token_events": [
    {
      "paradigm": "self_consistency",
      "agent": "aggressive",
      "ply_index": 62,
      "turn_number": 32,
      "round": 1,
      "response_source": "aggressive_gm",
      "prompt_tokens": 371,
      "completion_tokens": 640,
      "total_tokens": 1011,
      "model": "gpt-4.1-mini",
      "finish_reason": "length"
    },
    {
      "paradigm": "self_consistency",
      "agent": "positional",
      "ply_index": 62,
      "turn_number": 32,
      "round": 1,
      "response_source": "positional_gm",
      "prompt_tokens": 371,
      "completion_tokens": 284,
      "total_tokens": 655,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    },
    {
      "paradigm": "self_consistency",
      "agent": "neutral",
      "ply_index": 62,
      "turn_number": 32,
      "round": 1,
      "response_source": "neutral_gm",
      "prompt_tokens": 370,
      "completion_tokens": 346,
      "total_tokens": 716,
      "model": "gpt-4.1-mini",
      "finish_reason": "stop"
    }
  ]
}